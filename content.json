{"posts":[{"title":"规矩","text":"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 非礼勿视","link":"/2024/12/31/%E8%A7%84%E7%9F%A9/"},{"title":"反思","text":"b3ce3877181dba7d2dc822c297e3a5e461a588a800d045df3c29113d12bf7cbbb7d0f7661783787c364a123d51c9fbf700082b8c18d8f9e529d57580720f57be8970ca695dc7fbf44a86a874ba1e45b1ee1c2e39ee3b3f5eef2eb21a2a574136ace8821ae5f04c462bc469942411a6763087c3520426f068d9b4d1e7a67aa8fd50cb8809d71a2895d47ddc2cef1ebc35a989bf96ceb363de24fe779f1e2e355d99d847884ed2f20d283657dc072bf44b0b5b3740a2d8277f69a855487eab439895752bdd95d5eb6a2ef7cdbce14358f2f2ade8410983d5ad6c19c9c6b5e69a2d324959dd7bc91b1f8f8426318419b63b322ae04ea43565af44181cce4cb1d52d13470a5459d5849c42d41ee3558d6f51ab9a97551c2e0cfc2b4d8b24cd95d2344c80f97ac1f39a35a0813b76712d2bf64c94b1c75c899544f2fa3209129d03b34a3afb04ac00363675175e11f9e9193732b802ae0812b7a94939070e90c1b6c85067495137e3b421f1f726d36e2d62c9607c716818a9959bcee3d42f8e96b67432e6a017818a82012a77a959d3fd1f2fe835ed402231e6cf4c93ecc3fa8cf1e4c321f11ba6dbdd47e1165caed412fe13f2c7f1ed00579029402e488b58c3a5337ecceeda0ccd36bc642950e3ebea299dc9d3f25c6fe3a58650102e3c02d5a8162e7d328d38bd8e569f9a707c66f570dd9e8987f8a3fdf11a13c6dbe6057130be4d7bbbcc3c78a2a13ff0071817d561c9b8d99343c71777cf70e962606b443e67069920e8d0f126ea97261913f5525f076c1dda67d2ac9370a383a468fb6ab5982619a8e952376546bd3d0b2e8c41f8fc70eeaa2dbdb2c2f80c40cbd9d02f85f49492896074089b9078ebc2dc82fe802c25d4fc021cb2779f93b11e8714951c00dede05c39f4b01b8c8cf8d020d1cb4fb6c7d15906f7a4211933985f93ca58d460c5e24513f31477d15f53c1db0854b898ee75eb8399590a719cf1cfaa68245245915b710488d5c5964ba4f9165fd60ec9780eb254f8a68055210b015d4f48a66b9a15f7e51c66ed504222498d9dc107a108c2b50e0529dbaa3535da7b788725f4817b8091878982e7d3ac61ff712f0a9c1c22fcc2776c1f0e4e8eb97ccf56aef321ff80fed775e14142db4254c008b25088edb1d1338d45e248462dd983c1b3b8b356800b56c2b0f74b37aefee31816d463086e6f078b403af48c906576cbf52d5ba35652e25da43b6f75ad918ec04a3d5d048693ea6e04daac94f06cd769adcd03b12e08018526cded605c9d151443f8200ed686a3ddc168dae70ff2573ddc32beed35685ffc8c557d49aece9bccddc487443153abbdb6b917031a0d48afdb64b337e5fbf3b5df532a62802c3b7c400894679970b1eb1639a3b9d872e200e3a51a3e9a4431d760b7fac70c3a66fea721665239c95d17cbf4e3382bfea169157b12b9da292b2f483067f0eb57010d8133cc56ff8902d5e601d1849bb6edfb8b1913ce86b29d53e73e5480608129b2454cd29e6882dcc555a7a43814d3c5d574fba754e7525702039b9930e32426ba9dfd83b54bf708e9e95b42bae2c827e28fc4738b627d936739a4a1cf14cf13c423fa8ff6eb0899adc54c09fbd39c65f59a996c8da2276058267d3a52dd79cac62c24f221df1971b20855124dbb0c6e4a37d70c526daf45290a66067a55bc2359683011496c7bdb14e46844723f05fb27daf1668c1688219ce51c7516c18426dcebfe5cf5ae8e666c12300280ab16c41ab01856b33b428950b226d9ccfac7811624a0cc9440a967cb00b52cca5fe97c211aa88850e37a251e26579270cf8af2c531bccc9ecf9af7c6cbb9aff9a8dd579cfd85b219667bc11a12035a1958d24143c778941bdf8a9c64304d88ed1c3f095a9635fb83897f6485e96b71020aab7bc715ef20050aafb9ed0a7c4c7663e8c3b831c189d21de01ce0ac8f86333579165c4c8e33c8d49592acdc9ce1f719adc59b08c9042ec76c95f452ad54e05483e0867f28dc520fb8d34e5206b4928d4d63b38259da80514c1bb4a5483209be53481299f0ada53ccbee457e494959c106ded39cbe824b74935e603e34b0e18db65c0b65c7a0a969edd04d68163b391e0ad9a41408a48c509ec3a5516995021695391260e07e6eae3989a3103836756afb8d9e341e897b0bb7691902cb45221d8b64ba7f2dcd40b8dcf0a83b6604c33f8f0d46ad9b16aa57f2e32ae39ea3b113602096ea3cc41bd319517e3a5cd612bbf169fcc531c114641a7b5ec0213ac20bf1725b7d9515816abb8e02f960e6a88624bb0571978401d87dcf0c628202627c09925dfa5d1128ba561d0c3c797110d55c9fecdd25fb95ba2e212f9a546b2212e00b4e094bed9b2bb8337039a60626bc29729b437842837ccbcb647df6aafd0f5c35d0efef54feba8c19fd26b53f4652f40229a22e536f72c43244a12de2a81fb71838145459f86b3778612250af7e445e7fc08e62f7ed92e45309cb71b81a8818ad2c6df24a2915dcf8ea5f3e525c13f271f102d56c1bc1f1e9c8e9d2ceb873de2d1c225b15abfafa1e94e37ef34f0ddb15726e15e03c179f58991846f8e6d2de3e80699e3bd8a91ed0318441050b534761dd64f2117afffead4c9806d9c70d80816f5194ad55189bd06c99a4c6954c3358f7b76c374a09a32be4e42626440d554180934f2c2ce974cba75b5c18cf4db12a4d2fd20c1df36ff2d53de532d4856725f97a0a5ebe669d3e1ab98d3703ba5ec1ade0779e062aa757c33fa5439ae7b58adc87bb99469e5b84f9b6554f0a0309c33bd366205da99fd52ca9e6668b6a8f1fd705865b97a01332cfcca0a42043118595d36f3e490f9671da33fedc69904cf27ff62ecce90546b156748e8865e95273f91f26880e7039d80e19f3777d7a7a5ead656b79c74217b9eeb2cbc610ad8b3dceadf807d1af099c5c02526b7ead2931b6541f695cf3659bebfe3451a28e87cf34df90849acc58e3f0e3adda83cd6ecb0e4f253dd7ca98b1611c2041c874f881f3060ab941031d34b5bdf069b9be7810a8b27fb810891efecbf9b4d2acf9bf6eb6de6b50a1677b4a4b958bb2dda6240234fa62e27d66bdfa5321aed965dea65320f0955e86c322b54420db2855aea1d1afe2434cd260268c38be16579407f243df40deff6a32d7f6943c71e734173faec54d1300a4f708a49402c30c1c8e10fc5837520dce65a228cc3342cd83d404132e33d5bae48dab6be270c0b2beeafd778cab3b2e8e64560686657502b5445def32b24303c4acc944a25ccd5ba94a3e7f5ae05eb20611495f87fd513175eb277dcc362644e8c9ed78b5e227548f83de6bfa60c0f3eb068c25b70baaac9bb88eb48608f18cc70a9e99a80f5f9636f102ad2e795837b804f3cb11630bbd2d817a0e788dc9980424ec1065e2458da6525b675cdeb1da9fce637509cb492deb5525a99d17a6898d86a5439aed71a9984b99245cf4c2eb60a03b42fcdf1d35724e31ec70fe338583fe5438579882db8b9c40e40d7f476574598abc8b9e4e25179ed9c4e89a2ef9cb99d879516179f4a0d706a6c940394fa6dacbe61dfb0739178a44d5df496e43e630f61418aae84e389c6cecebf2da85e238335727091037a13e58b58fff0a6bb25c8850d1bf2a6847bfcb234889280e88b1e0b77b5cce55760a2fecdaabaed5feca43756766d3b7b9d90a0c440159bf3e84ad0b7934c62df2317a597ad05e635c72414ffc38ee3640243915d2e4f7aa999e335ef502b790bbf10c069089ca5eaa3995ed36cce76314a91e7e47dd2895b6f1e99913a77cd97609eca0cb1f2d0b2d8f97e7a64682d7721736bbdae828d80be604a3c0e47e2e7e1dc8444c37bdcd7106ff20781b6f9ae4e734958cd3fb6c65bd8625aac2d4c9768030d96838ad58a4f740f13016f51a5700c3b4e7610d5d2bc214f80619ecc3418d9a1aca34f2d28b1ea839d4832b71144383b94c4683d9b7c2ae889bd67241c9dcf85c147cb0c60129eaf0200a0c55ec5c55bf59d607f14d6587501be865019260c0c284b2e7b8c66a574af1e907bab73ba41e82e346e0ac8e4284b6df2407e7bf3f21240d2e27c5462948526ce0bbc43afc929383b3074efd663939d86a32cbfb8270762b84c855368076af456431cd0eed6961adcccf8ffff686fcb982ce2d199e3e959f7bef0228bdb44373972ddc8cbca7629bd074c7120bf8b1bf7bcb9b75ab042996f39dda3255eeb076852dfb75a499f905e2cb586dbf6833107c33f54092c855be6d07735a9a84d42040640fbd310e9459ee179931865450627366430ae1f2e77d948292bc2092b2d43c5663f88d110f2be11ba5a673e1415133347adbc43b781d91aa97d83df10de5d1de71be53c3573bb0206466533d47e7930453b263bb492862386b2751170ef35b4f7807833b6f27709ea8278a95076f5f16d577949aaad45246d446ea5e7d9d87288903bd7e042385f8e6d5b0972f8b5fa90f69b285a5f501cfcfbe78bfa6181ba960c59c41885479c61b57523ea45174f73624930f08bdfa2739078e42a210e0a0143f6d5d7033182ba87a4431536ed021807b3e070b9a9621b7e8b7f0c049b4d5d05b63ad17246e8a9a9b1afa45c4ba4c073e6b90bf0c2fde77d9eb0f531ab9434d76e1afd2d09f7d221f7104f4fe77632084094ec391189c9c5ecfe02fca3a6a0c309bd2974d542844fec97aef8ca71a9208527cd73e227f51f394b74f65c7ed592e80121cf3e75baee3baaefb294ab83fcd1acf2c9c25ede21e6668a8069da3da94f347530739d012dc89727032a2f4001f5675827f386291b06afd2bfe78eaa8b9f11096675f231b4108c59d77aaeba11274b7589870c35e530acb818cff3c2331341abeb2158877e9d366ec0e0d01981a41a4b1279fc0eec8b5497dcbd05dac387404c55cec71596a1a6246c9e4cffee7b3a26a3e8123e928a222f500f7ddf8d8adebf281d82f0b074eb15bf7ffe00c19053bca7f79c2645f8485f34a4e94fad59ab8a884347af14bbbed710f346c43cb92c23f20ed589b918fe9bd31b4172a5026a5c0ea7a5e225ca8c5dbd2ea7aedd4b23d1a910de9f24c9315b22042a17d524983ed99b092624db9e011abcedb6c9402844e0d0e5eb87e0182f9bc6211ce11ccad9693d8e36ab5713678d5efd3a384686e896014f368ecc5ced04770cc486ea36517ca2c4c48f1fffb3dbe9ad52e23e61f153cca4908bd3c230cd39f80569b0467ee0dc4b7a1b3ad74801e95985cf3e9c3771ebf52e81346276910524637da6b9001eb8188096f6f9c978156cbd099d3a88fa6c943ac3a6de4d0fbf0b6f91b65f796d87fdfc4903c8cdc9c0df6cc730199cec61bb9f90034e5d0b885cbd3e47763c89ef0dc4c9137fcff3c0e37e6d17c9231873351a79fe54e3f06f03c7ba38d66989c28433fb968959d6601744a7f29b8a83e2946493ac4c4e9a02742cb49a3c6ad08e8c37ca207f137bceebaf3fa978a7af7986fe79aad0f0d9e00d0a7c66360e058a8501558d1fda45092898961c4600fd09540011f81dbb72a59267225185528220f5b71c70a8d71c8194a75e998535712eca13b566110d4f289849d117f01ad16e6f160aa40833762e558d50263819200d3b7e42fedbd435ce5a4756b6bc6f2c5ee52332bcc804c066dcf6cfb655b156aaca4e7c0308ba3e57dc02b76b5ad8e9b51ecaa5fcf1d8b8c6dc7be5afdd75f85d5978d0e95de4708ce194586f9740749301bcd6e915eb0b173785fe6c7f8a705d2bdb50e9b55fd1e6380e98ed760ca6681d7ba25a84366f5c72b84fb6e383395d4100931eaca5416ba1abe167d728cd32826ab27c8040c32a361b4e1dd0079f5bf090a9673b1b5140dc83a43820f60de09a060119ad730bd500a3a2784ae9954add04ebebb16763909750c796d3a17f18dae17b7089470d18abed5172905c6dab1fe8605fdcd3456bd016941e1f7fcfb0787a6a5a3f2cb1fba710700d3832f3a060cef07ab748487ff2684344e1f75d7b38499066977c317b4b818f167d3d070332ca37bf844b9911c186bcf17e939df9e73438a4a2795cb997c6fc19b7ad63bb6083a3723262129527c79f9b481afb15196b4d237bc817f268b3653a99a537bd92fd3616df9731f751d412f640bb5af642fec4cbe25ca33bd64aa91a29188310df9791909d8a86eaec528c915f35c65ac300970dc3fa27c5d718e919796b770d6e060e75b4b8dbc51a3661042de2c9a6566bd3a1c015a70b1c18054ec778e22e9c1a293e9e5fe63df9b40b327d0f5fd5946fd77f80b817cecb95b0c7ff3b8c28b0c631e8fd6cdb1ae4bfa7b2b541d5a27b16f8c968e963c74953496039324e89954a55888fc685c346a72599a1061dcc81bc94a843712be130144cd84958290397df46a5034cefd4187c3e8578c7419bec9f254352086ab16e701a946c60ddb2e625a58f3d11ad45aa234c51be41c2579b77e60f78af494b60c273673242f38ceb3c37b37c499173d11a7205d08995d9176885a076c3722e1f6773dcdd4b48feca5283ce3fbf28858788fcee893f1b330bdcfb7b6c39dbe0a2ee48ad2f4f16da913947877792703298e23574d29392504ee9dc9242987cffdcb12bdc3da8c01d10baaf4442ecc6cb40babe2d6920da8c625d9286ab472664769f791e1b0fd98a351249c2871231b6c39f3e477c19eb3673426a3687b8b570a9d861641e49ac79eb3f5b87056050858d7dd40053ddda4dc4edbee79994ee7a94a51f92c888102cedc769d1a074fd39303ebdc530ae3410ee4699eb18406cfd317301d4388a2c25f973261aca5bc62e55ebe612be9e8738ea36ec059bc6a5719ebbbba3f05a3b3a405ac5a544248e17ea38a3ba509772a6d4c1417cee9988febe95def452ccad975233caa10bc00c04f22eaac70c63445474ffcf0bdaa549070c443c4b898d4cbd86d9cecf0d5bb8c0762dd66efb1dd0ffb381b3abb3659c93aa6ed2c990085badfec3bec5623e78ea58e230c978d9f8408f3ac47160da686c346e594f0b28441f964d4377437222690e6de4d559a0f6da0936cbf762eb4bf1b7be42a4068d8a24200ee600299e66aa1da1705ebfe0fad55dc5b9cdd496a95a3d9b933525cd693b501d03693b631c0b8a864720f6ed5a08c29782ac2816a0c8aed7665bc82d43de3b31792be67e4f72beca19591c2f2b525449ec01e21aadfd91769988a3606298a13a48b6b5adff2d12fc45b806bafc8a30960643297a9d4fb05eb4824532bb4de684bbd04def60edd3c4ef3aef282c2ef3d824d8367c16b31d4f2ca88934f57ede18e2a8fd44e4c6dd3b7fbce627fbea8c00aeffed4b15a542294f6d572bf0391de05d982f8d77616d20143d655639c56967c7f3c74e0e5dcc5e6c224e63673ad8d001a766c94bfa4ae572d63831e5388c4f7a5f4def0d3496747c2591843b4d58c6e44d8a29a5554395d331613bb10787068ba646977584b7c9f5ef5e787d74e526ec00a92cf08e859d9dad87fcbb652bacf155a3de6b4c7de77bb650a32bcbf81a0850a9ff3690ef439084bc55192938cfa2e2290fde95420c2871e3e6f99ed11dfc2eb1cc2130919aa065e44a2fc5305529915d018d96166481d08aa7753e1d7e9d155562bb0b9ec96bdcac6a9ea3b97a38355b7f9ea2984432a7704b605f564049fd4675e46fed27bb35381f441021173055e230cf8b5e55697f509107d93282f2e0632565f9b95f5f9c54f707baabdfbd82a6959cc3cdffac29a2d2c4dfef716a4aeac801c66d91fd41de3df30d3127d91630f03e9353ff9fe08bd46029da1b5f4ef155dbdb7f4128a066d8b694bb1893e0b277ea3226b4a81ad31a16cc8d376207318027b73637272909fe350d60c0962962548d88f29d9ea3c943c44a4a112388b25019565f1e8bf49cb8391ec636734de702e0ce570c73d9f7e1a7a0ee8b293e77aa9dc9a72c9cdcd4e6911e41f3c20c8ed0b715eb5ae80dbecd812c66d617164bfe59bc89d14a56367337b9c6575bc7a8032c278cddb06672420f085d3941f6108e80eca48f88259e7922e4845c3f58f1bd81f141bf99a3f956afc63f8c1b4db673cbe19ed92aee49964489aedafdca0a0966b128005fdf40e6f250595202a8886fd54bcf04aa0398fe4000929e142559738a1072ed8b60cd1f58aec028642bdf850d0bd60bdcf0348bc5f13746d3a863930c286aa68f3aff8eff04676eedc39af4db78e7f9b2413305cc8c655aaf11c5b3a8ecf822d5fd67ad12092e0c8eead02243e6a3a81a533d22c48c1e1d288a0a1ed36bbf59ce8c69c9bfa3ec7870d88f1af4b48235ed234d3749e4c18545806a206ddef4ab0813b7c945e82f4b286fd593d3071cd8fa03c05a0d05fb072cbeb02a77185c850e1b67d824aa6bdc7ba688a1a5c8687477658a26fdc8e3b8393751eb5d0e060413dfa39c9fb535d846b6e09198a73ba164ccf14f19056787833d2449b6a4c566f79aff52f2b8fe6ae69d9b782ccdd148ed1a4a20ca9915bb5b32f40f3f9cdf13ebad7b3f1c5686584b42148eb4bf0aa88630a3ef45d7d69534724b1cf1a9679ebfde4bd8cfd792ef1cc8f1c95a044d28f9deee6481677e632587bdb65f21f4d12e3049fe4ca40a80fb188131e383ae73bd2bb741dd67e5be5a00f011a6c5125a3072e422301c9e5a6c8604ff47fbbcab051864b9ed6afb8491a7a25b3d9aa5c4bc258389a85f90eef6b95b1be46bae8ae9be964e96afac015b31cdd17aa6087a731f5946f16503a96fee8602548a694878b1321d6f824557c986272f9870c2b24926ed0493839e0ec2933d4bfe59d0cbc7afdc9d2209859f0893d1e02e57fb963895d89ac28669a7a0f7c1f06e067985f38e0a0ca99f0b9c22798616def578f45f0d65437f8f15dec1abd34902318fcce25b4ffc66e0fa7dd37c417a078bdf02681ec8a763de159216ba588778521900e528ee37cb088135d450e86d9c230eab265f1693965840673d9ce3940485c7c82ccd406c65851cdd887634732a7f1c3cab3f03c743fa7ef45fd010ce63dedc72d86be7a88627514b0ba53d9f0fb28d7f68956f4d88c063d802f061bac6041b6ef99d170f8706eb287283440f4999a39dca7cccbf4ac6de39544ef49f5ec945f7859d89aa7570311db900ad65bf7f63a2b160714a4d27ead8e80637db57ec13989f3f0ab8533ed403ac0bf9b862e8956dd3d91a9d722d2e764e332d106a9555a6ba9bb8cc11be33f7856867fe10ca25a808c6ac94cde95b87e4cf4a4043060595cf23431609a349c24f1d3827f1a1f662da8e79dbd37db612d0763a81dd8f7e8ce2c86771226e046be3f61302da1f3bbefa5b1f5cd230eacae871a48ad703af03dcd11e4626af2bb556b580052e88004a0e051a217c188cc68a1b4fcc9c734babf80e98d3eabe6e487c6e7f64e2d0e1709e8f93c635da012cce10d662c46988cdaf277c090efc857821b080e49d6168c45b7218e9717ed74245db4948e455d1076bcd5695b10659bf787c05fdb1658127bc14a54fb4e4c684f9d05158a7694fcd10d1c9e44febc6840bb2f29e40a3332cd41af4acdbf37242d5ecaa0d6e4c0f030b074ba5f5148ded9a2a879b121710106743da03fc0238b7fbc089372e16486678fe854ce0ffb0649161d525f78082c96206c9d4a7743c6f718735d407d67f6824440fa9e845c09cd3e06f6436c04e19cc8598cff09d4a8177956d83170092cea249c0db1d05d442a1f193c1d569dd7fbb5c673b34235721782d1c40d6d734b8a85c147e2848d05adef66ab0bd67a6de0a1c5a1014a6fa68ad8c200d12d7917b343e90691bd0c1799c8121f90588240f4df64a6fb5b9d2bd1bada9225ed05fe2c5c8bdd23bba956d7ad631cbacca41e02a36211245782e04b5bc5c40cbb0877f78a55702eff7e74a67cdaf48d456cfd85656156b8ad0a049454826ef317ce6af567eda40d5119a462110678963d7def977b9b2e72e9bdfaebe6306e72c1004a35e26cdfc2d7426a3288055b5b1afe06d21600893030ac45405bfbfa1bcbdfe2320ce8fab49d46f5fdbb51f021a18535e4c96e69f87f82cb4a008d55da2c376edf9ff8c72109c67f094eeb14ee0558126cf8513dfe9c2d460ae6580c935c497801a94bb0be156e4fe618289ede0aed1e700916659663c1d59c865b7f949fa82414e9cca1ba6625cfb8511848ad740fa2a176c355370addd8d6db4d126c007a8482902ec9b462cb58b6b5462d241f6f28aad9b54f06f85ce7084a2ec6e52a5918a4b6c03b3848aea00354df103cab9acdef441da5a69e723a276f3dfd8402e975cde5c994a9492df953eb0057771d827abe6cb0b9a2f63a424ad908bcbe69a15410bde7d8533a3fec92ad4d01d12207762dfbea08f94b5481d75158a7a1446a2a0ed6e0770e1af897e8df8b6677ea118f3a27c36aeeed3ede27bc7c00f40e9e23fbe934f3cf56cf810b9d4cbf84b30591164d91a50c39dc1a54c72c218666763eb87d4aa5f69001079b8bf19ef46132471ab598a82c166489e476cacc8bf4874551596b5312f5cf1495db2702a0d30fb53063fa6ad380f2578d760dade07b9981f8e01b02bfeef5086c01d1ee75e36296058d91a13255a6bf45eac160f73816c5119e7168d15e332f85cca970df318cd4ae39d994cd7f479c54e7bd51686f1ba52f88566269ec267c682f16cacab21418d3b85068ebd94f9a718f9f92cf2262b149e1bc555a27c499ec8829c89f64058daf0eac9c8312ccc68af8729e29201aabc6f87233c3d1bc6b3e1a5019ffff23d0d741bf1e05b3661350ba6410bbaef215b86ef1cfd40c3d435a26fc4283d25747393949f7e1754fe7a3884fa764d33828b90059a029c38a5b059518c5a248e8c9c96641ffd42711783e3695e03bc6c2bf4dbe39faf788f9b54aba67ea490054eedbf2e76d15e33e4fd6a4cfb3bd52ea40e72153c71871759c8dac3a2f47ad4b4e6a84dcbf01704c8a8df0bba1c6aa3b5ff868dde772de493a346c9a77bb84f67f6eb35b23ed1a2ffbec7dfbf892af49e17d0f2a6b3fbe7b4f1385f41aafe183d5cde102d8d1e521c4e991d5b076052729009696bc1db76d735dc832325c2491dfad522f1841d7265ebca13fdeb5337c3b97431a5ae92a6abf6452ba4199f0263cb1220756e2557e19a42e459c55ed6ffb2b02b7ae036cb546875cc9530638433e5afb16fd66db5e514a8425d043bf5700a098947d317d98b62e531b6725770e36e632b13ae99a2ab9504dd9ab4759ee500591320183a7e040c7c4be0108c4bd080316f5dd83b0d5bfa09d158f2d91dabf0231f581bac6581cdad9fbfb7e6924693bf7fa70701d12657e952713e703a385c6724e098bee210e040b84b16ad7a9cfbb099e668da9041180e47e49504432bd8eab9db28b35765556622cb286809bc9d07f3e9e6ea4ef7f17241b565e916d4e900a923c590985c1f9ad17f5c9e6eaefb9570cacdc80492c3fc70246e0ff4c111492544f86cbff02e4309a38938c393ab99bdfa2c95484dccd9171d52fe5692a2833c14d3598720fc7c03faeea7e4c1629bed15868e9cd9f8abae8881636b551555a1db569ee8fdd1523c56a3b0b60e88677e04906548f2227b8ddaeb5279325b4455245bb0fac5b3a0c6da536746696e79d84f1ae2407d473a51403d6659639b2ccfad1c577ea7f2c8cf59a6f5b53b6394f4e5baa77d07ff7a35a8b09536ca207543466e8fb070cbe146a89e7e296ec411ddc41906195b56a3144a793ec1632986e07860d50997c435a8aac86baf843752280702870579a4c9b1e37b4181ee9fcfbdf0bc39b207de51d7ede86a8c8a8108ed5320d78f30028dc21ab34b5ca2f5ee712c2ce108a43165eb834998ccc4dcd2393cb656a6bc9f05ec521210dd9aa21c0fe490689db2f189aad8a511c2be358ff05cda4e847d6bd998e3c456d7d313acbf932383cc32f86ccf23efdcf3bd890abaa4b015e82ea6c3945a5197aedf613888794811a00f44d19f5feb6c9c82356366f8f1fae3ffe61421e6caf23aced2773fd8bce58529aa909b4e3e02580ef52794fbe70a99cf84261b015669e6996ce4d209904e531343636889a1c304b187cc21ecbc3edb8f8be19a6895f7101b6b36a92465fa6d23c91edccc74a55197ba3385513c8ee24c076826d04dc465ff92d2ec86e213aaa92f02be5bfbcfaa3d0583cbb649fd48b1b68ff9a8672b8e588a2064a45af213cd224ba2684414428c7f6acf44f80b9e9171f23cea97defec1065ca3c98cbe77d6a5c4c2f636ed7327dd0ecef09305a8cfbcdae5e78ff7e246cb0ae9a42aa43b342bcf8c3e52b2ffb6e1315915e5890057c838cc892622a5be258f560c9585c5cc8da2936adbc177514193ea08409d885ed5834619728440a321d53ff272eb0fed8142bbc8f6719782b599465a7e541ea64a26c2d6d8736a9a4d6a87af4119075ce5ebc3746f85fbedf0d11eb664f4a836f5722758c0c50a3e172c4fd2ca87ec2c5c8448ac6777481091f27d973a43d938db8bcc75b2de64908e426e9756663bf550b2a6fd9893d34318dcc77a04ff717667f353a14a741a481b450430635423cf52b7ea0b42cebd0c723863603a29e9e0be458c674c8668e0f6cd360d9393722861130cafb1ca952e0663d141b810f51422de0913a54f21cc13bc143f44dd579db885d7b0eb10ba38ca14c2590bd707d4b844a8361532c9a0d27c68e64d89b01dfce9727fa3eb5a74a833e39d4dffe6e643a0d27ce46f4d8e62b618d56631e66132017f8906cc773c00093cf901ec75bd56b358c16cdc524edd842783ac49eda38cb7a8877bdf062b64bfc83bf88d899fbbdc3bc582ce954aaf860d26d25779f84d2ac5644d382a2f5dc8f8951f313d0c464114cb9570f94d282df0f07cd1d245626f9a52c99b760780e62bb912d4ed4326bee8db4b006cff73ff8f6d571f3fed2e29cfa32b818879ee0d2e22cf76ba6663c8bc77108ec641cce0be4a19546fd311163608b29cc788989b16b88acf4c5cd9268953b41e1047723b80f2efc0bde2c31a4d04e322cc1f5a3e8a215456161cc457b13f88df82f3adfaf173585d5ec076bb5d6595d4b6a0ea6fc62532ee0238ddf23474309f810b9014e86601912bb01aa07c9f18ade1465eca6c0c426bfc45bff36b064a787c673404d4fc26aadc4c6ef71ef1164ed526c6d97705d1f617ac0f402c704c2878a7b45c752121bd78ffad09cb54ffcfaaa54766fd566652a7d66053f66f71bba0862a839f8632568d59b71fc8730248e3c990f7aef11cab0c764c863a0489f294c0cc74f5a78645437972224ac760414b556b04cebbf2d9ff1bf66a8f06981df81372544433ebc3023fa10a2553ad11e72e3f09bc43c8c620c953b4b41391c13eee02dc7254e2d27457cfd3e4f324e6b3be3984a6f2d8065d890198d38d81ed8d03619ce25f07ccf95ffa807a18970f1a4a64c3bc8fa81adaf38d7a5585cf17c30cb835dba0a7a1a5f625733bcae5797c0f83ec1d3651345ec4bd216a094d395d4b9dd9565d8d281b2f35511e967d59c5264686d569f7c21766fb21c25eabafeebf46179926ca879f3ec22f556757d633912621479edc4b63ddaf5e0c039e28521f5a39ad73555db650fef278e346815370af4fc59935fa8dcf16f028aedf43fa0768a6814ac1fff3d7f8328f4d4eb1efcae61e8fb335ccdf937e3f3462415f1e465bc71f75058ddc63b78d725b801f743b836ea36ef152097097663eb6ecf155d585b2eb868a3c4bd30ff3313df45a7c1e181bb662acfb86babde820955b7c347cb1a1bdafd8fdab68fae728c43ba1525689e89b82254c5db689c45b267308f3473b8788b441132b523eb286c28a29af3536656c1df3cb478349d7d70cd37c9eb714329c5cba55021395f10ed668dd9425d31beb4d95cb41cb2f5b602a8902616dc2058d134e553727d92ba34aec0994ff3fca4f551b60f29d6c005417b8fdf61ef22700b5aedd9d953ed7080ed72bc32aa817f3f3091992acf78c1a0b5e53f394898604b72ffcce8a4719c73c5e1ab4255d9944dc39a01fcda04c94308243528f79bd4c4661f2fe90a78a40ff4f099246fb339eefad31eea8badfe37ed51300921539abd940cae550d454fe24dbd5dfcc78cb5e51351a6c7a50f09dbc311194de24090466be7286160a4e09cff6415075cab643a5bef43c62550e625fcc4979a53f978a5f271e21c2ce0565064236dd83e48df36d8684b8f5d5a72ed4960172160ad71501e766753880e2838a76062233822dc8429dceb3ff18ec725ccb05c61d33acdeeaedffe266a7bda95ee9e4a8a4fbbbe83e84dbe06e320d69472a91edaaca95f66de105420ea7330eb83c901b02775c81d82051b81b5ebb0845cc11e57a6f219d1d9ac2c0ff143ea4d0cb3f6b1feb50b8415eaf03bb7f1b0f54602c1b72608921300abe5d3ab344fe05384dc4f4c3fff67c986de58ed99a25b048df51f3f020bfbc0bec8f5e2f849f4ca36ace5c69cdb804d5bfe848446e087c2e0c8035819844c762635f6146822229c128cbfdf8b6a4df22a70f3f02054de5544949b95a22ba25285bc3a0f964529b3ec2b05a65ffb8753858e4c2d84b5143d057b645ebbd27170ea4a739d9845ac7ff0087caec76753c8898c390c8d62388c7bbb68f01589664b3a7aa4bbb6f8ee986cee367c6b91d44224eaa08413ecf8857d0c163dfc5dfc123d8e2a4916b867d0ed75c6005544cd8b5fa04eeeeab083bccb1ae9f4f517ac45cca8e8907ea32a835ab3cfeecc9461e8bbbdabb3816dc71633c7a7a37577242d0eb97ab18f15a4e0940294c4f7f3735ca0e87e0ba9eb7d784a088bd2aaf5bb940a298e7dd519ef362e9914535ba5030c101d1a3916045ff16f5b6a6fe2120f6a43306f93f255f761580b5ba330f1e54fd844452395c44528573d68cdd785999d8cdd445d3691707579e9cec142090d74f9a8e1ac1421c439a46c9ca10c4676e45f27a496fc775ce05cded342ba6fceddded6926f83eb8ffa7d086a5c0c4431a9bf7d17c6fa045cd4b632f0f4555af4f9d5c4a190a405809a98fe1e3f628db0d3a7b8f70f92fbddf2f79d9f6478d45056ccf64b1d3343f9ccefe90eef242a5358e56b7dfe10e82c24bfaf913c1b2b49eb4aa8e493b1c5b89c35338d832821d58ae71bc9ca693ea1c825fed9b75a6ab6a2cf282183f11483b4979c90f26ac47254f31c4fed917ae577b00b3250550d8d63766d5f168234bd106d9b75c45423e0fcc69f3fab6b757e62f3e5305323b5d4da3cdc5994e4d69d0269d1a51902e4b5b941414d34869378e4ac39959f9a807a24c60b323c831741d2edbe71e0d146cff88ccf94fa8715fef696e4cf792c767abca18c11112f875c625a834e603a87dd9b86cff9a10d62955d1399fd067c883e20b46a55ceeed4d4b361882ac891b7e8cc8f59ae10539c77a6fc17a8bab19637b679bd84e3fe4c4f12a3bcf106586eb27082291c798b941c9ebe9a05a9eb7e30d8fc719210a07a795e9df46f56e6159d92e289e017c33ef36ece55249214ddb47a26efc855b6f8e21dc3944a7ea360b2729e9f3da4bc0ea9bbfc4f64a43a7d694e718968eb6c433d8963cb995a9c0843f5b1fcccea4a89171deece5dbe99eb0edf47568dfb3a6e6a2ff5d2435abdbc14e6edf1f0a17cef39b89a70b3db3fe71f1528de46aa6e661d1b8d38fdd099187329fb69df7ef9826241e2809977062291eb362e48c07d6f9af163930b1685ed9d8f7b1ec31d06781ae894b37900409341faef27b2bc8d3849981ccd7b6539d20e8e3a2a80fbff61103e3496e65cdfa4c448051702896bffc9d0b8289c7810435a16371602bb49052b0096744b86af73ecac49cdf7e3b2da482cf7272aa478d1a424f747d8c181bb90f6dc7f846ad8a331d1283cd170c3d315e1346addb9ea720957ac0aeb3356f79830b1e66ff1ca65e1e3975bd515278464b24281c628e33cf301015d4f4e2fd4f83ec2bfad73e16093d17293a5acc1b2a6c4f41e5ac7d5e8241077c2dd9fab27f0893e93cd720d266114db4a21d79d9a36673abb73478f51067c901486cbe86e66f291505510075af8ce22f017a1c2396034147a85a37d4308af08598ace6639ed234e7b3b716ab641e04bb13bea88453126e1e6ace014f17a441fcaf227982da9975aa3f1b429ea1f53caa462b812764b52ec2142c82a7c7702d516a07dd0ac976614da9274a6e180b84d2703ef94554b13eea1fc3784d8921a094b80d0b74707fcdfa3dfc73af6844604e919f1b08b3580247e440e1e85c82b246756a97e31219794d29111604b8fb8f46cc1bf1ebf482a14939f82d53a11bd5c74adc7fca7371bb32cda0aea5628979b614434f3da1d6654d9afa4fbdbc3c0c7b5e5a3b7e7d975aa781ff2faca3da7a75b330b67030add4bbf49928f0fa9075b0d0483445163e8d0875a4f2766140e37a670362da6f19725bc5bfd44134692bebc806a5d7ba694d64bb9de08a2932811ae9d20129811ee3b865cc29defc7eaf412ae43e577b796b2caf83a20ab09c4760cbde91b0376682a06878d1603a1a349d35fdb38757c13be96f0b9a569500dfdb22c85de0f3aef097a48db4348f449a8db7f9e3c4a01ed0a59b6458fc8b2e86a8d651cf956c95ac1672afed479fe383e465fac802f9f897fd52d9b867c5bba2f8a13e5d4ab4c48fc3ad1558145d5424bce427a6d14548126f0eb8914239fc4feafc6c8be265ab4b1176736680e45842be760142f0e38d6d59739d7d07369e92b10452da036a0bb9794da52c3aee95fe1c045d5d6d5156d8dfbd77f4f664efa2f71f9b6f6338453d0ab4d69985387f4a185a6bd0fc71fa67d4b7874bb8974a44866ce753277ad178fc4de5b287230ae53583272f4a27bb28e26c5efd7ffdb5d93b92ba2cb08763a3204af7559ae36c7c3482ba95f49246ea207757f584e9a1b4055bf0c2dc7797aa7f3df70e849faa2e042a399ad6085b2aa380c902b2d2320825233615396e30cd6a20e125c9703525537d50f0cb5e3ea82342c7f658d30af3fa1903f512e06af75bcc906e1150b7a013b935c8699921399c103adb173d8a7dfb87d42e90c31df96c9f2bd4abb7acd0eaca3e2673305780208b1162f1d5f47812bc014d5a93bbb9b1afb4226d106d7932a90f2665ac2b6cc60453a9e91f3636338124899a7f406d40affa7f916253806905b7c8cae2433531bb70fd6b522949a2b19cf0e8e6f514df4bb59b8e8ab9cd775749dce8053848e0f15cc9ae33501c4c61f48184dc76093d07c6988c21112f1dfa245a0770bc4b9ea006fc25891e247704e5192a40c2831ee13531dbeffc105e15d195bd40f6e30ab4fc06f5f05c05dffe3bd1fd3a9ccba47b115852d47ba28dbfcf2c6120bddaa489bc7356b6196833049a50037b2d8a5808f6776e086c13f47b419edd9b522f1ee96560a937977e7aafdb9e66e160c552e40a0fc14ff335b0deb13ebabd050c76bd98fc3e79c7422ef2ae1ec69c2d83faca29383c334da6858a9f80e5e8b5148beb81648e015d003ed9f15e79d3c9b7e5f153b49f85a35fb3ae67a9c3e6c7a18193cc778f22e3885d368156fb0fcd63fe9055127015bd48e23b3c2faa0ee479a92857aa5fcac63351dfe9d4ad9885ddf56a84c3d36545ab21dd8bf9e3e4ffebde34a58bcfdab032ba6940aebe9d8b9b047c9e566f86730d6536b2e6394f2d3f90d8d74649a7431c2044c8576148e724c0906f2e71a74090d8728efeb00124e23b16feac39a69c553bc43f98ffab8ebd711a9b4766cec53d58077b884cd9f17c4d96c775db39372e75aed6cc8ba8b4fef24e4886639c36f8474457af9f1233057d41632e86deea72cffe3fdf467f8c1da7bfbf2128dcc6cc8b2701c3b02df8cf8d6730cd0f0402f8fea4131b4af24960331fda11f04da2b73064e89ce7cdd7c3b0685a49b5ad33afd3f4f6f5e03874e2eccdaa0d319c85e2d5d736bd3825a1b88c31ea64f7732f0ff19823c3ed5736a182d9756d11870ac618ab3f6ecb58b24aec6f6fe0d13fc7505dd7ab613382be8525894edbb137472f3d60e1a589f129d7b6301864a563d2ba1977691241a9015c23da86b774505e6e1a633e76f0cf0136794507572063fbd3eec5b512f2b97714ad99b21c0d16f4bd22c3dd8abc664c260b14ac4ab3970e5918c5198fc3dfd9281ecd6065ecca1eda8078e940e3f805326263abb7bea907108e1bb0abc1e0bb17ec5e58588358b8b27590e31ee150f3be53068c295447cfb6397ae40f32d02ea4258e065215e1e501a409e732083ce834ac9cd9f8c47428b4d0eadf7407ed85bcc4a460887993f1187a9756d3795290c6f13036ece65199264cbd6f8648c653e4b5ad0f3f79669719805255c23a6e4e6533425dd2064f7b8382e1094d28c3c8083f869b3bada679b284270c1d6e33627652a105260a5d7991eac46d3a245ebb053c53c57109e7ace52581c26e4a1748d51b480ba6fa4a30e751a30fc4d0dbb4d6f56e89786e85f1e908909c7d3b71bd377cc5e489710f7df8d641b083bf4ea527f7320016839fd6d1ebe39c1b747f149375d285163eaabdd137c80771f4e6bcf23ba99d5fe9e2fcefaacf921b0d22c9840714abf9ed429fbe5e243c5873d3a17a7c37df2a5f5826183ad446e3a95d10bf948003ce6f0ef6303c977be1033184b36069493b485dc604642875fe642fd3f3a3f6c4f585c43e30718bc0efa35565adf34dbeb2cacf35cb520f11ce2d369d2cf310cb5845a58426b0ee98886c5626c62d3f3b548c88cb2d9b3630e63b2a4db5b461c7ab70be344b43165a6d75076fc06e4756a942d8c2146045659842e27184939ab8c106376f5d492517f38f4d040748aa0a8e28f783b82a2c9ae6b28b1b9101f8bd6d83ec051a06807b11cb1dd27a8b67753a24f68939d3f25658d72098124e09908931f551f03c7b8dc907ceffd0cec8ef798323f893f4db715fbb80e0793942caed6fe4de88c728f138a3f53b181da8be887cf13f988efccac8fc79eb679968604a6ce18254b5c27f9847af879c776d2f55bf2a53362048a04e435180cd50a2375b45fc9be2fdb18f8602514b1af0e4cbb9aae1fb83c1ad547d5bd1a8108f860da0583f565bf8ec148c5eb00235a2425fdbdc8dd956fe21f6bc57067347f56e68134dab4be8dc78dbaf6c776af7a574007bbfe89ccfecd4bcb04e699e5e4759a4470c21c61adb7417030a05bcfedb88c8b03b7b862e0c326031c4ad623074971b21a7eefdb73d1ef3d7ee389f3556302c182a5938ffe20c28bcacadc17df7d5c1061e0d060b254cf3f1e56334b7230bc58b737540c882c903aad80f5816d6ee340956edfe5c4a0a4b418c65d0c91b32dc861156deaad85bf72e46aa7f7c455db7ff64605b2196a9baaf809e675fc22ca6d3967538a53690edf4a375dc9fa7b6469d95a52b66c171a6c7fb8b1b17057cf146e89237293d39bf51061183078001c010b59f0e6e8ab5c99c8e77221362bc694e82d2f9fec7edbf927b94b3fa586ce1781302e7f4b2159e509ecbc75943ce94488babf3a672612a3a790e7be5ad5a4f51645826ad0d05c4272bf1a5d6c903317f0653667ca3641259ba7efdb095b38553da669eb9f73c28b66dc1ad00331827adc0726c92bb390285f3dcb5734845e03dc0e1144f2643c22172109b8969eadafe65957ccd8f5bde3af1f374c02004f4bbdc040f8e9dfe63c7cd8ec02494fe66aa37b054557175ad70542dee8d10c69e544ea4b7de22ce18edd32da000e47dc75572093f4551dd94722d3ac237bdaa81abaa9c97c66a70c2011f8bf3c3882e4b525e4166b16d131282fe66ec4d33b114e46340799a561919b01f70284488f4e8483908c96b85dd31fc8ca66bb3657229d1ac53cf41475060f464c3138157b1fda0741e753180de9d7dc12c90e862dd57b5660fdd212e0295863841d0e343a8cb720b351105befeb5b2d399ac6ae9e5c0cbf955a5ace7085ac8aa3071368f1c6701ec78b9d4fd8d2b0fd19799ce1858dcdec2adcb50ef84b3ce896fe765afb93d18e4b271c9daf321a4ad3b193a5d37db4f5ea2a20cb360247d8bf8a5581cecdbaf0c1701b8bfed1bdb09e2d1f3fb30247fbb0d5a693b8e04702c55c06caeb4aef19437b64c676e527ee8429aa6c56547741c02890d346b20a0489074746d7b8aebb4d935271f3a5e4d4f669d6c98c531ebd5a8ed3059838ebc2333027730c6685f426465fcbdc0057ccb7a18548a0c6f31c072ae3f25ead904e9ff661e3faa6d8057e6f58f93342318cff9954b0c446719a7cca782cf938fbcc54b84a35759e9eec68f15830c0986d1c42b4b7ab987921e4a062b6e74b6777db808d822ab2d43bc420edda1e0acc0a2ce231946dba0964bd730ba3c40b86dbcd85d28dd5d16d5809004edb36e6ab104edfc75a43c5880aece83926ac3d7efe0f44a7ade56af3ecabeb821901a1586becda092d729db7024db84200b66c176d840b072daf7765c969e5a6acb2f905798c58d79df6197fa0df4c182176090d5a57ebec4eb628fe69b464e085641448cc8ad8956f033decdd1417e4f9600f6dac22658005e268bc215a3151eec7c9d49c506b01d9f3b7343704cb61d958b23f77e3fe329b36522d459837457ec6fe113593be02c6d1bfab482ca65837f09bc0cab4b670f777c7e2ba40e944d8bd52abe08e430ef62707b55b49c795d94ef99d9eaf72613ef92616e9d5cb228ff77b74d990a4be63e9464b48d55a56880d89230570e9189917e3aaed6d078fb8bfbc3d8b464af27f60bdcd4a51b43fdcc19cc56a13aae98fdc832cb7ef97c0b5ad6a8395dd91d32ba29d4f923c5808ab914e2873f6189915c97a9b234a848546d547719151689cde68a75ee8885a34b26700516179159462bccd3d28bb655c3fc5a6b983f4f05ae3d78669e75ef5e467b87dedeae7ac41745575f48f47aff074cc3893687204a37cf6775fa4989a3cf4ce23fced07490bc47b0e640054e5192d1cadd3043bddc221c7ff9d80d77d7ef1c2e941c07fb25a9d598485f8696f7e30da5d02abcd9029a664f632f9e39cc0354a1b0e2fcc2dbc83c856981a49c7bc5ea5b27cc9ad4bf8a0b9781540d27dc8854036fcbb991bbcb027017bfa9eb02305f7d39304d1924199362ae17acd830e7fe8c61 非礼勿视","link":"/2024/12/31/%E5%8F%8D%E6%80%9D/"},{"title":"读后感","text":"​ 先说一下前提条件，在五年前的大一下学期，我第一次系统的学习了C语言，但那也仅仅只是一个初步的入门，并且在学校中的学习呀，大家懂的都懂，没有 1.斗破苍穹 为什么看完《斗破苍穹》会有一种失落感？ 因为那终究是人们的黄粱一梦，我们都是在生活中跌宕起伏的普通人，梦醒之前是，梦醒之后依然是，但即使这样，我们依然要满怀热情的过好这一生，这便是在读了斗破之后的意义。 萧炎的一生（现实生活版）: 生来就是世界顶级天才，智商280+。 父亲萧战，是县城里的巨富之一。 和伊万卡 · 特朗普 (古薰儿）是青梅竹马，后来伊万卡 · 特朗普成为他的老婆。 还有个老婆是市里某龙头企业女总裁，后来成为某独角兽企业炎盟的CEO(美杜莎），炎盟上市之后成为世界200强企业，后来逐步成为成为天府公司（世界前20强企业）高级总裁，银河系无尽火域公司CEO。 还有几个红颜知己: 一个是加玛市首富（云山）的干女儿，本市龙头企业CEO(云韵），后成为花宗公司（世界前50强企业）CEO。 一个年纪轻轻成为了隔壁出云市龙头企业的董事长，后来成为了天府公司（世界前20强企业）高级副总裁(小医仙）。 一个是马斯克的千金Exa Dark Siderl(紫妍)，后来成为了天府公司（世界前20强企业）股东。 一个是斯坦福学霸，拿奥运金牌的谷爱凌(青鳞)，后来成为了天府公司（世界前20强企业）高级副总裁。 简历： 4岁识万字，会小学以内的算术，会英语（斗之气）。 10岁上高中（斗者）。 11岁上高二，患脑瘫+精神病，智商止步于小学生水平，被家族歧视，被迫休学三年。 15-16岁，病被药尘院士治好，在药尘院士指导下，直接参加高考，一年内考上985（斗者）。 17-19岁，三年之内速通本硕博，发表数篇sci二区论文（斗师到斗灵）。本科发的论文能爆杀一堆博士。期间，萧炎自主创业，创办萧门公司，磐门公司等公司，后来发展为地方龙头企业。 20岁，做博后，受聘成为讲师，发表数篇顶刊，顶会（斗王，斗皇）。期间萧炎创办炎盟公司，后来发展为世界前200强企业。 23岁，去几个qs100的学校做访问学者，发表一篇science，几个qs100的学校震动，成为特聘副教授（斗宗）。 24岁，升为教授（斗尊）。 26岁，到藤校做访问学者，发表数篇nature子刊，技惊四座，回国后拿海归青千帽子（斗尊巅峰）。 27岁，研究某个方向，发表一篇nature正刊，轰动学术界，一个月内被评为院士（九转斗尊），又一个月内获得诺奖（斗圣）。之后不久，萧炎创办天府公司，该公司后来发展为世界前20强的巨型企业。 在之后的几年里，又斩获图灵奖，菲尔兹奖等奖项（斗圣）。 33岁，发表数篇重量级论文，轰动全世界，推动该领域革命性进步，成为某藤校校长，划时代科学家，被誉为“xx学之父”（斗帝）。 此外，萧炎从小到大每次数学，物理，编程比赛(炼丹比赛）都能拿第一，无论是县级，市级，省级还是世界级。 靠着极强的工程能力和创新能力，解决了无数的工程难题，获得了极高的威望，被各家大企业争着招为客座科学家，首席科学家。 麾下有天府公司(世界前20强企业），炎盟(世界前200强企业）等公司，还有萧门公司，磐门公司等地方龙头企业，总资产几十万亿，成为世界首富。 若干年后，成为银河系三大首席科学家及首富之一（步入主宰境，大千世界无尽火域之主，苍穹榜题名）。 之所以一些人会有失落感，是因为他们把自己代入了主角。 别人的人生，终究是别人的。 大部分人穷其一生，也只不过是斗者，斗师，大斗师水平，顶多是个斗灵。 而斗皇，无论是在科学界，企业界，还是玄幻界，都是普通人奋斗一生难以突破的天花板。 你的爱情不会像萧炎一样完美。 你是个普通人，没有萧炎的实力，没有萧炎的颜值，也没有萧炎的魄力和毅力，提供不了异性需要的情绪价值。 薰儿不会喜欢你。因为你成为不了斗气大陆的巅峰强者，即使你们是青梅竹马。 彩鳞也不会喜欢你，你炼不出六品丹，她会直接拍死你。 小医仙可能会喜欢你，但是你治不了她的病。 紫妍不会喜欢你，或许你做的饭能吸引到她，但是她随手一挥，就能招来一堆世界级大厨。 云韵不会喜欢你，她即便是跟萧炎的生活也没有太多交集，倒是云山可能会一掌拍死你。 雅菲当然不会喜欢你，因为她后来会成为全市首富，无数男子追求，开个男后宫，都绰绰有余。 纳兰嫣然更不会喜欢你，极度慕强的她，不会把弱者当人看。 青鳞可能会被你感动，但是她后来去了更高的平台，你没有实力也遇不到她。 韩雪不会找你帮忙，因为你打不了巅峰赛，打个王者荣耀都够呛。 叶欣蓝不会找你帮忙，因为你炼丹赢不了曹家。 曹颖不会喜欢你，你拿不了丹会第一。 唐火儿不会喜欢你，你练不成丹药。 还有个从来不舔萧炎的凤清儿，但她是每天开法拉利（七彩巨鹤）上班的女人。 这些人，你大概率一辈子都接触不到。 普通人若是有机缘，或许能够逢着卡冈大叔和苓儿，和苓儿相伴一生，仅此而已。 你的学业不会像萧炎那样开挂。 你上学的时候生病了，找若琳导师请个三天的假，可能都会被质疑半天。 你被白程欺负了，只能把屈辱咽在肚子里，想着哪一天忍不住了，就找白程一换一。 苏千和长老们，也不会像小说里那样和蔼。 他们会根据他们的kpi，给你教一堆没用的东西。 在你还是斗之气和斗者的时候，他们会给你教，古人写了些什么诗词歌赋，给你教怎么算术，说这是帮你凝聚灵智的必备法门。 他们会给你教中洲的方言。这个的作用因人而异。如果一直你待在西北大陆，那么这辈子都不会用到。如果你想润到中洲，那么可能会后悔当年没有学好。 他们会告诉你斗气大陆的风貌和各势力的渊源，有的人觉得这课程挺有意思的，不过大家都知道没什么用，上课就是在睡觉中度过。 他们会给你讲加刑天，法犸，纳兰桀，雷族族长有多么多么的伟大，考核是写一堆赞美加刑天，法犸的文章。 当然，他们偶尔也会讲讲斗气原理，炼药原理，药材种类，魔兽种类，人体体质。但是就是不会给你教斗技和炼药术。 在你是斗师和大斗师的时候，他们就会给你教一堆没用的，这辈子都不会用到的斗技。学不会这些斗技，没通过考核，就要受到惩罚，这辈子也别想进入内院。 而有用的斗技，则要么是自学成才，要么是家族传承。 一群长老和斗师们还会给你洗脑，比如： “你突破了斗者，你以后就轻松了。” “考上了斗师，大宗门抢着要。” “现在斗师没啥用，多如牛毛，想找到好工作，还是得突破大斗师。” “现在大斗师多如狗，能自创黄阶斗技的也一大堆，精通玄阶、甚至地阶斗技的也有一大堆，你这样出去毫无竞争力，要不，你在我院突破斗灵吧。” “区区斗灵，也配留在我校当老师？你自创过几个玄阶斗技？” …… 并且，外院还有一些奇怪的规定，比如，学生每天必须排成密集的方阵，在校场上跑两圈，仰天高呼一万次“桀桀桀”，比如学生每天需要穿统一的黑袍制服，在校内必须呈跑步状态前进，哪怕你会斗气化甲，斗气凝物，斗气化翼也得这么干。虽然你不知道这有什么用，但是你必须照做。 因为校长邙天尺很羡慕魂族的管理方法，他时不时地会来视察学生们的精气神，他认为这样就可以让迦南学院达到魂族的高度。 并且他可以把这种整齐划一的拍成视频，拿到雷族或者其他族去炫耀，这样雷族族长可能会给他更多的赏赐。 你靠着苦修而来的斗技和一手炼药术，好不容易从外院卷到了内院。 但是你又发现，林修崖，柳擎，林焱这些人，不但会斗技和炼丹，人家制作傀儡，制符，结阵，魂技，星象，占卜，历史，琴棋书画，样样精通。 人家这些中产家庭的孩子，每天除了修炼，还能到处游山玩水，吟诗作对，修炼也没落下，你在人家面前就是个笑话。 他们的女朋友还会变着法的换。你每天看着韩月和林修崖花前月下，你侬我侬。柳菲的男朋友换了一个又一个，就是不会瞅你一眼。 即便你不是最差的那个，你比内院70%的人要强，甚至比她们的对象还要强。但是人家觉得，你强不强，跟我有什么关系？跟大街上那些人有什么区别？人家可能宁愿找个长得帅的斗者，或者天生就是斗王的贵族。 你的事业不会像萧炎那样顺利。 你工作了，运气好又肯努力的话，给云岚宗投个简历，或许人家会招你当苦力。当然，如果云岚宗公司经营管理不善的话，你就会成为云岚宗被解散之后，失业的那个人。 运气和能力差点儿的话，就只能去血战佣兵团这些，或者天天给柳席，穆蛇，哈朗捏脚。 当然，能力极强，去牛逼的企业，这个人生，也未必会过的很舒坦。 比如，你能力很强，突破了斗皇，投奔了风雷阁公司。结果风雷阁老板闲着没事，非得抢星陨阁的业务，结果被人家一纸诉状告上法庭，公司直接破产，你失业了。 你精彩绝艳，身怀三种异火，名动中洲北域。有一堆七八品的炼药师，带着一群斗尊、斗宗来抢你的异火。 你能力极强，突破了斗宗，投奔了魂殿。魂殿每天让你收集灵魂体，每年收集的灵魂体达不到kpi，就会把你架在异火上面烤，让你生不如死。而你如果碰到棘手的问题，需要向上反映，上司们只会桀桀怪笑，一个比一个拖延，层层外包，层层甩锅。必要的时候会壮士断腕，引爆你的灵魂，然后对外宣称某某事情是这个外包干的。桀桀桀，还不是你不努力，没人会管你。 你跑到圣丹城炼药，结果光是一个月的房租，都得支付一枚六品高级丹药。而在圣丹城买房，则是好几枚八品高级丹药的价格。 你又辗转去投奔了天妖凰族，结果碰上一堆斗尊干扰，有个事情不幸干砸了，就要受到各种惩罚和绩效淘汰，甚至直接卡试用期，或者塞给你一堆事情变着法的恶心你，美其名曰培养你，不达标就直接把你优化掉，中年危机让你这辈子都找不到工作。 你历尽千辛万苦，突破斗尊，去了古族，想拿个编制，从此躺平，但受到各路强者排挤。他们在你面前摆老资格，给你穿小鞋。翎泉实力远不如你，但是人家有背景，就是可以骑在你脖子上拉s。 面试的时候，你在大寂灭指下瑟瑟发抖。试用期培训的时候，你在天墓里九死一生。做业务的时候，你在兽潮里杀的心力交瘁。所有的脏活累活都会派给你，假期是别人的，你的工作是你的，别人的工作？对不起，也是你的。 而古族的公子们，有的即使只有斗者，斗师实力，有的实力和智商连条鲶鱼都不如，但是每天可以游山玩水，有的在云雨宗里寻欢作乐，有的在花宗里寻觅伴侣，有的在极乐世界的赌场狂欢，还有的在丹域和药界体验生活，光是躺着就能被喂药喂到斗皇。 而有的公子们，则是极为恐怖的斗尊实力，身怀各种天阶斗技，丹符傀阵，星象占卜，琴棋书画也是样样精通，每天高喊着家族传承吾辈责。但他们不会出手，他们就等着你把菩提子带回来，炼成菩提丹，让他们吃掉就行。 你又历尽千难万险，突破半圣，结果斗圣们打了一架，你的五脏六腑，被他们打架的余波震成了粉末。 靠着强横的灵魂力量，你侥幸活了下来，但是实力又重新掉回了斗灵。你饱受病痛的折磨，没有宗门愿意招揽你，你也没法炼药，所以你只能吃老本。你的孩子嗷嗷待哺，你的老婆骂你不成器，跟你退婚。你的父亲被病痛天天折磨，你救不了他，救不了他。你的孩子又重复你的人生，被老师pua，被宗主pua，开始了新一轮的轮回。 掉回斗灵的你，选择走入塔戈尔沙漠隐居，你捡到了一片净莲妖火的残图，把它撕成了两半…… 斗破是一场梦，梦醒了，还得上学，还得加班，未来仍然没什么起色，悲惨的生活依旧。 当然，以上只是把加玛，出云等，对应到现实生活中一个市，斗气大陆对应到世界。 如果把加玛算成一个郭，斗气大陆算作整个太阳系或者银河系，人口直接拉到一万亿人，那差距又会增大。 大部分人会连斗者，斗师都很难达到，大斗师就是绝对的天花板。 18岁之前到斗者，是一件极为稀罕的事情。有的人终其一生修炼，也只能止步于斗者。 要知道木战年轻的时候，当个斗师，都能被称为精彩绝艳之辈。 年轻的时候突破大斗师，则具备成为云岚宗少宗主的资格。 斗皇，斗王，斗灵，大斗师，斗师，斗者，在军队中，可以分别对应帅，将，校，尉，士，兵六个级别。 现实生活中，很多人因为近视之类的身体缺陷参不了军，即使入伍也只能作为填线部队。普通专科生参军，最开始只能到兵级，大部分只能在军中待两三年，立功提干后可以到士，知识分子可以到尉，军校优秀博士或许能给到少校。再想往前，就看天意了。 如果对应到学业的话，可以对应古代的科举。斗灵，大斗师，斗师，斗者，分别对应进士，贡生，举人，秀才四个级别。 秀才的录取率大致相当于211本科录取率，秀才的实际地位，远高于211本。 举人的录取率大致相当于清北本科录取率，举人的实际地位，远高于清北。 而斗皇和斗王两级，已经是加玛帝国的高级官员，无法通过科举获得。 所以，大部分人在斗破里边，就是路边随时会被打成肉酱的小摊贩，佣兵团的小佣兵，炼药师的采药队员（我似乎想不到什么别的职业了）。 能给柳席捏脚，是普通人的福分，想给哈朗捏脚，人家可能都看不上。 你是个人才，踏实勤奋，到老了，突破了大斗师或者低级斗灵，也最多找找关系，给云岚宗，炼药师公会之类的当个保安。 但其实，我认为，斗破的魅力，并非是便于读者代入主角，享受那一路金手指开挂的爽感。 斗破的作者，虽然很年轻，但是社会阅历，应该也远远超过当时同年龄的人。 虽然小说有不少不合理的地方，但是小说中的一些配角和情节，我认为灵感可能是来源于现实中具体的人和故事。 看似很梦幻，实际上，也很现实。梦幻或是现实，只是取决于读者是自己代入主角，还是将自己代入小说中的一个小斗师。 我小时候不太喜欢修仙文，当时就觉得，大部分人放到这种修仙文的世界里，穷其一生努力，最多也就是大斗师或斗灵的水平，幻想一路开挂，只能是异想天开。 直到走上社会，被社会毒打到怀疑人生，怀疑奋斗的价值，怀疑过去走过的路是否值得。 我回过头来再看这本小说，才发现这本小说这就是人生啊。 人和人的差距，确实，就如同斗者和斗圣的差距一样大，无论是颜值，才能，财富，差距都是巨大的鸿沟。而人的努力，只不过是在弥补这种鸿沟。 有斗帝血脉的种族，给富二代小辈们几本天阶功法和斗技，小辈就可以坐火箭一样爬到斗宗，甚至斗尊。甚至一出生就是斗宗，可以飙升到八星斗圣，不用修炼，随便玩就行了。 而没天赋、没血脉、没颜值、没实力，不但异性不会多看一眼，就连强者们打架的余波，都能震死你。类比到现实生活中，就是郭嘉，企业等各种势力之间的斗争，导致的大裁员和大萧条。 虽然现实生活并不如斗破那么混乱，但为了生存，为了发展，大多数普通人都在忍受痛苦，实际上是众生皆苦。 大部分时候，忍受痛苦仅仅只是在忍受痛苦，什么也得不到。 斗破里边，努力的人其实并不少。 有的人修炼百年，而不放弃。 有的人以斗皇之躯，硬闯莽荒古域。 有的人经历换骨吸髓之痛。 有的人布局千年，机关算尽，只为了一朝突破斗帝。 有的人没有修炼焚诀，但为了变强，仍然硬吞异火。 然而很多人到老了，也只止步于大斗师，斗灵，斗王，斗皇，斗宗，斗尊。 有天赋的人也并不少，但要说斗破的运气王，只有萧炎这一个人。 我总是在想，为什么我的人生会那么痛苦。 我为什么要经历学生时代无休止的刷题，只为了争取那一个月薪一两万，甚至可能不到五千的工作机会。 为什么学校里别人都可以打游戏、谈恋爱，到处旅游。 而我则要经受各种考试，科研，找工作的折磨，来到工作岗位上还要996，甚至通宵加班，被上司批评，被公司优化，跟妻子离婚，跟父母生离死别，最后在病痛交加中离世。 最后孩子还要忍受这样的人生，父母仍然想要逼我结婚生孩子，仍然不希望我就这样放弃，我死掉他们仍然会伤心。 没意思，真的没意思。 有时真的会想象自己有金刚琉璃身，可以把地球一拳打爆。 但是如果积极一点来看的话，我感觉，或许我所受的一些苦难都是值得的。 小学初中时代，我被同学孤立，遭受过校园暴力，当时极为痛苦。但是回过头去看，如果没有这些经历，我可能仍然是一个狂妄自大的人，不会低头去审视自己身上的缺点和不讨喜的地方。 高中时期，我经历过衡水模式的折磨，虽然很痛苦，也没有考到什么好学校里去。但是现在想想，如果当时没有生活在这种高压的环境，或许我就会止步于二本，或者普通一本，更加为工作而发愁。 大学时期，我舍弃了几乎所有的玩耍时间去学习，我获得过一些奖学金，参加过一些竞赛，做过一些科研。虽然做的时候都很痛苦，获得的奖项都很水，远远比不上真正的强者。但是最后看来，这些东西也不是毫无用处，简历总不至于什么都写不上去。 研究生期间，我每天做在实验室里度年如日，科研上却毫无成果，技术上也是毫无突破。我深感痛苦，焦虑，时刻感觉要分裂成两个人。但是最后看来，即使毫无成果，这些平平无奇的经历，也可以吸引到一些面试官。 工作期间，我每天战战兢兢，如履薄冰。但最后看来，我也攒到了一些钱，可以买自己想要的东西，不用再依赖父母。我也见到了不少世面，我周围有一堆斗灵强者的师兄，小老板算是斗王强者，大老板算是斗宗强者，经常带我们去见斗尊强者，甚至偶尔还能见到斗圣强者。 我把自己经受的一切苦难，都想象成自己是在吞噬火焰，吸收风雷之力。 斗破围绕的两个最核心的思想是: 1.只要一念尚存，痛苦便不会将人击倒。 2.亲情，爱情，友情这些东西其实才是成长路上最宝贵的财富，也是激励人不断进步的动力源泉。 我们每攀上一个阶梯，总会见到无数比我们强的多的强者，都会感到一种来自灵魂的威压。当我们是斗师时，看到斗皇觉得他们好厉害，当我们是斗皇时，发现周围斗皇一大堆，而斗尊和斗圣，又好像是普通人不可能企及的存在。但是伴随着我们的努力，打造出属于我们的优势，那么我们即使达不到他们的水平，也不必去羡慕这些强者，专心走自己的路即可。 我总想逃避苦难，但有些事是躲不过去的。为了父母眼中的骄傲，为了我的孩子以后能少些痛苦，为了我能一步一步地提升实力，换个更幸福的环境，我愿意继续奔跑下去。 就像书里说的：人就是那么傻，明知道不可能，明知道自己渺小，但还是会豁出性命，去保护自己重要的东西。","link":"/2024/12/11/24%20%E8%AF%BB%E5%90%8E%E6%84%9F/"},{"title":"嵌入式C语言的自我修养","text":"​ 先说一下前提条件，在五年前的大一下学期，我第一次系统的学习了C语言，但那也仅仅只是一个初步的入门，并且在学校中的学习呀，大家懂的都懂，没有深究、没有思考、一切呀都是为了考试，然而如今的我不一样了，相对而言，我更喜欢研究研究研究这些，或者在小说的世界里躲避一下生活，这些都是类似的，只不过研究研究这些更让我有成就感，晚上就慢慢的来吧。 1.计算机理论基石​ 前面的关于二极管、三极管以及cmos管的原理这里就不深究了，等我以后再更深层次的学习的时候再说，现在就直接从CPU直接的工作原理开始。 ​ 计算机的核心：==任何复杂的运算都可以分解为有限个的基本指令运算==。这句话其实我好久好久之前就听说过了，但其实呀一直不解其意这个原理被称为图灵完备性，它表明只要有足够的基本指令，就可以执行任何可计算的任务。 ​ 在现代计算机上，也是采用这个原理。计算机的中央处理器（CPU）通过执行一系列的基本指令来完成各种复杂的任务。这些基本指令包括算术操作（如加法、减法、乘法）、逻辑操作（如与、或、非）、条件分支（如if语句）和循环（如for循环）等。 ​ 下面是一个简单的例子，展示了如何使用基本指令来执行一个较复杂的任务，即计算一个整数的阶乘： 1234567def factorial(n): result = 1 for i in range(1, n+1): result *= i return resultprint(factorial(5)) # 输出 120 ​ 在这个例子中，我们使用了基本的乘法和循环指令来计算给定整数的阶乘。通过多次执行乘法操作和循环迭代，实现了一个复杂的计算任务。 ​ 即使是电脑上的按键操作和视频播放这样的高级任务，也可以通过分解为基本指令运算来实现。 ​ 例如，当你在电脑上按下一个键时，操作系统会通过底层的指令来检测按键的状态。这可能涉及到读取硬件设备的输入状态、处理中断信号和执行相应的操作。这些底层指令可能包括读取寄存器、执行条件分支、更新内存等等。通过组合这些基本指令，操作系统可以捕捉到按键事件，并触发相应的操作，如打开应用程序、输入字符等。 ​ 类似地，视频播放也可以通过基本指令来实现。当你打开一个视频文件时，视频播放器会解码视频数据、渲染图像、播放音频等。这些操作涉及到复杂的算法和数据处理，但它们可以分解为基本指令的执行。例如，视频解码可能包括读取文件、解析视频编码、处理图像数据、渲染图像等。通过执行这些基本指令的组合，视频播放器可以实现流畅的视频播放。 ​ 因此，无论是按键操作还是视频播放，都可以通过将复杂的任务分解为基本指令运算来实现，并且现代计算机提供了这些基本指令的支持。 ​ ==电脑上的一切操作都可以分解为上面所说的算术操作、逻辑操作、条件分支等一系列基本指令== ​ 当然你要懂得的肯定不止上面这些，还有一些跟深层次的分解，就比如复杂的操作是如何被分解为一个个基本指令的、CPU是如何识别这些基本指令的、CPU如何确定这条指令是否运行完成，以及这些基本指令是如何一条条的排序逐次运行的呢？ ​ 指令集：CPU的加减乘除、与或非、load、store等基本指令一般称之为指令集，任何复杂的运算都可以分解为指令集中的基本指令 ​ 程序：这种由基本指令组成的不同组合就称之程序。 ​ 汇编语言：为了变成方便，我们给每个二进制的指令起了一个别名，也可以称之为助记符，也就是我们常说的汇编指令。 ​ 高级语言：虽然汇编语言的出现给人们带来了极大的便利，人们不需要面对不懂含义的101010，但是当工程更为复杂的时候，汇编的维护也会变得极为艰难，所以为了迎合人们的开发和阅读，人们在汇编的基础上做了一系列的高级语言，就比如python、C、c++和java。 ​ 然后用一个最简单的C语言程序和C++程序来验证 12345671 #include &lt;stdio.h&gt;2 3 int main()4 {5 printf(&quot;hello world \\r\\n&quot;); 6 return 0;7 } 12345678#include &lt;iostream&gt;using namespace std;int main(){ cout &lt;&lt; &quot;hello world&quot; &lt;&lt; endl; return 0;} ​ 上面是两个最简单的C语言和C++语言的helloworld编程示例，而且最终的实现效果相同都是打印出来helloworld，如下所示： ​ 这个a.out是编译过后的可执行文件，中间的编译过程又是怎么样的呢？ ​ 就像上面图示绘制的那样，高级语言都有对应的编译器，C语言又gcc,C++有g++，如果只是通过下面的命令进行编译的话只会得到最后的可执行文件 12gcc test.cg++ test.cpp ​ 当然因为上面两个命令生成的都是a.out所以就覆盖了，也可以通过-o命令进行执行生成的可执行文件名称 12gcc test.c -o test_cg++ test.cpp -o test_c++ 一个高级语言编译成可执行文件，更详细的过程为预处理、编译、汇编、链接 (1)预处理指的是将头文件、函数、恒定义等都展开，可以通过-E参数来实现 12gcc -E test.cg++ -E test.cpp (2)编译指的是通过编译器将高级语言编译为汇编语言，可以通过-S参数来完成 12gcc -S test.c -o test_c.sg++ -S test.cpp -o test_cpp.s 以s结尾的就是汇编文件，现在对于汇编语言的理解可以不用过深，以后再说。 (3)汇编指的是将汇编程序通过汇编器编译为二进制的.o文件，可以通过参数-c来完成。 12gcc -c test.c -o test_c.og++ -c test.cpp -o test_cpp.o (4)链接，可以将多个.o文件链接到一起从而生成可执行文件，没有命令，直接gcc编译即可。 ​ ==我这里有个疑问，我这个程序是最简单那的hello world，也没有多个文件，那他未什么要进行链接呢，我这个地方不是很懂，希望下面的学习能解答我这个疑惑== 2.CPU的频率指的是什么​ 我先说一下，这个我确实是不知道，我学了这么多年的计算机，我第一台电脑是18年大学，我爸给买的戴尔G3，那时候是一个8300的CPU，后来电脑烧了，我爸又给我买了一个洋垃圾台式机，CPU是2690,虽然现在知道了他是洋垃圾，但之前是不知道的呀，其实就也还好吧，每一段时间都有一段时间的感悟，再后来我工作了，自己花实习的一个月工资高了一台小主机，5900hx的CPU，一年之后没有笔记本，又搞了一台联想的笔记本，笔记本的CPU是6800hx，总体跟我的5900hx差不多，再后来不满足需求了，又因为我的4070ti显卡一直在闲置，我也不想卖掉，所以两个月前又买了一个13900kf的无核显主机，买了这么多电脑，终于是对电脑有了一些基本的认识，但是对于CPU的频率依然是一知半解，趁着这个机会学习一下。 ​ 频率的概念 ​ 在CPU这个复杂的数字系统中，为了确保内部所有硬件单元能够协同快速工作，CPU架构工程师们往往会设计一套时钟信号与系统同步进行操作。时钟信号是由一系列的脉冲信号构成，并且总是按一定电压幅度、时间间隔连续发出的方波信号，它周期性地在0与1之间往复变化。在第一脉冲和第二个脉冲之间的时间间隔称之为周期，它的单位是秒（s）。但单位时间1s内所产生的脉冲个数称之为频率，频率的最基本计量单位就是赫兹Hz。 ​ 以Intel Core i3-8350k为例，它的默频是4GHz，意味着它内部时钟频率为4GHz，一秒钟可以产生40亿个脉冲信号，换句话说每一个脉冲信号仅仅用时0.25ns（时钟周期）。这是多么令人震惊的时钟，可以想象到CPU内部结构是多么精妙，可以处理如此之短的信号，整套系统协同有序地运行，所以才会说CPU是全人类智慧的结晶，极大地提升了我们的科技水平进步。 ​ 时钟周期作为CPU操作的最小时间单位，内部的所有操作都是以这个时钟周期作为基准。一般来说CPU都是以时钟脉冲的上升沿作为执行指令的基准，频率越高，CPU执行的指令数越多，工作速度越快。 ​ 那么CPU频率是由什么决定的呢？其实这个是一个非常复杂的问题，因为决定这个频率是一个系统学的东西，影响到频率高度的因素非常之多，诸如CPU的架构、流水线设计、内部寄存器设计、支持的指令甚至是功耗、温度这些物理因素，所以说CPU出厂频率就是综合多种考虑，以木桶效应下的最小值作为CPU的最高频率。 ​ G是十的9次方也就是十亿，M是10的6次方也就是百万，K是10的3次方， 外频 ​ CPU在诞生后不久，各大CPU巨头为了追求高性能，开启了频率大战（有没有效果这个我们先不提），但是这样一来，CPU虽然跑得更换了（主频更高），但是外部的主板芯片组、内存、外部接口（PCIe、Sata）可还是处于旧有标准，而且这些设备的运行频率早就固定下来了，并且远低于CPU工作频率。 ​ 这样一来CPU就无法很好与之交流，Intel就机智地提出了倍频的概念（下面讲述），并且提出了影响至今的一个CPU主频计算公式：主频=外频 X 倍频，外频的提出可以让主板外部的设备工作在较低的频率下，并且还能正确地CPU进行交流。 ​ 但总是有很多网友将前端总线频率和外频混为一谈，其实他们不太一样。在以前有北桥的时代，前端总线是CPU总线接口单元和北桥芯片之间的数据交换通道，曾经在AMD雷鸟系列、Intel奔腾 4处理器以前，前端总线与外频是一致的，但后来有了四倍数据传输率技术或者是八倍数据传输率技术，前端总线频率就极大地提高了。 ​ 举个例子，如果一个处理器的频率是2GHz，外频为100MHz，使用四倍数据传输率技术时，前端总线频率就变成400MHz；如果是八倍，那么就是800MHz。前端总线频率越大, 代表着CPU与北桥芯片之间的数据传输能力越大, 更能充分发挥出CPU的功能。目前处理器的默认外频基本上都是100MHz 倍频 ​ 目前的CPU设计的外频都相当低，只有100MHz，CPU要获得更快运算速度，我们就需要获得一个超高速的频率来支撑更快运算速度。而CPU通常就是在内部设计有一个锁相环频率发生器，对于输入的时钟信号进行分频处理，按照一定比例提高输入的外频频率，从而得到CPU的实际工作频率，这个比例就称之为倍频系数（简称倍频）。 ​ 利用倍频技术, 较为完美地解决了CPU和内存等数据中转站的异步运行问题。为CPU后来向更高频率方向发展打下了扎实的基础。 ​ 倍频系数是指CPU主频与外频之间的相对比例关系。在相同的外频下，倍频越高CPU的频率也越高。但实际上，在相同外频的前提下，高倍频的CPU本身意义并不大。这是因为CPU与系统之间数据传输速度是有限的，一味追求高主频而得到高倍频的CPU就会出现明显的“瓶颈”效应－CPU从系统中得到数据的极限速度不能够满足CPU运算的速度。 ​ 我有个问题，我的13900KF的CPU频率是5.8GHZ ,我的内存频率是6000M的DDR5内存，这么算的话我的内存比CPU频率高呀，但理论来说不是呀，那问题出在哪？ ​ 时间的单位是纳秒（ns，十亿分之一秒），毫秒（ms，千分之一秒），和秒（s）。吞吐量的单位是兆字节（MB）和千兆字节（GB）。让我们先从CPU和内存开始，下图是北桥部分： ​ 第一个令人惊叹的事实是：CPU快得离谱。在Core 2 3.0GHz上，大部分简单指令的执行只需要一个时钟周期，也就是1/3纳秒。即使是真空中传播的光，在这段时间内也只能走10厘米（约4英寸）。把上述事实记在心中是有好处的。当你要对程序做优化的时候就会想到，执行指令的开销对于当今的CPU而言是多么的微不足道。 ​ 当CPU运转起来以后，它便会通过L1 cache和L2 cache对系统中的主存进行读写访问。cache使用的是静态存储器(SRAM)。相对于系统主存中使用的动态存储器（DRAM），cache读写速度快得多、造价也高昂得多。cache一般被放置在CPU芯片的内部，加之使用昂贵高速的存储器，使其给CPU带来的延迟非常低。在指令层次上的优化（instruction-level optimization），其效果是与优化后代码的大小息息相关。由于使用了高速缓存技术（caching），那些能够整体放入L1/L2 cache中的代码，和那些在运行时需要不断调入/调出（marshall into/out of）cache的代码，在性能上会产生非常明显的差异。 ​ 正常情况下，当CPU操作一块内存区域时，其中的信息要么已经保存在L1/L2 cache，要么就需要将之从系统主存中调入cache，然后再处理。如果是后一种情况，我们就碰到了第一个瓶颈，一个大约250个时钟周期的延迟。在此期间如果CPU没有其他事情要做，则往往是处在停机状态的（stall）。为了给大家一个直观的印象，我们把CPU的一个时钟周期看作一秒。那么，从L1 cache读取信息就好像是拿起桌上的一张草稿纸（3秒）；从L2 cache读取信息则是从身边的书架上取出一本书（14秒）；而从主存中读取信息则相当于走到办公楼下去买个零食（4分钟）。 ​ 主存操作的准确延迟是不固定的，与具体的应用以及其他许多因素有关。比如，它依赖于列选通延迟(CAS)以及内存条的型号，它还依赖于CPU指令预取的成功率。指令预取可以根据当前执行的代码来猜测主存中哪些部分即将被使用，从而提前将这些信息载入cache。 看看L1/L2 cache的性能，再对比主存，就会发现：配置更大的cache或者编写能更好的利用cache的应用程序，会使系统的性能得到多么显著的提高。 ​ 人们通常把CPU与内存之间的瓶颈叫做冯·诺依曼瓶颈（von Neumann bottleneck）。当今系统的前端总线带宽约为10GB/s，看起来很令人满意。在这个速度下，你可以在1秒内从内存中读取8GB的信息，或者10纳秒内读取100字 节。遗憾的是，这个吞吐量只是理论最大值（图中其他数据为实际值），而且是根本不可能达到的，因为主存控制电路会引入延迟。在做内存访问时，会遇到很多零 散的等待周期。比如电平协议要求，在选通一行、选通一列、取到可靠的数据之前，需要有一定的信号稳定时间。由于主存中使用电容来存储信息，为了防止因自然 放电而导致的信息丢失，就需要周期性的刷新它所存储的内容，这也带来额外的等待时间。某些连续的内存访问方式可能会比较高效，但仍然具有延时。而那些随机 的内存访问则消耗更多时间。所以延迟是不可避免的。 图中下方的南桥连接了很多其他总线（如：PCI-E, USB）和外围设备： ​ 令人沮丧的是，南桥管理了一些反应相当迟钝的设备，比如硬盘。就算是缓慢的系统主存，和硬盘相比也可谓速度如飞了。继续拿办公室做比喻，等待硬盘寻道的时间相当于离开办公大楼并开始长达一年零三个月的环球旅行。这就解释了为何电脑的大部分工作都受制于磁盘I/O，以及为何数据库的性能在内存缓冲区被耗尽后会陡然下降。同时也解释了为何充足的RAM（用于缓冲）和高速的磁盘驱动器对系统的整体性能如此重要。 虽然磁盘的”连续”存取速度确实可以在实际使用中达到，但这并非故事的全部。真正令人头疼的瓶颈在于寻道操作，也就是在磁盘表面移动读写磁头到正确的磁道上，然后再等待磁盘旋转到正确的位置上，以便读取指定扇区内的信息。RPM（每分钟绕转次数）用来指示磁盘的旋转速度：RPM越大，耽误在寻道上的时间就越少，所以越高的RPM意味着越快的磁盘。 当 磁盘驱动器读取一个大的、连续存储的文件时会达到更高的持续读取速度，因为省去了寻道的时间。文件系统的碎片整理器就是用来把文件信息重组在连续的数据块 中，通过尽可能减少寻道来提高数据吞吐量。然而，说到计算机实际使用时的感受，磁盘的连续存取速度就不那么重要了，反而应该关注驱动器在单位时间内可以完 成的寻道和随机I/O操作的次数。对此，固态硬盘可以成为一个很棒的选择。 硬盘的cache也有助于改进性能。虽然16MB的cache只能覆盖整个磁盘容量的0.002%，可别看cache只有这么一点大，其效果十分明显。它可以把一组零散的写入操作合成一个，也就是使磁盘能够控制写入操作的顺序，从而减少寻道的次数。同样的，为了提高效率，一系列读取操作也可以被重组，而且操作系统和驱动器固件(firmware)都会参与到这类优化中来。 最后，图中还列出了网络和其他总线的实际数据吞吐量。火线(fireware)仅供参考，Intel X48芯片组并不直接支持火线。我们可以把Internet看作是计算机之间的总线。去访问那些速度很快的网站（比如http://google.com），延迟大约45毫秒，与硬盘驱动器带来的延迟相当。事实上，尽管硬盘比内存慢了5个数量级，它的速度与Internet是在同一数量级上的。目前，一般家用网络的带宽还是要落后于硬盘连续读取速度的，但”网络就是计算机”这句话可谓名符其实。如果将来Internet比硬盘还快了，那会是个什么景象呢？ ==内存频率（6000 MHz）指的是内存模块的时钟速度，它表示内存模块每秒钟能够完成的数据传输次数。它通常用于衡量内存模块的性能，较高的内存频率可以提供更快的数据传输速度。== ==CPU频率（5.8 GHz）指的是中央处理器（CPU）的时钟速度，它表示CPU每秒钟执行指令的次数。CPU频率是衡量CPU性能的指标之一，较高的CPU频率通常表示更高的计算能力和处理速度。== 3.cache​ cache是sram是静态随机存储器，而内存是sram是动态随机存储器，静态是比动态速度更快的，但是呢，更快意味着更贵。我之前一直对cache了解的不多，知道一级cache、二级cache、三级cache，但并不明白他们的作用，如今学习到这里了，就认识一下。找了一段cdsn大佬的讲解，很生动，这里记录一下。 对于没有接触过底层技术的朋友来说，或许从未听说过cache。毕竟cache的存在对程序员来说是透明的。在接触cache之前，先为你准备段code分析： 12345int arr[10][128]; for (i = 0; i &lt; 10; i++) for (j = 0; j &lt; 128; j++) arr[i][j] = 1; 如果你曾经学习过C/C++语言，这段code自然不会陌生。如此简单的将arr数组所有元素置1。 你有没有想过这段code还有下面的一种写法： 12345int arr[10][128]; for (i = 0; i &lt; 128; i++) for (j = 0; j &lt; 10; j++) arr[j][i] = 1; ​ 功能完全一样，但是我们一直在重复着第一种写法（或许很多的书中也是建议这么编码），你是否想过这其中的缘由？文章的主角是cache，所以你一定猜到了答案。那么cache是如何影响这2段code的呢？ 为什么需要cache在思考为什么需要cache之前，我们首先先来思考另一个问题：我们的程序是如何运行起来的？ 我们应该知道程序是运行在 RAM之中，RAM 就是我们常说的DDR（例如： DDR3、DDR4等）。我们称之为main memory（主存）。当我们需要运行一个进程的时候，首先会从磁盘设备（例如，eMMC、UFS、SSD等）中将可执行程序load到主存中，然后开始执行。在CPU内部存在一堆的通用寄存器（register）。如果CPU需要将一个变量（假设地址是A）加1，一般分为以下3个步骤： CPU 从主存中读取地址A的数据到内部通用寄存器 x0（ARM64架构的通用寄存器之一） 通用寄存器 x0 加1 CPU 将通用寄存器 x0 的值写入主存 我们将这个过程可以表示如下： 其实现实中，CPU通用寄存器的速度和主存之间存在着太大的差异。两者之间的速度大致如下关系： ​ CPU register的速度一般小于1ns，主存的速度一般是65ns左右。速度差异近百倍。因此，上面举例的3个步骤中，步骤1和步骤3实际上速度很慢。当CPU试图从主存中load/store 操作时，由于主存的速度限制，CPU不得不等待这漫长的65ns时间。如果我们可以提升主存的速度，那么系统将会获得很大的性能提升。如今的DDR存储设备，动不动就是几个GB，容量很大。如果我们采用更快材料制作更快速度的主存，并且拥有几乎差不多的容量。其成本将会大幅度上升。我们试图提升主存的速度和容量，又期望其成本很低，这就有点难为人了。因此，我们有一种折中的方法，那就是制作一块速度极快但是容量极小的存储设备。那么其成本也不会太高。这块存储设备我们称之为cache memory。在硬件上，我们将cache放置在CPU和主存之间，作为主存数据的缓存。 当CPU试图从主存中load/store数据的时候， CPU会首先从cache中查找对应地址的数据是否缓存在cache 中。如果其数据缓存在cache中，直接从cache中拿到数据并返回给CPU。当存在cache的时候，以上程序如何运行的例子的流程将会变成如下： CPU和主存之间直接数据传输的方式转变成CPU和cache之间直接数据传输，cache负责和主存之间数据传输。 多级cache存储结构cahe的速度在一定程度上同样影响着系统的性能。一般情况cache的速度可以达到1ns，几乎可以和CPU寄存器速度媲美。但是，这就满足人们对性能的追求了吗？并没有。当cache中没有缓存我们想要的数据的时候，依然需要漫长的等待从主存中load数据。为了进一步提升性能，引入多级cache。前面提到的cache，称之为L1 cache（第一级cache）。我们在L1 cache 后面连接L2 cache，在L2 cache 和主存之间连接L3 cache。等级越高，速度越慢，容量越大。但是速度相比较主存而言，依然很快。不同等级cache速度之间关系如下： 经过3级cache的缓冲，各级cache和主存之间的速度最萌差也逐级减小。在一个真实的系统上，各级cache之间硬件上是如何关联的呢？我们看下Cortex-A53架构上各级cache之间的硬件抽象框图如下： ​ 在Cortex-A53架构上，L1 cache分为单独的instruction cache（ICache）和data cache（DCache），指令和数据分开。L1 cache是每个CPU私有的，每个CPU都有一个L1 cache。一个cluster 内的所有CPU共享一个L2 cache，L2 cache不区分指令和数据，都可以缓存。所有cluster之间共享L3 cache，L3 cache通过总线和主存相连 ​ 关于cache就学习到这里，如果想要学习更多相关的可以看这个博客. 4.总线和地址​ 先来阐述一个疑惑32位的CPU和64位的CPU这里的32和64指的什么？ ​ 32位CPU：指的是处理器的寻址能力或数据总线宽度为32位。这意味着该处理器可以在单个时钟周期内处理32位（4字节）的数据或地址。它最大支持的物理内存容量通常限制在4GB左右。 ​ 64位CPU：指的是处理器的寻址能力或数据总线宽度为64位。这意味着该处理器可以在单个时钟周期内处理64位（8字节）的数据或地址。它的寻址能力更大，可以支持更大的物理内存容量，通常可以支持数TB（1TB = 1024GB）的内存。 ​ 因此，32位和64位CPU主要区别在于它们的寻址能力和数据总线宽度，这直接影响到它们在处理数据和内存方面的能力和限制。64位CPU相对于32位CPU具有更高的处理能力和更大的内存扩展性。 ​ CPU和内存以及各种外部设备是通过总线连接在一起的，那CPU是如何访问内存或者控制各个外部设备的呢？在CPU内部，存在一系列的寄存器，这些寄存器是没有地址的，只需要寄存器的名称去访问即可，而内存以及各个外部设备就需要地址去访问了。那这里的地址是什么，这里的地址又是如何分配的呢？ ​ 地址的本质实际上就是由CPU管教发出的一组地址控制信号，因为这些信号是由CPU管教直接发出的，因此也被称之为物理地址。在带有MMU的CPU平台下 ，程序的运行一般使用的是虚拟地址，MMU会把虚拟地址转换为物理地址，然后通过CPU的管教发送出去。 ​ 所谓总线（Bus），是指计算机设备和设备之间传输信息的公共数据通道。总线是连接计算机硬件系统内多种设备的通信线路，它的一个重要特征是由总线上的所有设备共享，可以将计算机系统内的多种设备连接到总线上。如果是某两个设备或设备之间专用的信号连线，就不能称之为总线。 ​ 一些总线标准： 5.指令集和微架构​ 在第一节提到过，任何一个复杂的程序都可以分解位=为有限个基本指令的组合，而这些是在CPU设计的时候就已经确定了的，他的内部只允许对应指令的完成，而不同架构的处理器，他们的指令是不一样的，哪怕是同样的指令，他们的内部电路实现也是不一样的，所以不同架构的可执行程序是不能混用的。ARM架构的处理器只能运行ARM架构的程序，X86架构的处理器只允许运行X86架构的程序。上面提到的这些指令的集合就被称之为指令集。 ​ 在芯片工程师设计CPU的时候，要根据指令集中规定的格式指令作为标准，实现那不同的译码电路来支持指令集各种指令的运行（==这里你不用管如何译码的，这里目前不需要深究==），指令集的最终实现就是微架构，也就是CPU内部的各种译码和执行电路。 ​ 就比如a7核心 a9核心等就是微架构，而RK3568的四核心A55就是指的微架构。 ​ 这里目前认识到这个程度就可以了，不做过多的深究，以及后面有需要再去学习了解一下汇编语言。 6.可执行文件的组成​ 在上面已经讲解过了，编译完成之后会生成一个二进制的可执行文件，这个可执行文件只能在对应架构的机器上才能运行，那这个可执行程序都是由什么组成的呢？这时候就要提到一个命令了，也就是readelf，从名字就可以看出他的作用是读取一个可执行文件，先来用file命令查看一下可执行程序，如下所示： “test_c:”: 这是文件的名称。 “ELF 64-bit LSB shared object, x86-64”: 这是文件的类型和架构。它是一个64位的LSB（Linux Standard Base）共享对象，针对x86-64架构。 “version 1 (SYSV)”: 这是ELF文件的版本，采用SYSV格式。 “dynamically linked”: 这表示该文件是动态链接的，它依赖于其他共享库来提供其所需的功能。 “interpreter /lib64/ld-linux-x86-64.so.2”: 这是解释器路径，指示系统在执行该文件时使用的动态链接器。 “BuildID[sha1]=cad02772db45e07867103cc6069ae544863b9ebc”: 这是文件的构建ID，用于唯一标识该文件的构建版本。它是使用SHA1算法计算的哈希值。 “for GNU/Linux 3.2.0”: 这表示该文件是为GNU/Linux 3.2.0版本编译的。 “not stripped”: 这表示该文件没有被剥离（stripped），即没有从文件中移除调试信息和符号表。 Executable and Linkable Format 可执行和可链接的格式。 可以通过readelf -h命令查看可执行文件的文件头（header）信息，例如查看上面编译的hellloworld文件，具体内容如下所示： ​ 这里了解到的信息其实并没有什么用，唯一有用的就是最下面的section header数量，section header用来主要用来描述可执行文件的section信息，一个可执行文件通常由不同的section来组成，包括代码段、数据段、BSS段、只读数据段，每个section由section header来描述。这里的文件头其实也就是指的文件最开始的那几个字节的信息，然后通过readelf -S 查看可执行文件的节头表（section header）。仍旧以helloworld为里，查看到的节头表内容如下所示： ​ 通过节头表的信息可以窥探到一个可执行文件的组成，上面我比较熟悉的其实并不多，其实也就知道代码段 text ，数据段 data，。bss段，其他知道的并不多，函数翻译成二级制指令放在代码段之中，初始化的全局变量和静态局部变量放在数据段之中，未初始化的全局变量和静态局部变量放在BSS段当中，其他就没了。 7.汇编过程​ 先说一下我的想法，本来我是不想学习这个的，后来我感觉这个东西与后面的链接、与动态库静态库有很深的联系，所以我还是回来看这个了。 ​ 预处理之后就是编译，汇编的过程就是将程序代码转换为一个个的汇编指令，再后面才是真正的汇编过程，汇编依靠汇编器，汇编器会将汇编语言转换为二进制语言。 ​ 每个重定位的目标文件都是以零地址为基地址进行的代码段的组装，但是后面的链接过程需要将好多个目标文件链接为一个可执行文件，而每个文件都是以零地址进行偏移的，所以在链接的时候需要更新目标文件中的变量或者函数的地址，这个被称之为重定义。那链接器如何知道哪些函数或者变量需要重定位呢？很简单将需要重定位的符号收集起来，生成一个重定位表，以section的形式保存到每个可重定位目标文件即可。 ​ 上面提到符号表和重定位表都是很重要的概念。符号表可以通过readelf -s命令来获取，注意这里是小s 使用readelf -r可以获得该重定位目标文件的重定位表，如下所示： 8.静态链接库​ 仍旧先说一下我的理解和看法，无论是静态链接库还是动态链接库，他们实际上就是可重定位的目标文件，即汇编过程之后生成的文件，当然也不对，可以是由一个目标文件生成的库文件也可以是由好几个目标文件生成库文件。很多时候人们会将函数的实现给封装起来，我们只需要调用相应的函数即可，而很多不开源的项目，也会提供封装好的库，让人们只需要使用头文件中定义的相应函数即可。 ​ 静态库会在编译程序的时候将引用的函数代码或者变量链接到可执行文件里，和在可执行程序组装到一起，而动态库不会和可执行文件组装到一起，而是在程序运行的时候加载到内存参与链接。 ​ 所以静态库的本质就是一个可重定位的目标文件，与上面经过汇编编译出来的.o文件没什么不同，只是多了一个归档的过程。静态库的制作使用ar归档命令来实现，ar是一个用于创建和管理静态库（Archive）的命令行工具。它的名称是”ar”，代表”archive”，可以在Unix和Unix-like系统上使用。ar命令可以用于创建静态库、向静态库中添加对象文件、从静态库中提取对象文件以及执行其他与静态库相关的操作。下面是对ar命令的一些常见用法的详细解释： 1.创建静态库 1ar -rcs libexample.a file1.o file2.o file3.o 这个命令将创建一个名为”libexample.a”的静态库，并将文件”file1.o”、”file2.o”和”file3.o”添加到该库中。选项”r”表示替换库中的现有文件，选项”c”表示创建库，选项”s”用于在库中添加索引信息。 -r：将指定的文件插入或替换到归档文件中。 -s：创建索引表。 -c: 不在必须创建库的时候给出警告 2.向静态库中添加对象文件 1ar -r libexample.a newfile.o 这个命令将向现有的静态库”libexample.a”中添加新的对象文件”newfile.o”。选项”r”表示替换库中的现有文件。 3.从静态库中提取对象文件 1ar -x libexample.a newfile.o 这个命令将从静态库”libexample.a”中提取出对象文件”file1.o”。选项”x”表示提取 4.列出静态库中的对象文件 1ar -t libexample.a 5.替换静态库中的对象文件 12ar -d libexample.a file1.oar -r libexample.a newfile.o 这两个命令分别用于从静态库中删除对象文件”file1.o”和向静态库中添加新的对象文件”newfile.o”。选项”d”表示删除。 ​ 编译器是以源文件为单位进行程序编译的，链接器在连接的过程中逐个对目标文件进行分解和组装，但这样很容易产生一个问题，如果一个源文件中我们定义了一百个函数，但是只使用了其中的一个，链接器在连接的过程中会将这一百个函数都组装到可执行文件中，这会让最终生成的可执行文件大大增加，那要如何解决这个问题呢，只需要将每一个函数单独使用一个源文件来实现，最终将多个目标文件打包即可。而我们最常用的libc库就是这样实现的，可以通过上面学习的ar -t命令来查看对象文件列表 ​ 可以看到libc将每个函数都搞成了一个目标文件，从而解决了上面提到的问题。这时候又出现了另一个问题，就比如我们经常用到printf进行字段的打印，可能很多个程序都调用了它，链接器在链接的时候就要将多个printf指令添加到多个可执行文件中，在一个多任务的环境中，多个进程并发运行的时候，你会发现内存中有大量重复的printf指令代码，从而浪费了很多的资源，那这个问题要如何解决呢，聪明的工程师们想出来了动态库的方法。 ​ ==今天就学习到这个地方了，其实上面的这些东西你都不配说难，因为已经有先人替你踩过坑了，也有更厉害的先人提出来了这些理论，并且用到了实践中，计算机当中的一切都不再属于新鲜事，我们已经站在了巨人的肩膀上，没有理由后人比前人笨，也没有道理学不会，学不会只能证明你没有用心== 9.动态链接库​ 在讲解静态链接库的最后面也提到了静态链接库现有的一些问题，所以人们就提出了动态链接库，动态链接库在程序运行时进行加载，而且不同的可执行文件可以共用动态链接库，所以可以极大的节省内存，动态链接库的编译方式如下： 1gcc -fPIC -shared C文件 -o 库文件 ​ 在Linux环境下，当我们运行一个程序时，操作系统首先会在给程序fork一个子进程，接着动态连接器加载到内存，操作系统将控制器权交给动态链接器，让动态链接器完成动态库的加载和重定位搞作，最后跳转到要运行的程序。动态链接器在C标准库中实现，是glibc的一部分，主要完成程序运行前的动态链接工作，在可执行文件的.interp段中存放的有动态链接器的加载路径，可以通过objdump命令查看。 1objdump -j .interp -s a.out objdump是一个用于分析目标文件（object file）的常用命令行工具。它在各种操作系统和编程环境中都有提供，例如Linux和Windows。 objdump的主要作用是提供目标文件的反汇编、符号表、节（section）信息等相关信息。以下是一些常见的用途： 反汇编目标文件：objdump可以将目标文件中的机器码转换为可读的汇编代码，以便进行代码分析、调试和优化。这对于理解代码的执行流程、查找问题和进行二进制分析非常有用。 显示符号表：objdump可以列出目标文件中的符号表，包括函数、变量和其他符号的信息。这对于了解代码的结构、查找特定符号、检查符号的可见性和解决符号冲突非常有帮助。 显示节信息：objdump可以显示目标文件中各个节（section）的信息，例如代码段、数据段、符号表、重定位表等。这对于了解目标文件的布局、存储的数据、链接信息和其他元数据非常有用。 检查目标文件的属性：objdump可以提供有关目标文件的一些属性，例如目标文件格式、目标架构、入口点等。这对于验证目标文件的正确性和兼容性非常有帮助。 ​ 动态链接器本身也是一个动态库，即lib/ld-linux.so文件，动态链接器被加载到内存后，会首先给自己重定位，然后才能运行，像这种给自己重定位然后自动运行的行为，我们称之为自举，在嵌入式系统中Uboot也有自举功能，它在系统上电启动之后会完成代码的自我复制和重定位操作，然后加载到Linux内核镜像中运行。 ​ 动态链接器解析解析可执行文件中未确定的符号以及需要链接的动态库信息，将对应的动态库加载到内存，并进行重定位操作，这个过程其实和静态链接的重定位过程相同，只不过推迟到了运行阶段，重定位结束之后，程序中要引用的符号都有了地址和定义，动态链接器要将控制权交给可执行程序，跳转到该程序运行。 ​ 静态链接的可执行程序在运行时，一般加载地址等于链接地址，而且这个地址是固定的，可执行文件是操作系统帮我们创建一个子进程之后第一个被加载到内存空间的文件，此时进程的地址一马平川，还未被占用，所以不用考虑地址资源的问题，而动态链接库加载到内存的地址是随机的，因为每一个可执行文件的带线啊哦不同，所以加载到内存后剩余的地址空间也不相同，动态链接库的地址要根据进程地址空间的实际空间的情况随机分配。 ​ so文件是在加载时进行的重定位，虽然解决了可执行文件中对绝对地址的引用问题，但也带来了另外的问题，那就是对于每个进行，动态库加载到内存的不同地址，只能被进程自身共享，无法再多个进程间共享，无法节约内存，但这也又违背了动态库设计的初衷，跟静态库是一样的效果，要如何解决这个问题呢。 ​ 如果想要让动态库放到内存的任何位置都可以运行，都可以被多个进行共享，那就是将动态库设计成与位置无关的代码，上面的gcc的-fPIC参数就是指与位置无关，最终的设计思路为，将指令中需要修改的部分分离出来，剩余的部分就与地址无关了，放在哪里都能执行，而且可以被多个进程共享，需要被修改的指令和数据在每个进行中都有一个副本，互不影响各自的运行。 ​ 对于同一个程序，我们很容易通过相对寻址来实现代码和地址无关，但是当动态库作为第三方模块被不同的应用程序引用的时候，库中的一些绝对地址符号，如何能做到同时被不同的应用程序引用的呢，解决这个问题的方法其实也很简单，那就是将应用程序引用的动态库符号收集起来，保存到一个表之中买这个表用来记录各个引用符号的地址，这个表被称之为全局偏移表。 ​ 现在大部分软件都是通过动态链接的方式开发的，不仅可以节省内存空间，升级维护也比较方便。动态链接器会在系统默认的路径下查找，即lib usr/lib，也回到系统指定的一些路径下查找，用户可以在/etc/ld.so.conf文件中添加自己的共享库路径，修改之后可以使用ldconbfig重新生成一个缓存的/etc/ld.so.chche，每次增加或者删除共享库的路径时，都需要使用ldconfig更新缓存。除此之外也可以使用 1export LD_LIBRARY_PATH=库的路径 ​ 临时改变共享库的查找路径。","link":"/2023/12/11/23%20%E5%B5%8C%E5%85%A5%E5%BC%8FC%E8%AF%AD%E8%A8%80%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB/"},{"title":"tabby的使用","text":"​ 先说一下前提条件，本来我其实挺不爱用终端的，就算使用终端也是用mobaxterm，只能说这个软件很是强大，但是并没有给我一种给经验的感觉，当然肯定比之前的超级终端强得多，但还是不能给我一个十分想用的感觉，而这个tabby的软件就不一样，简洁而且看起来很好用，他的分屏、颜色、背景插件等等一系列的操作都让我很是喜欢，所以下面就简单的讲解一下tabby的使用。 1.Tabby简介 🍀 Tabby是一个无限可定制的跨平台终端应用程序，适用于local shells、serial、SSH和Telnet的连接。 🍁 Tabby是基于TypeScript开发的终端模拟器，可用于Linux、Windows和Mac OS系统。 🌺 Tabby (前身是 Terminus) 是一个可高度配置的终端模拟器和 SSH 或串口客户端，支持 Windows，macOS 和 Linux 集成 SSH，Telnet 客户端和连接管理器 集成串行终端 定制主题和配色方案 完全可配置的快捷键和多键快捷键 分体式窗格 自动保存标签页 支持 PowerShell（和 PS Core）、WSL、Git-Bash、Cygwin、MSYS2、Cmder 和 CMD 在 SSH 会话中通过 Zmodem 进行直接文件传输 完整的 Unicode 支持，包括双角字符 不会因快速的输出而卡住 Windows 上舒适的 shell 体验，包括 tab 自动补全（通过 Clink） 为 SSH secrets 和设置集成了加密容器 SSH、SFTP 和 Telnet 客户端可用作 Web 应用（也可托管） 2.tabby的安装下载地址：https://github.com/Eugeny/tabby/releases/tag/v1.0.205 ​ 有windows macos和linux多种类型的安装包，当然也包括多种架构的，我这里要在windows上进行使用，所以下载了windowd的exe文件，也就是这个tabby-1.0.205-setup-x64.exe，下载完成之后进行安装。安装完成之后打开该软件 ​ 由于我要写markdown，所以我把之前下载的删掉了，但是它仍旧保存了我之前的配置，所以除了删掉软件之外还需要去删掉C盘的配置文件：C:\\Users\\Administrator\\AppData\\Roaming。 ​ 第一次启动如下所示： ​ 这里的语言可以选择中文，选择之后如下所示： ​ 而且我比较喜欢黑色的终端，所以就保持默认的黑色的配色方案了。关闭退出之后进入软件界面如下所示： ​ 至此，关于tabby的安装就完成了。 3.tabby快捷键的修改删除显示配置选择器 ctrl+shift+e，因为我想要让该快捷键改为向右分割窗格。 然后将ctrl+shift的快捷按键也删除掉， 这里的关闭标签为ctrl+shift+w，我认为不方便，由于我经常将该快捷按键设置为关闭单一的窗格，所以这里也删除掉 将向右拆分窗格设置为ctrl+shift+e，将向下拆分窗格设置为ctrl+shift+o 将关闭已聚焦的窗格设置为ctrl+shift+w 最后在写几个好用的快捷按键 1.ctrl+shift+左右按键可以切换不同的==标签页== 2.alt+数字按键也可以切换不同的==标签页== 3.ctrl+alt +上下左右可以切换不同的==窗格== ==上面这些确实不错可以让我解放双手，不需要懂鼠标，只需要键盘即可== 4.当窗格进行拆分之后，可以通过ctrl+alt+回车最大化当前的==窗格== 5.ctrl+alt+t 可以切换当前==窗格==的配置（==本来不知道是做啥的后来才知道，但还挺好用==） 6.ctrl+shift+. 可以将当前的窗格修改为单独的==标签页== 7.ctrl+shift+， 将所有的==标签页==合并到当前页 可以看到跟ctrl+shift有关的都是标签页，而跟窗格有关的都是ctrl+alt，反正ctrl是不能少的，而是窗格还是标签就要根据shift和alt来决定了。 4.串口的连接​ 点击右上角的齿轮按钮或者标签页右侧的按钮都可以进行配置。 ​ 我这里是串口5，点击之后可以选择波特率，我这里选择115200，如下图所示： 如果是从齿轮设置打开，则需要先点击配置和连接，再选择串口5，如下所示： 5.ssh的连接​ 如果仅仅只是上面的串口功能，还并不能吸引我，更重要的是这个ssh功能，ssh功能因为要配置IP和密码，所以不能直接点击，需要从配置和连接中，点击ssh右侧小箭头中的克隆，如下图所示： ​ 然后以此输入名称，连接的主机ip即可，我这里连接的是ip为192.168.1.84的ubuntu20，我们一般情况下加载普通用户，就不要使用root用户了，设置完成如下所示： ​ 而ssh的色彩我更喜欢这个名叫Argonaut的，看着还挺好的。 ​ 然后点击保存，可以发现刚刚配置的ssh已经在未命名的组内了： ​ 然后点击箭头进行连接即可，连接成功如下所示： 6.字体设置​ 现在的字体特别小，而且颜色也并不是很好看，可以通过设置中的外观进行修改，进入之后如下所示： 这里的字体我喜欢设置为Cascadia Code SemiBold，而字体大小设置为20即可 ​ 最后的效果如下所示： ​ 对比度鲜艳，让人看着就赏心悦目，工作更加有动力，哈哈。 7.好用的插件7.1 background​ 重点来了，这个是我最最最最推荐的一个插件了，当你的终端背后是一个小姐姐的时候，你是不是想要多看会儿，这样你连摸鱼的时间都会少很多，而且还能适当的放松一下，极大的提高到了工作效率。 ​ 获取之后需要重启软件，在菜单中会多出一个背景，如下图所示： ​ 首先启用背景，如下所示： ​ 然后选择一个你喜欢的图片，我这里当然是神里凌华了==我是神里凌华的狗==，修改完之后是这个样子 ​ 但这也太招摇了，这时候下面的选项就有用了，将背景不透明度设置为6或者7这个样子，我测试最为合适，如下图所示： ​ 最后的效果如下所示： ​ ==嘿嘿是不是感觉还不错== 我发现每次重新启动tabby的时候都会自动打开一个 windows的tabby，我感觉好烦，可以在菜单栏中找到终端如下所示： 然后取消下面的这个即可 7.2.trzsz​ 默认情况下可以通过这里右上角的sftp进行文件的传输，但是这里有个问题，只能上传文件，但是不能上传文件夹： ​ 而trzsz插件可以解决这个问题 安装之后重启tabby，测试发现仍旧不行，但我看github有人说这个问题呀，就很奇怪，算了传输文件不行还能接受，就先这样吧。 7.3 highlight从名字可以看出这是一个高亮的插件，有时候的一些错误信息是需要查看的，或者调试的时候需要捕获到一些特殊字符，所以这个高亮插件还是很重要的。 安装完成重启，可以看到多出来了一个高亮的图标如下所示： 然后点击启动即可： ​ 默认已经给你写好了一些关键字，自己也可以根据需求进行添加。 7.4 save-output ​ 有时候需要保存终端的输出，默认情况下该终端软件是没有保存的功能的，所以需要安装一个名为save-output的插件。 ​ 安装完成之后会在菜单栏中多出来一个名为save-output的按钮如下所示： ​ 设置为on之后设置要存储的路径即可。然后随意打开一个终端。按右键之后可以发现会有一个save-output to file的选项 点击保存即可 在对应的文件中可以看到打印信息，如下图所示： ​ 到这里，关于tabby的简单设置和使用就介绍完成了，下面说一下感受吧，我之前其实并不是很喜欢这些华丽花哨的东西，感觉简简单单能用就好了，但随着时间的推移，发现有些东西并不是你想的那样的，一个好用的工具确实能给人带来不一样的体验，最后祝看到这里的小伙伴，事事顺心。 ​ 为了方便我的后续使用，我将相应的配置进行了打包，以后如果换电脑了只需要将下面网盘的资料放到C:\\Users\\Administrator\\AppData\\Roaming目录下解压即可。 链接：https://pan.baidu.com/s/1EBBtEmSY9SCBeIlB5YVoWQ提取码：bs5v–来自百度网盘超级会员V6的分享","link":"/2023/12/10/22%20tabby%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"git的学习","text":"​ 前提条件，先来说一下未什么要学习git吧，目前先不考虑远程git和github，我目前只是想要在Linux环境下进行git的使用，说一个最简单的目的，我想让我的Linux目录用到什么就显示什么，而且其他的文件也会进行存档，当我需要这个项目的时候就切换到这个分支进行开发，而不是像我现在这个样子，还要保存，删除等等，这样我也能知道我都做了哪些的修改，目前的需求就这样，学习去。 1.git的安装​ 关于git的介绍就不再多说了，linus的丰功伟绩，一直是我的指路明灯，也是我为之不断努力的方向， 过多的就不再多说。 安装需要的插件： 1sudo apt-get install libcurl4-gnutls-dev libexpat1-dev gettext libz-dev libssl-dev git 安装完成之后查看git的版本： 1git --version 2. git的配置配置个人的用户名和电子邮箱 12git config --global user.name &quot;chai&quot;git config --global user.email &quot;1361382269@qq.com&quot; 查看配置 1git config --list --global 配置也可以在 ~/.gitconfig 或 /etc/gitconfig 看到这里加上 –global 是全局的配置， 如果想要在某个特定的配置中使用单独的配置就将–global去掉 设置颜色差异： 1git config --global color.ui true 设置git命令补全 1wget https://github.com/markgandolfo/git-bash-completion/blob/master/git-completion.bash ​ 然后将 1234sudo mv git-completion.bash /usr/bin/sudo echo source /usr/bin/git-completion.bash &gt;&gt; /home/topeet/.bashrc# root的配置文件需要权限，sudo不顶用，所以要换到root用户sudo echo source /usr/bin/git-completion.bash &gt;&gt; /root/.bashrc 现在git就可以正常的进行命令的提示了，如下图所示： ==默认情况下ssh连接是不能翻墙的，原因是一些环境变量的问题，所以就需要手动导入一下下面的上网的环境变量== 123456export ftp_proxy=http://127.0.0.1:8889/export https_proxy=http://127.0.0.1:8889/export FTP_PROXY=http://127.0.0.1:8889/export HTTPS_PROXY=http://127.0.0.1:8889/export HTTP_PROXY=http://127.0.0.1:8889/export http_proxy=http://127.0.0.1:8889/ 目前还不想用码云和github所以这里的ssh配置就先不配置 3.git 基础理论​ 我其实早就学习过了一遍git了，但是一直没有用起来，关于理论这里也算是学习过了，而git的核心命令也就在这个地方。我这里就不复制了，凭借我的记忆复述一下。 ​ git有三个工作区域，分别为工作目录（working directory）、暂存区（stage/index）和资源库（repository），而原创git仓库这里先不管，以后再说，大概是长这个样子： 加上各种命令的切换，长这个样子： Workspace:工作区，就是平时存放项目代码的地方 Index/Stage:暂存区，用于临时存放你的改动，事实上它是一个文件，保存即将提交的列表信息 local Repository:仓库区（或本地仓库），就是安全存放数据的位置，这里有你提交到所有版本的数据，其中HEAD指向最新放入仓库的版本 Remote Repository:远程仓库，托管代码的服务器，可以简单的认为是你项目组中的一台电脑用于远程数据交换 4.git工作流程git的工作流程一般是这样的： 在工作中添加，修改文件 将需要进行的版本管理的文件放入暂存区域 将暂存区域文件提交到git仓库 因此，git管理的文件有三种状态：已修改（modified）,已暂存（staged）,已提交（committed） 5.Git项目搭建工作目录（WorkSpace）一般就是你希望Git帮助你管理的文件夹，可以是你的项目目录，也可以是空目录，建议不要有中文。 日常使用只需要记住下图6个命令： 建立一个git仓库 1git init 执行万命令后可以看到，仅仅在项目目录多出了一个.git目录（注意这个默认是隐藏的文件夹，需要手动在查看选项里面去掉隐藏的文件才能显示），关于版本等所有信息都在这个目录里面 git文件操作 版本控制就是对文件的版本控制，要对文件进行修改，提交等操作，首先要知道文件当前什么状态，不然可能会提交了现在还不想提交的文件，或者要提交的文件没提交上。 ​ (1):Untracked:未跟踪，此文件在文件夹中，但并没有加入到git仓库，不参与版本控制.通过git add 状态变为Staged. ​ (2):Unmodify:文件已经入库，未修改，即版本库中的文件快照内容与文件夹完全一致.这种类型的文件有两种去处，如果它被修改，而变为Modified.如果使用git rm 移出版本库，则成为Untracked文件. ​ (3):Modified:文件已修改，仅仅是修改，并没有进行其他的操作.这个文件也有两个去处，通过git add可进入暂存staged状态，使用git checkout，则丢弃修改过，返回unmodify状态，这个git checkout即从库中取出文件，覆盖当前修改！ ​ (4):Staged：暂存状态，执行git commit则将修改同步到库中，这时库中的文件和本地文件又变为一致，文件为Unmodify状态.执行git reset 查看制定文件状态 1git status [文件名] 查看所有文件状态 1git status 添加所有文件到暂存区 1git add . ​ 这里也仅仅只是将工作区上传到了暂存区，可以看到status已经变为了绿色。 提交暂存区中的内容到本地仓库 -m:提交的信息 1git commit -m &quot;信息&quot; 可以看到git status的状态也已经更新了，如下所示： 6.忽略文件有些时候我们不想把某些文件纳入版本控制中，比如数据库文件，临时文件，设计文件等 在主目录下建立“.gitignore”文件，此文件有如下规则： 1.忽略文件中的空行或以井号（# ）开始的行将会被忽略。 2.可以使用Linux通配符。例如∶星号(*)代表任意多个字符，问号(﹖)代表一个字符，方括号([abc] )代表可选字符范围，大括号( {string1,string2……})代表可选的字符串等。 3.如果名称的最前面有一个感叹号( !)，表示例外规则，将不被忽略。 4.如果名称的最前面是一个路径分隔符(/ )，表示要忽略的文件在此目录下，而子目录中的文件不忽略。 5.如果名称的最后面是一个路径分隔符(/ )，表示要忽略的是此目录下该名称的子目录，而非文件（默认文件或目录都忽略）。 例如以下这些实例: 12345*.txt #忽略所有的.txt结尾的文件！lib.txt #但lib.txt除外/temp #进忽略项目根目录下的TODO文件，不包括其他目录tempbulid/ #忽略bulid目录下的所有文件doc/*.txt #会忽略doc/notes.txt 但是不包括doc/sever/arch.txt 7.查看日志以及恢复版本在第5小节已经进行了第一次的提交，然后我进行第二次的提交 上面是进行的修改，接下来进行提交，如下所示： 然后进行提交的查看 1git log 可以看到这是两个提交，现在指向的是第二次提交，而目前的情况是这样的，这一次的提交是错误的我不想要了，我想回退到第一次的提交，可以使用git reset进行回复 1git reset [哈希值] 然后查看提交的状态如下所示： 但是仍旧需要手动删除才行，如下所示： 8.分支操作分支是Git使用过程中非常重要的概念。使用分支意味着你可以把你的工作从开发主线上分离开来，以免影响开发主线。同一个仓库可以有多个分支,各个分支相互独立,互不干扰。通过git init命令创建本地仓库时默认会创建- -个master分支。 ​ ==之前还是不懂，对于分支有了不一样的想法，分支并不是一个新的，而是一个当前内容的分支== 查看分支： （1）列出所有本地分支 1git branch 列出所有远程分支 1git branch -r 列出所有本地分支和远程分支 1git branch -a 我这里并没有涉及到远程分支，所以也就先不用管。 （2）创建分支 1git branch name （3）删除分支 1git branch -d name （4）分支切换 首先在主分支创建了一个markdown测试文件，并且提交 然后创建另一个分支 1git branch test 切换到新创建的分支 1git checkout name 这里关于分支的还是不太懂，这里应该是要看一看视频。现在懂了，分支的名称才真正的懂得了。 （5）分支合并 可以看到目前head领先了master一个提交，使用下面的命令进行分支合并，将分支上的修改进行合并 1git merge test 可以看到head和master已经是同一个分支了。 9.scp命令的学习 scp（Secure Copy）命令用于在本地主机和远程主机之间进行文件传输。它使用SSH协议进行安全的文件传输。 scp命令的基本语法如下： 1scp [选项] 源文件 目标文件 其中，源文件是要传输的文件或目录的路径，目标文件是传输到的目标位置的路径。 以下是一些常用的scp命令选项： -r：递归复制整个目录。 -P &lt;port&gt;：指定SSH端口号。 -i &lt;identity_file&gt;：指定用于身份验证的私钥文件。 -v：显示详细的调试信息。 -C：开启压缩传输。 下面是几个示例，演示了如何使用scp命令： 从本地主机复制文件到远程主机： 1scp /path/to/local/file user@remote:/path/to/destination/ 从远程主机复制文件到本地主机： 1scp user@remote:/path/to/remote/file /path/to/destination/ 从本地主机复制整个目录到远程主机： 1scp -r /path/to/local/directory user@remote:/path/to/destination/ 从远程主机复制整个目录到本地主机： 1scp -r user@remote:/path/to/remote/directory /path/to/destination/ 这些示例中的user是远程主机上的用户名，remote是远程主机的地址（可以是IP地址或域名），/path/to/是文件或目录的路径。","link":"/2023/12/10/22%20git%E7%9A%84%E5%AD%A6%E4%B9%A0/"},{"title":"opencv的学习","text":"==多好的周日呀，玩了一半总要学习一半，你说对吧== RGA是我总想要要学习的一个东西，只是一直没有机会，好吧，还是我自己的问题~ RGA是一个硬件，他是用来加速2d的，也就是说对于画线等2d操作有很好的加速作用，而我是在哪些时候见到的RGA的呢，是在opencv里面，具体RK是怎样用的呢，我忘记了，所以这里先来重新学习一下opencv，也不用多学，只需要学习windows和Linux里面opencv的配置即可。 1 windows opencv的配置看样子最好的一个链接下面是我根据教程来构建的步骤。 1.1 软件准备MinGw：版本：8.1.0-release-posix-seh-rt_v6-rev0 Cmake：版本：3.20.2 Opencv：版本：4.5.2 其中Cmake和opencv我当然知道是什么，cmake是用来编译oepcnv的，而mingw是什么呢？ MinGW（Minimalist GNU for Windows）是一个用于在Windows操作系统上进行开发的开源软件开发工具集合。它提供了一组GNU工具和库，包括GCC编译器、GNU调试器（GDB）、GNU构建工具（Make）等，使开发者能够在Windows环境下编译和运行C、C++等程序。 MinGW的目标是为Windows提供一个简洁、轻量级的开发环境，以便开发者能够在Windows上进行基于GNU工具的软件开发，而无需依赖于Microsoft Visual Studio等大型开发工具。 MinGW基于GNU工具链，因此它支持标准的GNU编程工具和库，使开发者能够编写和构建跨平台的应用程序。通过MinGW，开发者可以使用GCC编译器在Windows上编译和构建命令行程序、库文件或者跨平台的应用程序。 此外，MinGW还有一个变种版本叫做MinGW-w64，它提供了对64位Windows系统的支持，并且在一些方面进行了改进和扩展。 ==上面是人工智能得到的，我目前就简单的将它理解为在windows上的一个GCC工具链吧== 1.2 软件的下载1.2.1 MinGw下载mingw x86_64: 表示64位x86架构。 i686: 表示32位x86架构（也称为x86或IA-32）。 posix: 表示采用POSIX标准的操作系统接口。 win32: 表示基于Windows操作系统的接口。 对于异常处理（Exception Handling）方式： sjlj（Set Jump/Long Jump）：使用基于setjmp/longjmp函数的异常处理机制。 seh（Structured Exception Handling）：使用Windows结构化异常处理机制。 对于调试信息（Debug Information）方式： dwarf：使用DWARF调试格式。 sjlj 和 seh 不涉及调试信息。 解压该软件包之后得到ming64的文件夹，我将它放到了D盘的根目录 随后将“==D:\\mingw64\\bin==”这个地址加入环境变量，注：win+q 搜索环境变量可以快速打开环境配置，对Path进行配置即可，之前这里对我还挺困难的，如果现在还不懂，那就是你的问题了。最后通过“==g++ -v==”来进行验证，验证成功如下所示： 1.2.2 Cmake下载cmake下载地址 这里直接选用最新的版本3.28，同理跟上面的mingw一样，以同样的方法设置cmake，解压之后的名字为cmake-3.28.0-rc5-windows-x86_64，也放到D盘下，如下所示： 具体要添加的路径为D:\\cmake-3.28.0-rc5-windows-x86_64\\bin，也要加入Path，然后测试如下所示： 1cmake --version 1.2.3 Opencv下载opencv 这里也直接下windows的最新版4.8 opencv也是一样的，opencv虽然是一个exe文件，实际也是解包的一个过程，解包完成如下所示： 1.3 编译OpenCV是一个广泛使用的计算机视觉库，它提供了各种图像和视频处理功能，用于开发计算机视觉应用程序。在Windows操作系统上，原生支持Visual Studio（VS）作为开发环境，可以直接在VS中使用OpenCV。 然而，Visual Studio过于庞大和笨重，不太方便使用。相比之下，Visual Studio Code（VSCode）是一个轻量级的代码编辑器，具有良好的可定制性和扩展性。因此，他们选择使用VSCode作为开发环境来配置OpenCV。 在使用VSCode配置OpenCV时，有一个重要的前提，那就是我们需要将OpenCV的源代码进行编译。编译是将源代码转换为可执行程序或库的过程。在这里，我们使用CMake作为构建工具来管理编译过程。 1.3.1、cmake-gui找到cmake文件夹下的bin里的cmake-gui 文件，启动。 Where is the source code: 这里使用opencv目录下的source目录 Where to build the binaries: 这里是编译后的文件的放置目录 配置完成如下所示： 点击configure之后一点不能选错，选择如下所示： 接下来编译器的选择，分别选择gcc和g++，选择完成如下所示： 然后开始配置，等待配置完成： 在执行完后，把关于python的都给取消勾选。勾选BUILD_opencv_world，WITH_OPENGL和BUILD_EXAMPLES，不勾选WITH_IPP、WITH_MSMF和ENABLE_PRECOMPILED_HEADERS（如果有的话），CPU_DISPATCH选空，然后继续General。 配置完成如下所示： 到这里，该配置的也都完成了，需要去用编译生成。 1.3.2 编译D:\\opencv\\build\\x64\\mingw执行命令: 1minGW32-make -j 32 问题1： 去掉WITH_DIRECTX,WITH_OPENCL_D3D11_NV选项-代表了windows下directx的使用以及d3d功能，编译会出错，应该是需要windows相关支持 问题2：去掉 test java python 问题3：去掉OPENCV_GENERATE_SETUPVARS 至此，编译成功： 1.3.3 安装1minGW32-make install 然后我们继续添加两个环境变量：第一个path是：D:\\opencv\\build\\x64\\vc16\\bin第二个path是：D:\\opencv\\build\\x64\\mingw\\bin 然后随便打开一个shell终端，输入以下命令测试即可。 1.4 vscode配置最终效果 launch.json 123456789101112131415161718192021222324252627282930{ &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ { &quot;name&quot;: &quot;opencv debuge&quot;, &quot;type&quot;: &quot;cppdbg&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;${workspaceFolder}\\\\Debugger\\\\${fileBasenameNoExtension}.exe&quot;, //上面这个Debugger是我自己定义的，为了方便放置生成的exe文件 &quot;args&quot;: [], &quot;stopAtEntry&quot;: false, //这里如果为 false，则说明调试直接运行。（反之则停止） &quot;cwd&quot;: &quot;${workspaceFolder}&quot;, &quot;environment&quot;: [], &quot;externalConsole&quot;: true,//是否调用外部cmd &quot;MIMode&quot;: &quot;gdb&quot;, &quot;miDebuggerPath&quot;: &quot;D:\\\\mingw64\\\\bin\\\\gdb.exe&quot;,//自己进行设置 &quot;setupCommands&quot;: [ { &quot;description&quot;: &quot;为 gdb 启用整齐打印&quot;, &quot;text&quot;: &quot;-enable-pretty-printing&quot;, &quot;ignoreFailures&quot;: false } ], &quot;preLaunchTask&quot;: &quot;opencv3.5.2&quot; } ]} c_cpp_properties.json 12345678910111213141516171819{ &quot;configurations&quot;: [ { &quot;name&quot;: &quot;win&quot;, &quot;includePath&quot;: [ &quot;${workspaceFolder}/**&quot;, &quot;D:/opencv/build/x64/mingw/install/include&quot;, &quot;D:/opencv/build/x64/mingw/install/include/opencv2&quot; ], &quot;defines&quot;: [], &quot;compilerPath&quot;: &quot;D:/mingw64/bin/g++.exe&quot;, &quot;cStandard&quot;: &quot;c11&quot;, &quot;cppStandard&quot;: &quot;c++17&quot;, &quot;intelliSenseMode&quot;: &quot;${default}&quot; } ], &quot;version&quot;: 4} tasks.json 123456789101112131415161718192021222324252627282930313233{ &quot;version&quot;: &quot;2.0.0&quot;, &quot;tasks&quot;: [ { &quot;type&quot;: &quot;shell&quot;, &quot;label&quot;: &quot;opencv3.5.2&quot;, &quot;command&quot;: &quot;D:/mingw64/bin/g++.exe&quot;, &quot;args&quot;: [ &quot;-g&quot;, &quot;${file}&quot;, &quot;-o&quot;, &quot;${workspaceFolder}\\\\Debugger\\\\${fileBasenameNoExtension}.exe&quot;, //上面这个Debugger是我自己定义的，为了方便放置生成的exe文件 &quot;D:/opencv/build/x64/mingw/bin/libopencv_world480.dll&quot;, &quot;-I&quot;, &quot;D:/opencv/build/x64/mingw/install/include&quot;, &quot;-I&quot;, &quot;D:/opencv/build/x64/mingw/install/include/opencv2&quot; ], &quot;options&quot;: { &quot;cwd&quot;: &quot;D:/mingw64/bin&quot; }, &quot;problemMatcher&quot;: [ &quot;$gcc&quot; ], &quot;group&quot;: { &quot;kind&quot;: &quot;build&quot;, &quot;isDefault&quot;: true } } ]} 测试例程 123456789101112131415161718192021222324#include &lt;opencv2/opencv.hpp&gt;#include &lt;iostream&gt;using namespace cv;using namespace std;int main(){ VideoCapture cap(0); Mat img; while (1) { cap &gt;&gt; img; if (img.empty()) break; namedWindow(&quot;img&quot;, WINDOW_NORMAL); imshow(&quot;img&quot;, img); if (27 == waitKey(20)) break; } return 0;} 2 VS opencv的配置2.1 安装vs​ 上面是VS code配置opencv事实上，可以直接通过vs来配置，上面也算是走了弯路了。 VS 官网 ​ 等待安装完成： 安装程序下载安装验证完毕，将会提示进入这个界面 选择C++的桌面开发和Visual Studio 扩展开发，然后更改安装位置。 2.2 安装opencv​ 在第一小节已经讲解过，就不再讲了 2.3 配置VSCODE​ 其实也就那几步，没啥好写的，我留个链接吧 测试完成如下所示： ​ 既然opencv中已经在ubuntu提供的库中了，那为什么人们更多的还是自己编译opencv再使用呢，就比如下面这个例子： 想用一些库，然而发现ubuntu自带的opencv是没有开启的，这时候就要自己编译opencv了。 3 oepncv源码的编译（Linux）1.拉取opencv源码opencv地址 https://opencv.org/releases/ https://github.com/opencv/opencv opencv-contrib 链接https://github.com/opencv/opencv_contrib OpenCV (Open Source Computer Vision Library) 是一个开源计算机视觉和图像处理库，提供了一系列用于处理图像和视频的函数和工具。OpenCV-contrib（OpenCV contributions）是对OpenCV的扩展和补充，包含了一些额外的模块和功能，以增强OpenCV的功能和应用范围。 OpenCV-contrib模块是由OpenCV社区的开发人员和贡献者创建和维护的，它提供了许多实用的功能、算法和工具，用于计算机视觉、图像处理、目标检测、机器学习等领域的应用。 以下是一些常见的OpenCV-contrib模块及其功能： aruco：提供了用于检测和跟踪ArUco标记的函数和类。ArUco标记是一种用于增强现实和相机姿态估计的二维条码。 bgsegm：包含了一些背景分割算法的实现，用于从视频中提取前景对象。这些算法可以用于运动检测、目标跟踪等任务。 bioinspired：实现了一些生物启发式的图像处理算法，包括视网膜模型、光流估计等。这些算法受到生物视觉系统的启发，用于模拟人眼的感知机制。 dnn：提供了深度学习的支持，包括加载和运行基于深度学习模型的图像分类、目标检测和图像分割等任务。 face：包含了人脸检测、人脸识别和人脸特征点检测等相关功能。这些功能可以用于人脸分析、人脸识别和表情识别等应用。 text：提供了文本检测和识别的功能，可以用于场景文本检测、OCR（光学字符识别）等任务。 xfeatures2d：扩展了OpenCV的特征检测和描述子模块，提供了一些额外的特征检测算法和描述子算法，如SURF、SIFT等。 除了上述模块，OpenCV-contrib还包括其他一些模块和功能，如光学流、结构光、三维重建、图像分割等。这些模块和功能可以通过下载和编译OpenCV-contrib库来使用。 在这里就只是编译opencv源码了，也就不再添加opencv-contrib，目前是用不到的。 克隆opencv源码 1git clone https://github.com/opencv/opencv github的仓库源码太大了，还是直接从官网下载吧~，这里下载最新的opencv4.8 ，拷贝到ubuntu之上然后解压： 在编译之前还需要先安装一些依赖 12345678910sudo apt-get install build-essential sudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-devsudo apt-get install python-dev-is-python2 python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libdc1394-22-devpip3 install numpy sudo update-alternatives --install /usr/bin/python python /usr/bin/python2 100sudo update-alternatives --install /usr/bin/python python /usr/bin/python3 150 2.源码编译（PC）然后在opencv源码目录下创建一个build目录进行工程 12mkdir buildcd build 构建命令如下所示： (1) 构建静态库 123456789101112131415161718192021cmake -D CMAKE_INSTALL_PREFIX=/usr/local \\-D CMAKE_BUILD_TYPE=Release \\-D OPENCV_GENERATE_PKGCONFIG=ON \\-D WITH_QUIRC=ON \\-D OPENCV_ENABLE_NONFREE=True \\-D OPENCV_GENERATE_PKGCONFIG=YES \\-D WITH_OPENGL=ON \\-D ENABLE_CXX11=1 \\-D WITH_OPENMP=ON \\-D WITH_1394=OFF \\-D INSTALL_C_EXAMPLES=OFF \\-D BUILD_EXAMPLES=OFF \\-D PYTHON_DEFAULT_EXECUTABLE=/usr/bin/python3 \\-D BUILD_opencv_python3=yes \\-D BUILD_opencv_python2=no \\-D PYTHON3_EXECUTABLE=/usr/bin/python3 \\-D PYTHON3_INCLUDE_DIR=/usr/include/python3.8 \\-D PYTHON3_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.8.so \\-D PYTHON3_NUMPY_INCLUDE_DIRS=/usr/local/lib/python3.8/dist-packages/numpy/core/include/ \\-D BUILD_SHARED_LIBS=OFF \\.. (2)构建动态库 1234567891011121314151617181920cmake -D CMAKE_INSTALL_PREFIX=/usr/local \\-D CMAKE_BUILD_TYPE=Release \\-D OPENCV_GENERATE_PKGCONFIG=ON \\-D WITH_QUIRC=ON \\-D OPENCV_ENABLE_NONFREE=True \\-D OPENCV_GENERATE_PKGCONFIG=YES \\-D WITH_OPENGL=ON \\-D ENABLE_CXX11=1 \\-D WITH_OPENMP=ON \\-D WITH_1394=OFF \\-D INSTALL_C_EXAMPLES=OFF \\-D BUILD_EXAMPLES=OFF \\-D PYTHON_DEFAULT_EXECUTABLE=/usr/bin/python3 \\-D BUILD_opencv_python3=yes \\-D BUILD_opencv_python2=no \\-D PYTHON3_EXECUTABLE=/usr/bin/python3 \\-D PYTHON3_INCLUDE_DIR=/usr/include/python3.8 \\-D PYTHON3_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.8.so \\-D PYTHON3_NUMPY_INCLUDE_DIRS=/usr/local/lib/python3.8/dist-packages/numpy/core/include/ \\.. -D CMAKE_INSTALL_PREFIX=/usr/local: 指定安装目录为/usr/local，生成的库和可执行文件将安装到该目录下。 -D CMAKE_BUILD_TYPE=Release: 指定构建类型为”Release”，这意味着生成的库将进行优化，并且不包含调试信息。 -D OPENCV_GENERATE_PKGCONFIG=ON: 生成用于pkg-config的OpenCV配置文件，这样其他程序可以使用pkg-config来查找和链接OpenCV库。 -D WITH_QUIRC=ON: 启用QUIRC支持，QUIRC是用于解码二维条码（如QR码）的库。通过这个参数，编译生成的OpenCV库将包含QUIRC功能。 -D OPENCV_ENABLE_NONFREE=True: 启用非免费模块，这些模块可能包含受限制的功能，需要购买或获取许可证才能使用。 -D OPENCV_GENERATE_PKGCONFIG=YES: 生成用于pkg-config的OpenCV配置文件，这样其他程序可以使用pkg-config来查找和链接OpenCV库。 -D WITH_OPENGL=ON: 启用OpenGL支持，用于与OpenGL相关的功能。 -D ENABLE_CXX11=1: 启用C++11标准支持。 -D WITH_OPENMP=ON: 启用OpenMP多线程支持。 -D WITH_1394=OFF: 禁用IEEE 1394（FireWire）支持。 -D INSTALL_C_EXAMPLES=OFF: 禁用C语言示例的安装。 -D BUILD_EXAMPLES=OFF: 禁用构建示例程序。 -D PYTHON_DEFAULT_EXECUTABLE=/usr/bin/python3: 指定默认的Python解释器路径为/usr/bin/python3，这将用于与Python相关的构建和安装操作 -D BUILD_opencv_python3=yes: 启用构建OpenCV的Python 3绑定。 -D BUILD_opencv_python2=no: 禁用构建OpenCV的Python 2绑定。 -D PYTHON3_EXECUTABLE=/usr/bin/python3: 指定Python 3解释器的路径为/usr/bin/python3。 -D PYTHON3_INCLUDE_DIR=/usr/include/python3.8: 指定Python 3的头文件目录的路径为/usr/include/python3.8，这里需要提供Python 3的开发包路径，具体版本号可能会有所不同。 -D PYTHON3_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.8.so: 指定Python 3的库文件路径为/usr/lib/x86_64-linux-gnu/libpython3.8.so，这里需要提供Python 3的动态链接库文件路径，具体路径和文件名可能会有所不同。 -D PYTHON_DEFAULT_EXECUTABLE=/usr/bin/python3: 指定默认的Python解释器路径为/usr/bin/python3，这将用于与Python相关的构建和安装操作。-D PYTHON_DEFAULT_EXECUTABLE=/usr/bin/python3: 指定默认的Python解释器路径为/usr/bin/python3，这将用于与Python相关的构建和安装操作。 ==注意：在CMake中，使用-D参数来定义变量。每个参数开头的-D表示要定义一个CMake变量，并为其赋予特定的值== 然后进行编译安装 12make -j32sudo make install 我这电脑还是很快的，两分钟吧也就，还是家里的电脑好呀 ​ 最后拷贝和链接python库（==这一步必须做，否则在使用的时候会找不到cv2这个模块==） 12cp lib/python3/cv2.cpython-38-x86_64-linux-gnu.so /usr/local/lib/python3.8/dist-packages/sudo ln -s /usr/local/lib/python3.8/dist-packages/cv2.cpython-38-x86_64-linux-gnu.so /usr/lib/python3/dist-packages/cv2.so 然后进行简单的测试： 1234pythonimport cv2cv2.__version__ 然后测试一个opencv的C++程序 首先创建三个目录build install src 1mkdir -p build install src 然后在src目录下创建测试例程demo.cpp,然后向该文件中添加以下程序： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &quot;opencv2/core/core.hpp&quot; #include &quot;opencv2/highgui/highgui.hpp&quot;#include &quot;opencv2/imgproc/imgproc.hpp&quot;#include &lt;iostream&gt;using namespace cv;using namespace std;int main(){ VideoCapture capture(0); if (!capture.isOpened()) { // 如果无法打开摄像头，则输出提示信息 cout &lt;&lt; &quot;无法打开摄像头&quot; &lt;&lt; endl; return -1; } double time0 = static_cast&lt;double&gt;(getTickCount()); // 获取开始时间 while (true) { // 从摄像头捕获帧 Mat frame; capture &gt;&gt; frame; // 如果捕获到帧，则显示它 if (!frame.empty()) { cvtColor(frame, frame, COLOR_RGB2BGR); double time1 = static_cast&lt;double&gt;(getTickCount()); // 获取结束时间 double fps = getTickFrequency() / (time1 - time0); // 计算实时帧率 time0 = time1; // 更新开始时间 putText(frame, &quot;FPS: &quot; + to_string(fps), Point(10, 30), FONT_HERSHEY_SIMPLEX, 1, Scalar(0, 0, 255), 2); // 在图像上显示帧率 imshow(&quot;MIPI Camera&quot;, frame); } // 按下'q'键退出循环 if (waitKey(1) == 'q') { break; } } // 释放资源并关闭窗口 capture.release(); destroyAllWindows(); return 0;} 然后创建cmake的配置文件CMakeLists.txt，添加内容如下所示： 123456789101112131415161718192021222324252627cmake_minimum_required(VERSION 3.4.1)# 设置项目名称为 opencv_demoproject(opencv_demo)# 设置 C++ 标准为 11，并且要求编译器支持该标准set(CMAKE_CXX_STANDARD 11)set(CMAKE_CXX_STANDARD_REQUIRED ON)# 查找并引入 OpenCVfind_package(OpenCV REQUIRED)# 添加可执行文件 opencv_demo，源文件为 src/demo.cppadd_executable(opencv_demo src/demo.cpp)# 链接 OpenCV 库target_link_libraries(opencv_demo ${OpenCV_LIBS})# 设置安装目录为 ./install/操作系统名set(CMAKE_INSTALL_PREFIX ${CMAKE_SOURCE_DIR}/install/${CMAKE_SYSTEM_NAME})# 安装可执行文件 opencv_demo 到指定目录install(TARGETS opencv_demo DESTINATION ./) 然后进入build目录，执行以下命令，进行配置、编译和安装三个步骤： 1234cd build/cmake ../make make install 在install/Linux目录下就生成了测试APP opencv_demo 然后接一个摄像头进行测试，测试功能正常： 至此，opencv在PC机的编译就完成了。 3.交叉编译（qemu）上面编译的其实都是在X86上编译的一些个版本，而这里将编译开发板的版本，本来想的是交叉编译呀，可是后来我一想，我有qemu呀，我还交叉编译啥呀，完全不需要呀，完全忘记了qemu还有这个~。 首先解压一下开发板ubuntu20的源码，解压完成如下所示： ​ 然后创建一个名为mount.sh的挂载脚本，该脚本的作用是挂载ubuntu并qemu 123456789101112131415161718192021222324252627282930313233343536373839#!/bin/bashfunction mnt() { echo &quot;MOUNTING&quot; sudo mount -t proc /proc ${2}proc sudo mount -t sysfs /sys ${2}sys sudo mount -o bind /dev ${2}dev sudo mount -B /dev/pts ${2}dev/pts sudo chroot ${2} /bin/sh}function umnt() { echo &quot;UNMOUNTING&quot; sudo umount ${2}proc sudo umount ${2}sys sudo umount ${2}dev/pts sudo umount ${2}dev}if [ &quot;$1&quot; == &quot;-m&quot; ] &amp;&amp; [ -n &quot;$2&quot; ] ;then mnt $1 $2elif [ &quot;$1&quot; == &quot;-u&quot; ] &amp;&amp; [ -n &quot;$2&quot; ];then umnt $1 $2else echo &quot;&quot; echo &quot;Either 1'st, 2'nd or both parameters were missing&quot; echo &quot;&quot; echo &quot;1'st parameter can be one of these: -m(mount) OR -u(umount)&quot; echo &quot;2'nd parameter is the full path of rootfs directory(with trailing '/')&quot; echo &quot;&quot; echo &quot;For example: ch-mount -m /media/sdcard/&quot; echo &quot;&quot; echo 1st parameter : ${1} echo 2nd parameter : ${2}fi 然后这样进行挂载： 1./mount.sh -m ubuntu/ 我这里首先更新了一下软件源，然后就是安装一些依赖，就跟上面在PC上安装依赖的方法相同。 12345678910sudo apt-get install build-essential sudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-devsudo apt-get install python-dev-is-python2 python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libdc1394-22-devpip3 install numpy sudo update-alternatives --install /usr/bin/python python /usr/bin/python2 100sudo update-alternatives --install /usr/bin/python python /usr/bin/python3 150 然后将opencv源码拷贝到qumu的uubntu目录下，如下图所示： 然后进行opencv源码的解压： 1unzip opencv-4.8.0.zip 然后在opencv源码目录下创建一个build目录进行工程 12mkdir buildcd build 构建命令如下所示： (1) 构建静态库 123456789101112131415161718192021cmake -D CMAKE_INSTALL_PREFIX=../install \\-D CMAKE_BUILD_TYPE=Release \\-D OPENCV_GENERATE_PKGCONFIG=ON \\-D WITH_QUIRC=ON \\-D OPENCV_ENABLE_NONFREE=True \\-D OPENCV_GENERATE_PKGCONFIG=YES \\-D WITH_OPENGL=ON \\-D ENABLE_CXX11=1 \\-D WITH_OPENMP=ON \\-D WITH_1394=OFF \\-D INSTALL_C_EXAMPLES=OFF \\-D BUILD_EXAMPLES=OFF \\-D PYTHON_DEFAULT_EXECUTABLE=/usr/bin/python3 \\-D BUILD_opencv_python3=yes \\-D BUILD_opencv_python2=no \\-D PYTHON3_EXECUTABLE=/usr/bin/python3 \\-D PYTHON3_INCLUDE_DIR=/usr/include/python3.8 \\-D PYTHON3_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.8.so \\-D PYTHON3_NUMPY_INCLUDE_DIRS=/usr/local/lib/python3.8/dist-packages/numpy/core/include/ \\-D BUILD_SHARED_LIBS=OFF \\.. 由于这里只是想要得到他的库，所以这里就不安装到usr/local目录下了 (2)构建动态库 1234567891011121314151617181920cmake -D CMAKE_INSTALL_PREFIX=../install \\-D CMAKE_BUILD_TYPE=Release \\-D OPENCV_GENERATE_PKGCONFIG=ON \\-D WITH_QUIRC=ON \\-D OPENCV_ENABLE_NONFREE=True \\-D OPENCV_GENERATE_PKGCONFIG=YES \\-D WITH_OPENGL=ON \\-D ENABLE_CXX11=1 \\-D WITH_OPENMP=ON \\-D WITH_1394=OFF \\-D INSTALL_C_EXAMPLES=OFF \\-D BUILD_EXAMPLES=OFF \\-D PYTHON_DEFAULT_EXECUTABLE=/usr/bin/python3 \\-D BUILD_opencv_python3=yes \\-D BUILD_opencv_python2=no \\-D PYTHON3_EXECUTABLE=/usr/bin/python3 \\-D PYTHON3_INCLUDE_DIR=/usr/include/python3.8 \\-D PYTHON3_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.8.so \\-D PYTHON3_NUMPY_INCLUDE_DIRS=/usr/local/lib/python3.8/dist-packages/numpy/core/include/ \\.. 由于这里只是想要得到他的库，所以这里就不安装到usr/local目录下了 -D CMAKE_INSTALL_PREFIX=/usr/local: 指定安装目录为/usr/local，生成的库和可执行文件将安装到该目录下。 -D CMAKE_BUILD_TYPE=Release: 指定构建类型为”Release”，这意味着生成的库将进行优化，并且不包含调试信息。 -D OPENCV_GENERATE_PKGCONFIG=ON: 生成用于pkg-config的OpenCV配置文件，这样其他程序可以使用pkg-config来查找和链接OpenCV库。 -D WITH_QUIRC=ON: 启用QUIRC支持，QUIRC是用于解码二维条码（如QR码）的库。通过这个参数，编译生成的OpenCV库将包含QUIRC功能。 -D OPENCV_ENABLE_NONFREE=True: 启用非免费模块，这些模块可能包含受限制的功能，需要购买或获取许可证才能使用。 -D OPENCV_GENERATE_PKGCONFIG=YES: 生成用于pkg-config的OpenCV配置文件，这样其他程序可以使用pkg-config来查找和链接OpenCV库。 -D WITH_OPENGL=ON: 启用OpenGL支持，用于与OpenGL相关的功能。 -D ENABLE_CXX11=1: 启用C++11标准支持。 -D WITH_OPENMP=ON: 启用OpenMP多线程支持。 -D WITH_1394=OFF: 禁用IEEE 1394（FireWire）支持。 -D INSTALL_C_EXAMPLES=OFF: 禁用C语言示例的安装。 -D BUILD_EXAMPLES=OFF: 禁用构建示例程序。 -D PYTHON_DEFAULT_EXECUTABLE=/usr/bin/python3: 指定默认的Python解释器路径为/usr/bin/python3，这将用于与Python相关的构建和安装操作 -D BUILD_opencv_python3=yes: 启用构建OpenCV的Python 3绑定。 -D BUILD_opencv_python2=no: 禁用构建OpenCV的Python 2绑定。 -D PYTHON3_EXECUTABLE=/usr/bin/python3: 指定Python 3解释器的路径为/usr/bin/python3。 -D PYTHON3_INCLUDE_DIR=/usr/include/python3.8: 指定Python 3的头文件目录的路径为/usr/include/python3.8，这里需要提供Python 3的开发包路径，具体版本号可能会有所不同。 -D PYTHON3_LIBRARY=/usr/lib/x86_64-linux-gnu/libpython3.8.so: 指定Python 3的库文件路径为/usr/lib/x86_64-linux-gnu/libpython3.8.so，这里需要提供Python 3的动态链接库文件路径，具体路径和文件名可能会有所不同。 -D PYTHON_DEFAULT_EXECUTABLE=/usr/bin/python3: 指定默认的Python解释器路径为/usr/bin/python3，这将用于与Python相关的构建和安装操作。-D PYTHON_DEFAULT_EXECUTABLE=/usr/bin/python3: 指定默认的Python解释器路径为/usr/bin/python3，这将用于与Python相关的构建和安装操作。 ==注意：在CMake中，使用-D参数来定义变量。每个参数开头的-D表示要定义一个CMake变量，并为其赋予特定的值== 12make -j32sudo make install 虽然是qemu，但是用的仍旧是PC的CPU，但是这个速度是真的慢呀，但我看CPU都跑满了呀~~竟然搞了三十分钟~ ​ 最后拷贝和链接python库（==这一步必须做，否则在使用的时候会找不到cv2这个模块==） 12cp lib/python3/cv2.cpython-38-aarch64-linux-gnu.so ../install/lib/python3.8/site-packages/ln -s /usr/local/lib/python3.8/dist-packages/cv2.cpython-38-aarch64-linux-gnu.so /usr/lib/python3/dist-packages/cv2.so 然后进行简单的测试： 1234pythonimport cv2cv2.__version__ 然后测试一个opencv的C++程序 首先创建三个目录build install src 1mkdir -p build install src 然后在src目录下创建测试例程demo.cpp,然后向该文件中添加以下程序： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &quot;opencv2/core/core.hpp&quot; #include &quot;opencv2/highgui/highgui.hpp&quot;#include &quot;opencv2/imgproc/imgproc.hpp&quot;#include &lt;iostream&gt;using namespace cv;using namespace std;int main(){ VideoCapture capture(0); if (!capture.isOpened()) { // 如果无法打开摄像头，则输出提示信息 cout &lt;&lt; &quot;无法打开摄像头&quot; &lt;&lt; endl; return -1; } double time0 = static_cast&lt;double&gt;(getTickCount()); // 获取开始时间 while (true) { // 从摄像头捕获帧 Mat frame; capture &gt;&gt; frame; // 如果捕获到帧，则显示它 if (!frame.empty()) { cvtColor(frame, frame, COLOR_RGB2BGR); double time1 = static_cast&lt;double&gt;(getTickCount()); // 获取结束时间 double fps = getTickFrequency() / (time1 - time0); // 计算实时帧率 time0 = time1; // 更新开始时间 putText(frame, &quot;FPS: &quot; + to_string(fps), Point(10, 30), FONT_HERSHEY_SIMPLEX, 1, Scalar(0, 0, 255), 2); // 在图像上显示帧率 imshow(&quot;MIPI Camera&quot;, frame); } // 按下'q'键退出循环 if (waitKey(1) == 'q') { break; } } // 释放资源并关闭窗口 capture.release(); destroyAllWindows(); return 0;} 然后创建cmake的配置文件CMakeLists.txt，添加内容如下所示： 123456789101112131415161718192021222324252627cmake_minimum_required(VERSION 3.4.1)# 设置项目名称为 opencv_demoproject(opencv_demo)# 设置 C++ 标准为 11，并且要求编译器支持该标准set(CMAKE_CXX_STANDARD 11)set(CMAKE_CXX_STANDARD_REQUIRED ON)# 查找并引入 OpenCVfind_package(OpenCV REQUIRED)# 添加可执行文件 opencv_demo，源文件为 src/demo.cppadd_executable(opencv_demo src/demo.cpp)# 链接 OpenCV 库target_link_libraries(opencv_demo ${OpenCV_LIBS})# 设置安装目录为 ./install/操作系统名set(CMAKE_INSTALL_PREFIX ${CMAKE_SOURCE_DIR}/install/${CMAKE_SYSTEM_NAME})# 安装可执行文件 opencv_demo 到指定目录install(TARGETS opencv_demo DESTINATION ./) 然后进入build目录，执行以下命令，进行配置、编译和安装三个步骤（==这里由于我是将opencv的库和头文件等放到了上一级的install目录，所以这里可能要修改一下CmakeLists，但也还好==）： 1234cd build/cmake ../make make install 至此，opencv qemu编译就完成了。 4.vscode 配置python4.1.下载VScode附上官网地址：Visual Studio Code - Code Editing. Redefined 4.2.在vs安装python插件这个很简单，我就不再截图了。 4.3.配置python环境python官网：Welcome to Python.org 虽然已经到了3.12的版本，但这个随意了，我认为无所谓。 然后打开一个shell终端，发现运行python之后没什么问题，如下图所示： 然后安装两个包： 1pip install flake8 yapf -i https://pypi.tuna.tsinghua.edu.cn/simple flake8会检查编写代码时的不规范的地方和语法错误。 yapf是一个代码格式化工具，可以一键美化代码。Shift + Alt + F一键美化代码 一定要在python目录下才可以，难道我需要再添加一下路径吗，很奇怪反正~~。 4.4选择python解释器打开VScode，点击左上角，文件-&gt;首选项-&gt;设置 然后打开界面右上角的箭头纸张这就是json设置 然后将下面代码替换里面的内容，第一行即为python所在路径。记得在路径多加 \\ 123456789101112131415{ &quot;python.PYTHONPATH&quot;:&quot;D:\\\\Python\\\\Python312&quot;, &quot;python.linting.flake8Enabled&quot;: true, &quot;editor.formatOnSave&quot;: true, &quot;python.formatting.provider&quot;: &quot;yapf&quot;, &quot;python.formatting.yapfArgs&quot;: [ &quot;--style={based_on_style: pep8, indent_width: 4}&quot; ], &quot;python.linting.flake8Args&quot;: [&quot;--max-line-length=248&quot;], &quot;python.linting.pylintEnabled&quot;: false, &quot;explorer.confirmDelete&quot;: false, &quot;[python]&quot;: { &quot;editor.formatOnType&quot;: true }} 之后保存即可，就可以在python文件中使用Shift + Alt + F来格式化你的代码啦。 测试可用： 5 windows c++环境的配置5.1 Visual Studio Code相关信息 Visual Studio Code 下载地址：https://code.visualstudio.com/download VS Code建议安装插件列表： 中文菜单： MS-CEINTL.vscode-language-pack-zh-hans SSH远程开发： ms-vscode-remote.remote-ssh ms-vscode-remote.remote-ssh-edit ms-vscode.remote-explorer C++开发 ms-vscode.cpptools 代码补全 TabNine.tabnine-vscode GitHub.copilot 5.2下载安装g++==具体可以看1.2.1小节== 5.3配置调试功能首先大家在一个你希望的位置建一个文件夹，随意起名就可以（注意不可以用中文！），以后的C/C++代码文件都要放在这个文件夹里才可以正常调试。 然后进入VSCode,点击Open Folder或者点击左上角File -&gt; Open Folder，然后打开刚刚建的文件夹，选择信任父级文件夹点击这个图标新建一个文件夹，命名为.vscode（注意必须是这个名字！） 创建完成后再点击这个图标新建四个文件，文件名分别是 1234//c_cpp_properties.json//launch.json//settings.json//tasks.json 接下来复制粘贴这四个文件的内容 首先是c_cpp_properties.json 123456789101112131415161718192021{ &quot;configurations&quot;: [ { &quot;name&quot;: &quot;Win64&quot;, &quot;includePath&quot;: [ &quot;${workspaceFolder}/**&quot; ], &quot;defines&quot;: [ &quot;_DEBUG&quot;, &quot;UNICODE&quot;, &quot;_UNICODE&quot; ], &quot;windowsSdkVersion&quot;: &quot;10.0.18362.0&quot;, &quot;compilerPath&quot;: &quot;D:/mingw64/bin/gcc.exe&quot;, &quot;cStandard&quot;: &quot;c17&quot;, &quot;cppStandard&quot;: &quot;c++17&quot;, &quot;intelliSenseMode&quot;: &quot;gcc-x64&quot; } ], &quot;version&quot;: 4} 注意compilerPath这一项要把路径改成刚才g++的安装路径：找到刚刚的安装文件夹-&gt;MinGW-&gt;bin-&gt;g++,exe ,然后复制或者手动把g++.exe的路径敲上去，格式要跟上面代码段一样 然后是launch.json 1234567891011121314151617181920212223242526{ &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ { &quot;name&quot;: &quot;(gdb) Launch&quot;, &quot;type&quot;: &quot;cppdbg&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;${fileDirname}\\\\${fileBasenameNoExtension}.exe&quot;, &quot;args&quot;: [], &quot;stopAtEntry&quot;: false, &quot;cwd&quot;: &quot;${workspaceRoot}&quot;, &quot;environment&quot;: [], &quot;externalConsole&quot;: true, &quot;MIMode&quot;: &quot;gdb&quot;, &quot;miDebuggerPath&quot;: &quot;D:\\\\mingw64\\\\bin\\\\gdb.exe&quot;, &quot;preLaunchTask&quot;: &quot;g++&quot;, &quot;setupCommands&quot;: [ { &quot;description&quot;: &quot;Enable pretty-printing for gdb&quot;, &quot;text&quot;: &quot;-enable-pretty-printing&quot;, &quot;ignoreFailures&quot;: true } ] } ]} 注意miDebuggerPath这一项也要把路径改成刚才g++的安装路径：找到刚刚的安装文件夹-&gt;MinGW-&gt;bin-&gt;gdb,exe ,然后复制或者手动把gdb.exe的路径敲上去，格式要跟上面代码段一样 接下来是settings.json 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667{ &quot;files.associations&quot;: { &quot;*.py&quot;: &quot;python&quot;, &quot;iostream&quot;: &quot;cpp&quot;, &quot;*.tcc&quot;: &quot;cpp&quot;, &quot;string&quot;: &quot;cpp&quot;, &quot;unordered_map&quot;: &quot;cpp&quot;, &quot;vector&quot;: &quot;cpp&quot;, &quot;ostream&quot;: &quot;cpp&quot;, &quot;new&quot;: &quot;cpp&quot;, &quot;typeinfo&quot;: &quot;cpp&quot;, &quot;deque&quot;: &quot;cpp&quot;, &quot;initializer_list&quot;: &quot;cpp&quot;, &quot;iosfwd&quot;: &quot;cpp&quot;, &quot;fstream&quot;: &quot;cpp&quot;, &quot;sstream&quot;: &quot;cpp&quot;, &quot;map&quot;: &quot;c&quot;, &quot;stdio.h&quot;: &quot;c&quot;, &quot;algorithm&quot;: &quot;cpp&quot;, &quot;atomic&quot;: &quot;cpp&quot;, &quot;bit&quot;: &quot;cpp&quot;, &quot;cctype&quot;: &quot;cpp&quot;, &quot;clocale&quot;: &quot;cpp&quot;, &quot;cmath&quot;: &quot;cpp&quot;, &quot;compare&quot;: &quot;cpp&quot;, &quot;concepts&quot;: &quot;cpp&quot;, &quot;cstddef&quot;: &quot;cpp&quot;, &quot;cstdint&quot;: &quot;cpp&quot;, &quot;cstdio&quot;: &quot;cpp&quot;, &quot;cstdlib&quot;: &quot;cpp&quot;, &quot;cstring&quot;: &quot;cpp&quot;, &quot;ctime&quot;: &quot;cpp&quot;, &quot;cwchar&quot;: &quot;cpp&quot;, &quot;exception&quot;: &quot;cpp&quot;, &quot;ios&quot;: &quot;cpp&quot;, &quot;istream&quot;: &quot;cpp&quot;, &quot;iterator&quot;: &quot;cpp&quot;, &quot;limits&quot;: &quot;cpp&quot;, &quot;memory&quot;: &quot;cpp&quot;, &quot;random&quot;: &quot;cpp&quot;, &quot;set&quot;: &quot;cpp&quot;, &quot;stack&quot;: &quot;cpp&quot;, &quot;stdexcept&quot;: &quot;cpp&quot;, &quot;streambuf&quot;: &quot;cpp&quot;, &quot;system_error&quot;: &quot;cpp&quot;, &quot;tuple&quot;: &quot;cpp&quot;, &quot;type_traits&quot;: &quot;cpp&quot;, &quot;utility&quot;: &quot;cpp&quot;, &quot;xfacet&quot;: &quot;cpp&quot;, &quot;xiosbase&quot;: &quot;cpp&quot;, &quot;xlocale&quot;: &quot;cpp&quot;, &quot;xlocinfo&quot;: &quot;cpp&quot;, &quot;xlocnum&quot;: &quot;cpp&quot;, &quot;xmemory&quot;: &quot;cpp&quot;, &quot;xstddef&quot;: &quot;cpp&quot;, &quot;xstring&quot;: &quot;cpp&quot;, &quot;xtr1common&quot;: &quot;cpp&quot;, &quot;xtree&quot;: &quot;cpp&quot;, &quot;xutility&quot;: &quot;cpp&quot;, &quot;stdlib.h&quot;: &quot;c&quot;, &quot;string.h&quot;: &quot;c&quot; }, &quot;editor.suggest.snippetsPreventQuickSuggestions&quot;: false, &quot;aiXcoder.showTrayIcon&quot;: true} 最后是tasks.json 12345678910111213141516171819202122232425262728293031{ &quot;version&quot;: &quot;2.0.0&quot;, &quot;tasks&quot;: [ { &quot;label&quot;: &quot;g++&quot;, &quot;command&quot;: &quot;g++&quot;, &quot;args&quot;: [ &quot;-g&quot;, &quot;${file}&quot;, &quot;-o&quot;, &quot;${fileDirname}/${fileBasenameNoExtension}.exe&quot; ], &quot;problemMatcher&quot;: { &quot;owner&quot;: &quot;cpp&quot;, &quot;fileLocation&quot;: [&quot;relative&quot;, &quot;${workspaceRoot}&quot;], &quot;pattern&quot;: { &quot;regexp&quot;: &quot;^(.*):(\\\\d+):(\\\\d+):\\\\s+(warning|error):\\\\s+(.*)$&quot;, &quot;file&quot;: 1, &quot;line&quot;: 2, &quot;column&quot;: 3, &quot;severity&quot;: 4, &quot;message&quot;: 5 } }, &quot;group&quot;: { &quot;kind&quot;: &quot;build&quot;, &quot;isDefault&quot;: true } } ]} 保存这四个文件就配置完成了！ 再次强调：以后的C/C++代码文件必须放在这个Code文件夹里，或者说有.vscode文件夹的文件夹里，如果调试放在其他位置的代码文件会报错！ 测试完成如下所示： 6.opencv的学习6.1 读取图片并显示12345678910111213141516171819202122232425262728293031323334353637// 图片的读取和显示// 导入opencv头文件#include &quot;opencv2/opencv.hpp&quot;#include &lt;iostream&gt;int main(int argc, char **argv){ // 读取图片，mat是matrix的缩写，是一个矩阵，类似与numpy ndarray cv::Mat image = cv::imread(&quot;E:\\\\05_opencv\\\\work\\\\src\\\\cat.jpg&quot;); // 判断是否读取成功 if (image.empty()) { std::cout &lt;&lt; &quot;无法读取图片 &quot; &lt;&lt; std::endl; return 1; } // 打印图片高度和宽度 std::cout &lt;&lt; &quot;图片高度: &quot; &lt;&lt; image.rows &lt;&lt; &quot; 宽度: &quot; &lt;&lt; image.cols &lt;&lt; std::endl; // 打印图片data // 以Numpy的方式打印 // std::cout &lt;&lt; &quot;图片data: &quot; &lt;&lt; cv::format(image, cv::Formatter::FMT_NUMPY) &lt;&lt; std::endl; // 以python list的方式打印 // std::cout &lt;&lt; &quot;图片data: &quot; &lt;&lt; cv::format(image, cv::Formatter::FMT_PYTHON) &lt;&lt; std::endl; // 创建一个灰度图 cv::Mat gray; // 转换为灰度图 cv::cvtColor(image, gray, cv::COLOR_BGR2GRAY); // 保存 cv::imwrite(&quot;gray.jpg&quot;, gray); // 显示 cv::imshow(&quot;原图&quot;, image); cv::imshow(&quot;灰度图&quot;, gray); // 等待按键 cv::waitKey(0);} 遇到的第一个问题，第9行的路径问题，在windows目录下必须要使用两个\\不知道这是为啥 在Windows目录中，反斜杠 \\ 是用作路径分隔符。然而，反斜杠在C++中被用作转义字符，用于表示特殊字符序列。因此，如果您想在字符串中使用反斜杠作为路径分隔符，您需要使用双反斜杠 \\\\ 来表示一个单独的反斜杠。 这是因为一个反斜杠 \\ 表示一个转义字符的开始，例如 \\n 表示换行符。为了在字符串中表示一个反斜杠字符本身，您需要使用两个连续的反斜杠 \\\\ 来转义它，告诉编译器它是一个普通的反斜杠字符。 没有自动补全，重新确定一下插件：1)、C/C++，这个肯定是必须的。 2)、C/C++ Snippets，即 C/C++重用代码块。 3)、C/C++ Advanced Lint,即 C/C++静态检测 。 4)、Code Runner，即代码运行。 5)、Include AutoComplete，即自动头文件包含。 6)、Rainbow Brackets，彩虹花括号，有助于阅读代码。 7)、One Dark Pro，VSCode 的主题。 8)、GBKtoUTF8，将 GBK 转换为 UTF8。 9)、ARM，即支持 ARM 汇编语法高亮显示。 10)、Chinese(Simplified)，即中文环境。 11)、vscode-icons，VSCode 图标插件，主要是资源管理器下各个文件夹的图标。 12)、compareit，比较插件，可以用于比较两个文件的差异。 13)、DeviceTree，设备树语法插件。 14)、CMake Tools Cmake 工具 ==还是不能补全，不知道为啥windows的环境会这样，这样下去可不行，问题该解决的当然还是要解决的，遇到问题解决问题== 上面这个案例有以下几个重点我来回顾一下 头文件 一般情况下使用c++和opencv都会包含上面提到的两个头文件，也就是&lt;opencv2/opencv.hpp&gt;和这两个头文件。 &lt;opencv/opencv.hpp&gt;中包含了一些opencv中的常用函数，就比如imread、imwrite、imshow、waitkey、cvtColor等等，而中存放的是c++中的一些常用函数，就比如cout输出等等。 工作区using namespace 如果是我一般写C语言的话，我都会写上工作区，但是老师给的这些示例代码并没有，而是直接使用的就比如cv::imread() std::cout这些，都是在前加上工作去，然后再引用的，这样的好处应该是防止混乱引用，目前我还没遇到这个情况，这个以后再说。 opencv图像的格式Mat 没记错的话这个Mat格式用来存放的是RGB三原色每个像素的值 相关函数的使用 cv::imread 两个参数，第一个参数为要读取图片的路径、第二个参数为flag标志位我记得是0 1 -1，这三个最常用，其中0代表灰度值，1代表彩色。 cv::imwrite 这个是用来写入的，其实跟读取的使用方法一样，也是两个参数，其中第一个参数为要保存的图片名称，第二个参数为图片的数据，没有数据你只保存名字那肯定不行呀。 cv::imshow 从名字可以看出来这是图片的展示，有两个参数，第一个参数为展示图片的框的名称，第二个参数为图片数据，同理，你只显示框的名称，但是没有数据拿什么也显示不出来呀，我说的对吗. cv::cvtColor 这个函数是用来进行颜色通道转换的，就比如从RGB转换为BGR等等，你可以思考一下应该有几个参数，你看要转换肯定要有一个原始数据对吧，然后肯定有一个输出数据对吧，最后必然要有一个如何转换对吧，所以必要填写的是三个参数。 最后是cv::waitKey(0)这个函数的意义是让图片一直显示，直到按下一个按键。 6.2 读取视频并显示123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 导入opencv 库#include &lt;opencv2/opencv.hpp&gt;#include &lt;iostream&gt;// 导入gflags 库#include &lt;gflags/gflags.h&gt;// 定义命令行参数DEFINE_string(video, &quot;./media/dog.mp4&quot;, &quot;Input video&quot;); // 视频路径int main(int argc, char **argv){ // 解析命令行参数 gflags::ParseCommandLineFlags(&amp;argc, &amp;argv, true); // 读取视频：创建了一个VideoCapture对象，参数为视频路径 cv::VideoCapture capture(FLAGS_video); // 判断视频是否读取成功，返回true表示成功 if (!capture.isOpened()) { std::cout &lt;&lt; &quot;无法读取视频: &quot; &lt;&lt; FLAGS_video &lt;&lt; std::endl; return 1; } // 读取视频帧，使用Mat类型的frame存储返回的帧 cv::Mat frame; // 灰度图 cv::Mat gray_frame; // 循环读取视频帧 while (true) { // 读取视频帧，使用 &gt;&gt; 运算符或者read()函数，他的参数是返回的帧 capture.read(frame); // capture &gt;&gt; frame; // 判断是否读取成功 if (frame.empty()) { std::cout &lt;&lt; &quot;文件读取完毕&quot; &lt;&lt; std::endl; break; } // 转成灰度图 cv::cvtColor(frame, gray_frame, cv::COLOR_BGR2GRAY); // 显示视频帧 cv::imshow(&quot;raw frame&quot;, frame); cv::imshow(&quot;gray frame&quot;, gray_frame); // 等待按键，延迟30ms，否则视频播放太快 int k = cv::waitKey(30); // 按下ESC键退出 if (k == 27) { std::cout &lt;&lt; &quot;退出&quot; &lt;&lt; std::endl; break; } } return 0;} 重点1：VideoCapture类 ​ 就跟上一个小节讲解的Mat一样，可以看到VideoCapture的第一个字母也大写了，所以他也是一个opencv中的类型，用来存放捕获到的视频，cv::VideoCapture 类的构造函数可以接受不同的参数来指定要打开的视频源： 1.通过设备索引：您可以传递一个整数值作为设备索引来指定要打开的摄像头设备。例如，0 表示默认的摄像头设备，1 表示第二个摄像头设备，以此类推。 1cv::VideoCapture cap(0); // 打开默认的摄像头设备 2.通过视频文件路径：您可以传递一个字符串参数，表示要打开的视频文件的路径。 1cv::VideoCapture cap(&quot;video.mp4&quot;); // 打开名为 &quot;video.mp4&quot; 的视频文件 一旦创建了 cv::VideoCapture 对象，您可以使用 read() 方法来连续读取视频帧。read() 方法将返回一个布尔值，指示是否成功读取了一帧图像。 12345678910cv::Mat frame;while (cap.read(frame)) { // 处理当前帧 cv::imshow(&quot;Video&quot;, frame); // 等待按键退出 if (cv::waitKey(1) == 'q') { break; }}","link":"/2023/12/09/11-opencv%E7%9A%84%E5%AD%A6%E4%B9%A0/"},{"title":"ubuntu和debian源","text":"ubuntu20 123456789101112131415deb https://repo.huaweicloud.com/ubuntu-ports/ focal main restricted universe multiversedeb-src https://repo.huaweicloud.com/ubuntu-ports/ focal main restricted universe multiversedeb https://repo.huaweicloud.com/ubuntu-ports/ focal-security main restricted universe multiversedeb-src https://repo.huaweicloud.com/ubuntu-ports/ focal-security main restricted universe multiversedeb https://repo.huaweicloud.com/ubuntu-ports/ focal-updates main restricted universe multiversedeb-src https://repo.huaweicloud.com/ubuntu-ports/ focal-updates main restricted universe multiversedeb https://repo.huaweicloud.com/ubuntu-ports/ focal-backports main restricted universe multiversedeb-src https://repo.huaweicloud.com/ubuntu-ports/ focal-backports main restricted universe multiverse## Not recommended# deb https://repo.huaweicloud.com/ubuntu-ports/ focal-proposed main restricted universe multiverse# deb-src https://repo.huaweicloud.com/ubuntu-ports/ focal-proposed main restricted universe multiverse ubuntu22 123456789101112131415deb https://repo.huaweicloud.com/ubuntu-ports/ jammy main restricted universe multiversedeb-src https://repo.huaweicloud.com/ubuntu-ports/ jammy main restricted universe multiversedeb https://repo.huaweicloud.com/ubuntu-ports/ jammy-updates main restricted universe multiversedeb-src https://repo.huaweicloud.com/ubuntu-ports/ jammy-updates main restricted universe multiversedeb https://repo.huaweicloud.com/ubuntu-ports/ jammy-backports main restricted universe multiversedeb-src https://repo.huaweicloud.com/ubuntu-ports/ jammy-backports main restricted universe multiversedeb https://repo.huaweicloud.com/ubuntu-ports/ jammy-security main restricted universe multiversedeb-src https://repo.huaweicloud.com/ubuntu-ports/ jammy-security main restricted universe multiverse# Not recommended# deb http://ports.ubuntu.com/ubuntu-ports/ jammy-proposed main restricted universe multiverse# deb-src http://ports.ubuntu.com/ubuntu-ports/ jammy-proposed main restricted universe multiverse debian10 12345678deb https://mirrors.huaweicloud.com/repository/debian/ buster main contrib non-freedeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster main contrib non-freedeb https://mirrors.huaweicloud.com/repository/debian/ buster-updates main contrib non-freedeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-updates main contrib non-freedeb https://mirrors.huaweicloud.com/repository/debian/ buster-backports main contrib non-freedeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-backports main contrib non-freedeb https://mirrors.huaweicloud.com/repository/debian-security buster/updates main contrib non-freedeb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security buster/updates main contrib non-free debian11 12345678deb https://mirrors.huaweicloud.com/debian/ bullseye main non-free contribdeb-src https://mirrors.huaweicloud.com/debian/ bullseye main non-free contribdeb https://mirrors.huaweicloud.com/debian-security/ bullseye-security maindeb-src https://mirrors.huaweicloud.com/debian-security/ bullseye-security maindeb https://mirrors.huaweicloud.com/debian/ bullseye-updates main non-free contribdeb-src https://mirrors.huaweicloud.com/debian/ bullseye-updates main non-free contribdeb https://mirrors.huaweicloud.com/debian/ bullseye-backports main non-free contribdeb-src https://mirrors.huaweicloud.com/debian/ bullseye-backports main non-free contrib debian12 12345678deb https://mirrors.huaweicloud.com/debian/ bookworm main non-free non-free-firmware contrib deb-src https://mirrors.huaweicloud.com/debian/ bookworm main non-free non-free-firmware contribdeb https://mirrors.huaweicloud.com/debian-security/ bookworm-security main deb-src https://mirrors.huaweicloud.com/debian-security/ bookworm-security main deb https://mirrors.huaweicloud.com/debian/ bookworm-updates main non-free non-free-firmware contrib deb-src https://mirrors.huaweicloud.com/debian/ bookworm-updates main non-free non-free-firmware contrib deb https://mirrors.huaweicloud.com/debian/ bookworm-backports main non-free non-free-firmware contrib deb-src https://mirrors.huaweicloud.com/debian/ bookworm-backports main non-free non-free-firmware contrib","link":"/2023/12/03/20%20ubuntu%E5%92%8Cdebian%E6%BA%90/"},{"title":"shell脚本学习","text":"一、shell 入门简介1.1 什么是shell什么是shell 网上有很多shell 的概念介绍，其实都很官方化，如果你对linux 命令很熟悉，那么编写shell 就不是一个难事，shell 本质上是 linux 命令，一条一条命令组合在一起，实现某一个目的，就变成了shell脚本。它从一定程度上 减轻了工作量，提高了工作效率。 官方化的shell 介绍 Shell（也称为命令行解释器或命令行外壳）是计算机操作系统中提供与用户交互的一种用户界面。它允许用户通过键入文本命令来与操作系统进行通信和控制。Shell接受用户输入的命令并将其解释为操作系统可以理解和执行的指令。 Shell是一个命令解释器，它可以解释和执行用户输入的命令。它提供了一种方式，使用户能够直接与计算机的操作系统进行交互，而无需依赖图形用户界面（GUI）或其他可视化工具。 Shell的主要功能包括： 命令执行：Shell接受用户输入的命令，并将其传递给操作系统执行。这些命令可以是操作文件、管理进程、执行系统命令、编译代码等。 环境控制：Shell可以设置和管理操作系统的环境变量、路径和其他系统配置。用户可以使用Shell来自定义其工作环境和行为。 脚本编写：Shell提供了一种脚本编写的能力，用户可以编写一系列的命令和操作，以便自动化任务、批处理处理数据、执行复杂的操作流程等。 输入/输出重定向：Shell允许用户将命令的输入和输出重定向到不同的文件或设备。这使得用户可以通过管道（pipe）和重定向（redirection）等技术，将一个命令的输出作为另一个命令的输入，或将输出保存到文件中。 常见的shell 有哪些 Bourne Shell（/usr/bin/sh或/bin/sh） Bourne Again Shell（/bin/bash） C Shell（/usr/bin/csh） K Shell（/usr/bin/ksh） Shell for Root（/sbin/sh） 最常用的shell是Bash，也就是Bourne Again Shell。Bash由于易用和免费，在日常工作中被广泛使用，也是大多数Linux操作系统默认的Shell环境。 1.2 shell 编程注意事项当进行Shell编程时，有一些注意事项需要注意。以下是一些常见的Shell编程注意事项： Shell脚本命名：Shell脚本的文件名通常应该使用英文，可以使用大写或小写字母，并以.sh作为后缀。避免使用特殊符号和空格，以确保脚本的可读性和可执行性。为了清晰明了，建议在命名中体现脚本的功能和用途。 脚本文件的首行：Shell脚本文件的首行应该以#!/bin/bash开头，这是指定脚本使用的Shell解释器为Bash的约定写法。这样操作系统会根据该行指定的解释器来执行脚本。 变量命名：当在Shell脚本中声明变量时，需要遵循一些规则。变量名不能以数字或特殊符号开头，但可以使用下划线。变量名最好使用有意义的、描述性的命名，以便在代码中可以清晰地理解和使用这些变量。避免使用破折号 -，因为它可能会与Shell的参数传递语法产生冲突。 引用变量：在使用变量时，最好将变量用双引号 &quot; 包围起来，以避免由于变量值中的空格或特殊字符而导致的意外行为。例如，使用&quot;$variable&quot;而不是$variable。 文件权限：在使用Shell脚本时，要注意给予脚本文件执行权限。可以使用chmod命令来修改文件权限，使其可执行，例如：chmod +x script.sh。 错误处理：为了编写健壮的Shell脚本，应该考虑错误处理和错误消息的输出。可以使用条件语句和错误处理机制来捕获和处理脚本中可能出现的错误情况。 注释：使用注释来解释代码的作用和逻辑，以提高代码的可读性。在Shell脚本中使用#符号开头的行被视为注释，不会被执行。 调试：在开发过程中，可以使用echo命令输出变量值或调试信息，以帮助跟踪代码执行路径和调试潜在问题。 1.3 第一个shell 脚本 hello world1234567891011121314151617181920# 创建一个Helloword.sh 文件topeet@ubuntu:~/shell$ touch Helloword.sh# 编辑Helloword.sh 文件topeet@ubuntu:~/shell$ vim Helloword.shtopeet@ubuntu:~/shell$ ll Helloword.sh-rw-rw-r-- 1 topeet topeet 31 Dec 3 20:44 Helloword.sh# 赋予执行权限topeet@ubuntu:~/shell$ chmod o+x Helloword.shtopeet@ubuntu:~/shell$ ./Helloword.sh-bash: ./Helloword.sh: Permission deniedtopeet@ubuntu:~/shell$ lsHelloword.sh# 运行helloword.sh 脚本topeet@ubuntu:~/shell$ sudo ./Helloword.sh[sudo] password for topeet: hello worldtopeet@ubuntu:~/shell$ 二、shell 环境变量讲解2.1 shell 变量详解变量是在Shell编程中用于存储数据的一种机制。它们允许我们将值赋给一个名称，并在脚本中引用该名称来获取或修改存储的值。变量可以存储各种类型的数据，例如文本、数字、文件路径等。 在Shell编程中，常见的变量分为以下三种类型： 系统变量：系统变量是由Shell程序或操作系统预先定义的变量，用于提供有关系统环境和配置的信息。这些变量通常以大写字母命名，例如PATH、HOME等。系统变量的值可以在Shell脚本中读取和使用，但通常不允许更改。 环境变量：环境变量是用户定义的变量，它们在整个Shell会话中持久存在，并可以在不同的Shell脚本之间共享。环境变量的值可以在Shell脚本中读取、修改和设置。常见的环境变量包括USER、LANG、PWD等。可以使用export命令将用户变量导出为环境变量，例如export MY_VAR=value。 用户变量：用户变量是在Shell脚本中由用户自行定义的变量。它们用于存储临时数据、中间结果或用户自定义配置。用户变量的名称由用户自行指定，遵循变量命名规则。用户变量的值可以在Shell脚本中进行赋值和修改，并在需要时进行引用。例如，name=&quot;John&quot;定义了一个名为name的用户变量，并将其赋值为John。 在Shell编程中，可以使用以下方式来操作变量： 赋值：使用等号（=）将值赋给变量，例如var=value。 引用：在脚本中使用$符号加上变量名来引用变量的值，例如echo $var将打印出变量var的值。 修改：通过重新赋值来修改变量的值，例如var=new_value。 删除：使用unset命令来删除变量，例如unset var会将变量var从内存中删除。 特殊变量：Shell还提供了一些特殊的系统变量，如$HOME表示当前用户的主目录，$PWD表示当前工作目录，$PATH表示可执行程序的搜索路径等。 2.2 shell 系统变量 介绍系统变量在Shell编程中扮演着重要的角色，用于提供关于脚本执行环境和参数的信息。下面是常见的系统变量及其详细介绍： $0: 当前脚本的名称。它保存了当前正在执行的Shell脚本的文件名。可以通过$0来获取脚本文件的名称，包括路径（如果有的话）。 $n: 当前脚本的第n个参数。n的取值范围为1到9，用于获取脚本在执行时传递的命令行参数。例如，$1表示第一个参数，$2表示第二个参数，以此类推。 $*: 当前脚本的所有参数（不包括程序本身）。它表示所有传递给脚本的命令行参数的列表。可以使用$*来获取所有参数的字符串，参数之间使用空格分隔。 $#: 当前脚本的参数个数（不包括程序本身）。它表示传递给脚本的命令行参数的数量。可以使用$#来获取参数的个数。 $?: 前一个命令或程序执行完后的状态。它保存了上一个命令或程序执行完毕后的返回状态码。一般情况下，返回0表示执行成功，非零值表示执行失败。可以通过检查$?的值来判断前一个命令或程序是否成功执行。 $$: 程序本身的PID号（进程ID）。它保存了当前Shell脚本或程序的进程ID。可以使用$$来获取当前脚本的进程ID。 2.3 shell 环境变量介绍环境变量在Shell编程中起着重要的作用，它们是用户自定义的变量，用于设置和存储与Shell会话和程序执行环境相关的信息。下面是常见的环境变量及其详细介绍： PATH: 命令所示路径，以冒号为分隔。它是一个包含可执行程序的搜索路径的列表。当在Shell中执行一个命令时，会根据PATH变量中所列出的路径依次搜索命令的可执行文件。如果命令在PATH中的某个路径下找到，则可以直接执行。 HOME: 打印用户家目录。它保存了当前用户的主目录路径。许多程序会使用HOME变量来确定用户的个人文件和配置存放的位置。 SHELL: 显示当前Shell类型。它保存了当前正在使用的Shell的类型，例如/bin/bash表示Bash Shell，/bin/sh表示Bourne Shell等。 USER: 打印当前用户名。它保存了当前登录用户的用户名。 ID: 打印当前用户ID信息。它包含了当前用户的用户ID（UID）、组ID（GID）等相关信息。 PWD: 显示当前所在路径。它保存了当前工作目录的路径，即Shell当前所在的路径。 TERM: 打印当前终端类型。它保存了当前终端的类型或终端仿真器的名称。 HOSTNAME: 显示当前主机名。它保存了当前主机的名称。 PS1: 定义主机命令提示符。它用于设置Shell命令行的提示符，可以自定义提示符的格式和内容。 HISTSIZE: 历史命令大小。它确定了Shell历史记录中保存的命令的数量。可以通过设置HISTSIZE变量来调整历史命令的大小。 RANDOM: 随机生成一个0至32767的整数。它保存了一个随机生成的整数，可以用于在Shell脚本中生成随机数。 1234567891011121314151617181920212223242526272829303132333435363738#!/bin/bash# 打印当前脚本的名称echo &quot;当前脚本的名称：$0&quot;# 打印位置参数的数量和列表echo &quot;位置参数的数量：$#&quot;echo &quot;位置参数的列表（作为单个字符串）：$*&quot;echo &quot;位置参数的列表（作为多个独立字符串）：$@&quot;# 打印上一个命令的退出状态echo &quot;上一个命令的退出状态：$?&quot;# 打印当前进程的 ID 和后台进程的 IDecho &quot;当前脚本的进程 ID：$$&quot;sleep 5 &amp;echo &quot;后台进程的 ID：$!&quot;# 打印当前用户的用户名和主目录路径echo &quot;当前用户的用户名：$USER&quot;echo &quot;当前用户的主目录路径：$HOME&quot;# 打印可执行文件的搜索路径和当前工作目录的路径echo &quot;可执行文件的搜索路径：$PATH&quot;echo &quot;当前工作目录的路径：$PWD&quot;echo &quot;上一个工作目录的路径：$OLDPWD&quot;# 打印给定路径的文件名和目录部分path=&quot;/path/to/somefile.txt&quot;echo &quot;给定路径的文件名部分：$(basename $path)&quot;echo &quot;给定路径的目录部分：$(dirname $path)&quot;# 打印正在执行的当前行的行号和当前正在执行的函数的名称echo &quot;正在执行的当前行的行号：$LINENO&quot;echo &quot;当前正在执行的函数的名称：$FUNCNAME&quot;# 打印 Bash 版本号和随机整数echo &quot;Bash 版本号：$BASH_VERSION&quot;echo &quot;随机整数：$RANDOM&quot; 运行结果如下所示： 12345678910111213141516171819COPY./01_special_variables.sh 111 222 333COPY当前脚本的名称：./01_special_variables.sh位置参数的数量：3位置参数的列表（作为单个字符串）：111 222 333位置参数的列表（作为多个独立字符串）：111 222 333上一个命令的退出状态：0当前脚本的进程 ID：77749后台进程的 ID：77750当前用户的用户名：topeet当前用户的主目录路径：/home/topeet可执行文件的搜索路径：/home/topeet/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin当前工作目录的路径：/home/topeet/shell上一个工作目录的路径：/home/topeet给定路径的文件名部分：somefile.txt给定路径的目录部分：/path/to正在执行的当前行的行号：34当前正在执行的函数的名称：Bash 版本号：5.0.17(1)-release随机整数：2591 2.4 shell 用户环境变量 介绍2.4.1 自定义shell环境变量12345# 常见的变量之三用户变量，用户变量又称为局部变量，主要用在Shell脚本内部或者临时局部使用，系统变量详解如下：a=rivers 自定义变量A；Httpd_sort=httpd-2.4.6-97.tar 自定义变量N_SOFT；BACK_DIR=/data/backup/ 自定义变量BACK_DIR；IPaddress=10.0.0.1 自定义变量IP1； 2.4.2 shell 中彩色输出 helloworld123456789101112131415#!/bin/bash# This is echo color shell# by author rivers 2021.09-23# 字体颜色for i in {31..37}; doecho -e &quot;\\033[$i;40mHello world!\\033[0m&quot;done# 背景颜色for i in {41..47}; doecho -e &quot;\\033[47;${i}mHello world!\\033[0m&quot;done# 显示方式for i in {1..8}; doecho -e &quot;\\033[$i;31;40mHello world!\\033[0m&quot;done 三、shell 编程流程控制语句3.1 if 条件语句介绍3.1.1 常用的单/双分支 if 条件语句 条件判断语句（if语句）是Shell编程中用于根据条件执行不同代码块的结构。if语句通常以if开头，以fi结尾，可以包含else和elif（else if的缩写）来实现多条件判断。下面是对不同类型的if语句进行详细的讲解： 单分支语句（比较大小）: 123if [ 条件表达式 ]; then 语句1fi 在单分支语句中，根据条件表达式的结果（真或假），如果条件为真，则执行语句1，否则跳过整个if语句。 双分支if语句: 12345if [ 表达式 ]; then 语句1else 语句2fi 在双分支if语句中，根据表达式的结果，如果表达式为真，则执行语句1；如果表达式为假，则执行语句2。 多支条件语句（判断成绩）: 1234567if [ 表达式1 ]; then 语句1elif [ 表达式2 ]; then 语句2elif [ 表达式3 ]; then 语句3fi 在多支条件语句中，根据每个表达式的结果，按照顺序依次判断条件，并执行相应的语句。如果表达式1为真，则执行语句1；如果表达式1为假且表达式2为真，则执行语句2；如果表达式1和表达式2都为假且表达式3为真，则执行语句3。如果所有条件都为假，则跳过整个if语句。 在if语句中，条件表达式可以使用各种比较运算符（如-eq、-ne、-lt、-gt等）来比较数字，也可以使用字符串比较运算符（如=、!=、-z、-n等）来比较字符串。可以使用逻辑运算符（如&amp;&amp;、||）组合多个条件。 需要注意的是，if语句中的语句块可以是单个命令，也可以是包含多个命令的代码块。在代码块中，可以执行任意需要的Shell命令和逻辑。 通过使用条件判断语句，我们可以根据不同的条件执行不同的代码逻辑，实现程序的流程控制和条件分支。它在Shell脚本中非常常用，可用于控制程序的逻辑流程、处理不同的错误情况、根据条件执行不同的操作等。 3.1.2 if 常见判断逻辑运算符详解 -f：判断文件是否存在。例如，if [ -f filename ]会检查filename是否为一个存在的文件。 -d：判断目录是否存在。例如，if [ -d dir ]会检查dir是否为一个存在的目录。 -eq：等于，用于整数比较。例如，if [ &quot;$a&quot; -eq &quot;$b&quot; ]会判断变量a和b是否相等。 -ne：不等于，用于整数比较。例如，if [ &quot;$a&quot; -ne &quot;$b&quot; ]会判断变量a和b是否不相等。 -lt：小于，用于整数比较。例如，if [ &quot;$a&quot; -lt &quot;$b&quot; ]会判断变量a是否小于b。 -gt：大于，用于整数比较。例如，if [ &quot;$a&quot; -gt &quot;$b&quot; ]会判断变量a是否大于b。 -le：小于或等于，用于整数比较。例如，if [ &quot;$a&quot; -le &quot;$b&quot; ]会判断变量a是否小于等于b。 -ge：大于或等于，用于整数比较。例如，if [ &quot;$a&quot; -ge &quot;$b&quot; ]会判断变量a是否大于等于b。 -a：逻辑与，表示双方都成立。例如，if [ condition1 -a condition2 ]会检查condition1和condition2是否同时成立。 -o：逻辑或，表示单方成立。例如，if [ condition1 -o condition2 ]会检查condition1和condition2是否有一个成立。 -z：空字符串，判断一个字符串是否为空。例如，if [ -z &quot;$string&quot; ]会判断变量string是否为空字符串。 -x：是否具有可执行权限，判断文件是否有可执行权限。例如，if [ -x filename ]会判断filename是否具有可执行权限。 ||：逻辑或，表示单方成立。例如，command1 || command2会执行command1，如果command1执行失败，则执行command2。 &amp;&amp;：逻辑与，表示双方都成立。例如，command1 &amp;&amp; command2会执行command1，如果command1执行成功，则执行command2。 3.1.3 使用单分支语句判断crond 进程是否在运行—案例123456789101112#!/bin/bash# this is check crond# by author rivers on 2021-9.23# 定义一个变量名name=crondnum=$(ps -ef|grep $name|grep -vc grep)if [ $num -eq 1 ];then echo &quot;$num running!&quot;else echo &quot;$num is not running!&quot;fi 3.1.4 判断系统目录是否存在 —案例123456#!/bin/bash# this is check directory # by author rivers on 2021-9.27 if [ ! -d /data/rivers -a ! -d /tmp/rivers ]；then mkdir -p /data/rivers f i 3.1.5 多个条件判断学生分数等级 — 案例123456789101112131415161718# if 语句可以直接对命令状态进行判断，就省去了获取$?这一步！ # 如果第一个条件符合就不再向下匹配#!/bin/bash # this check grade shell # by author rivers on 2021-09-27 grade=$1 if [ $grade -gt 90 ];then echo &quot;Is's very good!&quot; elif [ $grade -gt 70 ];then echo &quot;Is's is good!&quot; elif [ $grade -ge 60 ];then echo &quot;pass&quot; else echo &quot;no pass&quot; fi 3.2 for 循环语句介绍Shell脚本中的for循环语句。它的一般格式如下： 123for name [ in [ word ... ] ] ; do listdone 或者可以写成： 123for 变量名 in 取值列表; do 语句 1done 下面是对这个for循环语句的详细介绍： name或变量名：循环变量的名称，可以是任意合法的变量名。在每次循环迭代中，该变量将被赋予取值列表中的一个值。 in：关键字，用于指定取值列表的开始。 word或取值列表：一个或多个值，用空格分隔。这些值将依次赋给循环变量，循环将针对每个值执行一次。 list或语句 1：在每次循环迭代中执行的命令列表。可以包含任意数量的命令和语句。 for循环的工作原理是，在每次循环迭代时，将取值列表中的一个值赋给循环变量，然后执行list中的命令列表。每次迭代完成后，循环变量将更新为取值列表中的下一个值，直到所有的值都被处理完毕。 以下是一个例子来说明for循环的使用： 1234for fruit in apple banana cherrydo echo &quot;I like $fruit&quot;done 在上述例子中，循环变量fruit依次被赋值为apple、banana和cherry，然后执行echo语句打印出相应的结果。循环将重复执行这个过程，直到处理完所有的值。 输出结果： 123I like appleI like bananaI like cherry for循环在Shell脚本中经常用于遍历数组、文件列表或指定的取值范围，并对每个元素执行相同的操作。它提供了一种方便且简洁的方式来处理重复的任务。 3.3 while 循环语句介绍while循环语句是Shell脚本中用于重复执行一组命令或语句的一种循环结构。它的一般格式如下： 1234while 表达式do 语句1done 下面是对while循环语句的详细介绍： 表达式：一个条件表达式，用于判断是否继续执行循环。如果表达式的值为真（非零），则循环会一直执行；如果表达式的值为假（零），则循环结束。 语句1：在每次循环迭代中执行的命令列表。可以包含任意数量的命令和语句。 while循环的工作原理是，首先对表达式进行求值，如果表达式的值为真，则执行语句1中的命令列表。执行完语句1后，再次对表达式进行求值，如果仍然为真，则继续执行语句1，以此类推。直到表达式的值为假时，循环结束，程序将跳出循环并继续执行循环之后的代码。 以下是一个例子来说明while循环的使用： 123456count=0while [ $count -lt 5 ]do echo &quot;Count: $count&quot; count=$((count+1))done 在上述例子中，count变量初始值为0。while循环会判断$count -lt 5的条件表达式，如果为真，则执行echo语句打印出当前的count值，并将count的值递增1。循环将重复执行这个过程，直到count的值大于等于5时，循环结束。 输出结果： 12345Count: 0Count: 1Count: 2Count: 3Count: 4 while循环可用于对条件进行判断，并在满足条件时反复执行一组命令或语句。它提供了一种灵活的方式来处理需要重复执行的任务，直到满足某个条件才停止循环。 3.3.1 break和continuebreak和continue是在循环中使用的控制语句，可以对循环的执行进行控制。 break语句用于终止当前所在的循环，跳出循环体，继续执行循环之后的代码。它通常用于满足某个条件时提前结束循环。在示例1中的代码中，当$N的值等于5时，执行了break语句，终止了while循环的执行。 continue语句用于跳过当前循环迭代的剩余代码，直接进行下一次循环迭代。它通常用于在特定情况下跳过某些循环迭代。在示例2中的代码中，当$N的值等于3时，执行了continue语句，跳过了echo语句，直接进行下一次循环迭代。 以下是一个示例，演示如何使用break和continue语句： 1234567891011121314151617i=0while ((i&lt;=100))do if ((i % 2 == 0)) then i=$((i+1)) continue fi if ((i &gt; 50)) then break fi echo $i i=$((i+1))done 在上述示例中，循环从0到100打印数字。使用了continue语句来跳过偶数，使用了break语句来终止循环当数字大于50时。输出结果为1到49的奇数。 总结： break用于终止当前循环，并跳出循环体。 continue用于跳过当前循环迭代的剩余代码，直接进行下一次循环迭代。 3.3.2 While循环求1-100的总和 —案例这是一个使用while循环求解1到100的总和的案例。在这个案例中，我们使用了两个变量i和j，其中i用于循环计数，j用于存储求和的结果。 以下是代码示例： 123456789101112#!/bin/bash# by author rivers on 2021-9-27j=0i=1while ((i&lt;=100))do j=$((j+i)) ((i++))doneecho $j 在循环开始之前，我们将变量j初始化为0，变量i初始化为1。然后，使用while循环来迭代从1到100的所有数字。 在每次循环迭代中，我们将当前的数值i加到变量j上，以累积求和的结果。然后，通过递增i的值来更新循环计数。 当i的值大于100时，循环终止。最后，我们使用echo语句输出求和的结果j。 运行该脚本，将会输出1到100的总和： 15050 因此，通过使用while循环和累加操作，我们成功求得了1到100的总和。 3.3.3 每10秒循环判断一次 hbs用户是否登录系统这是一个每10秒循环判断用户是否登录系统的案例。在这个案例中，我们使用了一个无限循环while true来进行循环判断。 以下是代码示例： 1234567891011121314#!/bin/bash#Check File to change. #By author rivers 2021-9-27USERS=&quot;hbs&quot;while truedo echo &quot;The Time is `date +%F-%T`&quot; sleep 10 NUM=`who|grep &quot;$USERS&quot;|wc -l` if [[ $NUM -ge 1 ]];then echo &quot;The $USERS is login in system.&quot; fidone 在循环开始之前，我们将要检查的用户名定义为变量USERS，这里设置为”hbs”，可以根据需要修改。 然后，使用while true来创建一个无限循环，表示每10秒进行一次判断。 在每次循环迭代中，我们首先使用date命令输出当前时间。 然后，通过who命令获取当前登录的用户信息，并使用grep命令过滤出包含指定用户名的行。使用wc -l命令统计满足条件的行数，将结果保存在变量NUM中。 接下来，我们使用条件语句if判断NUM是否大于等于1，如果是，则输出相应的提示信息，表示该用户已登录系统。 最后，使用sleep 10命令使脚本暂停10秒，然后继续下一次循环。 运行该脚本，将会每10秒判断一次用户”hbs”是否登录系统，并在登录时输出相应的提示信息。 3.4 case 选择语句介绍Case选择语句是一种用于对多个选择条件进行匹配输出的语句。它类似于if-elif语句结构，通常在脚本中用于根据输入参数的不同情况打印输出结果和内容。 Case选择语句的语法格式如下： 12345678910case 模式名 in 模式1) 命令1 ;; 模式2) 命令2 ;; *) 不符合以上模式时执行的命令esac 在这个语法格式中，模式名是要匹配的值或表达式，可以是变量或常量。 每个模式使用圆括号(和)括起来，并以双冒号;;结束。在每个模式下面，可以写入相应的命令。 当模式名与某个模式匹配时，对应的命令将被执行。如果没有匹配任何模式，将执行*)下的命令，它表示不符合以上模式时要执行的命令。 以下是一个示例，演示了Case选择语句的用法： 1234567891011121314151617#!/bin/bashfruit=&quot;apple&quot;case $fruit in &quot;apple&quot;) echo &quot;Selected fruit: Apple&quot; ;; &quot;banana&quot;) echo &quot;Selected fruit: Banana&quot; ;; &quot;orange&quot;) echo &quot;Selected fruit: Orange&quot; ;; *) echo &quot;Unknown fruit&quot;esac 在这个示例中，我们定义了一个变量fruit，并将其值设置为”apple”。 然后，使用Case选择语句来匹配fruit的值。如果fruit的值与某个模式匹配，将执行相应的命令。 在这个示例中，fruit的值为”apple”，因此第一个模式被匹配，命令echo &quot;Selected fruit: Apple&quot;将被执行，输出”Selected fruit: Apple”。 如果将fruit的值改为”banana”，那么第二个模式将被匹配，输出结果将是”Selected fruit: Banana”。 如果fruit的值不匹配任何模式，将执行*)下的命令，输出”Unknown fruit”。 3.5 Select选择语句Select选择语句是一种类似于for循环的语句，用于创建选择菜单。它通常与PS3结合使用，用于打印菜单的输出信息。 Select选择语句的语法格式如下： 1234select 变量名 in 表达式do 语句done 在这个语法格式中，变量名用于保存用户选择的值。表达式可以是一个列表、数组或命令的输出结果。 在每次循环迭代中，会打印出一个带有选择索引的菜单，用户可以根据提示选择其中一个选项。 当用户进行选择后，选择的值将会保存在变量名中，并执行相应的语句。 以下是一个示例，演示了Select选择语句的用法： 12345678910111213141516171819202122232425#!/bin/bash# by author rivers on 2021-9-27PS3=&quot;Select a number: &quot;while true; do select mysql_version in 5.1 5.6 quit; do case $mysql_version in 5.1) echo &quot;mysql 5.1&quot; break ;; 5.6) echo &quot;mysql 5.6&quot; break ;; quit) exit ;; *) echo &quot;Input error, Please enter again!&quot; break esac donedone 在这个示例中，我们首先定义了一个PS3变量，用于提示用户选择一个数字。 然后，使用select选择语句创建了一个菜单，菜单选项是”5.1”、”5.6”和”quit”。 在每次循环迭代中，会打印出菜单，并等待用户的选择。 根据用户的选择，使用case选择语句执行相应的命令。如果选择了”5.1”，则输出”mysql 5.1”；如果选择了”5.6”，则输出”mysql 5.6”；如果选择了”quit”，则退出脚本；如果选择了其他值，输出”Input error, Please enter again!”。 3.6 Shell函数Shell函数是一组命令或语句的可重用块，可以在Shell脚本中定义一次，然后随时调用，避免了重复编写相同的代码块。函数的语法格式是以”function name()”开始，以”}”结束。 在Shell编程中，默认情况下无法将参数传递给函数的括号内部，而是通过调用函数名称时传递参数，例如”func arg1 arg2”。 下面是一个示例的Shell脚本，其中定义了一个名为”func”的函数，函数内部计算了一个变量的值，并使用”return”语句返回该值。然后，调用该函数并打印返回的值。 12345678#!/bin/bashfunc() { VAR=$((1+1)) return $VAR echo &quot;This is a function.&quot;}funcecho $? 通过运行”bash test.sh”命令，将执行上述脚本，调用”func”函数，并打印返回的值。 3.7 shell数组在Shell编程中，数组是一组按照特定顺序排列的相同类型元素的集合。以下是关于数组的一些常见用法和语法： 初始化数组： 使用小括号将元素括起来，并使用空格分隔元素。 格式：array=(元素1 元素2 元素3 …) 例如：array=(“a” “b” “c”)，这样就创建了一个包含元素 “a”、”b” 和 “c” 的数组。 新建数组并添加元素： 使用下标来为数组分配元素。 格式：array[下标]=元素 例如：array[0]=”a”，array[1]=”b”，array[2]=”c”，这样就创建了一个包含元素 “a”、”b” 和 “c” 的数组。 将命令输出作为数组元素： 使用命令的输出结果作为数组的元素。 格式：array=($(command)) 例如：array=($(ls))，这样就将 “ls” 命令的输出结果作为数组的元素。 请注意，数组的下标从0开始计数。可以使用下标来访问数组的元素，例如 ${array[0]} 表示数组的第一个元素。 以下是一个示例，展示了如何定义和使用数组： 1234567891011121314#!/bin/basharray=(&quot;a&quot; &quot;b&quot; &quot;c&quot;) # 使用小括号初始化数组echo &quot;数组的第一个元素：${array[0]}&quot;echo &quot;数组的第二个元素：${array[1]}&quot;echo &quot;数组的第三个元素：${array[2]}&quot;new_array=() # 新建一个空数组new_array[0]=&quot;x&quot; # 添加第一个元素new_array[1]=&quot;y&quot; # 添加第二个元素new_array[2]=&quot;z&quot; # 添加第三个元素echo &quot;新数组的元素：${new_array[@]}&quot;command_output=($(ls)) # 将 ls 命令的输出作为数组元素echo &quot;命令输出作为数组元素：${command_output[@]}&quot; 通过运行上述脚本，您将看到输出结果显示了数组的元素和命令输出作为数组元素的情况。","link":"/2023/12/02/19%20shell%E8%84%9A%E6%9C%AC%E5%AD%A6%E4%B9%A0/"},{"title":"香橙派文件系统构建脚本分析","text":"怎么说呢，好容易能静下心来来分析一下，倒感觉也是不错的，这三个月来也算是又学习到了很多东西，希望重新来一遍能让我有所收获。 1.build.sh 分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302# 根目录地址SRC=&quot;$(dirname &quot;$(realpath &quot;${BASH_SOURCE[0]}&quot;)&quot;)&quot;# check for whitespace in ${SRC} and exit for safety reasons# 检查变量 ${SRC} 是否包含空白字符grep -q &quot;[[:space:]]&quot; &lt;&lt;&lt;&quot;${SRC}&quot; &amp;&amp; { echo &quot;\\&quot;${SRC}\\&quot; contains whitespace. Not supported. Aborting.&quot; &gt;&amp;2 ; exit 1 ; }cd &quot;${SRC}&quot; || exit# 这个变量没有，所以不会进入if [[ &quot;${ORANGEPI_ENABLE_CALL_TRACING}&quot; == &quot;yes&quot; ]]; then set -T # inherit return/debug traps mkdir -p &quot;${SRC}&quot;/output/debug echo -n &quot;&quot; &gt; &quot;${SRC}&quot;/output/debug/calls.txt trap 'echo &quot;${BASH_LINENO[@]}|${BASH_SOURCE[@]}|${FUNCNAME[@]}&quot; &gt;&gt; ${SRC}/output/debug/calls.txt ;' RETURNfi# 这个general.sh 脚本是有的，所以会执行，下一个小节就是他的讲解，关于这个文件只是定义了一些函数，实际上没有要执行的if [[ -f &quot;${SRC}&quot;/scripts/general.sh ]]; then # shellcheck source=scripts/general.sh source &quot;${SRC}&quot;/scripts/general.shelse echo &quot;Error: missing build directory structure&quot; echo &quot;Please clone the full repository by https://github.com/orangepi-xunlong/orangepi-build&quot; exit 255fi# Add the variables needed at the beginning of the path# 检查传入的参数并设置相应的变量，我这里并没有传入变量，而是直接的build.shcheck_args (){for p in &quot;$@&quot;; do case &quot;${p%=*}&quot; in LIB_TAG) # Take a variable if the branch exists locally if [ &quot;${p#*=}&quot; == &quot;$(git branch | \\ gawk -v b=&quot;${p#*=}&quot; '{if ( $NF == b ) {print $NF}}')&quot; ]; then echo -e &quot;[\\e[0;35m warn \\x1B[0m] Setting $p&quot; eval &quot;$p&quot; else echo -e &quot;[\\e[0;35m warn \\x1B[0m] Skip $p setting as LIB_TAG=\\&quot;\\&quot;&quot; eval LIB_TAG=&quot;&quot; fi ;; esacdone}# 所以这里并没有值check_args &quot;$@&quot;# 更新源代码，不用理解update_src() { cd &quot;${SRC}&quot; || exit if [[ ! -f &quot;${SRC}&quot;/.ignore_changes ]]; then echo -e &quot;[\\e[0;32m o.k. \\x1B[0m] This script will try to update&quot; CHANGED_FILES=$(git diff --name-only) if [[ -n &quot;${CHANGED_FILES}&quot; ]]; then echo -e &quot;[\\e[0;35m warn \\x1B[0m] Can't update since you made changes to: \\e[0;32m\\n${CHANGED_FILES}\\x1B[0m&quot; while true; do echo -e &quot;Press \\e[0;33m&lt;Ctrl-C&gt;\\x1B[0m or \\e[0;33mexit\\x1B[0m to abort compilation&quot;\\ &quot;, \\e[0;33m&lt;Enter&gt;\\x1B[0m to ignore and continue, \\e[0;33mdiff\\x1B[0m to display changes&quot; read -r if [[ &quot;${REPLY}&quot; == &quot;diff&quot; ]]; then git diff elif [[ &quot;${REPLY}&quot; == &quot;exit&quot; ]]; then exit 1 elif [[ &quot;${REPLY}&quot; == &quot;&quot; ]]; then break else echo &quot;Unknown command!&quot; fi done elif [[ $(git branch | grep &quot;*&quot; | awk '{print $2}') != &quot;${LIB_TAG}&quot; &amp;&amp; -n &quot;${LIB_TAG}&quot; ]]; then git checkout &quot;${LIB_TAG:-master}&quot; git pull fi fi}# 创建一个临时文件,重定向TMPFILE=$(mktemp)chmod 644 &quot;${TMPFILE}&quot;{ echo SRC=&quot;$SRC&quot; echo LIB_TAG=&quot;$LIB_TAG&quot; declare -f update_src #echo &quot;update_src&quot;} &gt; &quot;$TMPFILE&quot;#do not update/checkout git with root privileges to messup files onwership.#due to in docker/VM, we can't su to a normal user, so do not update/checkout git.if [[ $(systemd-detect-virt) == 'none' ]]; then if [[ &quot;${EUID}&quot; == &quot;0&quot; ]]; then su &quot;$(stat --format=%U &quot;${SRC}&quot;/.git)&quot; -c &quot;bash ${TMPFILE}&quot; else bash &quot;${TMPFILE}&quot; fifirm &quot;${TMPFILE}&quot;if [[ &quot;${EUID}&quot; == &quot;0&quot; ]] || [[ &quot;${1}&quot; == &quot;vagrant&quot; ]]; then :elif [[ &quot;${1}&quot; == docker || &quot;${1}&quot; == dockerpurge || &quot;${1}&quot; == docker-shell ]] &amp;&amp; grep -q &quot;$(whoami)&quot; &lt;(getent group docker); then :else display_alert &quot;This script requires root privileges, trying to use sudo&quot; &quot;&quot; &quot;wrn&quot; sudo &quot;${SRC}/build.sh&quot; &quot;$@&quot; exit $?fiif [ &quot;$OFFLINE_WORK&quot; == &quot;yes&quot; ]; then echo -e &quot;\\n&quot; display_alert &quot;* &quot; &quot;You are working offline.&quot; display_alert &quot;* &quot; &quot;Sources, time and host will not be checked&quot; echo -e &quot;\\n&quot; sleep 3selse # check and install the basic utilities here prepare_host_basicfi# Check for Vagrantif [[ &quot;${1}&quot; == vagrant &amp;&amp; -z &quot;$(command -v vagrant)&quot; ]]; then display_alert &quot;Vagrant not installed.&quot; &quot;Installing&quot; sudo apt-get update sudo apt-get install -y vagrant virtualboxfi# Purge Orange Pi Docker imagesif [[ &quot;${1}&quot; == dockerpurge &amp;&amp; -f /etc/debian_version ]]; then display_alert &quot;Purging Orange Pi Docker containers&quot; &quot;&quot; &quot;wrn&quot; docker container ls -a | grep orangepi | awk '{print $1}' | xargs docker container rm &amp;&gt; /dev/null docker image ls | grep orangepi | awk '{print $3}' | xargs docker image rm &amp;&gt; /dev/null shift set -- &quot;docker&quot; &quot;$@&quot;fi# Docker shellif [[ &quot;${1}&quot; == docker-shell ]]; then shift #shellcheck disable=SC2034 SHELL_ONLY=yes set -- &quot;docker&quot; &quot;$@&quot;fi# Install Docker if not there but wanted. We cover only Debian based distro install. On other distros, manual Docker install is neededif [[ &quot;${1}&quot; == docker &amp;&amp; -f /etc/debian_version &amp;&amp; -z &quot;$(command -v docker)&quot; ]]; then DOCKER_BINARY=&quot;docker-ce&quot; # add exception for Ubuntu Focal until Docker provides dedicated binary codename=$(cat /etc/os-release | grep VERSION_CODENAME | cut -d&quot;=&quot; -f2) codeid=$(cat /etc/os-release | grep ^NAME | cut -d&quot;=&quot; -f2 | awk '{print tolower($0)}' | tr -d '&quot;' | awk '{print $1}') [[ &quot;${codename}&quot; == &quot;debbie&quot; ]] &amp;&amp; codename=&quot;buster&quot; &amp;&amp; codeid=&quot;debian&quot; [[ &quot;${codename}&quot; == &quot;ulyana&quot; || &quot;${codename}&quot; == &quot;jammy&quot; ]] &amp;&amp; codename=&quot;focal&quot; &amp;&amp; codeid=&quot;ubuntu&quot; # different binaries for some. TBD. Need to check for all others [[ &quot;${codename}&quot; =~ focal|hirsute ]] &amp;&amp; DOCKER_BINARY=&quot;docker containerd docker.io&quot; display_alert &quot;Docker not installed.&quot; &quot;Installing&quot; &quot;Info&quot; sudo bash -c &quot;echo \\&quot;deb [arch=$(dpkg --print-architecture)] https://download.docker.com/linux/${codeid} ${codename} stable\\&quot; &gt; /etc/apt/sources.list.d/docker.list&quot; sudo bash -c &quot;curl -fsSL \\&quot;https://download.docker.com/linux/${codeid}/gpg\\&quot; | apt-key add -qq - &gt; /dev/null 2&gt;&amp;1 &quot; export DEBIAN_FRONTEND=noninteractive sudo apt-get update sudo apt-get install -y -qq --no-install-recommends ${DOCKER_BINARY} display_alert &quot;Add yourself to docker group to avoid root privileges&quot; &quot;&quot; &quot;wrn&quot; &quot;${SRC}/build.sh&quot; &quot;$@&quot; exit $?fi# 上面都是关于docker的，可以先不用理解EXTER=&quot;${SRC}/external&quot;# Create userpatches directory if not existsmkdir -p &quot;${SRC}&quot;/userpatches# Create example configs if none found in userpatchesif ! ls &quot;${SRC}&quot;/userpatches/{config-example.conf,config-docker.conf,config-vagrant.conf} 1&gt; /dev/null 2&gt;&amp;1; then # Migrate old configs if ls &quot;${SRC}&quot;/*.conf 1&gt; /dev/null 2&gt;&amp;1; then display_alert &quot;Migrate config files to userpatches directory&quot; &quot;all *.conf&quot; &quot;info&quot; cp &quot;${SRC}&quot;/*.conf &quot;${SRC}&quot;/userpatches || exit 1 rm &quot;${SRC}&quot;/*.conf [[ ! -L &quot;${SRC}&quot;/userpatches/config-example.conf ]] &amp;&amp; ln -fs config-example.conf &quot;${SRC}&quot;/userpatches/config-default.conf || exit 1 fi display_alert &quot;Create example config file using template&quot; &quot;config-default.conf&quot; &quot;info&quot; # Create example config if [[ ! -f &quot;${SRC}&quot;/userpatches/config-example.conf ]]; then cp &quot;${EXTER}&quot;/config/templates/config-example.conf &quot;${SRC}&quot;/userpatches/config-example.conf || exit 1 ln -fs config-example.conf &quot;${SRC}&quot;/userpatches/config-default.conf || exit 1 fi # Create Docker config if [[ ! -f &quot;${SRC}&quot;/userpatches/config-docker.conf ]]; then cp &quot;${EXTER}&quot;/config/templates/config-docker.conf &quot;${SRC}&quot;/userpatches/config-docker.conf || exit 1 fi # Create Docker file if [[ ! -f &quot;${SRC}&quot;/userpatches/Dockerfile ]]; then cp &quot;${EXTER}&quot;/config/templates/Dockerfile &quot;${SRC}&quot;/userpatches/Dockerfile || exit 1 fi # Create Vagrant config if [[ ! -f &quot;${SRC}&quot;/userpatches/config-vagrant.conf ]]; then cp &quot;${EXTER}&quot;/config/templates/config-vagrant.conf &quot;${SRC}&quot;/userpatches/config-vagrant.conf || exit 1 fi # Create Vagrant file if [[ ! -f &quot;${SRC}&quot;/userpatches/Vagrantfile ]]; then cp &quot;${EXTER}&quot;/config/templates/Vagrantfile &quot;${SRC}&quot;/userpatches/Vagrantfile || exit 1 fifiif [[ -z &quot;${CONFIG}&quot; &amp;&amp; -n &quot;$1&quot; &amp;&amp; -f &quot;${SRC}/userpatches/config-$1.conf&quot; ]]; then CONFIG=&quot;userpatches/config-$1.conf&quot; shiftfi# usind default if custom not foundif [[ -z &quot;${CONFIG}&quot; &amp;&amp; -f &quot;${SRC}/userpatches/config-default.conf&quot; ]]; then CONFIG=&quot;userpatches/config-default.conf&quot;fi# source build configuration fileCONFIG_FILE=&quot;$(realpath &quot;${CONFIG}&quot;)&quot;if [[ ! -f &quot;${CONFIG_FILE}&quot; ]]; then display_alert &quot;Config file does not exist&quot; &quot;${CONFIG}&quot; &quot;error&quot; exit 254fiCONFIG_PATH=$(dirname &quot;${CONFIG_FILE}&quot;)# Source the extensions manager library at this point, before sourcing the config.# This allows early calls to enable_extension(), but initialization proper is done later.# shellcheck source=scripts/extensions.shsource &quot;${SRC}&quot;/scripts/extensions.shdisplay_alert &quot;Using config file&quot; &quot;${CONFIG_FILE}&quot; &quot;info&quot;pushd &quot;${CONFIG_PATH}&quot; &gt; /dev/null || exit# shellcheck source=/dev/nullsource &quot;${CONFIG_FILE}&quot;popd &gt; /dev/null || exit[[ -z &quot;${USERPATCHES_PATH}&quot; ]] &amp;&amp; USERPATCHES_PATH=&quot;${CONFIG_PATH}&quot;# Script parameters handlingwhile [[ &quot;${1}&quot; == *=* ]]; do parameter=${1%%=*} value=${1##*=} shift display_alert &quot;Command line: setting $parameter to&quot; &quot;${value:-(empty)}&quot; &quot;info&quot; eval &quot;$parameter=\\&quot;$value\\&quot;&quot;doneif [[ &quot;${BUILD_ALL}&quot; == &quot;yes&quot; || &quot;${BUILD_ALL}&quot; == &quot;demo&quot; ]]; then # shellcheck source=scripts/build-all-ng.sh source &quot;${SRC}&quot;/scripts/build-all-ng.shelse # shellcheck source=scripts/main.sh source &quot;${SRC}&quot;/scripts/main.shfi 其实上面对我有用的也就是general.sh脚本和main.sh，general脚本是一些用于的函数，而main,sh是最重要的，在第三个章节会进行讲解。 2.general.sh分析12345678910111213141516171819202122# Functions:# cleaning 清理操作# exit_with_error 输出错误并退出# get_package_list_hash 获取软件包列表的哈希值。# create_sources_list 创建源列表# clean_up_git 清理 Git 相关操作# waiter_local_git 等待本地 Git 操作完成# fetch_from_repo 。从仓库获取文件# improved_git改进的 Git 操作。# display_alert 显示警告。# fingerprint_image 生成图像指纹# distro_menu 显示发行版菜单# addtorepo 将软件包添加到仓库# repo-remove-old-packages 从仓库中移除旧的软件包# wait_for_package_manager 等待软件包管理器完成操作# install_pkg_deb 安装 deb 软件包# prepare_host_basic 准备基本主机环境# prepare_host 准备主机环境# webseed 使用 Webseed 下载文件# download_and_verify 下载并验证文件# show_developer_warning 显示开发者警告信息# show_checklist_variables 显示清单变量 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987988989990991992993994995996997998999100010011002100310041005100610071008100910101011101210131014101510161017101810191020102110221023102410251026102710281029103010311032103310341035103610371038103910401041104210431044104510461047104810491050105110521053105410551056105710581059106010611062106310641065106610671068106910701071107210731074107510761077107810791080108110821083108410851086108710881089109010911092109310941095109610971098109911001101110211031104110511061107110811091110111111121113111411151116111711181119112011211122112311241125112611271128112911301131113211331134113511361137113811391140114111421143114411451146114711481149115011511152115311541155115611571158115911601161116211631164116511661167116811691170117111721173117411751176117711781179118011811182118311841185118611871188118911901191119211931194119511961197119811991200120112021203120412051206120712081209121012111212121312141215121612171218121912201221122212231224122512261227122812291230123112321233123412351236123712381239124012411242124312441245124612471248124912501251125212531254125512561257125812591260126112621263126412651266126712681269127012711272127312741275127612771278127912801281128212831284128512861287128812891290129112921293129412951296129712981299130013011302130313041305130613071308130913101311131213131314131513161317131813191320132113221323132413251326132713281329133013311332133313341335133613371338133913401341134213431344134513461347134813491350135113521353135413551356135713581359136013611362136313641365136613671368136913701371137213731374137513761377137813791380138113821383138413851386138713881389139013911392139313941395139613971398139914001401140214031404140514061407140814091410141114121413141414151416141714181419142014211422142314241425142614271428142914301431143214331434143514361437143814391440144114421443144414451446144714481449145014511452145314541455145614571458145914601461146214631464146514661467146814691470147114721473147414751476147714781479148014811482148314841485148614871488148914901491149214931494149514961497149814991500150115021503150415051506150715081509151015111512151315141515151615171518151915201521152215231524152515261527152815291530153115321533153415351536153715381539154015411542154315441545154615471548154915501551155215531554155515561557155815591560156115621563156415651566156715681569157015711572157315741575157615771578157915801581158215831584158515861587158815891590159115921593159415951596159715981599160016011602160316041605160616071608160916101611161216131614161516161617161816191620162116221623162416251626162716281629163016311632163316341635163616371638163916401641164216431644164516461647164816491650165116521653165416551656165716581659166016611662166316641665166616671668166916701671167216731674167516761677167816791680168116821683168416851686168716881689169016911692169316941695169616971698169917001701170217031704170517061707170817091710171117121713171417151716171717181719172017211722172317241725172617271728172917301731173217331734173517361737173817391740174117421743174417451746174717481749175017511752175317541755175617571758175917601761176217631764176517661767176817691770177117721773177417751776177717781779178017811782178317841785178617871788178917901791179217931794179517961797179817991800180118021803180418051806180718081809181018111812181318141815181618171818181918201821182218231824182518261827182818291830183118321833183418351836183718381839184018411842184318441845184618471848184918501851185218531854185518561857185818591860186118621863186418651866186718681869187018711872187318741875187618771878187918801881188218831884188518861887188818891890189118921893189418951896189718981899190019011902190319041905190619071908190919101911191219131914191519161917191819191920#!/bin/bash## Copyright (c) 2015 Igor Pecovnik, igor.pecovnik@gma**.com## This file is licensed under the terms of the GNU General Public# License version 2. This program is licensed &quot;as is&quot; without any# warranty of any kind, whether express or implied.# Functions:# cleaning 清理操作# exit_with_error 输出错误并退出# get_package_list_hash 获取软件包列表的哈希值。# create_sources_list 创建源列表# clean_up_git 清理 Git 相关操作# waiter_local_git 等待本地 Git 操作完成# fetch_from_repo 。从仓库获取文件# improved_git改进的 Git 操作。# display_alert 显示警告。# fingerprint_image 生成图像指纹# distro_menu 显示发行版菜单# addtorepo 将软件包添加到仓库# repo-remove-old-packages 从仓库中移除旧的软件包# wait_for_package_manager 等待软件包管理器完成操作# install_pkg_deb 安装 deb 软件包# prepare_host_basic 准备基本主机环境# prepare_host 准备主机环境# webseed 使用 Webseed 下载文件# download_and_verify 下载并验证文件# show_developer_warning 显示开发者警告信息# show_checklist_variables 显示清单变量# cleaning &lt;target&gt;## target: what to clean# &quot;make&quot; - &quot;make clean&quot; for selected kernel and u-boot# &quot;debs&quot; - delete output/debs for board&amp;branch# &quot;ubootdebs&quot; - delete output/debs for uboot&amp;board&amp;branch# &quot;alldebs&quot; - delete output/debs# &quot;cache&quot; - delete output/cache# &quot;oldcache&quot; - remove old output/cache# &quot;images&quot; - delete output/images# &quot;sources&quot; - delete output/sources#cleaning(){ case $1 in debs) # delete ${DEB_STORAGE} for current branch and family if [[ -d &quot;${DEB_STORAGE}&quot; ]]; then display_alert &quot;Cleaning ${DEB_STORAGE} for&quot; &quot;$BOARD $BRANCH&quot; &quot;info&quot; # easier than dealing with variable expansion and escaping dashes in file names find &quot;${DEB_STORAGE}&quot; -name &quot;${CHOSEN_UBOOT}_*.deb&quot; -delete find &quot;${DEB_STORAGE}&quot; \\( -name &quot;${CHOSEN_KERNEL}_*.deb&quot; -o \\ -name &quot;orangepi-*.deb&quot; -o \\ -name &quot;plymouth-theme-orangepi_*.deb&quot; -o \\ -name &quot;${CHOSEN_KERNEL/image/dtb}_*.deb&quot; -o \\ -name &quot;${CHOSEN_KERNEL/image/headers}_*.deb&quot; -o \\ -name &quot;${CHOSEN_KERNEL/image/source}_*.deb&quot; -o \\ -name &quot;${CHOSEN_KERNEL/image/firmware-image}_*.deb&quot; \\) -delete [[ -n $RELEASE ]] &amp;&amp; rm -f &quot;${DEB_STORAGE}/${RELEASE}/${CHOSEN_ROOTFS}&quot;_*.deb [[ -n $RELEASE ]] &amp;&amp; rm -f &quot;${DEB_STORAGE}/${RELEASE}/orangepi-desktop-${RELEASE}&quot;_*.deb fi ;; ubootdebs) # delete ${DEB_STORAGE} for uboot, current branch and family if [[ -d &quot;${DEB_STORAGE}&quot; ]]; then display_alert &quot;Cleaning ${DEB_STORAGE} for u-boot&quot; &quot;$BOARD $BRANCH&quot; &quot;info&quot; # easier than dealing with variable expansion and escaping dashes in file names find &quot;${DEB_STORAGE}&quot; -name &quot;${CHOSEN_UBOOT}_*.deb&quot; -delete fi ;; extras) # delete ${DEB_STORAGE}/extra/$RELEASE for all architectures if [[ -n $RELEASE &amp;&amp; -d ${DEB_STORAGE}/extra/$RELEASE ]]; then display_alert &quot;Cleaning ${DEB_STORAGE}/extra for&quot; &quot;$RELEASE&quot; &quot;info&quot; rm -rf &quot;${DEB_STORAGE}/extra/${RELEASE}&quot; fi ;; alldebs) # delete output/debs [[ -d &quot;${DEB_STORAGE}&quot; ]] &amp;&amp; display_alert &quot;Cleaning&quot; &quot;${DEB_STORAGE}&quot; &quot;info&quot; &amp;&amp; rm -rf &quot;${DEB_STORAGE}&quot;/* ;; cache) # delete output/cache [[ -d $EXTER/cache/rootfs ]] &amp;&amp; display_alert &quot;Cleaning&quot; &quot;rootfs cache (all)&quot; &quot;info&quot; &amp;&amp; find $EXTER/cache/rootfs -type f -delete ;; images) # delete output/images [[ -d &quot;${DEST}&quot;/images ]] &amp;&amp; display_alert &quot;Cleaning&quot; &quot;output/images&quot; &quot;info&quot; &amp;&amp; rm -rf &quot;${DEST}&quot;/images/* ;; sources) # delete output/sources and output/buildpkg [[ -d $EXTER/cache/sources ]] &amp;&amp; display_alert &quot;Cleaning&quot; &quot;sources&quot; &quot;info&quot; &amp;&amp; rm -rf $EXTER/cache/sources/* &quot;${DEST}&quot;/buildpkg/* ;; oldcache) # remove old `cache/rootfs` except for the newest 8 files if [[ -d $EXTER/cache/rootfs &amp;&amp; $(ls -1 $EXTER/cache/rootfs/*.lz4 2&gt; /dev/null | wc -l) -gt &quot;${ROOTFS_CACHE_MAX}&quot; ]]; then display_alert &quot;Cleaning&quot; &quot;rootfs cache (old)&quot; &quot;info&quot; (cd $EXTER/cache/rootfs; ls -t *.lz4 | sed -e &quot;1,${ROOTFS_CACHE_MAX}d&quot; | xargs -d '\\n' rm -f) # Remove signatures if they are present. We use them for internal purpose (cd $EXTER/cache/rootfs; ls -t *.asc | sed -e &quot;1,${ROOTFS_CACHE_MAX}d&quot; | xargs -d '\\n' rm -f) fi ;; esac}# exit_with_error &lt;message&gt; &lt;highlight&gt;## a way to terminate build process# with verbose error message#exit_with_error(){ local _file local _line=${BASH_LINENO[0]} local _function=${FUNCNAME[1]} local _description=$1 local _highlight=$2 _file=$(basename &quot;${BASH_SOURCE[1]}&quot;) local stacktrace=&quot;$(get_extension_hook_stracktrace &quot;${BASH_SOURCE[*]}&quot; &quot;${BASH_LINENO[*]}&quot;)&quot; display_alert &quot;ERROR in function $_function&quot; &quot;$stacktrace&quot; &quot;err&quot; display_alert &quot;$_description&quot; &quot;$_highlight&quot; &quot;err&quot; display_alert &quot;Process terminated&quot; &quot;&quot; &quot;info&quot; if [[ &quot;${ERROR_DEBUG_SHELL}&quot; == &quot;yes&quot; ]]; then display_alert &quot;MOUNT&quot; &quot;${MOUNT}&quot; &quot;err&quot; display_alert &quot;SDCARD&quot; &quot;${SDCARD}&quot; &quot;err&quot; display_alert &quot;Here's a shell.&quot; &quot;debug it&quot; &quot;err&quot; bash &lt; /dev/tty || true fi # TODO: execute run_after_build here? overlayfs_wrapper &quot;cleanup&quot; # unlock loop device access in case of starvation exec {FD}&gt;/var/lock/orangepi-debootstrap-losetup flock -u &quot;${FD}&quot; exit 255}# get_package_list_hash## returns md5 hash for current package list and rootfs cache versionget_package_list_hash(){ local package_arr exclude_arr local list_content read -ra package_arr &lt;&lt;&lt; &quot;${DEBOOTSTRAP_LIST} ${PACKAGE_LIST}&quot; read -ra exclude_arr &lt;&lt;&lt; &quot;${PACKAGE_LIST_EXCLUDE}&quot; ( ( printf &quot;%s\\n&quot; &quot;${package_arr[@]}&quot;; printf -- &quot;-%s\\n&quot; &quot;${exclude_arr[@]}&quot; ) | sort -u; echo &quot;${1}&quot; ) \\ | md5sum | cut -d' ' -f 1}# create_sources_list &lt;release&gt; &lt;basedir&gt;## &lt;release&gt;: buster|bullseye|bookworm|bionic|focal|jammy|hirsute|sid# &lt;basedir&gt;: path to root directory#create_sources_list(){ local release=$1 local basedir=$2 [[ -z $basedir ]] &amp;&amp; exit_with_error &quot;No basedir passed to create_sources_list&quot; case $release in stretch|buster) cat &lt;&lt;-EOF &gt; &quot;${basedir}&quot;/etc/apt/sources.list deb http://${DEBIAN_MIRROR} $release main contrib non-free #deb-src http://${DEBIAN_MIRROR} $release main contrib non-free deb http://${DEBIAN_MIRROR} ${release}-updates main contrib non-free #deb-src http://${DEBIAN_MIRROR} ${release}-updates main contrib non-free deb http://${DEBIAN_MIRROR} ${release}-backports main contrib non-free #deb-src http://${DEBIAN_MIRROR} ${release}-backports main contrib non-free deb http://${DEBIAN_SECURTY} ${release}/updates main contrib non-free #deb-src http://${DEBIAN_SECURTY} ${release}/updates main contrib non-free EOF ;; bullseye) cat &lt;&lt;-EOF &gt; &quot;${basedir}&quot;/etc/apt/sources.list deb https://${DEBIAN_MIRROR} $release main contrib non-free #deb-src https://${DEBIAN_MIRROR} $release main contrib non-free deb https://${DEBIAN_MIRROR} ${release}-updates main contrib non-free #deb-src https://${DEBIAN_MIRROR} ${release}-updates main contrib non-free deb https://${DEBIAN_MIRROR} ${release}-backports main contrib non-free #deb-src https://${DEBIAN_MIRROR} ${release}-backports main contrib non-free deb https://${DEBIAN_SECURTY} ${release}-security main contrib non-free #deb-src https://${DEBIAN_SECURTY} ${release}-security main contrib non-free EOF ;; bookworm) cat &lt;&lt;- EOF &gt; &quot;${basedir}&quot;/etc/apt/sources.list deb http://${DEBIAN_MIRROR} $release main contrib non-free non-free-firmware #deb-src http://${DEBIAN_MIRROR} $release main contrib non-free non-free-firmware deb http://${DEBIAN_MIRROR} ${release}-updates main contrib non-free non-free-firmware #deb-src http://${DEBIAN_MIRROR} ${release}-updates main contrib non-free non-free-firmware deb http://${DEBIAN_MIRROR} ${release}-backports main contrib non-free non-free-firmware #deb-src http://${DEBIAN_MIRROR} ${release}-backports main contrib non-free non-free-firmware deb http://${DEBIAN_SECURTY} ${release}-security main contrib non-free non-free-firmware #deb-src http://${DEBIAN_SECURTY} ${release}-security main contrib non-free non-free-firmware EOF ;; sid) # sid is permanent unstable development and has no such thing as updates or security cat &lt;&lt;- EOF &gt; &quot;${basedir}&quot;/etc/apt/sources.list deb http://${DEBIAN_MIRROR} $release main contrib non-free non-free-firmware #deb-src http://${DEBIAN_MIRROR} $release main contrib non-free non-free-firmware deb http://${DEBIAN_MIRROR} unstable main contrib non-free non-free-firmware #deb-src http://${DEBIAN_MIRROR} unstable main contrib non-free non-free-firmware EOF ;; xenial|bionic|focal|hirsute|impish|jammy) cat &lt;&lt;-EOF &gt; &quot;${basedir}&quot;/etc/apt/sources.list deb http://${UBUNTU_MIRROR} $release main restricted universe multiverse #deb-src http://${UBUNTU_MIRROR} $release main restricted universe multiverse deb http://${UBUNTU_MIRROR} ${release}-security main restricted universe multiverse #deb-src http://${UBUNTU_MIRROR} ${release}-security main restricted universe multiverse deb http://${UBUNTU_MIRROR} ${release}-updates main restricted universe multiverse #deb-src http://${UBUNTU_MIRROR} ${release}-updates main restricted universe multiverse deb http://${UBUNTU_MIRROR} ${release}-backports main restricted universe multiverse #deb-src http://${UBUNTU_MIRROR} ${release}-backports main restricted universe multiverse EOF ;; raspi) cat &lt;&lt;-EOF &gt; &quot;${basedir}&quot;/etc/apt/sources.list deb http://${DEBIAN_MIRROR} bullseye main contrib non-free #deb-src http://${DEBIAN_MIRROR} bullseye main contrib non-free deb http://${DEBIAN_MIRROR} bullseye-updates main contrib non-free #deb-src http://${DEBIAN_MIRROR} bullseye-updates main contrib non-free deb http://${DEBIAN_MIRROR} bullseye-backports main contrib non-free #deb-src http://${DEBIAN_MIRROR} bullseye-backports main contrib non-free deb http://${DEBIAN_SECURTY} bullseye-security main contrib non-free #deb-src http://${DEBIAN_SECURTY} bullseye-security main contrib non-free EOF cat &lt;&lt;-EOF &gt; &quot;${basedir}&quot;/etc/apt/sources.list.d/raspi.list deb http://${RASPI_MIRROR} bullseye main # Uncomment line below then 'apt-get update' to enable 'apt-get source' #deb-src http://archive.raspberrypi.org/debian/ bullseye main EOF if [ -n &quot;$APT_PROXY&quot; ]; then install -m 644 files/51cache &quot;${APT_PROXY}/etc/apt/apt.conf.d/51cache&quot; sed &quot;${basedir}/etc/apt/apt.conf.d/51cache&quot; -i -e &quot;s|APT_PROXY|${APT_PROXY}|&quot; else rm -f &quot;${basedir}/etc/apt/apt.conf.d/51cache&quot; fi cat ${EXTER}/packages/raspi/stage0/00-configure-apt/files/raspberrypi.gpg.key | gpg --dearmor &gt; &quot;${basedir}/raspberrypi-archive-stable.gpg&quot; install -m 644 &quot;${basedir}/raspberrypi-archive-stable.gpg&quot; &quot;${basedir}/etc/apt/trusted.gpg.d/&quot; ;; esac # stage: add armbian repository and install key #if [[ $DOWNLOAD_MIRROR == &quot;china&quot; ]]; then # echo &quot;deb https://mirrors.tuna.tsinghua.edu.cn/armbian $RELEASE main ${RELEASE}-utils ${RELEASE}-desktop&quot; &gt; &quot;${SDCARD}&quot;/etc/apt/sources.list.d/armbian.list #elif [[ $DOWNLOAD_MIRROR == &quot;bfsu&quot; ]]; then # echo &quot;deb http://mirrors.bfsu.edu.cn/armbian $RELEASE main ${RELEASE}-utils ${RELEASE}-desktop&quot; &gt; &quot;${SDCARD}&quot;/etc/apt/sources.list.d/armbian.list #else # echo &quot;deb http://&quot;$([[ $BETA == yes ]] &amp;&amp; echo &quot;beta&quot; || echo &quot;apt&quot; )&quot;.armbian.com $RELEASE main ${RELEASE}-utils ${RELEASE}-desktop&quot; &gt; &quot;${SDCARD}&quot;/etc/apt/sources.list.d/armbian.list #fi # replace local package server if defined. Suitable for development #[[ -n $LOCAL_MIRROR ]] &amp;&amp; echo &quot;deb http://$LOCAL_MIRROR $RELEASE main ${RELEASE}-utils ${RELEASE}-desktop&quot; &gt; &quot;${SDCARD}&quot;/etc/apt/sources.list.d/armbian.list #display_alert &quot;Adding Armbian repository and authentication key&quot; &quot;/etc/apt/sources.list.d/armbian.list&quot; &quot;info&quot; #cp &quot;${EXTER}&quot;/config/armbian.key &quot;${SDCARD}&quot; #chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;cat armbian.key | apt-key add - &gt; /dev/null 2&gt;&amp;1&quot; #rm &quot;${SDCARD}&quot;/armbian.key}## This function retries Git operations to avoid failure in case remote is borked# If the git team needs to call a remote server, use this function.#improved_git(){ local realgit=$(command -v git) local retries=3 local delay=10 local count=1 while [ $count -lt $retries ]; do $realgit &quot;$@&quot; if [[ $? -eq 0 || -f .git/index.lock ]]; then retries=0 break fi let count=$count+1 sleep $delay done}clean_up_git (){ local target_dir=$1 # Files that are not tracked by git and were added # when the patch was applied must be removed. git -C $target_dir clean -qdf # Return the files that are tracked by git to the initial state. git -C $target_dir checkout -qf HEAD}# used : waiter_local_git arg1='value' arg2:'value'# waiter_local_git \\# url='https://github.com/megous/linux' \\# name='megous' \\# dir='linux-mainline/5.14' \\# branch='orange-pi-5.14' \\# obj=&lt;tag|commit&gt; or tag:$tag ...# An optional parameter for switching to a git object such as a tag, commit,# or a specific branch. The object must exist in the local repository.# This optional parameter takes precedence. If it is specified, then# the commit state corresponding to the specified git object will be extracted# to the working directory. Otherwise, the commit corresponding to the top of# the branch will be extracted.# The settings for the kernel variables of the original kernel# VAR_SHALLOW_ORIGINAL=var_origin_kernel must be in the main script# before calling the functionwaiter_local_git (){ for arg in $@;do case $arg in url=*|https://*|git://*) eval &quot;local url=${arg/url=/}&quot; ;; dir=*|/*/*/*) eval &quot;local dir=${arg/dir=/}&quot; ;; *=*|*:*) eval &quot;local ${arg/:/=}&quot; ;; esac done # Required variables cannot be empty. for var in url name dir branch; do [ &quot;${var#*=}&quot; == &quot;&quot; ] &amp;&amp; exit_with_error &quot;Error in configuration&quot; done local reachability # The 'offline' variable must always be set to 'true' or 'false' if [ &quot;$OFFLINE_WORK&quot; == &quot;yes&quot; ]; then local offline=true else local offline=false fi local work_dir=&quot;$(realpath ${EXTER}/cache/sources)/$dir&quot; mkdir -p $work_dir cd $work_dir || exit_with_error display_alert &quot;Checking git sources&quot; &quot;$dir $url$name/$branch&quot; &quot;info&quot; if [ &quot;$(git rev-parse --git-dir 2&gt;/dev/null)&quot; != &quot;.git&quot; ]; then git init -q . # Run in the sub shell to avoid mixing environment variables. if [ -n &quot;$VAR_SHALLOW_ORIGINAL&quot; ]; then ( $VAR_SHALLOW_ORIGINAL display_alert &quot;Add original git sources&quot; &quot;$dir $name/$branch&quot; &quot;info&quot; if [ &quot;$(improved_git ls-remote -h $url $branch | \\ awk -F'/' '{if (NR == 1) print $NF}')&quot; != &quot;$branch&quot; ];then display_alert &quot;Bad $branch for $url in $VAR_SHALLOW_ORIGINAL&quot; exit 177 fi git remote add -t $branch $name $url # Handle an exception if the initial tag is the top of the branch # As v5.16 == HEAD if [ &quot;${start_tag}.1&quot; == &quot;$(improved_git ls-remote -t $url ${start_tag}.1 | \\ awk -F'/' '{ print $NF }')&quot; ] then improved_git fetch --shallow-exclude=$start_tag $name else improved_git fetch --depth 1 $name fi improved_git fetch --deepen=1 $name # For a shallow clone, this works quickly and saves space. git gc ) [ &quot;$?&quot; == &quot;177&quot; ] &amp;&amp; exit fi fi files_for_clean=&quot;$(git status -s | wc -l)&quot; if [ &quot;$files_for_clean&quot; != &quot;0&quot; ];then display_alert &quot; Cleaning .... &quot; &quot;$files_for_clean files&quot; clean_up_git $work_dir fi if [ &quot;$name&quot; != &quot;$(git remote show | grep $name)&quot; ];then git remote add -t $branch $name $url fi if ! $offline; then for t_name in $(git remote show);do improved_git fetch $t_name done fi # When switching, we use the concept of only &quot;detached branch&quot;. Therefore, # we extract the hash from the tag, the branch name, or from the hash itself. # This serves as a check of the reachability of the extraction. # We do not use variables that characterize the current state of the git, # such as `HEAD` and `FETCH_HEAD`. reachability=false for var in obj tag commit branch;do eval pval=\\$$var if [ -n &quot;$pval&quot; ] &amp;&amp; [ &quot;$pval&quot; != *HEAD ]; then case $var in obj|tag|commit) obj=$pval ;; branch) obj=${name}/$branch ;; esac if t_hash=$(git rev-parse $obj 2&gt;/dev/null);then reachability=true break else display_alert &quot;Variable $var=$obj unreachable for extraction&quot; fi fi done if $reachability &amp;&amp; [ &quot;$t_hash&quot; != &quot;$(git rev-parse @ 2&gt;/dev/null)&quot; ];then # Switch &quot;detached branch&quot; as hash display_alert &quot;Switch $obj = $t_hash&quot; git checkout -qf $t_hash else # the working directory corresponds to the target commit, # nothing needs to be done display_alert &quot;Up to date&quot; fi}# fetch_from_repo &lt;url&gt; &lt;directory&gt; &lt;ref&gt; &lt;ref_subdir&gt;# &lt;url&gt;: remote repository URL# &lt;directory&gt;: local directory; subdir for branch/tag will be created# &lt;ref&gt;:# branch:name# tag:name# head(*)# commit:hash## *: Implies ref_subdir=no## &lt;ref_subdir&gt;: &quot;yes&quot; to create subdirectory for tag or branch name#fetch_from_repo(){ local url=$1 local dir=$2 local ref=$3 local ref_subdir=$4 # Set GitHub mirror before anything else touches $url url=${url//'https://github.com/'/$GITHUB_SOURCE'/'} # The 'offline' variable must always be set to 'true' or 'false' if [ &quot;$OFFLINE_WORK&quot; == &quot;yes&quot; ]; then local offline=true else local offline=false fi [[ -z $ref || ( $ref != tag:* &amp;&amp; $ref != branch:* &amp;&amp; $ref != head &amp;&amp; $ref != commit:* ) ]] &amp;&amp; exit_with_error &quot;Error in configuration&quot; local ref_type=${ref%%:*} if [[ $ref_type == head ]]; then local ref_name=HEAD else local ref_name=${ref##*:} fi display_alert &quot;Checking git sources&quot; &quot;$dir $ref_name&quot; &quot;info&quot; # get default remote branch name without cloning # local ref_name=$(git ls-remote --symref $url HEAD | grep -o 'refs/heads/\\S*' | sed 's%refs/heads/%%') # for git:// protocol comparing hashes of &quot;git ls-remote -h $url&quot; and &quot;git ls-remote --symref $url HEAD&quot; is needed if [[ $ref_subdir == yes ]]; then local workdir=$dir/$ref_name else local workdir=$dir fi mkdir -p &quot;${workdir}&quot; 2&gt;/dev/null || \\ exit_with_error &quot;No path or no write permission&quot; &quot;${workdir}&quot; cd &quot;${workdir}&quot; || exit # check if existing remote URL for the repo or branch does not match current one # may not be supported by older git versions # Check the folder as a git repository. # Then the target URL matches the local URL. if [[ &quot;$(git rev-parse --git-dir 2&gt;/dev/null)&quot; == &quot;.git&quot; &amp;&amp; \\ &quot;$url&quot; != *&quot;$(git remote get-url origin | sed 's/^.*@//' | sed 's/^.*\\/\\///' 2&gt;/dev/null)&quot; ]]; then display_alert &quot;Remote URL does not match, removing existing local copy&quot; rm -rf .git ./* fi if [[ &quot;$(git rev-parse --git-dir 2&gt;/dev/null)&quot; != &quot;.git&quot; ]]; then display_alert &quot;Creating local copy&quot; git init -q . git remote add origin &quot;${url}&quot; # Here you need to upload from a new address offline=false fi local changed=false # when we work offline we simply return the sources to their original state if ! $offline; then local local_hash local_hash=$(git rev-parse @ 2&gt;/dev/null) case $ref_type in branch) # TODO: grep refs/heads/$name local remote_hash remote_hash=$(improved_git ls-remote -h &quot;${url}&quot; &quot;$ref_name&quot; | head -1 | cut -f1) [[ -z $local_hash || &quot;${local_hash}&quot; != &quot;${remote_hash}&quot; ]] &amp;&amp; changed=true ;; tag) local remote_hash remote_hash=$(improved_git ls-remote -t &quot;${url}&quot; &quot;$ref_name&quot; | cut -f1) if [[ -z $local_hash || &quot;${local_hash}&quot; != &quot;${remote_hash}&quot; ]]; then remote_hash=$(improved_git ls-remote -t &quot;${url}&quot; &quot;$ref_name^{}&quot; | cut -f1) [[ -z $remote_hash || &quot;${local_hash}&quot; != &quot;${remote_hash}&quot; ]] &amp;&amp; changed=true fi ;; head) local remote_hash remote_hash=$(improved_git ls-remote &quot;${url}&quot; HEAD | cut -f1) [[ -z $local_hash || &quot;${local_hash}&quot; != &quot;${remote_hash}&quot; ]] &amp;&amp; changed=true ;; commit) [[ -z $local_hash || $local_hash == &quot;@&quot; ]] &amp;&amp; changed=true ;; esac fi # offline if [[ $changed == true ]]; then # remote was updated, fetch and check out updates display_alert &quot;Fetching updates&quot; case $ref_type in branch) improved_git fetch --depth 200 origin &quot;${ref_name}&quot; ;; tag) improved_git fetch --depth 200 origin tags/&quot;${ref_name}&quot; ;; head) improved_git fetch --depth 200 origin HEAD ;; esac # commit type needs support for older git servers that doesn't support fetching id directly if [[ $ref_type == commit ]]; then improved_git fetch --depth 200 origin &quot;${ref_name}&quot; # cover old type if [[ $? -ne 0 ]]; then display_alert &quot;Commit checkout not supported on this repository. Doing full clone.&quot; &quot;&quot; &quot;wrn&quot; improved_git pull git checkout -fq &quot;${ref_name}&quot; display_alert &quot;Checkout out to&quot; &quot;$(git --no-pager log -2 --pretty=format:&quot;$ad%s [%an]&quot; | head -1)&quot; &quot;info&quot; else display_alert &quot;Checking out&quot; git checkout -f -q FETCH_HEAD git clean -qdf fi else display_alert &quot;Checking out&quot; git checkout -f -q FETCH_HEAD git clean -qdf fi elif [[ -n $(git status -uno --porcelain --ignore-submodules=all) ]]; then # working directory is not clean display_alert &quot; Cleaning .... &quot; &quot;$(git status -s | wc -l) files&quot; # Return the files that are tracked by git to the initial state. git checkout -f -q HEAD # Files that are not tracked by git and were added # when the patch was applied must be removed. git clean -qdf else # working directory is clean, nothing to do display_alert &quot;Up to date&quot; fi if [[ -f .gitmodules ]]; then display_alert &quot;Updating submodules&quot; &quot;&quot; &quot;ext&quot; # FML: http://stackoverflow.com/a/17692710 for i in $(git config -f .gitmodules --get-regexp path | awk '{ print $2 }'); do cd &quot;${workdir}&quot; || exit local surl sref surl=$(git config -f .gitmodules --get &quot;submodule.$i.url&quot;) sref=$(git config -f .gitmodules --get &quot;submodule.$i.branch&quot;) if [[ -n $sref ]]; then sref=&quot;branch:$sref&quot; else sref=&quot;head&quot; fi fetch_from_repo &quot;$surl&quot; &quot;$workdir/$i&quot; &quot;$sref&quot; done fi} ##############################################################################--------------------------------------------------------------------------------------------------------------------------------# Let's have unique way of displaying alerts#--------------------------------------------------------------------------------------------------------------------------------display_alert(){ # log function parameters to install.log [[ -n &quot;${DEST}&quot; ]] &amp;&amp; echo &quot;Displaying message: $@&quot; &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/output.log local tmp=&quot;&quot; [[ -n $2 ]] &amp;&amp; tmp=&quot;[\\e[0;33m $2 \\x1B[0m]&quot; case $3 in err) echo -e &quot;[\\e[0;31m error \\x1B[0m] $1 $tmp&quot; ;; wrn) echo -e &quot;[\\e[0;35m warn \\x1B[0m] $1 $tmp&quot; ;; ext) echo -e &quot;[\\e[0;32m o.k. \\x1B[0m] \\e[1;32m$1\\x1B[0m $tmp&quot; ;; info) echo -e &quot;[\\e[0;32m o.k. \\x1B[0m] $1 $tmp&quot; ;; *) echo -e &quot;[\\e[0;32m .... \\x1B[0m] $1 $tmp&quot; ;; esac}#--------------------------------------------------------------------------------------------------------------------------------# fingerprint_image &lt;out_txt_file&gt; [image_filename]# Saving build summary to the image#--------------------------------------------------------------------------------------------------------------------------------fingerprint_image(){ cat &lt;&lt;-EOF &gt; &quot;${1}&quot; -------------------------------------------------------------------------------- Title: ${VENDOR} $REVISION ${BOARD^} $DISTRIBUTION $RELEASE $BRANCH Kernel: Linux $VER Build date: $(date +'%d.%m.%Y') Maintainer: $MAINTAINER &lt;$MAINTAINERMAIL&gt; Sources: https://github.com/orangepi-xunlong/orangepi-build Support: http://www.orangepi.org/ EOF if [ -n &quot;$2&quot; ]; then cat &lt;&lt;-EOF &gt;&gt; &quot;${1}&quot; -------------------------------------------------------------------------------- Partitioning configuration: $IMAGE_PARTITION_TABLE offset: $OFFSET Boot partition type: ${BOOTFS_TYPE:-(none)} ${BOOTSIZE:+&quot;(${BOOTSIZE} MB)&quot;} Root partition type: $ROOTFS_TYPE ${FIXED_IMAGE_SIZE:+&quot;(${FIXED_IMAGE_SIZE} MB)&quot;} CPU configuration: $CPUMIN - $CPUMAX with $GOVERNOR -------------------------------------------------------------------------------- Verify GPG signature: gpg --verify $2.img.asc Verify image file integrity: sha256sum --check $2.img.sha Prepare SD card (four methodes): zcat $2.img.gz | pv | dd of=/dev/sdX bs=1M dd if=$2.img of=/dev/sdX bs=1M balena-etcher $2.img.gz -d /dev/sdX balena-etcher $2.img -d /dev/sdX EOF fi cat &lt;&lt;-EOF &gt;&gt; &quot;${1}&quot; -------------------------------------------------------------------------------- $(cat &quot;${SRC}&quot;/LICENSE) -------------------------------------------------------------------------------- EOF}#--------------------------------------------------------------------------------------------------------------------------------# Create kernel boot logo from packages/blobs/splash/logo.png and packages/blobs/splash/spinner.gif (animated)# and place to the file /lib/firmware/bootsplash#--------------------------------------------------------------------------------------------------------------------------------function boot_logo (){display_alert &quot;Building kernel splash logo&quot; &quot;$RELEASE&quot; &quot;info&quot; LOGO=${EXTER}/packages/blobs/splash/logo.png LOGO_WIDTH=$(identify $LOGO | cut -d &quot; &quot; -f 3 | cut -d x -f 1) LOGO_HEIGHT=$(identify $LOGO | cut -d &quot; &quot; -f 3 | cut -d x -f 2) THROBBER=${EXTER}/packages/blobs/splash/spinner.gif THROBBER_WIDTH=$(identify $THROBBER | head -1 | cut -d &quot; &quot; -f 3 | cut -d x -f 1) THROBBER_HEIGHT=$(identify $THROBBER | head -1 | cut -d &quot; &quot; -f 3 | cut -d x -f 2) convert -alpha remove -background &quot;#000000&quot; $LOGO &quot;${SDCARD}&quot;/tmp/logo.rgb convert -alpha remove -background &quot;#000000&quot; $THROBBER &quot;${SDCARD}&quot;/tmp/throbber%02d.rgb ${EXTER}/packages/blobs/splash/bootsplash-packer \\ --bg_red 0x00 \\ --bg_green 0x00 \\ --bg_blue 0x00 \\ --frame_ms 48 \\ --picture \\ --pic_width $LOGO_WIDTH \\ --pic_height $LOGO_HEIGHT \\ --pic_position 0 \\ --blob &quot;${SDCARD}&quot;/tmp/logo.rgb \\ --picture \\ --pic_width $THROBBER_WIDTH \\ --pic_height $THROBBER_HEIGHT \\ --pic_position 0x05 \\ --pic_position_offset 200 \\ --pic_anim_type 1 \\ --pic_anim_loop 0 \\ --blob &quot;${SDCARD}&quot;/tmp/throbber00.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber01.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber02.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber03.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber04.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber05.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber06.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber07.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber08.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber09.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber10.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber11.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber12.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber13.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber14.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber15.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber16.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber17.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber18.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber19.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber20.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber21.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber22.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber23.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber24.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber25.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber26.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber27.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber28.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber29.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber30.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber31.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber32.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber33.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber34.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber35.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber36.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber37.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber38.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber39.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber40.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber41.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber42.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber43.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber44.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber45.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber46.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber47.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber48.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber49.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber50.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber51.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber52.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber53.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber54.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber55.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber56.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber57.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber58.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber59.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber60.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber61.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber62.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber63.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber64.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber65.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber66.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber67.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber68.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber69.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber70.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber71.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber72.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber73.rgb \\ --blob &quot;${SDCARD}&quot;/tmp/throbber74.rgb \\ &quot;${SDCARD}&quot;/lib/firmware/bootsplash.orangepi &gt;/dev/null 2&gt;&amp;1 if [[ $BOOT_LOGO == yes || $BOOT_LOGO == desktop &amp;&amp; $BUILD_DESKTOP == yes &amp;&amp; $RELEASE != buster ]]; then [[ -f &quot;${SDCARD}&quot;/boot/orangepiEnv.txt ]] &amp;&amp; grep -q '^bootlogo' &quot;${SDCARD}&quot;/boot/orangepiEnv.txt &amp;&amp; \\ sed -i 's/^bootlogo.*/bootlogo=true/' &quot;${SDCARD}&quot;/boot/orangepiEnv.txt || echo 'bootlogo=true' &gt;&gt; &quot;${SDCARD}&quot;/boot/orangepiEnv.txt [[ -f &quot;${SDCARD}&quot;/boot/boot.ini ]] &amp;&amp; sed -i 's/^setenv bootlogo.*/setenv bootlogo &quot;true&quot;/' &quot;${SDCARD}&quot;/boot/boot.ini fi # enable additional services chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl --no-reload enable bootsplash-ask-password-console.path &gt;/dev/null 2&gt;&amp;1&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl --no-reload enable bootsplash-hide-when-booted.service &gt;/dev/null 2&gt;&amp;1&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl --no-reload enable bootsplash-show-on-shutdown.service &gt;/dev/null 2&gt;&amp;1&quot;}DISTRIBUTIONS_DESC_DIR=&quot;external/config/distributions&quot;function distro_menu (){# create a select menu for choosing a distribution based EXPERT status local distrib_dir=&quot;${1}&quot; if [[ -d &quot;${distrib_dir}&quot; &amp;&amp; -f &quot;${distrib_dir}/support&quot; ]]; then local support_level=&quot;$(cat &quot;${distrib_dir}/support&quot;)&quot; if [[ &quot;${support_level}&quot; != &quot;supported&quot; &amp;&amp; $EXPERT != &quot;yes&quot; ]]; then : else local distro_codename=&quot;$(basename &quot;${distrib_dir}&quot;)&quot; local distro_fullname=&quot;$(cat &quot;${distrib_dir}/name&quot;)&quot; local expert_infos=&quot;&quot; [[ $EXPERT == &quot;yes&quot; ]] &amp;&amp; expert_infos=&quot;(${support_level})&quot; if [[ &quot;${BRANCH}&quot; == &quot;legacy&quot; ]]; then DISTRIB_TYPE=&quot;${DISTRIB_TYPE_LEGACY}&quot; [[ -z &quot;${DISTRIB_TYPE_LEGACY}&quot; ]] &amp;&amp; DISTRIB_TYPE=&quot;buster bionic focal&quot; elif [[ &quot;${BRANCH}&quot; == &quot;current&quot; ]]; then DISTRIB_TYPE=&quot;${DISTRIB_TYPE_CURRENT}&quot; [[ -z &quot;${DISTRIB_TYPE_CURRENT}&quot; ]] &amp;&amp; DISTRIB_TYPE=&quot;bullseye bookworm focal jammy&quot; elif [[ &quot;${BRANCH}&quot; == &quot;next&quot; ]]; then if [[ -n &quot;${DISTRIB_TYPE_NEXT}&quot; ]]; then DISTRIB_TYPE=&quot;${DISTRIB_TYPE_NEXT}&quot; else DISTRIB_TYPE=&quot;${DISTRIB_TYPE_CURRENT}&quot; [[ -z &quot;${DISTRIB_TYPE_CURRENT}&quot; ]] &amp;&amp; DISTRIB_TYPE=&quot;bullseye bookworm focal jammy&quot; fi fi if [[ &quot;${DISTRIB_TYPE}&quot; =~ &quot;${distro_codename}&quot; ]]; then options+=(&quot;${distro_codename}&quot; &quot;${distro_fullname} ${expert_infos}&quot;) fi fi fi}function distros_options() { for distrib_dir in &quot;${DISTRIBUTIONS_DESC_DIR}/&quot;*; do distro_menu &quot;${distrib_dir}&quot; done}function set_distribution_status() { local distro_support_desc_filepath=&quot;${SRC}/${DISTRIBUTIONS_DESC_DIR}/${RELEASE}/support&quot; if [[ ! -f &quot;${distro_support_desc_filepath}&quot; ]]; then exit_with_error &quot;Distribution ${distribution_name} does not exist&quot; else DISTRIBUTION_STATUS=&quot;$(cat &quot;${distro_support_desc_filepath}&quot;)&quot; fi [[ &quot;${DISTRIBUTION_STATUS}&quot; != &quot;supported&quot; ]] &amp;&amp; [[ &quot;${EXPERT}&quot; != &quot;yes&quot; ]] &amp;&amp; exit_with_error &quot;Orange Pi ${RELEASE} is unsupported and, therefore, only available to experts (EXPERT=yes)&quot;}adding_packages(){# add deb files to repository if they are not already there display_alert &quot;Checking and adding to repository $release&quot; &quot;$3&quot; &quot;ext&quot; for f in &quot;${DEB_STORAGE}${2}&quot;/*.deb do local name version arch name=$(dpkg-deb -I &quot;${f}&quot; | grep Package | awk '{print $2}') version=$(dpkg-deb -I &quot;${f}&quot; | grep Version | awk '{print $2}') arch=$(dpkg-deb -I &quot;${f}&quot; | grep Architecture | awk '{print $2}') # add if not already there aptly repo search -architectures=&quot;${arch}&quot; -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${1}&quot; 'Name (% '${name}'), $Version (='${version}'), $Architecture (='${arch}')' &amp;&gt;/dev/null if [[ $? -ne 0 ]]; then display_alert &quot;Adding ${1}&quot; &quot;$name&quot; &quot;info&quot; aptly repo add -force-replace=true -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${1}&quot; &quot;${f}&quot; &amp;&gt;/dev/null fi done}addtorepo(){# create repository# parameter &quot;remove&quot; dumps all and creates new# parameter &quot;delete&quot; remove incoming directory if publishing is succesful# function: cycle trough distributions local distributions=(&quot;stretch&quot; &quot;bionic&quot; &quot;buster&quot; &quot;bullseye&quot; &quot;bookworm&quot; &quot;focal&quot; &quot;hirsute&quot; &quot;jammy&quot; &quot;sid&quot;) #local distributions=($(grep -rw config/distributions/*/ -e 'supported' | cut -d&quot;/&quot; -f3)) local errors=0 for release in &quot;${distributions[@]}&quot;; do local forceoverwrite=&quot;&quot; # let's drop from publish if exits if [[ -n $(aptly publish list -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; -raw | awk '{print $(NF)}' | grep &quot;${release}&quot;) ]]; then aptly publish drop -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${release}&quot; &gt; /dev/null 2&gt;&amp;1 fi # create local repository if not exist if [[ -z $(aptly repo list -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; -raw | awk '{print $(NF)}' | grep &quot;${release}&quot;) ]]; then display_alert &quot;Creating section&quot; &quot;main&quot; &quot;info&quot; aptly repo create -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; -distribution=&quot;${release}&quot; -component=&quot;main&quot; \\ -comment=&quot;Armbian main repository&quot; &quot;${release}&quot; &gt;/dev/null fi if [[ -z $(aptly repo list -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; -raw | awk '{print $(NF)}' | grep &quot;^utils&quot;) ]]; then aptly repo create -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; -distribution=&quot;${release}&quot; -component=&quot;utils&quot; \\ -comment=&quot;Armbian utilities (backwards compatibility)&quot; utils &gt;/dev/null fi if [[ -z $(aptly repo list -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; -raw | awk '{print $(NF)}' | grep &quot;${release}-utils&quot;) ]]; then aptly repo create -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; -distribution=&quot;${release}&quot; -component=&quot;${release}-utils&quot; \\ -comment=&quot;Armbian ${release} utilities&quot; &quot;${release}-utils&quot; &gt;/dev/null fi if [[ -z $(aptly repo list -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; -raw | awk '{print $(NF)}' | grep &quot;${release}-desktop&quot;) ]]; then aptly repo create -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; -distribution=&quot;${release}&quot; -component=&quot;${release}-desktop&quot; \\ -comment=&quot;Armbian ${release} desktop&quot; &quot;${release}-desktop&quot; &gt;/dev/null fi # adding main if find &quot;${DEB_STORAGE}&quot;/ -maxdepth 1 -type f -name &quot;*.deb&quot; 2&gt;/dev/null | grep -q .; then adding_packages &quot;$release&quot; &quot;&quot; &quot;main&quot; else aptly repo add -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${release}&quot; &quot;${SCRIPTPATH}config/templates/example.deb&quot; &gt;/dev/null fi local COMPONENTS=&quot;main&quot; # adding main distribution packages if find &quot;${DEB_STORAGE}/${release}&quot; -maxdepth 1 -type f -name &quot;*.deb&quot; 2&gt;/dev/null | grep -q .; then adding_packages &quot;${release}-utils&quot; &quot;/${release}&quot; &quot;release packages&quot; else # workaround - add dummy package to not trigger error aptly repo add -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${release}&quot; &quot;${SCRIPTPATH}config/templates/example.deb&quot; &gt;/dev/null fi # adding release-specific utils if find &quot;${DEB_STORAGE}/extra/${release}-utils&quot; -maxdepth 1 -type f -name &quot;*.deb&quot; 2&gt;/dev/null | grep -q .; then adding_packages &quot;${release}-utils&quot; &quot;/extra/${release}-utils&quot; &quot;release utils&quot; else aptly repo add -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${release}-utils&quot; &quot;${SCRIPTPATH}config/templates/example.deb&quot; &gt;/dev/null fi COMPONENTS=&quot;${COMPONENTS} ${release}-utils&quot; # adding desktop if find &quot;${DEB_STORAGE}/extra/${release}-desktop&quot; -maxdepth 1 -type f -name &quot;*.deb&quot; 2&gt;/dev/null | grep -q .; then adding_packages &quot;${release}-desktop&quot; &quot;/extra/${release}-desktop&quot; &quot;desktop&quot; else # workaround - add dummy package to not trigger error aptly repo add -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${release}-desktop&quot; &quot;${SCRIPTPATH}config/templates/example.deb&quot; &gt;/dev/null fi COMPONENTS=&quot;${COMPONENTS} ${release}-desktop&quot; local mainnum utilnum desknum mainnum=$(aptly repo show -with-packages -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${release}&quot; | grep &quot;Number of packages&quot; | awk '{print $NF}') utilnum=$(aptly repo show -with-packages -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${release}-desktop&quot; | grep &quot;Number of packages&quot; | awk '{print $NF}') desknum=$(aptly repo show -with-packages -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${release}-utils&quot; | grep &quot;Number of packages&quot; | awk '{print $NF}') if [ $mainnum -gt 0 ] &amp;&amp; [ $utilnum -gt 0 ] &amp;&amp; [ $desknum -gt 0 ]; then # publish aptly publish \\ -acquire-by-hash \\ -passphrase=&quot;${GPG_PASS}&quot; \\ -origin=&quot;Armbian&quot; \\ -label=&quot;Armbian&quot; \\ -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; \\ -component=&quot;${COMPONENTS// /,}&quot; \\ -distribution=&quot;${release}&quot; repo &quot;${release}&quot; ${COMPONENTS//main/} &gt;/dev/null if [[ $? -ne 0 ]]; then display_alert &quot;Publishing failed&quot; &quot;${release}&quot; &quot;err&quot; errors=$((errors+1)) exit 0 fi else errors=$((errors+1)) local err_txt=&quot;: All components must be present: main, utils and desktop for first build&quot; fi done # cleanup display_alert &quot;Cleaning repository&quot; &quot;${DEB_STORAGE}&quot; &quot;info&quot; aptly db cleanup -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; # display what we have echo &quot;&quot; display_alert &quot;List of local repos&quot; &quot;local&quot; &quot;info&quot; (aptly repo list -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot;) | grep -E packages # remove debs if no errors found if [[ $errors -eq 0 ]]; then if [[ &quot;$2&quot; == &quot;delete&quot; ]]; then display_alert &quot;Purging incoming debs&quot; &quot;all&quot; &quot;ext&quot; find &quot;${DEB_STORAGE}&quot; -name &quot;*.deb&quot; -type f -delete fi else display_alert &quot;There were some problems $err_txt&quot; &quot;leaving incoming directory intact&quot; &quot;err&quot; fi}repo-manipulate(){# repository manipulation# &quot;show&quot; displays packages in each repository# &quot;server&quot; serve repository - useful for local diagnostics# &quot;unique&quot; manually select which package should be removed from all repositories# &quot;update&quot; search for new files in output/debs* to add them to repository# &quot;purge&quot; leave only last 5 versions local DISTROS=(&quot;stretch&quot; &quot;bionic&quot; &quot;buster&quot; &quot;bullseye&quot; &quot;bookworm&quot; &quot;focal&quot; &quot;hirsute&quot; &quot;jammy&quot; &quot;sid&quot;) #local DISTROS=($(grep -rw config/distributions/*/ -e 'supported' | cut -d&quot;/&quot; -f3)) case $@ in serve) # display repository content display_alert &quot;Serving content&quot; &quot;common utils&quot; &quot;ext&quot; aptly serve -listen=$(ip -f inet addr | grep -Po 'inet \\K[\\d.]+' | grep -v 127.0.0.1 | head -1):80 -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; exit 0 ;; show) # display repository content for release in &quot;${DISTROS[@]}&quot;; do display_alert &quot;Displaying repository contents for&quot; &quot;$release&quot; &quot;ext&quot; aptly repo show -with-packages -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${release}&quot; | tail -n +7 aptly repo show -with-packages -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${release}-desktop&quot; | tail -n +7 done display_alert &quot;Displaying repository contents for&quot; &quot;common utils&quot; &quot;ext&quot; aptly repo show -with-packages -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; utils | tail -n +7 echo &quot;done.&quot; exit 0 ;; unique) # which package should be removed from all repositories IFS=$'\\n' while true; do LIST=() for release in &quot;${DISTROS[@]}&quot;; do LIST+=( $(aptly repo show -with-packages -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${release}&quot; | tail -n +7) ) LIST+=( $(aptly repo show -with-packages -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${release}-desktop&quot; | tail -n +7) ) done LIST+=( $(aptly repo show -with-packages -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; utils | tail -n +7) ) LIST=( $(echo &quot;${LIST[@]}&quot; | tr ' ' '\\n' | sort -u)) new_list=() # create a human readable menu for ((n=0;n&lt;$((${#LIST[@]}));n++)); do new_list+=( &quot;${LIST[$n]}&quot; ) new_list+=( &quot;&quot; ) done LIST=(&quot;${new_list[@]}&quot;) LIST_LENGTH=$((${#LIST[@]}/2)); exec 3&gt;&amp;1 TARGET_VERSION=$(dialog --cancel-label &quot;Cancel&quot; --backtitle &quot;BACKTITLE&quot; --no-collapse --title &quot;Remove packages from repositories&quot; --clear --menu &quot;Delete&quot; $((9+${LIST_LENGTH})) 82 65 &quot;${LIST[@]}&quot; 2&gt;&amp;1 1&gt;&amp;3) exitstatus=$?; exec 3&gt;&amp;- if [[ $exitstatus -eq 0 ]]; then for release in &quot;${DISTROS[@]}&quot;; do aptly repo remove -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${release}&quot; &quot;$TARGET_VERSION&quot; aptly repo remove -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${release}-desktop&quot; &quot;$TARGET_VERSION&quot; done aptly repo remove -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;utils&quot; &quot;$TARGET_VERSION&quot; else exit 1 fi aptly db cleanup -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &gt; /dev/null 2&gt;&amp;1 done ;; update) # display full help test # run repository update addtorepo &quot;update&quot; &quot;&quot; # add a key to repo cp &quot;${SCRIPTPATH}&quot;config/armbian.key &quot;${REPO_STORAGE}&quot;/public/ exit 0 ;; purge) for release in &quot;${DISTROS[@]}&quot;; do repo-remove-old-packages &quot;$release&quot; &quot;armhf&quot; &quot;5&quot; repo-remove-old-packages &quot;$release&quot; &quot;arm64&quot; &quot;5&quot; repo-remove-old-packages &quot;$release&quot; &quot;amd64&quot; &quot;5&quot; repo-remove-old-packages &quot;$release&quot; &quot;all&quot; &quot;5&quot; aptly -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; -passphrase=&quot;${GPG_PASS}&quot; publish update &quot;${release}&quot; &gt; /dev/null 2&gt;&amp;1 done exit 0 ;; purgeedge) for release in &quot;${DISTROS[@]}&quot;; do repo-remove-old-packages &quot;$release&quot; &quot;armhf&quot; &quot;3&quot; &quot;edge&quot; repo-remove-old-packages &quot;$release&quot; &quot;arm64&quot; &quot;3&quot; &quot;edge&quot; repo-remove-old-packages &quot;$release&quot; &quot;amd64&quot; &quot;3&quot; &quot;edge&quot; repo-remove-old-packages &quot;$release&quot; &quot;all&quot; &quot;3&quot; &quot;edge&quot; aptly -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; -passphrase=&quot;${GPG_PASS}&quot; publish update &quot;${release}&quot; &gt; /dev/null 2&gt;&amp;1 done exit 0 ;; purgesource) for release in &quot;${DISTROS[@]}&quot;; do aptly repo remove -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${release}&quot; 'Name (% *-source*)' aptly -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; -passphrase=&quot;${GPG_PASS}&quot; publish update &quot;${release}&quot; &gt; /dev/null 2&gt;&amp;1 done aptly db cleanup -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &gt; /dev/null 2&gt;&amp;1 exit 0 ;; *) echo -e &quot;Usage: repository show | serve | unique | create | update | purge | purgesource\\n&quot; echo -e &quot;\\n show = display repository content&quot; echo -e &quot;\\n serve = publish your repositories on current server over HTTP&quot; echo -e &quot;\\n unique = manually select which package should be removed from all repositories&quot; echo -e &quot;\\n update = updating repository&quot; echo -e &quot;\\n purge = removes all but last 5 versions&quot; echo -e &quot;\\n purgeedge = removes all but last 3 edge versions&quot; echo -e &quot;\\n purgesource = removes all sources\\n\\n&quot; exit 0 ;; esac}# Removes old packages in the received repo## $1: Repository# $2: Architecture# $3: Amount of packages to keep# $4: Additional search patternrepo-remove-old-packages() { local repo=$1 local arch=$2 local keep=$3 for pkg in $(aptly repo search -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${repo}&quot; &quot;Architecture ($arch)&quot; | grep -v &quot;ERROR: no results&quot; | sort -t '.' -nk4 | grep -e &quot;$4&quot;); do local pkg_name count=0 pkg_name=$(echo &quot;${pkg}&quot; | cut -d_ -f1) for subpkg in $(aptly repo search -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${repo}&quot; &quot;Name ($pkg_name)&quot; | grep -v &quot;ERROR: no results&quot; | sort -rt '.' -nk4); do ((count+=1)) if [[ $count -gt $keep ]]; then pkg_version=$(echo &quot;${subpkg}&quot; | cut -d_ -f2) aptly repo remove -config=&quot;${SCRIPTPATH}config/${REPO_CONFIG}&quot; &quot;${repo}&quot; &quot;Name ($pkg_name), Version (= $pkg_version)&quot; fi done done}# wait_for_package_manager## * installation will break if we try to install when package manager is running#wait_for_package_manager(){ # exit if package manager is running in the back while true; do if [[ &quot;$(fuser /var/lib/dpkg/lock 2&gt;/dev/null; echo $?)&quot; != 1 &amp;&amp; &quot;$(fuser /var/lib/dpkg/lock-frontend 2&gt;/dev/null; echo $?)&quot; != 1 ]]; then display_alert &quot;Package manager is running in the background.&quot; &quot;Please wait! Retrying in 30 sec&quot; &quot;wrn&quot; sleep 30 else break fi done}# Installing debian packages in the orangepi build system.# The function accepts four optional parameters:# autoupdate - If the installation list is not empty then update first.# upgrade, clean - the same name for apt# verbose - detailed log for the function## list=&quot;pkg1 pkg2 pkg3 pkgbadname pkg-1.0 | pkg-2.0 pkg5 (&gt;= 9)&quot;# install_pkg_deb upgrade verbose $list# or# install_pkg_deb autoupdate $list## If the package has a bad name, we will see it in the log file.# If there is an LOG_OUTPUT_FILE variable and it has a value as# the full real path to the log file, then all the information will be there.## The LOG_OUTPUT_FILE variable must be defined in the calling function# before calling the install_pkg_deb function and unset after.#install_pkg_deb (){ local list=&quot;&quot; local log_file local for_install local need_autoup=false local need_upgrade=false local need_clean=false local need_verbose=false local _line=${BASH_LINENO[0]} local _function=${FUNCNAME[1]} local _file=$(basename &quot;${BASH_SOURCE[1]}&quot;) local tmp_file=$(mktemp /tmp/install_log_XXXXX) export DEBIAN_FRONTEND=noninteractive list=$( for p in $*;do case $p in autoupdate) need_autoup=true; continue ;; upgrade) need_upgrade=true; continue ;; clean) need_clean=true; continue ;; verbose) need_verbose=true; continue ;; \\||\\(*|*\\)) continue ;; esac echo &quot; $p&quot; done ) if [ -d $(dirname $LOG_OUTPUT_FILE) ]; then log_file=${LOG_OUTPUT_FILE} else log_file=&quot;${SRC}/output/${LOG_SUBPATH}/install.log&quot; fi # This is necessary first when there is no apt cache. if $need_upgrade; then apt-get -q update || echo &quot;apt cannot update&quot; &gt;&gt;$tmp_file apt-get -y upgrade || echo &quot;apt cannot upgrade&quot; &gt;&gt;$tmp_file fi # If the package is not installed, check the latest # up-to-date version in the apt cache. # Exclude bad package names and send a message to the log. for_install=$( for p in $list;do if $(dpkg-query -W -f '${db:Status-Abbrev}' $p |&amp; awk '/ii/{exit 1}');then apt-cache show $p -o APT::Cache::AllVersions=no |&amp; \\ awk -v p=$p -v tmp_file=$tmp_file \\ '/^Package:/{print $2} /^E:/{print &quot;Bad package name: &quot;,p &gt;&gt;tmp_file}' fi done ) # This information should be logged. if [ -s $tmp_file ]; then echo -e &quot;\\nInstalling packages in function: $_function&quot; &quot;[$_file:$_line]&quot; \\ &gt;&gt;$log_file echo -e &quot;\\nIncoming list:&quot; &gt;&gt;$log_file printf &quot;%-30s %-30s %-30s %-30s\\n&quot; $list &gt;&gt;$log_file echo &quot;&quot; &gt;&gt;$log_file cat $tmp_file &gt;&gt;$log_file fi if [ -n &quot;$for_install&quot; ]; then if $need_autoup; then apt-get -q update apt-get -y upgrade fi apt-get install -qq -y --no-install-recommends $for_install echo -e &quot;\\nPackages installed:&quot; &gt;&gt;$log_file dpkg-query -W \\ -f '${binary:Package;-27} ${Version;-23}\\n' \\ $for_install &gt;&gt;$log_file fi # We will show the status after installation all listed if $need_verbose; then echo -e &quot;\\nstatus after installation:&quot; &gt;&gt;$log_file dpkg-query -W \\ -f '${binary:Package;-27} ${Version;-23} [ ${Status} ]\\n' \\ $list &gt;&gt;$log_file fi if $need_clean;then apt-get clean; fi rm $tmp_file}# prepare_host_basic## * installs only basic packages#prepare_host_basic(){ # command:package1 package2 ... # list of commands that are neeeded:packages where this command is local check_pack install_pack local checklist=( &quot;whiptail:whiptail&quot; &quot;dialog:dialog&quot; &quot;fuser:psmisc&quot; &quot;getfacl:acl&quot; &quot;uuid:uuid uuid-runtime&quot; &quot;curl:curl&quot; &quot;gpg:gnupg&quot; &quot;gawk:gawk&quot; &quot;git:git&quot; ) for check_pack in &quot;${checklist[@]}&quot;; do if ! which ${check_pack%:*} &gt;/dev/null; then local install_pack+=${check_pack#*:}&quot; &quot;; fi done if [[ -n $install_pack ]]; then display_alert &quot;Installing basic packages&quot; &quot;$install_pack&quot; sudo bash -c &quot;apt-get -qq update &amp;&amp; apt-get install -qq -y --no-install-recommends $install_pack&quot; fi}# prepare_host## * checks and installs necessary packages# * creates directory structure# * changes system settings#prepare_host(){ display_alert &quot;Preparing&quot; &quot;host&quot; &quot;info&quot; # The 'offline' variable must always be set to 'true' or 'false' if [ &quot;$OFFLINE_WORK&quot; == &quot;yes&quot; ]; then local offline=true else local offline=false fi # wait until package manager finishes possible system maintanace wait_for_package_manager # fix for Locales settings if ! grep -q &quot;^en_US.UT -8 UTF-8&quot; /etc/locale.gen; then sudo sed -i 's/# en_US.UTF-8/en_US.UTF-8/' /etc/locale.gen sudo locale-gen fi export LC_ALL=&quot;en_US.UTF-8&quot; # packages list for host # NOTE: please sync any changes here with the Dockerfile and Vagrantfile local hostdeps=&quot;acl aptly aria2 bc binfmt-support bison btrfs-progs \\ build-essential ca-certificates ccache cpio cryptsetup curl \\ debian-archive-keyring debian-keyring debootstrap device-tree-compiler \\ dialog dirmngr dosfstools dwarves f2fs-tools fakeroot flex gawk \\ gcc-arm-linux-gnueabihf gdisk gpg imagemagick jq kmod libbison-dev \\ libc6-dev-armhf-cross libelf-dev libfdt-dev libfile-fcntllock-perl \\ libfl-dev liblz4-tool libncurses-dev libpython2.7-dev libssl-dev \\ libusb-1.0-0-dev linux-base locales lzop ncurses-base ncurses-term \\ nfs-kernel-server ntpdate p7zip-full parted patchutils pigz pixz \\ pkg-config pv python3-dev python3-distutils qemu-user-static rsync swig \\ systemd-container u-boot-tools udev unzip uuid-dev wget whiptail zip \\ zlib1g-dev&quot; if [[ $(dpkg --print-architecture) == amd64 ]]; then hostdeps+=&quot; distcc lib32ncurses-dev lib32stdc++6 libc6-i386&quot; grep -q i386 &lt;(dpkg --print-foreign-architectures) || dpkg --add-architecture i386 elif [[ $(dpkg --print-architecture) == arm64 ]]; then hostdeps+=&quot; gcc-arm-linux-gnueabi gcc-arm-none-eabi libc6 libc6-amd64-cross qemu&quot; else display_alert &quot;Please read documentation to set up proper compilation environment&quot; display_alert &quot;https://www.armbian.com/using-armbian-tools/&quot; exit_with_error &quot;Running this tool on non x86_64 build host is not supported&quot; fi # Add support for Ubuntu 20.04, 21.04 and Mint 20.x if [[ $HOSTRELEASE =~ ^(focal|hirsute|jammy|ulyana|ulyssa|bullseye|bookworm|uma)$ ]]; then hostdeps+=&quot; python2 python3&quot; ln -fs /usr/bin/python2.7 /usr/bin/python2 ln -fs /usr/bin/python2.7 /usr/bin/python else hostdeps+=&quot; python libpython-dev&quot; fi display_alert &quot;Build host OS release&quot; &quot;${HOSTRELEASE:-(unknown)}&quot; &quot;info&quot; # Ubuntu 21.04.x (Hirsute) x86_64 is the only fully supported host OS release # Using Docker/VirtualBox/Vagrant is the only supported way to run the build script on other Linux distributions # # NO_HOST_RELEASE_CHECK overrides the check for a supported host system # Disable host OS check at your own risk. Any issues reported with unsupported releases will be closed without discussion if [[ -z $HOSTRELEASE || &quot;focal jammy&quot; != *&quot;$HOSTRELEASE&quot;* ]]; then if [[ $NO_HOST_RELEASE_CHECK == yes ]]; then display_alert &quot;You are running on an unsupported system&quot; &quot;${HOSTRELEASE:-(unknown)}&quot; &quot;wrn&quot; display_alert &quot;Do not report any errors, warnings or other issues encountered beyond this point&quot; &quot;&quot; &quot;wrn&quot; else exit_with_error &quot;It seems you ignore documentation and run an unsupported build system: ${HOSTRELEASE:-(unknown)}&quot; fi fi if grep -qE &quot;(Microsoft|WSL)&quot; /proc/version; then if [ -f /.dockerenv ]; then display_alert &quot;Building images using Docker on WSL2 may fail&quot; &quot;&quot; &quot;wrn&quot; else exit_with_error &quot;Windows subsystem for Linux is not a supported build environment&quot; fi fi if systemd-detect-virt -q -c; then display_alert &quot;Running in container&quot; &quot;$(systemd-detect-virt)&quot; &quot;info&quot; # disable apt-cacher unless NO_APT_CACHER=no is not specified explicitly if [[ $NO_APT_CACHER != no ]]; then display_alert &quot;apt-cacher is disabled in containers, set NO_APT_CACHER=no to override&quot; &quot;&quot; &quot;wrn&quot; NO_APT_CACHER=yes fi CONTAINER_COMPAT=yes # trying to use nested containers is not a good idea, so don't permit EXTERNAL_NEW=compile if [[ $EXTERNAL_NEW == compile ]]; then display_alert &quot;EXTERNAL_NEW=compile is not available when running in container, setting to prebuilt&quot; &quot;&quot; &quot;wrn&quot; EXTERNAL_NEW=prebuilt fi SYNC_CLOCK=no fi # Skip verification if you are working offline if ! $offline; then # warning: apt-cacher-ng will fail if installed and used both on host and in # container/chroot environment with shared network # set NO_APT_CACHER=yes to prevent installation errors in such case if [[ $NO_APT_CACHER != yes ]]; then hostdeps+=&quot; apt-cacher-ng&quot;; fi export EXTRA_BUILD_DEPS=&quot;&quot; call_extension_method &quot;add_host_dependencies&quot; &lt;&lt;- 'ADD_HOST_DEPENDENCIES' *run before installing host dependencies* you can add packages to install, space separated, to ${EXTRA_BUILD_DEPS} here. ADD_HOST_DEPENDENCIES if [ -n &quot;${EXTRA_BUILD_DEPS}&quot; ]; then hostdeps+=&quot; ${EXTRA_BUILD_DEPS}&quot;; fi display_alert &quot;Installing build dependencies&quot; # don't prompt for apt cacher selection sudo echo &quot;apt-cacher-ng apt-cacher-ng/tunnelenable boolean false&quot; | sudo debconf-set-selections LOG_OUTPUT_FILE=&quot;${DEST}&quot;/${LOG_SUBPATH}/hostdeps.log install_pkg_deb &quot;autoupdate $hostdeps&quot; unset LOG_OUTPUT_FILE update-ccache-symlinks export FINAL_HOST_DEPS=&quot;$hostdeps ${EXTRA_BUILD_DEPS}&quot; call_extension_method &quot;host_dependencies_ready&quot; &lt;&lt;- 'HOST_DEPENDENCIES_READY' *run after all host dependencies are installed* At this point we can read `${FINAL_HOST_DEPS}`, but changing won't have any effect. All the dependencies, including the default/core deps and the ones added via `${EXTRA_BUILD_DEPS}` are installed at this point. The system clock has not yet been synced. HOST_DEPENDENCIES_READY # sync clock if [[ $SYNC_CLOCK != no ]]; then display_alert &quot;Syncing clock&quot; &quot;${NTP_SERVER:-pool.ntp.org}&quot; &quot;info&quot; ntpdate -s &quot;${NTP_SERVER:-pool.ntp.org}&quot; fi # create directory structure mkdir -p $SRC/output $EXTER/cache $USERPATCHES_PATH if [[ -n $SUDO_USER ]]; then chgrp --quiet sudo cache output &quot;${USERPATCHES_PATH}&quot; # SGID bit on cache/sources breaks kernel dpkg packaging chmod --quiet g+w,g+s output &quot;${USERPATCHES_PATH}&quot; # fix existing permissions find &quot;${SRC}&quot;/output &quot;${USERPATCHES_PATH}&quot; -type d ! -group sudo -exec chgrp --quiet sudo {} \\; find &quot;${SRC}&quot;/output &quot;${USERPATCHES_PATH}&quot; -type d ! -perm -g+w,g+s -exec chmod --quiet g+w,g+s {} \\; fi mkdir -p $DEST/debs/{extra,u-boot} $DEST/{config,debug,patch,images} $USERPATCHES_PATH/overlay $EXTER/cache/{debs,sources,hash} $SRC/toolchains $SRC/.tmp # build aarch64 if [[ $(dpkg --print-architecture) == amd64 ]]; then if [[ &quot;${SKIP_EXTERNAL_TOOLCHAINS}&quot; != &quot;yes&quot; ]]; then # bind mount toolchain if defined if [[ -d &quot;${ARMBIAN_CACHE_TOOLCHAIN_PATH}&quot; ]]; then mountpoint -q &quot;${SRC}&quot;/cache/toolchain &amp;&amp; umount -l &quot;${SRC}&quot;/cache/toolchain mount --bind &quot;${ARMBIAN_CACHE_TOOLCHAIN_PATH}&quot; &quot;${SRC}&quot;/cache/toolchain fi display_alert &quot;Checking for external GCC compilers&quot; &quot;&quot; &quot;info&quot; # download external Linaro compiler and missing special dependencies since they are needed for certain sources local toolchains=( &quot;gcc-linaro-aarch64-none-elf-4.8-2013.11_linux.tar.xz&quot; &quot;gcc-linaro-arm-none-eabi-4.8-2014.04_linux.tar.xz&quot; &quot;gcc-linaro-arm-linux-gnueabihf-4.8-2014.04_linux.tar.xz&quot; &quot;gcc-linaro-4.9.4-2017.01-x86_64_arm-linux-gnueabi.tar.xz&quot; &quot;gcc-linaro-4.9.4-2017.01-x86_64_aarch64-linux-gnu.tar.xz&quot; &quot;gcc-linaro-5.5.0-2017.10-x86_64_arm-linux-gnueabihf.tar.xz&quot; &quot;gcc-linaro-7.4.1-2019.02-x86_64_arm-linux-gnueabi.tar.xz&quot; &quot;gcc-linaro-7.4.1-2019.02-x86_64_aarch64-linux-gnu.tar.xz&quot; &quot;gcc-arm-9.2-2019.12-x86_64-arm-none-linux-gnueabihf.tar.xz&quot; &quot;gcc-arm-9.2-2019.12-x86_64-aarch64-none-linux-gnu.tar.xz&quot; &quot;gcc-arm-11.2-2022.02-x86_64-arm-none-linux-gnueabihf.tar.xz&quot; &quot;gcc-arm-11.2-2022.02-x86_64-aarch64-none-linux-gnu.tar.xz&quot; ) USE_TORRENT_STATUS=${USE_TORRENT} USE_TORRENT=&quot;no&quot; for toolchain in ${toolchains[@]}; do download_and_verify &quot;_toolchain&quot; &quot;${toolchain##*/}&quot; done USE_TORRENT=${USE_TORRENT_STATUS} rm -rf $SRC/toolchains/*.tar.xz* local existing_dirs=( $(ls -1 $SRC/toolchains) ) for dir in ${existing_dirs[@]}; do local found=no for toolchain in ${toolchains[@]}; do local filename=${toolchain##*/} local dirname=${filename//.tar.xz} [[ $dir == $dirname ]] &amp;&amp; found=yes done if [[ $found == no ]]; then display_alert &quot;Removing obsolete toolchain&quot; &quot;$dir&quot; rm -rf $SRC/toolchains/$dir fi done else display_alert &quot;Ignoring toolchains&quot; &quot;SKIP_EXTERNAL_TOOLCHAINS: ${SKIP_EXTERNAL_TOOLCHAINS}&quot; &quot;info&quot; fi fi fi # check offline # enable arm binary format so that the cross-architecture chroot environment will work if [[ $BUILD_OPT == &quot;image&quot; || $BUILD_OPT == &quot;rootfs&quot; ]]; then modprobe -q binfmt_misc mountpoint -q /proc/sys/fs/binfmt_misc/ || mount binfmt_misc -t binfmt_misc /proc/sys/fs/binfmt_misc if [[ &quot;$(arch)&quot; != &quot;aarch64&quot; ]]; then test -e /proc/sys/fs/binfmt_misc/qemu-arm || update-binfmts --enable qemu-arm test -e /proc/sys/fs/binfmt_misc/qemu-aarch64 || update-binfmts --enable qemu-aarch64 fi fi [[ ! -f &quot;${USERPATCHES_PATH}&quot;/customize-image.sh ]] &amp;&amp; cp &quot;${EXTER}&quot;/config/templates/customize-image.sh.template &quot;${USERPATCHES_PATH}&quot;/customize-image.sh if [[ ! -f &quot;${USERPATCHES_PATH}&quot;/README ]]; then rm -f &quot;${USERPATCHES_PATH}&quot;/readme.txt echo 'Please read documentation about customizing build configuration' &gt; &quot;${USERPATCHES_PATH}&quot;/README echo 'https:/www.orangepi.org' &gt;&gt; &quot;${USERPATCHES_PATH}&quot;/README # create patches directory structure under USERPATCHES_PATH find $EXTER/patch -maxdepth 2 -type d ! -name . | sed &quot;s%/.*patch%/$USERPATCHES_PATH%&quot; | xargs mkdir -p fi # check free space (basic) local freespace=$(findmnt --target &quot;${SRC}&quot; -n -o AVAIL -b 2&gt;/dev/null) # in bytes if [[ -n $freespace &amp;&amp; $(( $freespace / 1073741824 )) -lt 10 ]]; then display_alert &quot;Low free space left&quot; &quot;$(( $freespace / 1073741824 )) GiB&quot; &quot;wrn&quot; # pause here since dialog-based menu will hide this message otherwise echo -e &quot;Press \\e[0;33m&lt;Ctrl-C&gt;\\x1B[0m to abort compilation, \\e[0;33m&lt;Enter&gt;\\x1B[0m to ignore and continue&quot; read fi}function webseed (){ # list of mirrors that host our files unset text # Hardcoded to EU mirrors since local CCODE=$(curl -s redirect.armbian.com/geoip | jq '.continent.code' -r) WEBSEED=($(curl -s https://redirect.armbian.com/mirrors | jq -r '.'${CCODE}' | .[] | values')) # aria2 simply split chunks based on sources count not depending on download speed # when selecting china mirrors, use only China mirror, others are very slow there if [[ $DOWNLOAD_MIRROR == china ]]; then WEBSEED=( https://mirrors.tuna.tsinghua.edu.cn/armbian-releases/ ) elif [[ $DOWNLOAD_MIRROR == bfsu ]]; then WEBSEED=( https://mirrors.bfsu.edu.cn/armbian-releases/ ) fi for toolchain in ${WEBSEED[@]}; do text=&quot;${text} ${toolchain}${1}&quot; done text=&quot;${text:1}&quot; echo &quot;${text}&quot;}download_and_verify(){ local remotedir=$1 local filename=$2 local localdir=$SRC/toolchains local dirname=${filename//.tar.xz} if [[ $DOWNLOAD_MIRROR == china ]]; then local server=&quot;https://mirrors.tuna.tsinghua.edu.cn/armbian-releases/&quot; elif [[ $DOWNLOAD_MIRROR == bfsu ]]; then local server=&quot;https://mirrors.bfsu.edu.cn/armbian-releases/&quot; else local server=${ARMBIAN_MIRROR} fi if [[ -f ${localdir}/${dirname}/.download-complete ]]; then return fi # switch to china mirror if US timeouts timeout 10 curl --head --fail --silent ${server}${remotedir}/${filename} 2&gt;&amp;1 &gt;/dev/null if [[ $? -ne 7 &amp;&amp; $? -ne 22 &amp;&amp; $? -ne 0 ]]; then display_alert &quot;Timeout from $server&quot; &quot;retrying&quot; &quot;info&quot; server=&quot;https://mirrors.tuna.tsinghua.edu.cn/armbian-releases/&quot; # switch to another china mirror if tuna timeouts timeout 10 curl --head --fail --silent ${server}${remotedir}/${filename} 2&gt;&amp;1 &gt;/dev/null if [[ $? -ne 7 &amp;&amp; $? -ne 22 &amp;&amp; $? -ne 0 ]]; then display_alert &quot;Timeout from $server&quot; &quot;retrying&quot; &quot;info&quot; server=&quot;https://mirrors.bfsu.edu.cn/armbian-releases/&quot; fi fi # check if file exists on remote server before running aria2 downloader [[ ! `timeout 10 curl --head --fail --silent ${server}${remotedir}/${filename}` ]] &amp;&amp; return cd &quot;${localdir}&quot; || exit # use local control file if [[ -f &quot;${EXTER}&quot;/config/torrents/${filename}.asc ]]; then local torrent=&quot;${EXTER}&quot;/config/torrents/${filename}.torrent ln -sf &quot;${EXTER}/config/torrents/${filename}.asc&quot; &quot;${localdir}/${filename}.asc&quot; elif [[ ! `timeout 10 curl --head --fail --silent &quot;${server}${remotedir}/${filename}.asc&quot;` ]]; then return else # download control file local torrent=${server}$remotedir/${filename}.torrent aria2c --download-result=hide --disable-ipv6=true --summary-interval=0 --console-log-level=error --auto-file-renaming=false \\ --continue=false --allow-overwrite=true --dir=&quot;${localdir}&quot; ${server}${remotedir}/${filename}.asc $(webseed &quot;$remotedir/${filename}.asc&quot;) -o &quot;${filename}.asc&quot; [[ $? -ne 0 ]] &amp;&amp; display_alert &quot;Failed to download control file&quot; &quot;&quot; &quot;wrn&quot; fi # download torrent first if [[ ${USE_TORRENT} == &quot;yes&quot; ]]; then display_alert &quot;downloading using torrent network&quot; &quot;$filename&quot; local ariatorrent=&quot;--summary-interval=0 --auto-save-interval=0 --seed-time=0 --bt-stop-timeout=120 --console-log-level=error \\ --allow-overwrite=true --download-result=hide --rpc-save-upload-metadata=false --auto-file-renaming=false \\ --file-allocation=trunc --continue=true ${torrent} \\ --dht-file-path=$EXTER/cache/.aria2/dht.dat --disable-ipv6=true --stderr --follow-torrent=mem --dir=${localdir}&quot; # exception. It throws error if dht.dat file does not exists. Error suppress needed only at first download. if [[ -f $EXTER/cache/.aria2/dht.dat ]]; then # shellcheck disable=SC2086 aria2c ${ariatorrent} else # shellcheck disable=SC2035 aria2c ${ariatorrent} &amp;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/torrent.log fi # mark complete [[ $? -eq 0 ]] &amp;&amp; touch &quot;${localdir}/${filename}.complete&quot; fi # direct download if torrent fails if [[ ! -f &quot;${localdir}/${filename}.complete&quot; ]]; then if [[ ! `timeout 10 curl --head --fail --silent ${server}${remotedir}/${filename} 2&gt;&amp;1 &gt;/dev/null` ]]; then display_alert &quot;downloading using http(s) network&quot; &quot;$filename&quot; aria2c --download-result=hide --rpc-save-upload-metadata=false --console-log-level=error \\ --dht-file-path=&quot;${SRC}&quot;/cache/.aria2/dht.dat --disable-ipv6=true --summary-interval=0 --auto-file-renaming=false --dir=&quot;${localdir}&quot; ${server}${remotedir}/${filename} $(webseed &quot;${remotedir}/${filename}&quot;) -o &quot;${filename}&quot; # mark complete [[ $? -eq 0 ]] &amp;&amp; touch &quot;${localdir}/${filename}.complete&quot; &amp;&amp; echo &quot;&quot; fi fi if [[ -f ${localdir}/${filename}.asc ]]; then if grep -q 'BEGIN PGP SIGNATURE' &quot;${localdir}/${filename}.asc&quot;; then if [[ ! -d $EXTER/cache/.gpg ]]; then mkdir -p $EXTER/cache/.gpg chmod 700 $EXTER/cache/.gpg touch $EXTER/cache/.gpg/gpg.conf chmod 600 $EXTER/cache/.gpg/gpg.conf fi # Verify archives with Linaro and Armbian GPG keys if [ x&quot;&quot; != x&quot;${http_proxy}&quot; ]; then (gpg --homedir &quot;${EXTER}&quot;/cache/.gpg --no-permission-warning --list-keys 8F427EAF &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/output.log 2&gt;&amp;1\\ || gpg --homedir &quot;${EXTER}&quot;/cache/.gpg --no-permission-warning \\ --keyserver hkp://keyserver.ubuntu.com:80 --keyserver-options http-proxy=&quot;${http_proxy}&quot; \\ --recv-keys 8F427EAF &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/output.log 2&gt;&amp;1) (gpg --homedir &quot;${EXTER}&quot;/cache/.gpg --no-permission-warning --list-keys 9F0E78D5 &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/output.log 2&gt;&amp;1\\ || gpg --homedir &quot;${EXTER}&quot;/cache/.gpg --no-permission-warning \\ --keyserver hkp://keyserver.ubuntu.com:80 --keyserver-options http-proxy=&quot;${http_proxy}&quot; \\ --recv-keys 9F0E78D5 &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/output.log 2&gt;&amp;1) else (gpg --homedir &quot;${EXTER}&quot;/cache/.gpg --no-permission-warning --list-keys 8F427EAF &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/output.log 2&gt;&amp;1\\ || gpg --homedir &quot;${EXTER}&quot;/cache/.gpg --no-permission-warning \\ --keyserver hkp://keyserver.ubuntu.com:80 \\ --recv-keys 8F427EAF &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/output.log 2&gt;&amp;1) (gpg --homedir &quot;${EXTER}&quot;/cache/.gpg --no-permission-warning --list-keys 9F0E78D5 &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/output.log 2&gt;&amp;1\\ || gpg --homedir &quot;${EXTER}&quot;/cache/.gpg --no-permission-warning \\ --keyserver hkp://keyserver.ubuntu.com:80 \\ --recv-keys 9F0E78D5 &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/output.log 2&gt;&amp;1) fi gpg --homedir &quot;${EXTER}&quot;/cache/.gpg --no-permission-warning --verify \\ --trust-model always -q &quot;${localdir}/${filename}.asc&quot; &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/output.log 2&gt;&amp;1 [[ ${PIPESTATUS[0]} -eq 0 ]] &amp;&amp; verified=true &amp;&amp; display_alert &quot;Verified&quot; &quot;PGP&quot; &quot;info&quot; else md5sum -c --status &quot;${localdir}/${filename}.asc&quot; &amp;&amp; verified=true &amp;&amp; display_alert &quot;Verified&quot; &quot;MD5&quot; &quot;info&quot; fi if [[ $verified == true ]]; then if [[ &quot;${filename:(-6)}&quot; == &quot;tar.xz&quot; ]]; then display_alert &quot;decompressing&quot; pv -p -b -r -c -N &quot;[ .... ] ${filename}&quot; &quot;${filename}&quot; | xz -dc | tar xp --xattrs --no-same-owner --overwrite [[ $? -eq 0 ]] &amp;&amp; touch &quot;${localdir}/${dirname}/.download-complete&quot; fi else exit_with_error &quot;verification failed&quot; fi fi}show_developer_warning(){ local temp_rc temp_rc=$(mktemp) cat &lt;&lt;-'EOF' &gt; &quot;${temp_rc}&quot; screen_color = (WHITE,RED,ON) EOF local warn_text=&quot;You are switching to the \\Z1EXPERT MODE\\Zn This allows building experimental configurations that are provided \\Z1AS IS\\Zn to developers and expert users, \\Z1WITHOUT ANY RESPONSIBILITIES\\Zn from the Armbian team: - You are using these configurations \\Z1AT YOUR OWN RISK\\Zn - Bug reports related to the dev kernel, CSC, WIP and EOS boards \\Z1will be closed without a discussion\\Zn - Forum posts related to dev kernel, CSC, WIP and EOS boards should be created in the \\Z2\\&quot;Community forums\\&quot;\\Zn section &quot; DIALOGRC=$temp_rc dialog --title &quot;Expert mode warning&quot; --backtitle &quot;${backtitle}&quot; --colors --defaultno --no-label &quot;I do not agree&quot; \\ --yes-label &quot;I understand and agree&quot; --yesno &quot;$warn_text&quot; &quot;${TTY_Y}&quot; &quot;${TTY_X}&quot; [[ $? -ne 0 ]] &amp;&amp; exit_with_error &quot;Error switching to the expert mode&quot; SHOW_WARNING=no}# is a formatted output of the values of variables# from the list at the place of the function call.## The LOG_OUTPUT_FILE variable must be defined in the calling function# before calling the `show_checklist_variables` function and unset after.#show_checklist_variables (){ local checklist=$* local var pval local log_file=${LOG_OUTPUT_FILE:-&quot;${SRC}&quot;/output/${LOG_SUBPATH}/trash.log} local _line=${BASH_LINENO[0]} local _function=${FUNCNAME[1]} local _file=$(basename &quot;${BASH_SOURCE[1]}&quot;) echo -e &quot;Show variables in function: $_function&quot; &quot;[$_file:$_line]\\n&quot; &gt;&gt;$log_file for var in $checklist;do eval pval=\\$$var echo -e &quot;\\n$var =:&quot; &gt;&gt;$log_file if [ $(echo &quot;$pval&quot; | awk -F&quot;/&quot; '{print NF}') -ge 4 ];then printf &quot;%s\\n&quot; $pval &gt;&gt;$log_file else printf &quot;%-30s %-30s %-30s %-30s\\n&quot; $pval &gt;&gt;$log_file fi done}install_wiringop(){ install_deb_chroot &quot;$EXTER/cache/debs/arm64/wiringpi_2.51.deb&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;apt-mark hold wiringpi&quot; &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 if [[ ${IGNORE_UPDATES} != yes ]]; then fetch_from_repo &quot;https://github.com/orangepi-xunlong/wiringOP.git&quot; &quot;${EXTER}/cache/sources/wiringOP&quot; &quot;branch:next&quot; &quot;yes&quot; fetch_from_repo &quot;https://github.com/orangepi-xunlong/wiringOP-Python.git&quot; &quot;${EXTER}/cache/sources/wiringOP-Python&quot; &quot;branch:next&quot; &quot;yes&quot; fi cp ${EXTER}/cache/sources/wiringOP/next ${SDCARD}/usr/src/wiringOP -rfa cp ${EXTER}/cache/sources/wiringOP-Python/next ${SDCARD}/usr/src/wiringOP-Python -rfa}install_docker() { [[ $install_docker != yes ]] &amp;&amp; return display_alert &quot;Installing&quot; &quot;docker&quot; &quot;info&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;apt-get install -y -qq apt-transport-https ca-certificates curl gnupg2 software-properties-common &gt;/dev/null 2&gt;&amp;1&quot; case ${RELEASE} in buster|bullseye|bookworm) distributor_id=&quot;debian&quot; ;; xenial|bionic|focal|jammy) distributor_id=&quot;ubuntu&quot; ;; esac if [[ ${SELECTED_CONFIGURATION} == desktop ]]; then mirror_url=https://repo.huaweicloud.com else mirror_url=https://mirrors.aliyun.com fi chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;curl -fsSL ${mirror_url}/docker-ce/linux/${distributor_id}/gpg | apt-key add -&quot; echo &quot;deb [arch=${ARCH}] ${mirror_url}/docker-ce/linux/${distributor_id} ${RELEASE} stable&quot; &gt; &quot;${SDCARD}&quot;/etc/apt/sources.list.d/docker.list chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;apt-get update&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;apt-get install -y -qq docker-ce docker-ce-cli containerd.io&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;sudo groupadd docker&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;sudo usermod -aG docker ${OPI_USERNAME}&quot; run_on_sdcard &quot;systemctl --no-reload disable docker.service&quot;} 3.main.sh分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660#!/bin/bash## Copyright (c) 2013-2021 Igor Pecovnik, igor.pecovnik@gma**.com## This file is licensed under the terms of the GNU General Public# License version 2. This program is licensed &quot;as is&quot; without any# warranty of any kind, whether express or implied.## Main program## 函数，清理列表中的空白字符。cleanup_list() { local varname=&quot;${1}&quot; local list_to_clean=&quot;${!varname}&quot; list_to_clean=&quot;${list_to_clean#&quot;${list_to_clean%%[![:space:]]*}&quot;}&quot; list_to_clean=&quot;${list_to_clean%&quot;${list_to_clean##*[![:space:]]}&quot;}&quot; echo ${list_to_clean}}# 不能是直接执行main.sh,而是要间接执行if [[ $(basename &quot;$0&quot;) == main.sh ]]; then echo &quot;Please use build.sh to start the build process&quot; exit 255fi# default umask for root is 022 so parent directories won't be group writeable without this# this is used instead of making the chmod in prepare_host() recursive# 通过修改根用户的 umask 值，可以确保在创建新的父目录时，组成员具有写权限，而不需要进行递归的权限更改操作。umask 002# destination 设置输出目录if [ -d &quot;$CONFIG_PATH/output&quot; ]; then DEST=&quot;${CONFIG_PATH}&quot;/outputelse DEST=&quot;${SRC}&quot;/outputfi# 设置版本号[[ -z $REVISION ]] &amp;&amp; REVISION=&quot;3.0.8&quot;# 设置ntp时间[[ $DOWNLOAD_MIRROR == &quot;china&quot; ]] &amp;&amp; NTP_SERVER=&quot;cn.pool.ntp.org&quot;# 开始绘制节目if [[ $BUILD_ALL != &quot;yes&quot; ]]; then # override stty size [[ -n $COLUMNS ]] &amp;&amp; stty cols $COLUMNS [[ -n $LINES ]] &amp;&amp; stty rows $LINES TTY_X=$(($(stty size | awk '{print $2}')-6)) # determine terminal width TTY_Y=$(($(stty size | awk '{print $1}')-6)) # determine terminal heightfi# We'll use this title on all menusbacktitle=&quot;Orange Pi building script, http://www.orangepi.org&quot; titlestr=&quot;Choose an option&quot;# Warnings mitigation[[ -z $LANGUAGE ]] &amp;&amp; export LANGUAGE=&quot;en_US:en&quot; # set to english if not set[[ -z $CONSOLE_CHAR ]] &amp;&amp; export CONSOLE_CHAR=&quot;UTF-8&quot; # set console to UTF-8 if not set# Libraries include# shellcheck source=debootstrap.shsource &quot;${SRC}&quot;/scripts/debootstrap.sh # system specific install 系统特定的安装脚本。# shellcheck source=image-helpers.shsource &quot;${SRC}&quot;/scripts/image-helpers.sh # helpers for OS image building 用于操作系统镜像构建的辅助函数脚本# shellcheck source=distributions.shsource &quot;${SRC}&quot;/scripts/distributions.sh # system specific install 系统特定的安装脚本# shellcheck source=desktop.shsource &quot;${SRC}&quot;/scripts/desktop.sh # desktop specific install 桌面环境特定的安装脚本# shellcheck source=compilation.shsource &quot;${SRC}&quot;/scripts/compilation.sh # patching and compilation of kernel, uboot, ATF 补丁和编译内核、uboot、ATF（Arm Trusted Firmware）的脚本# shellcheck source=compilation-prepare.sh#source &quot;${SRC}&quot;/scripts/compilation-prepare.sh # drivers that are not upstreamed 非上游驱动程序的脚本。# shellcheck source=makeboarddeb.shsource &quot;${SRC}&quot;/scripts/makeboarddeb.sh # board support package 用于构建板级支持软件包的脚本# shellcheck source=general.shsource &quot;${SRC}&quot;/scripts/general.sh # general functions 通用函数脚本# shellcheck source=chroot-buildpackages.shsource &quot;${SRC}&quot;/scripts/chroot-buildpackages.sh # chroot packages building 在 chroot 环境中构建软件包的脚本# shellcheck source=pack.shsource &quot;${SRC}&quot;/scripts/pack-uboot.sh 打包 uboot 的脚本# set log pathLOG_SUBPATH=${LOG_SUBPATH:=debug}# compress and remove old logsmkdir -p &quot;${DEST}&quot;/${LOG_SUBPATH}(cd &quot;${DEST}&quot;/${LOG_SUBPATH} &amp;&amp; tar -czf logs-&quot;$(&lt;timestamp)&quot;.tgz ./*.log) &gt; /dev/null 2&gt;&amp;1rm -f &quot;${DEST}&quot;/${LOG_SUBPATH}/*.log &gt; /dev/null 2&gt;&amp;1date +&quot;%d_%m_%Y-%H_%M_%S&quot; &gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/timestamp# delete compressed logs older than 7 days(cd &quot;${DEST}&quot;/${LOG_SUBPATH} &amp;&amp; find . -name '*.tgz' -mtime +7 -delete) &gt; /dev/nullif [[ $PROGRESS_DISPLAY == none ]]; then OUTPUT_VERYSILENT=yeselif [[ $PROGRESS_DISPLAY == dialog ]]; then OUTPUT_DIALOG=yesfiif [[ $PROGRESS_LOG_TO_FILE != yes ]]; then unset PROGRESS_LOG_TO_FILE; fiSHOW_WARNING=yesif [[ $USE_CCACHE != no ]]; then CCACHE=ccache export PATH=&quot;/usr/lib/ccache:$PATH&quot; # private ccache directory to avoid permission issues when using build script with &quot;sudo&quot; # see https://ccache.samba.org/manual.html#_sharing_a_cache for alternative solution [[ $PRIVATE_CCACHE == yes ]] &amp;&amp; export CCACHE_DIR=$EXTER/cache/ccacheelse CCACHE=&quot;&quot;fiif [[ -n $REPOSITORY_UPDATE ]]; then # select stable/beta configuration if [[ $BETA == yes ]]; then DEB_STORAGE=$DEST/debs-beta REPO_STORAGE=$DEST/repository-beta REPO_CONFIG=&quot;aptly-beta.conf&quot; else DEB_STORAGE=$DEST/debs REPO_STORAGE=$DEST/repository REPO_CONFIG=&quot;aptly.conf&quot; fi # For user override if [[ -f &quot;${USERPATCHES_PATH}&quot;/lib.config ]]; then display_alert &quot;Using user configuration override&quot; &quot;userpatches/lib.config&quot; &quot;info&quot; source &quot;${USERPATCHES_PATH}&quot;/lib.config fi repo-manipulate &quot;$REPOSITORY_UPDATE&quot; exitfi# 创建一个选项数组 options，并为每个选项添加标签和描述 ，也就是执行之后进入的第一个界面，有4个选择，uboot 内核 文件系统和完整镜像，最后保存到BUILD_OPT # if BUILD_OPT, KERNEL_CONFIGURE, BOARD, BRANCH or RELEASE are not set, display selection menuif [[ -z $BUILD_OPT ]]; then options+=(&quot;u-boot&quot; &quot;U-boot package&quot;) options+=(&quot;kernel&quot; &quot;Kernel package&quot;) options+=(&quot;rootfs&quot; &quot;Rootfs and all deb packages&quot;) options+=(&quot;image&quot; &quot;Full OS image for flashing&quot;) menustr=&quot;Compile image | rootfs | kernel | u-boot&quot; BUILD_OPT=$(whiptail --title &quot;${titlestr}&quot; --backtitle &quot;${backtitle}&quot; --notags \\ --menu &quot;${menustr}&quot; &quot;${TTY_Y}&quot; &quot;${TTY_X}&quot; $((TTY_Y - 8)) \\ --cancel-button Exit --ok-button Select &quot;${options[@]}&quot; \\ 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3) unset options [[ -z $BUILD_OPT ]] &amp;&amp; exit_with_error &quot;No option selected&quot; [[ $BUILD_OPT == rootfs ]] &amp;&amp; ROOT_FS_CREATE_ONLY=&quot;yes&quot;fi# 内核的选择，两个选择，最后保存到KERNEL_CONFIGUREif [[ ${BUILD_OPT} =~ kernel|image ]]; then if [[ -z $KERNEL_CONFIGURE ]]; then options+=(&quot;no&quot; &quot;Do not change the kernel configuration&quot;) options+=(&quot;yes&quot; &quot;Show a kernel configuration menu before compilation&quot;) menustr=&quot;Select the kernel configuration.&quot; KERNEL_CONFIGURE=$(whiptail --title &quot;${titlestr}&quot; --backtitle &quot;$backtitle&quot; --notags \\ --menu &quot;${menustr}&quot; $TTY_Y $TTY_X $((TTY_Y - 8)) \\ --cancel-button Exit --ok-button Select &quot;${options[@]}&quot; \\ 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3) unset options [[ -z $KERNEL_CONFIGURE ]] &amp;&amp; exit_with_error &quot;No option selected&quot; fifi# 板子的选择，我这里选择orangepi5b，最后保存到BOARD变量中if [[ -z $BOARD ]]; then #options+=(&quot;orangepir1&quot; &quot;Allwinner H2+ quad core 256MB RAM WiFi SPI 2xETH&quot;) #options+=(&quot;orangepizero&quot; &quot;Allwinner H2+ quad core 256MB/512MB RAM WiFi SPI&quot;) #options+=(&quot;orangepipc&quot; &quot;Allwinner H3 quad core 1GB RAM&quot;) #options+=(&quot;orangepipcplus&quot; &quot;Allwinner H3 quad core 1GB RAM WiFi eMMC&quot;) #options+=(&quot;orangepione&quot; &quot;Allwinner H3 quad core 512MB RAM&quot;) #options+=(&quot;orangepilite&quot; &quot;Allwinner H3 quad core 512MB RAM WiFi&quot;) #options+=(&quot;orangepiplus&quot; &quot;Allwinner H3 quad core 1GB/2GB RAM WiFi GBE eMMC&quot;) #options+=(&quot;orangepiplus2e&quot; &quot;Allwinner H3 quad core 2GB RAM WiFi GBE eMMC&quot;) #options+=(&quot;orangepizeroplus2h3&quot; &quot;Allwinner H3 quad core 512MB RAM WiFi/BT eMMC&quot;) #options+=(&quot;orangepipch5&quot; &quot;Allwinner H5 quad core 1GB RAM&quot;) #options+=(&quot;orangepipc2&quot; &quot;Allwinner H5 quad core 1GB RAM GBE SPI&quot;) #options+=(&quot;orangepioneh5&quot; &quot;Allwinner H5 quad core 512MB/1GB RAM&quot;) #options+=(&quot;orangepiprime&quot; &quot;Allwinner H5 quad core 2GB RAM GBE WiFi/BT&quot;) #options+=(&quot;orangepizeroplus&quot; &quot;Allwinner H5 quad core 512MB RAM GBE WiFi SPI&quot;) #options+=(&quot;orangepizeroplus2h5&quot; &quot;Allwinner H5 quad core 512MB RAM WiFi/BT eMMC&quot;) options+=(&quot;orangepi3&quot; &quot;Allwinner H6 quad core 1GB/2GB RAM GBE WiFi/BT eMMC USB3&quot;) options+=(&quot;orangepi3-lts&quot; &quot;Allwinner H6 quad core 2GB RAM GBE WiFi/BT-AW859A eMMC USB3&quot;) #options+=(&quot;orangepilite2&quot; &quot;Allwinner H6 quad core 1GB RAM WiFi/BT USB3&quot;) #options+=(&quot;orangepioneplus&quot; &quot;Allwinner H6 quad core 1GB RAM GBE&quot;) options+=(&quot;orangepizero2&quot; &quot;Allwinner H616 quad core 512MB/1GB RAM WiFi/BT GBE SPI&quot;) #options+=(&quot;orangepizero2-b&quot; &quot;Allwinner H616 quad core 512MB/1GB RAM WiFi/BT GBE SPI&quot;) #options+=(&quot;orangepizero2-lts&quot; &quot;Allwinner H616 quad core 1.5GB RAM WiFi/BT GBE SPI&quot;) options+=(&quot;orangepizero3&quot; &quot;Allwinner H618 quad core 1GB/1.5GB/2GB/4GB RAM WiFi/BT GBE SPI&quot;) options+=(&quot;orangepizero2w&quot; &quot;Allwinner H618 quad core 1GB/1.5GB/2GB/4GB RAM WiFi/BT SPI&quot;) #options+=(&quot;orangepir1b&quot; &quot;Allwinner H618 quad core 1.5GB/2GB/4GB RAM WiFi/BT GBE SPI&quot;) #options+=(&quot;orangepi400&quot; &quot;Allwinner H616 quad core 4GB RAM WiFi/BT GBE eMMC VGA&quot;) options+=(&quot;orangepi4&quot; &quot;Rockchip RK3399 hexa core 4GB RAM GBE eMMC USB3 USB-C WiFi/BT&quot;) options+=(&quot;orangepi4-lts&quot; &quot;Rockchip RK3399 hexa core 4GB RAM GBE eMMC USB3 USB-C WiFi/BT&quot;) options+=(&quot;orangepi800&quot; &quot;Rockchip RK3399 hexa core 4GB RAM GBE eMMC USB3 USB-C WiFi/BT VGA&quot;) options+=(&quot;orangepi5&quot; &quot;Rockchip RK3588S octa core 4-16GB RAM GBE USB3 USB-C NVMe&quot;) #options+=(&quot;orangepicm5&quot; &quot;Rockchip RK3588S octa core 4-16GB RAM GBE USB3 USB-C&quot;) options+=(&quot;orangepi5b&quot; &quot;Rockchip RK3588S octa core 4-16GB RAM GBE USB3 USB-C WiFi/BT eMMC&quot;) #options+=(&quot;orangepitab&quot; &quot;Rockchip RK3588S octa core 4-16GB RAM USB-C WiFi/BT NVMe&quot;) #options+=(&quot;orangepi900&quot; &quot;Rockchip RK3588 octa core 4-16GB RAM 2.5GBE USB3 USB-C WiFi/BT NVMe&quot;) options+=(&quot;orangepi5plus&quot; &quot;Rockchip RK3588 octa core 4-32GB RAM 2.5GBE USB3 USB-C WiFi/BT NVMe eMMC&quot;) options+=(&quot;orangepicm4&quot; &quot;Rockchip RK3566 quad core 2-8GB RAM GBE eMMC USB3 NvMe WiFi/BT&quot;) options+=(&quot;orangepi3b&quot; &quot;Rockchip RK3566 quad core 2-8GB RAM GBE eMMC USB3 NvMe WiFi/BT&quot;) #options+=(&quot;orangepir1plus&quot; &quot;Rockchip RK3328 quad core 1GB RAM 2xGBE USB2 SPI&quot;) menustr=&quot;Please choose a Board.&quot; BOARD=$(whiptail --title &quot;${titlestr}&quot; --backtitle &quot;${backtitle}&quot; \\ --menu &quot;${menustr}&quot; &quot;${TTY_Y}&quot; &quot;${TTY_X}&quot; $((TTY_Y - 8)) \\ --cancel-button Exit --ok-button Select &quot;${options[@]}&quot; \\ 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3) unset options [[ -z $BOARD ]] &amp;&amp; exit_with_error &quot;No option selected&quot;fiBOARD_TYPE=&quot;conf&quot;# shellcheck source=/dev/null # external/config/boards/orangepi5b.conf，类似于瑞芯微的环境配置文件，# Rockchip RK3588s SoC# BOARD_NAME=&quot;Orange Pi 5B&quot;# BOARDFAMILY=&quot;rockchip-rk3588&quot;# BOOTCONFIG=&quot;orangepi_5b_defconfig&quot;# KERNEL_TARGET=&quot;legacy&quot;# BOOT_LOGO=&quot;desktop&quot;# BOOT_FDT_FILE=&quot;rockchip/rk3588s-orangepi-5b.dtb&quot;# BOOT_SCENARIO=&quot;spl-blobs&quot;# IMAGE_PARTITION_TABLE=&quot;gpt&quot;# BOOT_SUPPORT_SPI=&quot;yes&quot;# SKIP_BOOTSPLASH=&quot;yes&quot; # Skip boot splash patch, conflicts with CONFIG_VT=yes# DISTRIB_TYPE_LEGACY=&quot;bullseye bookworm bionic focal jammy&quot;# BOOTFS_TYPE=&quot;fat&quot;# REVISION=&quot;1.0.8&quot;source &quot;${EXTER}/config/boards/${BOARD}.${BOARD_TYPE}&quot;LINUXFAMILY=&quot;${BOARDFAMILY}&quot;[[ -z $KERNEL_TARGET ]] &amp;&amp; exit_with_error &quot;Board configuration does not define valid kernel config&quot;# 这个没有进入，跳过if [[ -z $BRANCH ]]; then options=() [[ $KERNEL_TARGET == *current* ]] &amp;&amp; options+=(&quot;current&quot; &quot;Recommended. Come with best support&quot;) [[ $KERNEL_TARGET == *legacy* ]] &amp;&amp; options+=(&quot;legacy&quot; &quot;Old stable / Legacy&quot;) [[ $KERNEL_TARGET == *next* ]] &amp;&amp; options+=(&quot;next&quot; &quot;Use the latest kernel&quot;) menustr=&quot;Select the target kernel branch\\nExact kernel versions depend on selected board&quot; # do not display selection dialog if only one kernel branch is available if [[ &quot;${#options[@]}&quot; == 2 ]]; then BRANCH=&quot;${options[0]}&quot; else BRANCH=$(whiptail --title &quot;${titlestr}&quot; --backtitle &quot;${backtitle}&quot; \\ --menu &quot;${menustr}&quot; &quot;${TTY_Y}&quot; &quot;${TTY_X}&quot; $((TTY_Y - 8)) \\ --cancel-button Exit --ok-button Select &quot;${options[@]}&quot; \\ 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3) fi unset options [[ -z $BRANCH ]] &amp;&amp; exit_with_error &quot;No kernel branch selected&quot; [[ $BRANCH == dev &amp;&amp; $SHOW_WARNING == yes ]] &amp;&amp; show_developer_warningfi# 这里没进入if [[ -z ${MEM_TYPE} &amp;&amp; ${BOARD} =~ orangepizero3|orangepir1b|orangepizero2w &amp;&amp; ${BUILD_OPT} =~ u-boot|image &amp;&amp; ${BRANCH} == next ]]; then options+=(&quot;1500MB&quot; &quot;1.5 GB Memory&quot;) options+=(&quot;Others&quot; &quot;1/2/4 GB Memory&quot;) menustr=&quot;Please choose memory size for ${BOARD}.&quot; MEM_TYPE=$(whiptail --title &quot;${titlestr}&quot; --backtitle &quot;${backtitle}&quot; \\ --menu &quot;${menustr}&quot; &quot;${TTY_Y}&quot; &quot;${TTY_X}&quot; $((TTY_Y - 8)) \\ --cancel-button Exit --ok-button Select &quot;${options[@]}&quot; \\ 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3) unset options [[ -z $MEM_TYPE ]] &amp;&amp; exit_with_error &quot;No option selected&quot;fi# 这里也没进入if [[ $BUILD_OPT =~ rootfs|image &amp;&amp; -z $RELEASE ]]; then options=() distros_options menustr=&quot;Select the target OS release package base&quot; RELEASE=$(whiptail --title &quot;Choose a release package base&quot; --backtitle &quot;${backtitle}&quot; \\ --menu &quot;${menustr}&quot; &quot;${TTY_Y}&quot; &quot;${TTY_X}&quot; $((TTY_Y - 8)) \\ --cancel-button Exit --ok-button Select &quot;${options[@]}&quot; \\ 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3) #echo &quot;options : ${options}&quot; [[ -z $RELEASE ]] &amp;&amp; exit_with_error &quot;No release selected&quot; unset optionsfi# 选择桌面端还是服务器端，保存到BUILD_DESKTOP变量中# don't show desktop option if we choose minimal build[[ $BUILD_MINIMAL == yes ]] &amp;&amp; BUILD_DESKTOP=noif [[ $BUILD_OPT =~ rootfs|image &amp;&amp; -z $BUILD_DESKTOP ]]; then # read distribution support status which is written to the orangepi-release file set_distribution_status options=() options+=(&quot;no&quot; &quot;Image with console interface (server)&quot;) options+=(&quot;yes&quot; &quot;Image with desktop environment&quot;) menustr=&quot;Select the target image type&quot; BUILD_DESKTOP=$(whiptail --title &quot;Choose image type&quot; --backtitle &quot;${backtitle}&quot; \\ --menu &quot;${menustr}&quot; &quot;${TTY_Y}&quot; &quot;${TTY_X}&quot; $((TTY_Y - 8)) \\ --cancel-button Exit --ok-button Select &quot;${options[@]}&quot; \\ 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3) unset options [[ -z $BUILD_DESKTOP ]] &amp;&amp; exit_with_error &quot;No option selected&quot; if [[ ${BUILD_DESKTOP} == &quot;yes&quot; ]]; then BUILD_MINIMAL=no SELECTED_CONFIGURATION=&quot;desktop&quot; fifi# 服务端的选择，我这里不会进入if [[ $BUILD_OPT =~ rootfs|image &amp;&amp; $BUILD_DESKTOP == no &amp;&amp; -z $BUILD_MINIMAL ]]; then options=() options+=(&quot;no&quot; &quot;Standard image with console interface&quot;) options+=(&quot;yes&quot; &quot;Minimal image with console interface&quot;) menustr=&quot;Select the target image type&quot; BUILD_MINIMAL=$(whiptail --title &quot;Choose image type&quot; --backtitle &quot;${backtitle}&quot; \\ --menu &quot;${menustr}&quot; &quot;${TTY_Y}&quot; &quot;${TTY_X}&quot; $((TTY_Y - 8)) \\ --cancel-button Exit --ok-button Select &quot;${options[@]}&quot; \\ 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3) unset options [[ -z $BUILD_MINIMAL ]] &amp;&amp; exit_with_error &quot;No option selected&quot; if [[ $BUILD_MINIMAL == &quot;yes&quot; ]]; then SELECTED_CONFIGURATION=&quot;cli_minimal&quot; else SELECTED_CONFIGURATION=&quot;cli_standard&quot; fifi#prevent conflicting setupif [[ $BUILD_DESKTOP == &quot;yes&quot; ]]; then BUILD_MINIMAL=no SELECTED_CONFIGURATION=&quot;desktop&quot;elif [[ $BUILD_MINIMAL != &quot;yes&quot; || -z &quot;${BUILD_MINIMAL}&quot; ]]; then BUILD_MINIMAL=no # Just in case BUILD_MINIMAL is not defined BUILD_DESKTOP=no SELECTED_CONFIGURATION=&quot;cli_standard&quot;elif [[ $BUILD_MINIMAL == &quot;yes&quot; ]]; then BUILD_DESKTOP=no SELECTED_CONFIGURATION=&quot;cli_minimal&quot;fi#[[ ${KERNEL_CONFIGURE} == prebuilt ]] &amp;&amp; [[ -z ${REPOSITORY_INSTALL} ]] &amp;&amp; \\#REPOSITORY_INSTALL=&quot;u-boot,kernel,bsp,orangepi-zsh,orangepi-config,orangepi-firmware${BUILD_DESKTOP:+,orangepi-desktop}&quot;#shellcheck source=configuration.sh# 这个脚本可能有问题，具体看一下，也是一些配置，source &quot;${SRC}&quot;/scripts/configuration.sh# optimize build time with 100% CPU usage# 获取CPU最大的线程数CPUS=$(grep -c 'processor' /proc/cpuinfo)if [[ $USEALLCORES != no ]]; then CTHREADS=&quot;-j$((CPUS + CPUS/2))&quot;else CTHREADS=&quot;-j1&quot;ficall_extension_method &quot;post_determine_cthreads&quot; &quot;config_post_determine_cthreads&quot; &lt;&lt; 'POST_DETERMINE_CTHREADS'*give config a chance modify CTHREADS programatically. A build server may work better with hyperthreads-1 for example.*Called early, before any compilation work starts.POST_DETERMINE_CTHREADSif [[ $BETA == yes ]]; then IMAGE_TYPE=nightlyelif [[ $BETA != &quot;yes&quot; &amp;&amp; $BUILD_ALL == yes &amp;&amp; -n $GPG_PASS ]]; then IMAGE_TYPE=stableelse IMAGE_TYPE=user-builtfibranch2dir() { [[ &quot;${1}&quot; == &quot;head&quot; ]] &amp;&amp; echo &quot;HEAD&quot; || echo &quot;${1##*:}&quot;}BOOTSOURCEDIR=&quot;${BOOTDIR}/$(branch2dir &quot;${BOOTBRANCH}&quot;)&quot;LINUXSOURCEDIR=&quot;${KERNELDIR}/$(branch2dir &quot;${KERNELBRANCH}&quot;)&quot;[[ -n $ATFSOURCE ]] &amp;&amp; ATFSOURCEDIR=&quot;${ATFDIR}/$(branch2dir &quot;${ATFBRANCH}&quot;)&quot;BSP_CLI_PACKAGE_NAME=&quot;orangepi-bsp-cli-${BOARD}&quot;BSP_CLI_PACKAGE_FULLNAME=&quot;${BSP_CLI_PACKAGE_NAME}_${REVISION}_${ARCH}&quot;BSP_DESKTOP_PACKAGE_NAME=&quot;orangepi-bsp-desktop-${BOARD}&quot;BSP_DESKTOP_PACKAGE_FULLNAME=&quot;${BSP_DESKTOP_PACKAGE_NAME}_${REVISION}_${ARCH}&quot;CHOSEN_UBOOT=linux-u-boot-${BRANCH}-${BOARD}CHOSEN_KERNEL=linux-image-${BRANCH}-${LINUXFAMILY}CHOSEN_ROOTFS=${BSP_CLI_PACKAGE_NAME}CHOSEN_DESKTOP=orangepi-${RELEASE}-desktop-${DESKTOP_ENVIRONMENT}CHOSEN_KSRC=linux-source-${BRANCH}-${LINUXFAMILY}do_default() {start=$(date +%s)# Check and install dependencies, directory structure and settings# The OFFLINE_WORK variable inside the function# 下载编译器等以及一些环境依赖prepare_host[[ &quot;${JUST_INIT}&quot; == &quot;yes&quot; ]] &amp;&amp; exit 0[[ $CLEAN_LEVEL == *sources* ]] &amp;&amp; cleaning &quot;sources&quot;# fetch_from_repo &lt;url&gt; &lt;dir&gt; &lt;ref&gt; &lt;subdir_flag&gt;# ignore updates help on building all images - for internal purposesif [[ ${IGNORE_UPDATES} != yes ]]; then display_alert &quot;Downloading sources&quot; &quot;&quot; &quot;info&quot; # 同步uboot和内核 [[ $BUILD_OPT =~ u-boot|image ]] &amp;&amp; fetch_from_repo &quot;$BOOTSOURCE&quot; &quot;$BOOTDIR&quot; &quot;$BOOTBRANCH&quot; &quot;yes&quot; [[ $BUILD_OPT =~ kernel|image ]] &amp;&amp; fetch_from_repo &quot;$KERNELSOURCE&quot; &quot;$KERNELDIR&quot; &quot;$KERNELBRANCH&quot; &quot;yes&quot; # 同步atfa if [[ -n ${ATFSOURCE} ]]; then [[ ${BUILD_OPT} =~ u-boot|image ]] &amp;&amp; fetch_from_repo &quot;$ATFSOURCE&quot; &quot;${EXTER}/cache/sources/$ATFDIR&quot; &quot;$ATFBRANCH&quot; &quot;yes&quot; fi if [[ ${BOARD} =~ orangepi4|orangepi4-lts|orangepi800 &amp;&amp; $BRANCH == legacy ]]; then [[ $BUILD_OPT =~ image ]] &amp;&amp; fetch_from_repo &quot;https://github.com/orangepi-xunlong/rk3399_gst_xserver_libs.git&quot; &quot;${EXTER}/cache/sources/rk3399_gst_xserver_libs&quot; &quot;branch:main&quot; fi if [[ ${BOARD} =~ orangepi4|orangepi4-lts|orangepi800 &amp;&amp; $RELEASE =~ focal|buster|bullseye|bookworm ]]; then [[ ${BUILD_OPT} == image ]] &amp;&amp; fetch_from_repo &quot;https://github.com/orangepi-xunlong/rk-rootfs-build.git&quot; &quot;${EXTER}/cache/sources/rk-rootfs-build-${RELEASE}&quot; &quot;branch:rk-rootfs-build-${RELEASE}&quot; fi # 同步3588的package if [[ ${BOARDFAMILY} == &quot;rockchip-rk3588&quot; &amp;&amp; $RELEASE =~ bullseye|bookworm|focal|jammy|raspi ]]; then [[ ${BUILD_OPT} == image ]] &amp;&amp; fetch_from_repo &quot;https://github.com/orangepi-xunlong/rk-rootfs-build.git&quot; &quot;${EXTER}/cache/sources/rk3588_packages_${RELEASE}&quot; &quot;branch:rk3588_packages_${RELEASE}&quot; fi if [[ ${BOARDFAMILY} == &quot;rockchip-rk356x&quot; &amp;&amp; $RELEASE =~ bullseye|focal|jammy|raspi ]]; then [[ ${BUILD_OPT} == image ]] &amp;&amp; fetch_from_repo &quot;https://github.com/orangepi-xunlong/rk-rootfs-build.git&quot; &quot;${EXTER}/cache/sources/rk356x_packages&quot; &quot;branch:rk356x_packages&quot; fi if [[ ${BOARD} =~ orangepi3|orangepi3-lts &amp;&amp; $RELEASE =~ bullseye &amp;&amp; $BRANCH == current ]]; then [[ ${BUILD_OPT} == image ]] &amp;&amp; fetch_from_repo &quot;https://github.com/orangepi-xunlong/rk-rootfs-build.git&quot; &quot;${EXTER}/cache/sources/ffmpeg_kodi_${RELEASE}&quot; &quot;branch:ffmpeg_kodi_${RELEASE}&quot; fi if [[ ${BOARD} =~ orangepi4|orangepi4-lts|orangepi800 &amp;&amp; $RELEASE =~ jammy &amp;&amp; $BRANCH == next ]]; then [[ ${BUILD_OPT} == image ]] &amp;&amp; fetch_from_repo &quot;https://github.com/orangepi-xunlong/rk-rootfs-build.git&quot; &quot;${EXTER}/cache/sources/ffmpeg_kodi_${RELEASE}&quot; &quot;branch:ffmpeg_kodi_${RELEASE}&quot; fi call_extension_method &quot;fetch_sources_tools&quot; &lt;&lt;- 'FETCH_SOURCES_TOOLS' *fetch host-side sources needed for tools and build* Run early to fetch_from_repo or otherwise obtain sources for needed tools. FETCH_SOURCES_TOOLS call_extension_method &quot;build_host_tools&quot; &lt;&lt;- 'BUILD_HOST_TOOLS' *build needed tools for the build, host-side* After sources are fetched, build host-side tools needed for the build. BUILD_HOST_TOOLSfifor option in $(tr ',' ' ' &lt;&lt;&lt; &quot;$CLEAN_LEVEL&quot;); do [[ $option != sources ]] &amp;&amp; cleaning &quot;$option&quot;done# Compile u-boot if packed .deb does not exist or use the one from Orange Pi# 编译uboot# 编译TF-aif [[ $BUILD_OPT == u-boot || $BUILD_OPT == image ]]; then if [[ ! -f &quot;${DEB_STORAGE}&quot;/u-boot/${CHOSEN_UBOOT}_${REVISION}_${ARCH}.deb ]]; then [[ -n &quot;${ATFSOURCE}&quot; &amp;&amp; &quot;${REPOSITORY_INSTALL}&quot; != *u-boot* ]] &amp;&amp; compile_atf [[ ${REPOSITORY_INSTALL} != *u-boot* ]] &amp;&amp; compile_uboot fi if [[ $BUILD_OPT == &quot;u-boot&quot; ]]; then unset BUILD_MINIMAL BUILD_DESKTOP COMPRESS_OUTPUTIMAGE display_alert &quot;U-boot build done&quot; &quot;@host&quot; &quot;info&quot; display_alert &quot;Target directory&quot; &quot;${DEB_STORAGE}/u-boot&quot; &quot;info&quot; display_alert &quot;File name&quot; &quot;${CHOSEN_UBOOT}_${REVISION}_${ARCH}.deb&quot; &quot;info&quot; fifi# 编译内核# Compile kernel if packed .deb does not exist or use the one from Orange Piif [[ $BUILD_OPT == kernel || $BUILD_OPT == image ]]; then if [[ ! -f ${DEB_STORAGE}/${CHOSEN_KERNEL}_${REVISION}_${ARCH}.deb ]]; then KDEB_CHANGELOG_DIST=$RELEASE [[ &quot;${REPOSITORY_INSTALL}&quot; != *kernel* ]] &amp;&amp; compile_kernel fi if [[ $BUILD_OPT == &quot;kernel&quot; ]]; then unset BUILD_MINIMAL BUILD_DESKTOP COMPRESS_OUTPUTIMAGE display_alert &quot;Kernel build done&quot; &quot;@host&quot; &quot;info&quot; display_alert &quot;Target directory&quot; &quot;${DEB_STORAGE}/&quot; &quot;info&quot; display_alert &quot;File name&quot; &quot;${CHOSEN_KERNEL}_${REVISION}_${ARCH}.deb&quot; &quot;info&quot; fifi# 编译文件系统，这里是最重要的if [[ $BUILD_OPT == rootfs || $BUILD_OPT == image ]]; then # Compile orangepi-config if packed .deb does not exist or use the one from Orange Pi if [[ ! -f ${DEB_STORAGE}/orangepi-config_${REVISION}_all.deb ]]; then [[ &quot;${REPOSITORY_INSTALL}&quot; != *orangepi-config* ]] &amp;&amp; compile_orangepi-config fi # Compile orangepi-zsh if packed .deb does not exist or use the one from repository if [[ ! -f ${DEB_STORAGE}/orangepi-zsh_${REVISION}_all.deb ]]; then [[ &quot;${REPOSITORY_INSTALL}&quot; != *orangepi-zsh* ]] &amp;&amp; compile_orangepi-zsh fi # Compile plymouth-theme-orangepi if packed .deb does not exist or use the one from repository if [[ ! -f ${DEB_STORAGE}/plymouth-theme-orangepi_${REVISION}_all.deb ]]; then [[ &quot;${REPOSITORY_INSTALL}&quot; != *plymouth-theme-orangepi* ]] &amp;&amp; compile_plymouth-theme-orangepi fi # Compile orangepi-firmware if packed .deb does not exist or use the one from repository if [[ &quot;${REPOSITORY_INSTALL}&quot; != *orangepi-firmware* ]]; then if ! ls &quot;${DEB_STORAGE}/orangepi-firmware_${REVISION}_all.deb&quot; 1&gt; /dev/null 2&gt;&amp;1; then FULL=&quot;&quot; REPLACE=&quot;-full&quot; compile_firmware fi #if ! ls &quot;${DEB_STORAGE}/orangepi-firmware-full_${REVISION}_all.deb&quot; 1&gt; /dev/null 2&gt;&amp;1; then #FULL=&quot;-full&quot; #REPLACE=&quot;&quot; #compile_firmware #fi fi overlayfs_wrapper &quot;cleanup&quot; # create board support package [[ -n $RELEASE &amp;&amp; ! -f ${DEB_STORAGE}/$RELEASE/${BSP_CLI_PACKAGE_FULLNAME}.deb ]] &amp;&amp; create_board_package # create desktop package #[[ -n $RELEASE &amp;&amp; $DESKTOP_ENVIRONMENT &amp;&amp; ! -f ${DEB_STORAGE}/$RELEASE/${CHOSEN_DESKTOP}_${REVISION}_all.deb ]] &amp;&amp; create_desktop_package #[[ -n $RELEASE &amp;&amp; $DESKTOP_ENVIRONMENT &amp;&amp; ! -f ${DEB_STORAGE}/${RELEASE}/${BSP_DESKTOP_PACKAGE_FULLNAME}.deb ]] &amp;&amp; create_bsp_desktop_package [[ -n $RELEASE &amp;&amp; $DESKTOP_ENVIRONMENT ]] &amp;&amp; create_desktop_package [[ -n $RELEASE &amp;&amp; $DESKTOP_ENVIRONMENT ]] &amp;&amp; create_bsp_desktop_package # build additional packages [[ $EXTERNAL_NEW == compile ]] &amp;&amp; chroot_build_packages [[ $BSP_BUILD != yes ]] &amp;&amp; debootstrap_ngfi# hook for function to run after build, i.e. to change owner of $SRC# NOTE: this will run only if there were no errors during build process[[ $(type -t run_after_build) == function ]] &amp;&amp; run_after_build || trueend=$(date +%s)runtime=$(((end-start)/60))display_alert &quot;Runtime&quot; &quot;$runtime min&quot; &quot;info&quot;# Make it easy to repeat build by displaying build options used[ &quot;$(systemd-detect-virt)&quot; == 'docker' ] &amp;&amp; BUILD_CONFIG='docker'display_alert &quot;Repeat Build Options&quot; &quot;sudo ./build.sh ${BUILD_CONFIG} BOARD=${BOARD} BRANCH=${BRANCH} \\$([[ -n $BUILD_OPT ]] &amp;&amp; echo &quot;BUILD_OPT=${BUILD_OPT} &quot;)\\$([[ -n $RELEASE ]] &amp;&amp; echo &quot;RELEASE=${RELEASE} &quot;)\\$([[ -n $BUILD_MINIMAL ]] &amp;&amp; echo &quot;BUILD_MINIMAL=${BUILD_MINIMAL} &quot;)\\$([[ -n $BUILD_DESKTOP ]] &amp;&amp; echo &quot;BUILD_DESKTOP=${BUILD_DESKTOP} &quot;)\\$([[ -n $KERNEL_CONFIGURE ]] &amp;&amp; echo &quot;KERNEL_CONFIGURE=${KERNEL_CONFIGURE} &quot;)\\$([[ -n $DESKTOP_ENVIRONMENT ]] &amp;&amp; echo &quot;DESKTOP_ENVIRONMENT=${DESKTOP_ENVIRONMENT} &quot;)\\$([[ -n $DESKTOP_ENVIRONMENT_CONFIG_NAME ]] &amp;&amp; echo &quot;DESKTOP_ENVIRONMENT_CONFIG_NAME=${DESKTOP_ENVIRONMENT_CONFIG_NAME} &quot;)\\$([[ -n $DESKTOP_APPGROUPS_SELECTED ]] &amp;&amp; echo &quot;DESKTOP_APPGROUPS_SELECTED=\\&quot;${DESKTOP_APPGROUPS_SELECTED}\\&quot; &quot;)\\$([[ -n $DESKTOP_APT_FLAGS_SELECTED ]] &amp;&amp; echo &quot;DESKTOP_APT_FLAGS_SELECTED=\\&quot;${DESKTOP_APT_FLAGS_SELECTED}\\&quot; &quot;)\\$([[ -n $COMPRESS_OUTPUTIMAGE ]] &amp;&amp; echo &quot;COMPRESS_OUTPUTIMAGE=${COMPRESS_OUTPUTIMAGE} &quot;)\\&quot; &quot;ext&quot;} # end of do_default()if [[ -z $1 ]]; then do_defaultelse eval &quot;$@&quot;fi 4.configuration.sh分析看样子是配置一些环境变量 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765#!/bin/bash## Copyright (c) 2013-2021 Igor Pecovnik, igor.pecovnik@gma**.com## This file is licensed under the terms of the GNU General Public# License version 2. This program is licensed &quot;as is&quot; without any# warranty of any kind, whether express or implied.[[ -z $VENDOR ]] &amp;&amp; VENDOR=&quot;Orange Pi&quot;[[ -z $ROOTPWD ]] &amp;&amp; ROOTPWD=&quot;orangepi&quot; # Must be changed @first login[[ -z $OPI_USERNAME ]] &amp;&amp; OPI_USERNAME=&quot;orangepi&quot; [[ -z $OPI_PWD ]] &amp;&amp; OPI_PWD=&quot;orangepi&quot; [[ -z $MAINTAINER ]] &amp;&amp; MAINTAINER=&quot;Orange Pi&quot; # deb signature[[ -z $MAINTAINERMAIL ]] &amp;&amp; MAINTAINERMAIL=&quot;leeboby@aliyun.com&quot; # deb signature[[ -z $DEB_COMPRESS ]] &amp;&amp; DEB_COMPRESS=&quot;xz&quot; # compress .debs with XZ by default. Use 'none' for faster/larger buildsTZDATA=$(cat /etc/timezone) # Timezone for target is taken from host or defined here.USEALLCORES=yes # Use all CPU cores for compilingHOSTRELEASE=$(cat /etc/os-release | grep VERSION_CODENAME | cut -d&quot;=&quot; -f2)[[ -z $HOSTRELEASE ]] &amp;&amp; HOSTRELEASE=$(cut -d'/' -f1 /etc/debian_version)[[ -z $EXIT_PATCHING_ERROR ]] &amp;&amp; EXIT_PATCHING_ERROR=&quot;&quot; # exit patching if failed[[ -z $HOST ]] &amp;&amp; HOST=&quot;$BOARD&quot; # set hostname to the board[[ -z $CHINA_DOWNLOAD_MIRROR ]] &amp;&amp; CHINA_DOWNLOAD_MIRROR=huaweicd &quot;${SRC}&quot; || exit[[ -z &quot;${ROOTFSCACHE_VERSION}&quot; ]] &amp;&amp; ROOTFSCACHE_VERSION=11[[ -z &quot;${CHROOT_CACHE_VERSION}&quot; ]] &amp;&amp; CHROOT_CACHE_VERSION=7[[ -z $PLYMOUTH ]] &amp;&amp; PLYMOUTH=&quot;yes&quot;cd ${SRC}/scriptsBUILD_REPOSITORY_URL=$(improved_git remote get-url $(improved_git remote 2&gt;/dev/null | grep origin) 2&gt;/dev/null)BUILD_REPOSITORY_COMMIT=$(improved_git describe --match=d_e_a_d_b_e_e_f --always --dirty 2&gt;/dev/null)ROOTFS_CACHE_MAX=200 # max number of rootfs cache, older ones will be cleaned upDEB_STORAGE=$DEST/debsDEB_ORANGEPI=$EXTER/cache/debs# TODO: fixed name can't be used for parallel image buildingROOT_MAPPER=&quot;orangepi-root&quot;[[ -z $ROOTFS_TYPE ]] &amp;&amp; ROOTFS_TYPE=ext4 # default rootfs type is ext4[[ &quot;ext4 f2fs btrfs xfs nfs fel&quot; != *$ROOTFS_TYPE* ]] &amp;&amp; exit_with_error &quot;Unknown rootfs type&quot; &quot;$ROOTFS_TYPE&quot;[[ -z $BTRFS_COMPRESSION ]] &amp;&amp; BTRFS_COMPRESSION=zlib # default btrfs filesystem compression method is zlib[[ ! $BTRFS_COMPRESSION =~ zlib|lzo|zstd|none ]] &amp;&amp; exit_with_error &quot;Unknown btrfs compression method&quot; &quot;$BTRFS_COMPRESSION&quot;# Fixed image size is in 1M dd blocks (MiB)# to get size of block device /dev/sdX execute as root:# echo $(( $(blockdev --getsize64 /dev/sdX) / 1024 / 1024 ))[[ &quot;f2fs&quot; == *$ROOTFS_TYPE* &amp;&amp; -z $FIXED_IMAGE_SIZE ]] &amp;&amp; exit_with_error &quot;Please define FIXED_IMAGE_SIZE&quot;# a passphrase is mandatory if rootfs encryption is enabledif [[ $CRYPTROOT_ENABLE == yes &amp;&amp; -z $CRYPTROOT_PASSPHRASE ]]; then exit_with_error &quot;Root encryption is enabled but CRYPTROOT_PASSPHRASE is not set&quot;fi# small SD card with kernel, boot script and .dtb/.bin files[[ $ROOTFS_TYPE == nfs ]] &amp;&amp; FIXED_IMAGE_SIZE=64# Since we are having too many options for mirror management,# then here is yet another mirror related option.# Respecting user's override in case a mirror is unreachable.case $REGIONAL_MIRROR in china) [[ -z $USE_MAINLINE_GOOGLE_MIRROR ]] &amp;&amp; [[ -z $MAINLINE_MIRROR ]] &amp;&amp; MAINLINE_MIRROR=tuna [[ -z $USE_GITHUB_UBOOT_MIRROR ]] &amp;&amp; [[ -z $UBOOT_MIRROR ]] &amp;&amp; UBOOT_MIRROR=gitee [[ -z $GITHUB_MIRROR ]] &amp;&amp; GITHUB_MIRROR=gitclone [[ -z $DOWNLOAD_MIRROR ]] &amp;&amp; DOWNLOAD_MIRROR=china ;; *) ;;esac# used by multiple sources - reduce code duplication[[ $USE_MAINLINE_GOOGLE_MIRROR == yes ]] &amp;&amp; MAINLINE_MIRROR=googlecase $MAINLINE_MIRROR in google) MAINLINE_KERNEL_SOURCE='https://kernel.googlesource.com/pub/scm/linux/kernel/git/stable/linux-stable' MAINLINE_FIRMWARE_SOURCE='https://kernel.googlesource.com/pub/scm/linux/kernel/git/firmware/linux-firmware.git' ;; tuna) MAINLINE_KERNEL_SOURCE='https://mirrors.tuna.tsinghua.edu.cn/git/linux-stable.git' MAINLINE_FIRMWARE_SOURCE='https://mirrors.tuna.tsinghua.edu.cn/git/linux-firmware.git' ;; bfsu) MAINLINE_KERNEL_SOURCE='https://mirrors.bfsu.edu.cn/git/linux-stable.git' MAINLINE_FIRMWARE_SOURCE='https://mirrors.bfsu.edu.cn/git/linux-firmware.git' ;; *) MAINLINE_KERNEL_SOURCE='git://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git' MAINLINE_FIRMWARE_SOURCE='git://git.kernel.org/pub/scm/linux/kernel/git/firmware/linux-firmware.git' ;;esacMAINLINE_KERNEL_DIR=&quot;$SRC/kernel&quot;[[ $USE_GITHUB_UBOOT_MIRROR == yes ]] &amp;&amp; UBOOT_MIRROR=githubcase $UBOOT_MIRROR in gitee) MAINLINE_UBOOT_SOURCE='https://github.com/orangepi-xunlong/u-boot-orangepi.git' ;; github) MAINLINE_UBOOT_SOURCE='https://github.com/orangepi-xunlong/u-boot-orangepi.git' ;; *) MAINLINE_UBOOT_SOURCE='https://source.denx.de/u-boot/u-boot.git' ;;esacMAINLINE_UBOOT_DIR=&quot;$SRC/u-boot&quot;case $GITHUB_MIRROR in fastgit) GITHUB_SOURCE='https://hub.fastgit.xyz' ;; gitclone) GITHUB_SOURCE='https://gitclone.com/github.com' ;; *) GITHUB_SOURCE='https://github.com' ;;esac# Let's set default data if not defined in board configuration above[[ -z $OFFSET ]] &amp;&amp; OFFSET=4 # offset to 1st partition (we use 4MiB boundaries by default)ARCH=armhfKERNEL_IMAGE_TYPE=zImageCAN_BUILD_STRETCH=yesATF_COMPILE=yes[[ -z $CRYPTROOT_SSH_UNLOCK ]] &amp;&amp; CRYPTROOT_SSH_UNLOCK=yes[[ -z $CRYPTROOT_SSH_UNLOCK_PORT ]] &amp;&amp; CRYPTROOT_SSH_UNLOCK_PORT=2022# Default to pdkdf2, this used to be the default with cryptroot &lt;= 2.0, however# cryptroot 2.1 changed that to Argon2i. Argon2i is a memory intensive# algorithm which doesn't play well with SBCs (need 1GiB RAM by default !)# https://gitlab.com/cryptsetup/cryptsetup/-/issues/372[[ -z $CRYPTROOT_PARAMETERS ]] &amp;&amp; CRYPTROOT_PARAMETERS=&quot;--pbkdf pbkdf2&quot;[[ -z $WIREGUARD ]] &amp;&amp; WIREGUARD=&quot;no&quot;[[ -z $EXTRAWIFI ]] &amp;&amp; EXTRAWIFI=&quot;yes&quot;[[ -z $SKIP_BOOTSPLASH ]] &amp;&amp; SKIP_BOOTSPLASH=&quot;no&quot;[[ -z $AUFS ]] &amp;&amp; AUFS=&quot;yes&quot;[[ -z $IMAGE_PARTITION_TABLE ]] &amp;&amp; IMAGE_PARTITION_TABLE=&quot;msdos&quot;[[ -z $EXTRA_BSP_NAME ]] &amp;&amp; EXTRA_BSP_NAME=&quot;&quot;[[ -z $EXTRA_ROOTFS_MIB_SIZE ]] &amp;&amp; EXTRA_ROOTFS_MIB_SIZE=0[[ -z $BUILD_KSRC ]] &amp;&amp; BUILD_KSRC=&quot;no&quot;# single ext4 partition is the default and preferred configuration#BOOTFS_TYPE=''[[ ! -f ${EXTER}/config/sources/families/$LINUXFAMILY.conf ]] &amp;&amp; \\ exit_with_error &quot;Sources configuration not found&quot; &quot;$LINUXFAMILY&quot;source &quot;${EXTER}/config/sources/families/${LINUXFAMILY}.conf&quot;if [[ -f $USERPATCHES_PATH/sources/families/$LINUXFAMILY.conf ]]; then display_alert &quot;Adding user provided $LINUXFAMILY overrides&quot; source &quot;$USERPATCHES_PATH/sources/families/${LINUXFAMILY}.conf&quot;fi# load architecture defaultssource &quot;${EXTER}/config/sources/${ARCH}.conf&quot;## Extensions: at this point we've sourced all the config files that will be used,## and (hopefully) not yet invoked any extension methods. So this is the perfect## place to initialize the extension manager. It will create functions## like the 'post_family_config' that is invoked below.initialize_extension_managercall_extension_method &quot;post_family_config&quot; &quot;config_tweaks_post_family_config&quot; &lt;&lt; 'POST_FAMILY_CONFIG'*give the config a chance to override the family/arch defaults*This hook is called after the family configuration (`sources/families/xxx.conf`) is sourced.Since the family can override values from the user configuration and the board configuration,it is often used to in turn override those.POST_FAMILY_CONFIG# Myy : Menu configuration for choosing desktop configurationsshow_menu() { provided_title=$1 provided_backtitle=$2 provided_menuname=$3 # Myy : I don't know why there's a TTY_Y - 8... #echo &quot;Provided title : $provided_title&quot; #echo &quot;Provided backtitle : $provided_backtitle&quot; #echo &quot;Provided menuname : $provided_menuname&quot; #echo &quot;Provided options : &quot; &quot;${@:4}&quot; #echo &quot;TTY X: $TTY_X Y: $TTY_Y&quot; whiptail --title &quot;${provided_title}&quot; --backtitle &quot;${provided_backtitle}&quot; --notags \\ --menu &quot;${provided_menuname}&quot; &quot;${TTY_Y}&quot; &quot;${TTY_X}&quot; $((TTY_Y - 8)) \\ &quot;${@:4}&quot; \\ 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3}# Myy : FIXME Factorizeshow_select_menu() { provided_title=$1 provided_backtitle=$2 provided_menuname=$3 #dialog --stdout --title &quot;${provided_title}&quot; --backtitle &quot;${provided_backtitle}&quot; \\ #--checklist &quot;${provided_menuname}&quot; $TTY_Y $TTY_X $((TTY_Y - 8)) &quot;${@:4}&quot; #whiptail --separate-output --title &quot;${provided_title}&quot; --backtitle &quot;${provided_backtitle}&quot; \\ # --checklist &quot;${provided_menuname}&quot; &quot;${TTY_Y}&quot; &quot;${TTY_X}&quot; $((TTY_Y - 8)) \\ # &quot;${@:4}&quot; \\ # 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3 whiptail --title &quot;${provided_title}&quot; --backtitle &quot;${provided_backtitle}&quot; \\ --checklist &quot;${provided_menuname}&quot; &quot;${TTY_Y}&quot; &quot;${TTY_X}&quot; $((TTY_Y - 8)) \\ &quot;${@:4}&quot; \\ 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3}# Myy : Once we got a list of selected groups, parse the PACKAGE_LIST inside configuration.shDESKTOP_ELEMENTS_DIR=&quot;${EXTER}/config/desktop/${RELEASE}&quot;DESKTOP_CONFIGS_DIR=&quot;${DESKTOP_ELEMENTS_DIR}/environments&quot;DESKTOP_CONFIG_PREFIX=&quot;config_&quot;DESKTOP_APPGROUPS_DIR=&quot;${DESKTOP_ELEMENTS_DIR}/appgroups&quot;desktop_element_available_for_arch() { local desktop_element_path=&quot;${1}&quot; local targeted_arch=&quot;${2}&quot; local arch_limitation_file=&quot;${1}/only_for&quot; echo &quot;Checking if ${desktop_element_path} is available for ${targeted_arch} in ${arch_limitation_file}&quot; &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/output.log if [[ -f &quot;${arch_limitation_file}&quot; ]]; then grep -- &quot;${targeted_arch}&quot; &quot;${arch_limitation_file}&quot; &gt; /dev/null return $? else return 0 fi}desktop_element_supported() { local desktop_element_path=&quot;${1}&quot; local support_level_filepath=&quot;${desktop_element_path}/support&quot; if [[ -f &quot;${support_level_filepath}&quot; ]]; then local support_level=&quot;$(cat &quot;${support_level_filepath}&quot;)&quot; if [[ &quot;${support_level}&quot; != &quot;supported&quot; &amp;&amp; &quot;${EXPERT}&quot; != &quot;yes&quot; ]]; then return 65 fi desktop_element_available_for_arch &quot;${desktop_element_path}&quot; &quot;${ARCH}&quot; if [[ $? -ne 0 ]]; then return 66 fi else return 64 fi return 0}if [[ $BUILD_DESKTOP == &quot;yes&quot; &amp;&amp; -z $DESKTOP_ENVIRONMENT ]]; then desktop_environments_prepare_menu() { for desktop_env_dir in &quot;${DESKTOP_CONFIGS_DIR}/&quot;*; do local desktop_env_name=$(basename ${desktop_env_dir}) local expert_infos=&quot;&quot; [[ &quot;${EXPERT}&quot; == &quot;yes&quot; ]] &amp;&amp; expert_infos=&quot;[$(cat &quot;${desktop_env_dir}/support&quot; 2&gt; /dev/null)]&quot; desktop_element_supported &quot;${desktop_env_dir}&quot; &quot;${ARCH}&quot; &amp;&amp; options+=(&quot;${desktop_env_name}&quot; &quot;${desktop_env_name^} desktop environment ${expert_infos}&quot;) done } options=() desktop_environments_prepare_menu if [[ &quot;${options[0]}&quot; == &quot;&quot; ]]; then exit_with_error &quot;No desktop environment seems to be available for your board ${BOARD} (ARCH : ${ARCH} - EXPERT : ${EXPERT})&quot; fi DESKTOP_ENVIRONMENT=$(show_menu &quot;Choose a desktop environment&quot; &quot;$backtitle&quot; &quot;Select the default desktop environment to bundle with this image&quot; &quot;${options[@]}&quot;) unset options if [[ -z &quot;${DESKTOP_ENVIRONMENT}&quot; ]]; then exit_with_error &quot;No desktop environment selected...&quot; fifiif [[ $BUILD_DESKTOP == &quot;yes&quot; ]]; then # Expected environment variables : # - options # - ARCH desktop_environment_check_if_valid() { local error_msg=&quot;&quot; desktop_element_supported &quot;${DESKTOP_ENVIRONMENT_DIRPATH}&quot; &quot;${ARCH}&quot; local retval=$? if [[ ${retval} == 0 ]]; then return elif [[ ${retval} == 64 ]]; then error_msg+=&quot;Either the desktop environment ${DESKTOP_ENVIRONMENT} does not exist &quot; error_msg+=&quot;or the file ${DESKTOP_ENVIRONMENT_DIRPATH}/support is missing&quot; elif [[ ${retval} == 65 ]]; then error_msg+=&quot;Only experts can build an image with the desktop environment \\&quot;${DESKTOP_ENVIRONMENT}\\&quot;, since the Armbian team won't offer any support for it (EXPERT=${EXPERT})&quot; elif [[ ${retval} == 66 ]]; then error_msg+=&quot;The desktop environment \\&quot;${DESKTOP_ENVIRONMENT}\\&quot; has no packages for your targeted board architecture (BOARD=${BOARD} ARCH=${ARCH}). &quot; error_msg+=&quot;The supported boards architectures are : &quot; error_msg+=&quot;$(cat &quot;${DESKTOP_ENVIRONMENT_DIRPATH}/only_for&quot;)&quot; fi # supress error when cache is rebuilding [[ -n &quot;$ROOT_FS_CREATE_ONLY&quot; ]] &amp;&amp; exit 0 exit_with_error &quot;${error_msg}&quot; } DESKTOP_ENVIRONMENT_DIRPATH=&quot;${DESKTOP_CONFIGS_DIR}/${DESKTOP_ENVIRONMENT}&quot; desktop_environment_check_if_validfiif [[ $BUILD_DESKTOP == &quot;yes&quot; &amp;&amp; -z $DESKTOP_ENVIRONMENT_CONFIG_NAME ]]; then # FIXME Check for empty folders, just in case the current maintainer # messed up # Note, we could also ignore it and don't show anything in the previous # menu, but that hides information and make debugging harder, which I # don't like. Adding desktop environments as a maintainer is not a # trivial nor common task. options=() for configuration in &quot;${DESKTOP_ENVIRONMENT_DIRPATH}/${DESKTOP_CONFIG_PREFIX}&quot;*; do config_filename=$(basename ${configuration}) config_name=${config_filename#&quot;${DESKTOP_CONFIG_PREFIX}&quot;} options+=(&quot;${config_filename}&quot; &quot;${config_name} configuration&quot;) done DESKTOP_ENVIRONMENT_CONFIG_NAME=$(show_menu &quot;Choose the desktop environment config&quot; &quot;$backtitle&quot; &quot;Select the configuration for this environment.\\nThese are sourced from ${desktop_environment_config_dir}&quot; &quot;${options[@]}&quot;) unset options if [[ -z $DESKTOP_ENVIRONMENT_CONFIG_NAME ]]; then exit_with_error &quot;No desktop configuration selected... Do you really want a desktop environment ?&quot; fifiif [[ $BUILD_DESKTOP == &quot;yes&quot; ]]; then DESKTOP_ENVIRONMENT_PACKAGE_LIST_DIRPATH=&quot;${DESKTOP_ENVIRONMENT_DIRPATH}/${DESKTOP_ENVIRONMENT_CONFIG_NAME}&quot; DESKTOP_ENVIRONMENT_PACKAGE_LIST_FILEPATH=&quot;${DESKTOP_ENVIRONMENT_PACKAGE_LIST_DIRPATH}/packages&quot;fi# &quot;-z ${VAR+x}&quot; allows to check for unset variable# Technically, someone might want to build a desktop with no additional# appgroups.if [[ $BUILD_DESKTOP == &quot;yes&quot; &amp;&amp; -z ${DESKTOP_APPGROUPS_SELECTED+x} &amp;&amp; ${RELEASE} != &quot;raspi&quot; ]]; then options=() for appgroup_path in &quot;${DESKTOP_APPGROUPS_DIR}/&quot;*; do appgroup=&quot;$(basename &quot;${appgroup_path}&quot;)&quot; options+=(&quot;${appgroup}&quot; &quot;${appgroup^}&quot; off) done DESKTOP_APPGROUPS_SELECTED=$(\\ show_select_menu \\ &quot;Choose desktop softwares to add&quot; \\ &quot;$backtitle&quot; \\ &quot;Select which kind of softwares you'd like to add to your build&quot; \\ &quot;${options[@]}&quot;) DESKTOP_APPGROUPS_SELECTED=${DESKTOP_APPGROUPS_SELECTED//\\&quot;/} unset optionsfi#exit_with_error 'Testing'# Expected variables# - aggregated_content# - potential_paths# - separator# Write to variables :# - aggregated_contentaggregate_content() { LOG_OUTPUT_FILE=&quot;${SRC}/output/${LOG_SUBPATH}/potential-paths.log&quot; echo -e &quot;Potential paths :&quot; &gt;&gt; &quot;${LOG_OUTPUT_FILE}&quot; show_checklist_variables potential_paths for filepath in ${potential_paths}; do if [[ -f &quot;${filepath}&quot; ]]; then echo -e &quot;${filepath/&quot;$EXTER&quot;\\//} yes&quot; &gt;&gt; &quot;${LOG_OUTPUT_FILE}&quot; aggregated_content+=$(cat &quot;${filepath}&quot;) aggregated_content+=&quot;${separator}&quot;# else# echo -e &quot;${filepath/&quot;$EXTER&quot;\\//} no\\n&quot; &gt;&gt; &quot;${LOG_OUTPUT_FILE}&quot; fi done echo &quot;&quot; &gt;&gt; &quot;${LOG_OUTPUT_FILE}&quot; unset LOG_OUTPUT_FILE}# set unique mounting directoryMOUNT_UUID=$(uuidgen)SDCARD=&quot;${SRC}/.tmp/rootfs-${MOUNT_UUID}&quot;MOUNT=&quot;${SRC}/.tmp/mount-${MOUNT_UUID}&quot;DESTIMG=&quot;${SRC}/.tmp/image-${MOUNT_UUID}&quot;# dropbear needs to be configured differently[[ $CRYPTROOT_ENABLE == yes &amp;&amp; $RELEASE == xenial ]] &amp;&amp; exit_with_error &quot;Encrypted rootfs is not supported in Xenial&quot;[[ $RELEASE == stretch &amp;&amp; $CAN_BUILD_STRETCH != yes ]] &amp;&amp; exit_with_error &quot;Building Debian Stretch images with selected kernel is not supported&quot;[[ $RELEASE == bionic &amp;&amp; $CAN_BUILD_STRETCH != yes ]] &amp;&amp; exit_with_error &quot;Building Ubuntu Bionic images with selected kernel is not supported&quot;[[ $RELEASE == hirsute &amp;&amp; $HOSTRELEASE == focal ]] &amp;&amp; exit_with_error &quot;Building Ubuntu Hirsute images requires Hirsute build host. Please upgrade your host or select a different target OS&quot;[[ -n $ATFSOURCE &amp;&amp; -z $ATF_USE_GCC ]] &amp;&amp; exit_with_error &quot;Error in configuration: ATF_USE_GCC is unset&quot;[[ -z $UBOOT_USE_GCC ]] &amp;&amp; exit_with_error &quot;Error in configuration: UBOOT_USE_GCC is unset&quot;[[ -z $KERNEL_USE_GCC ]] &amp;&amp; exit_with_error &quot;Error in configuration: KERNEL_USE_GCC is unset&quot;BOOTCONFIG_VAR_NAME=BOOTCONFIG_${BRANCH^^}[[ -n ${!BOOTCONFIG_VAR_NAME} ]] &amp;&amp; BOOTCONFIG=${!BOOTCONFIG_VAR_NAME}[[ -z $LINUXCONFIG ]] &amp;&amp; LINUXCONFIG=&quot;linux-${LINUXFAMILY}-${BRANCH}&quot;[[ -z $BOOTPATCHDIR ]] &amp;&amp; BOOTPATCHDIR=&quot;u-boot-$LINUXFAMILY&quot;[[ -z $ATFPATCHDIR ]] &amp;&amp; ATFPATCHDIR=&quot;atf-$LINUXFAMILY&quot;[[ -z $KERNELPATCHDIR ]] &amp;&amp; KERNELPATCHDIR=&quot;$LINUXFAMILY-$BRANCH&quot;if [[ &quot;$RELEASE&quot; =~ ^(xenial|bionic|focal|hirsute|impish|jammy)$ ]]; then DISTRIBUTION=&quot;Ubuntu&quot;elif [[ &quot;$RELEASE&quot; == raspi ]]; then DISTRIBUTION=&quot;Bullseye&quot; else DISTRIBUTION=&quot;Debian&quot;fiCLI_CONFIG_PATH=&quot;${EXTER}/config/cli/${RELEASE}&quot;DEBOOTSTRAP_CONFIG_PATH=&quot;${CLI_CONFIG_PATH}/debootstrap&quot;if [[ $? != 0 ]]; then exit_with_error &quot;The desktop environment ${DESKTOP_ENVIRONMENT} is not available for your architecture ${ARCH}&quot;fiAGGREGATION_SEARCH_ROOT_ABSOLUTE_DIRS=&quot;${EXTER}/config${EXTER}/config/optional/_any_board/_config${EXTER}/config/optional/architectures/${ARCH}/_config${EXTER}/config/optional/families/${LINUXFAMILY}/_config${EXTER}/config/optional/boards/${BOARD}/_config${USERPATCHES_PATH}&quot;DEBOOTSTRAP_SEARCH_RELATIVE_DIRS=&quot;cli/_all_distributions/debootstrapcli/${RELEASE}/debootstrap&quot;CLI_SEARCH_RELATIVE_DIRS=&quot;cli/_all_distributions/maincli/${RELEASE}/main&quot;PACKAGES_SEARCH_ROOT_ABSOLUTE_DIRS=&quot;${EXTER}/packages${EXTER}/config/optional/_any_board/_packages${EXTER}/config/optional/architectures/${ARCH}/_packages${EXTER}/config/optional/families/${LINUXFAMILY}/_packages${EXTER}/config/optional/boards/${BOARD}/_packages&quot;DESKTOP_ENVIRONMENTS_SEARCH_RELATIVE_DIRS=&quot;desktop/_all_distributions/environments/_all_environmentsdesktop/_all_distributions/environments/${DESKTOP_ENVIRONMENT}desktop/_all_distributions/environments/${DESKTOP_ENVIRONMENT}/${DESKTOP_ENVIRONMENT_CONFIG_NAME}desktop/${RELEASE}/environments/_all_environmentsdesktop/${RELEASE}/environments/${DESKTOP_ENVIRONMENT}desktop/${RELEASE}/environments/${DESKTOP_ENVIRONMENT}/${DESKTOP_ENVIRONMENT_CONFIG_NAME}&quot;DESKTOP_APPGROUPS_SEARCH_RELATIVE_DIRS=&quot;desktop/_all_distributions/appgroupsdesktop/_all_distributions/environments/${DESKTOP_ENVIRONMENT}/appgroupsdesktop/${RELEASE}/appgroupsdesktop/${RELEASE}/environments/${DESKTOP_ENVIRONMENT}/appgroups&quot;get_all_potential_paths() { local root_dirs=&quot;${AGGREGATION_SEARCH_ROOT_ABSOLUTE_DIRS}&quot; local rel_dirs=&quot;${1}&quot; local sub_dirs=&quot;${2}&quot; local looked_up_subpath=&quot;${3}&quot; for root_dir in ${root_dirs}; do for rel_dir in ${rel_dirs}; do for sub_dir in ${sub_dirs}; do potential_paths+=&quot;${root_dir}/${rel_dir}/${sub_dir}/${looked_up_subpath} &quot; done done done # for ppath in ${potential_paths}; do # echo &quot;Checking for ${ppath}&quot; # if [[ -f &quot;${ppath}&quot; ]]; then # echo &quot;OK !|&quot; # else # echo &quot;Nope|&quot; # fi # done}# Environment variables expected :# - aggregated_content# Arguments :# 1. File to look up in each directory# 2. The separator to add between each concatenated file# 3. Relative directories paths added to ${3}# 4. Relative directories paths added to ${4}## The function will basically generate a list of potential paths by# generating all the potential paths combinations leading to the# looked up file# ${AGGREGATION_SEARCH_ROOT_ABSOLUTE_DIRS}/${3}/${4}/${1}# Then it will concatenate the content of all the available files# into ${aggregated_content}## TODO :# ${4} could be removed by just adding the appropriate paths to ${3}# dynamically for each case# (debootstrap, cli, desktop environments, desktop appgroups, ...)aggregate_all_root_rel_sub() { local separator=&quot;${2}&quot; local potential_paths=&quot;&quot; get_all_potential_paths &quot;${3}&quot; &quot;${4}&quot; &quot;${1}&quot; aggregate_content}aggregate_all_debootstrap() { local sub_dirs_to_check=&quot;. &quot; if [[ ! -z &quot;${SELECTED_CONFIGURATION+x}&quot; ]]; then sub_dirs_to_check+=&quot;config_${SELECTED_CONFIGURATION}&quot; fi aggregate_all_root_rel_sub &quot;${1}&quot; &quot;${2}&quot; &quot;${DEBOOTSTRAP_SEARCH_RELATIVE_DIRS}&quot; &quot;${sub_dirs_to_check}&quot;}aggregate_all_cli() { local sub_dirs_to_check=&quot;. &quot; if [[ ! -z &quot;${SELECTED_CONFIGURATION+x}&quot; ]]; then sub_dirs_to_check+=&quot;config_${SELECTED_CONFIGURATION}&quot; fi aggregate_all_root_rel_sub &quot;${1}&quot; &quot;${2}&quot; &quot;${CLI_SEARCH_RELATIVE_DIRS}&quot; &quot;${sub_dirs_to_check}&quot;}aggregate_all_desktop() { aggregate_all_root_rel_sub &quot;${1}&quot; &quot;${2}&quot; &quot;${DESKTOP_ENVIRONMENTS_SEARCH_RELATIVE_DIRS}&quot; &quot;.&quot; aggregate_all_root_rel_sub &quot;${1}&quot; &quot;${2}&quot; &quot;${DESKTOP_APPGROUPS_SEARCH_RELATIVE_DIRS}&quot; &quot;${DESKTOP_APPGROUPS_SELECTED}&quot;}one_line() { local aggregate_func_name=&quot;${1}&quot; local aggregated_content=&quot;&quot; shift 1 $aggregate_func_name &quot;${@}&quot; cleanup_list aggregated_content}DEBOOTSTRAP_LIST=&quot;$(one_line aggregate_all_debootstrap &quot;packages&quot; &quot; &quot;)&quot;DEBOOTSTRAP_COMPONENTS=&quot;$(one_line aggregate_all_debootstrap &quot;components&quot; &quot; &quot;)&quot;DEBOOTSTRAP_COMPONENTS=&quot;${DEBOOTSTRAP_COMPONENTS// /,}&quot;PACKAGE_LIST=&quot;$(one_line aggregate_all_cli &quot;packages&quot; &quot; &quot;)&quot;PACKAGE_LIST_ADDITIONAL=&quot;$(one_line aggregate_all_cli &quot;packages.additional&quot; &quot; &quot;)&quot;LOG_OUTPUT_FILE=&quot;$SRC/output/${LOG_SUBPATH}/debootstrap-list.log&quot;show_checklist_variables &quot;DEBOOTSTRAP_LIST DEBOOTSTRAP_COMPONENTS PACKAGE_LIST PACKAGE_LIST_ADDITIONAL PACKAGE_LIST_UNINSTALL&quot;# Dependent desktop packages# Myy : Sources packages from file here# Myy : FIXME Rename aggregate_all to aggregate_all_desktopif [[ $BUILD_DESKTOP == &quot;yes&quot; ]]; then PACKAGE_LIST_DESKTOP+=&quot;$(one_line aggregate_all_desktop &quot;packages&quot; &quot; &quot;)&quot; echo -e &quot;\\nGroups selected ${DESKTOP_APPGROUPS_SELECTED} -&gt; PACKAGES :&quot; &gt;&gt; &quot;${LOG_OUTPUT_FILE}&quot; show_checklist_variables PACKAGE_LIST_DESKTOPfiunset LOG_OUTPUT_FILEDEBIAN_MIRROR='deb.debian.org/debian'DEBIAN_SECURTY='security.debian.org/'UBUNTU_MIRROR='ports.ubuntu.com/'RASPI_MIRROR='archive.raspberrypi.org/debian/'if [[ $DOWNLOAD_MIRROR == &quot;china&quot; ]] ; then if [[ ${CHINA_DOWNLOAD_MIRROR} == tsinghua ]]; then DEBIAN_MIRROR='mirrors.tuna.tsinghua.edu.cn/debian' DEBIAN_SECURTY='mirrors.tuna.tsinghua.edu.cn/debian-security' UBUNTU_MIRROR='mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/' fi if [[ ${CHINA_DOWNLOAD_MIRROR} == huawei ]]; then DEBIAN_MIRROR='repo.huaweicloud.com/debian' DEBIAN_SECURTY='repo.huaweicloud.com/debian-security' UBUNTU_MIRROR='repo.huaweicloud.com/ubuntu-ports/' fi RASPI_MIRROR='mirrors.ustc.edu.cn/archive.raspberrypi.org/debian/'fiif [[ $DOWNLOAD_MIRROR == &quot;bfsu&quot; ]] ; then DEBIAN_MIRROR='mirrors.bfsu.edu.cn/debian' DEBIAN_SECURTY='mirrors.bfsu.edu.cn/debian-security' UBUNTU_MIRROR='mirrors.bfsu.edu.cn/ubuntu-ports/'fiif [[ &quot;${ARCH}&quot; == &quot;amd64&quot; ]]; then UBUNTU_MIRROR='archive.ubuntu.com/ubuntu' # ports are only for non-amd64, of course. if [[ -n ${CUSTOM_UBUNTU_MIRROR} ]]; then # ubuntu redirector doesn't work well on amd64 UBUNTU_MIRROR=&quot;${CUSTOM_UBUNTU_MIRROR}&quot; fifi# don't use mirrors that throws garbage on 404if [[ -z ${ARMBIAN_MIRROR} ]]; then while true; do ARMBIAN_MIRROR=$(wget -SO- -T 1 -t 1 https://redirect.armbian.com 2&gt;&amp;1 | egrep -i &quot;Location&quot; | awk '{print $2}' | head -1) [[ ${ARMBIAN_MIRROR} != *armbian.hosthatch* ]] &amp;&amp; break donefi# For (late) user override.# Notice: it is too late to define hook functions or add extensions in lib.config, since the extension initialization already ran by now.# in case the user tries to use them in lib.config, hopefully they'll be detected as &quot;wishful hooking&quot; and the user will be wrn'ed.if [[ -f $USERPATCHES_PATH/lib.config ]]; then display_alert &quot;Using user configuration override&quot; &quot;$USERPATCHES_PATH/lib.config&quot; &quot;info&quot; source &quot;$USERPATCHES_PATH&quot;/lib.configficall_extension_method &quot;user_config&quot; &lt;&lt; 'USER_CONFIG'*Invoke function with user override*Allows for overriding configuration values set anywhere else.It is called after sourcing the `lib.config` file if it exists,but before assembling any package lists.USER_CONFIGcall_extension_method &quot;extension_prepare_config&quot; &lt;&lt; 'EXTENSION_PREPARE_CONFIG'*allow extensions to prepare their own config, after user config is done*Implementors should preserve variable values pre-set, but can default values an/or validate them.This runs *after* user_config. Don't change anything not coming from other variables or meant to be configured by the user.EXTENSION_PREPARE_CONFIG# apt-cacher-ng mirror configurarionif [[ $DISTRIBUTION == Ubuntu ]]; then APT_MIRROR=$UBUNTU_MIRRORelse APT_MIRROR=$DEBIAN_MIRRORfi[[ -n $APT_PROXY_ADDR ]] &amp;&amp; display_alert &quot;Using custom apt-cacher-ng address&quot; &quot;$APT_PROXY_ADDR&quot; &quot;info&quot;# Build final package list after possible overridePACKAGE_LIST=&quot;$PACKAGE_LIST $PACKAGE_LIST_RELEASE $PACKAGE_LIST_ADDITIONAL&quot;PACKAGE_MAIN_LIST=&quot;$(cleanup_list PACKAGE_LIST)&quot;[[ $BUILD_DESKTOP == yes ]] &amp;&amp; PACKAGE_LIST=&quot;$PACKAGE_LIST $PACKAGE_LIST_DESKTOP&quot;PACKAGE_LIST=&quot;$(cleanup_list PACKAGE_LIST)&quot;# remove any packages defined in PACKAGE_LIST_RM in lib.configaggregated_content=&quot;${PACKAGE_LIST_RM} &quot;aggregate_all_cli &quot;packages.remove&quot; &quot; &quot;aggregate_all_desktop &quot;packages.remove&quot; &quot; &quot;PACKAGE_LIST_RM=&quot;$(cleanup_list aggregated_content)&quot;unset aggregated_contentaggregated_content=&quot;&quot;aggregate_all_cli &quot;packages.uninstall&quot; &quot; &quot;aggregate_all_desktop &quot;packages.uninstall&quot; &quot; &quot;PACKAGE_LIST_UNINSTALL=&quot;$(cleanup_list aggregated_content)&quot;unset aggregated_contentif [[ -n $PACKAGE_LIST_RM ]]; then display_alert &quot;Package remove list ${PACKAGE_LIST_RM}&quot; # Turns out that \\b can be tricked by dashes. # So if you remove mesa-utils but still want to install &quot;mesa-utils-extra&quot; # a &quot;\\b(mesa-utils)\\b&quot; filter will convert &quot;mesa-utils-extra&quot; to &quot;-extra&quot;. # \\W is not tricked by this but consumes the surrounding spaces, so we # replace the occurence by one space, to avoid sticking the next word to # the previous one after consuming the spaces. DEBOOTSTRAP_LIST=$(sed -r &quot;s/\\W($(tr ' ' '|' &lt;&lt;&lt; ${PACKAGE_LIST_RM}))\\W/ /g&quot; &lt;&lt;&lt; &quot; ${DEBOOTSTRAP_LIST} &quot;) PACKAGE_LIST=$(sed -r &quot;s/\\W($(tr ' ' '|' &lt;&lt;&lt; ${PACKAGE_LIST_RM}))\\W/ /g&quot; &lt;&lt;&lt; &quot; ${PACKAGE_LIST} &quot;) PACKAGE_MAIN_LIST=$(sed -r &quot;s/\\W($(tr ' ' '|' &lt;&lt;&lt; ${PACKAGE_LIST_RM}))\\W/ /g&quot; &lt;&lt;&lt; &quot; ${PACKAGE_MAIN_LIST} &quot;) if [[ $BUILD_DESKTOP == &quot;yes&quot; ]]; then PACKAGE_LIST_DESKTOP=$(sed -r &quot;s/\\W($(tr ' ' '|' &lt;&lt;&lt; ${PACKAGE_LIST_RM}))\\W/ /g&quot; &lt;&lt;&lt; &quot; ${PACKAGE_LIST_DESKTOP} &quot;) # Removing double spaces... AGAIN, since we might have used a sed on them # Do not quote the variables. This would defeat the trick. PACKAGE_LIST_DESKTOP=&quot;$(echo ${PACKAGE_LIST_DESKTOP})&quot; fi # Removing double spaces... AGAIN, since we might have used a sed on them # Do not quote the variables. This would defeat the trick. DEBOOTSTRAP_LIST=&quot;$(echo ${DEBOOTSTRAP_LIST})&quot; PACKAGE_LIST=&quot;$(echo ${PACKAGE_LIST})&quot; PACKAGE_MAIN_LIST=&quot;$(echo ${PACKAGE_MAIN_LIST})&quot;fiLOG_OUTPUT_FILE=&quot;$SRC/output/${LOG_SUBPATH}/debootstrap-list.log&quot;echo -e &quot;\\nVariables after manual configuration&quot; &gt;&gt;$LOG_OUTPUT_FILEshow_checklist_variables &quot;DEBOOTSTRAP_COMPONENTS DEBOOTSTRAP_LIST PACKAGE_LIST PACKAGE_MAIN_LIST&quot;unset LOG_OUTPUT_FILE# Give the option to configure DNS server used in the chroot during the build process[[ -z $NAMESERVER ]] &amp;&amp; NAMESERVER=&quot;1.0.0.1&quot; # default is cloudflare alternatecall_extension_method &quot;post_aggregate_packages&quot; &quot;user_config_post_aggregate_packages&quot; &lt;&lt; 'POST_AGGREGATE_PACKAGES'*For final user override, using a function, after all aggregations are done*Called after aggregating all package lists, before the end of `compilation.sh`.Packages will still be installed after this is called, so it is the last chanceto confirm or change any packages.POST_AGGREGATE_PACKAGES# debugcat &lt;&lt;-EOF &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/output.log## BUILD SCRIPT ENVIRONMENTRepository: $REPOSITORY_URLVersion: $REPOSITORY_COMMITHost OS: $HOSTRELEASEHost arch: $(dpkg --print-architecture)Host system: $(uname -a)Virtualization type: $(systemd-detect-virt)## Build script directoriesBuild directory is located on:$(findmnt -o TARGET,SOURCE,FSTYPE,AVAIL -T &quot;${SRC}&quot;)Build directory permissions:$(getfacl -p &quot;${SRC}&quot;)Temp directory permissions:$(getfacl -p &quot;${SRC}&quot;/.tmp 2&gt; /dev/null)## BUILD CONFIGURATIONBuild target:Board: $BOARDBranch: $BRANCHMinimal: $BUILD_MINIMALDesktop: $BUILD_DESKTOPDesktop Environment: $DESKTOP_ENVIRONMENTSoftware groups: $DESKTOP_APPGROUPS_SELECTEDKernel configuration:Repository: $KERNELSOURCEBranch: $KERNELBRANCHConfig file: $LINUXCONFIGU-boot configuration:Repository: $BOOTSOURCEBranch: $BOOTBRANCHConfig file: $BOOTCONFIGPartitioning configuration: $IMAGE_PARTITION_TABLE offset: $OFFSETBoot partition type: ${BOOTFS_TYPE:-(none)} ${BOOTSIZE:+&quot;(${BOOTSIZE} MB)&quot;}Root partition type: $ROOTFS_TYPE ${FIXED_IMAGE_SIZE:+&quot;(${FIXED_IMAGE_SIZE} MB)&quot;}CPU configuration: $CPUMIN - $CPUMAX with $GOVERNOREOF 5.debootstrap_ng 分析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210310410510610710810911011111211311411511611711811912012112212312412512612712812913013113213313413513613713813914014114214314414514614714814915015115215315415515615715815916016116216316416516616716816917017117217317417517617717817918018118218318418518618718818919019119219319419519619719819920020120220320420520620720820921021121221321421521621721821922022122222322422522622722822923023123223323423523623723823924024124224324424524624724824925025125225325425525625725825926026126226326426526626726826927027127227327427527627727827928028128228328428528628728828929029129229329429529629729829930030130230330430530630730830931031131231331431531631731831932032132232332432532632732832933033133233333433533633733833934034134234334434534634734834935035135235335435535635735835936036136236336436536636736836937037137237337437537637737837938038138238338438538638738838939039139239339439539639739839940040140240340440540640740840941041141241341441541641741841942042142242342442542642742842943043143243343443543643743843944044144244344444544644744844945045145245345445545645745845946046146246346446546646746846947047147247347447547647747847948048148248348448548648748848949049149249349449549649749849950050150250350450550650750850951051151251351451551651751851952052152252352452552652752852953053153253353453553653753853954054154254354454554654754854955055155255355455555655755855956056156256356456556656756856957057157257357457557657757857958058158258358458558658758858959059159259359459559659759859960060160260360460560660760860961061161261361461561661761861962062162262362462562662762862963063163263363463563663763863964064164264364464564664764864965065165265365465565665765865966066166266366466566666766866967067167267367467567667767867968068168268368468568668768868969069169269369469569669769869970070170270370470570670770870971071171271371471571671771871972072172272372472572672772872973073173273373473573673773873974074174274374474574674774874975075175275375475575675775875976076176276376476576676776876977077177277377477577677777877978078178278378478578678778878979079179279379479579679779879980080180280380480580680780880981081181281381481581681781881982082182282382482582682782882983083183283383483583683783883984084184284384484584684784884985085185285385485585685785885986086186286386486586686786886987087187287387487587687787887988088188288388488588688788888989089189289389489589689789889990090190290390490590690790890991091191291391491591691791891992092192292392492592692792892993093193293393493593693793893994094194294394494594694794894995095195295395495595695795895996096196296396496596696796896997097197297397497597697797897998098198298398498598698798898999099199299399499599699799899910001001100210031004100510061007100810091010101110121013101410151016101710181019102010211022#!/bin/bash## Copyright (c) 2013-2021 Igor Pecovnik, igor.pecovnik@gma**.com## This file is licensed under the terms of the GNU General Public# License version 2. This program is licensed &quot;as is&quot; without any# warranty of any kind, whether express or implied.# Functions:# debootstrap_ng# create_rootfs_cache# prepare_partitions# update_initramfs# create_image# debootstrap_ng#debootstrap_ng(){ display_alert &quot;Starting rootfs and image building process for&quot; &quot;${BRANCH} ${BOARD} ${RELEASE} ${DESKTOP_APPGROUPS_SELECTED:-null} ${DESKTOP_ENVIRONMENT:-null} ${BUILD_MINIMAL}&quot; &quot;info&quot; [[ $ROOTFS_TYPE != ext4 ]] &amp;&amp; display_alert &quot;Assuming $BOARD $BRANCH kernel supports $ROOTFS_TYPE&quot; &quot;&quot; &quot;wrn&quot; # trap to unmount stuff in case of error/manual interruption trap unmount_on_exit INT TERM EXIT # stage: clean and create directories rm -rf $SDCARD $MOUNT mkdir -p $SDCARD $MOUNT $DEST/images $EXTER/cache/rootfs # stage: verify tmpfs configuration and mount # CLI needs ~1.5GiB, desktop - ~3.5GiB # calculate and set tmpfs mount to use 9/10 of available RAM+SWAP local phymem=$(( (($(awk '/MemTotal/ {print $2}' /proc/meminfo) + $(awk '/SwapTotal/ {print $2}' /proc/meminfo))) / 1024 * 9 / 10 )) # MiB if [[ $BUILD_DESKTOP == yes ]]; then local tmpfs_max_size=3500; else local tmpfs_max_size=1500; fi # MiB if [[ $FORCE_USE_RAMDISK == no ]]; then local use_tmpfs=no elif [[ $FORCE_USE_RAMDISK == yes || $phymem -gt $tmpfs_max_size ]]; then local use_tmpfs=yes fi [[ -n $FORCE_TMPFS_SIZE ]] &amp;&amp; phymem=$FORCE_TMPFS_SIZE [[ $use_tmpfs == yes ]] &amp;&amp; mount -t tmpfs -o size=${phymem}M tmpfs $SDCARD # stage: prepare basic rootfs: unpack cache or create from scratch create_rootfs_cache call_extension_method &quot;pre_install_distribution_specific&quot; &quot;config_pre_install_distribution_specific&quot; &lt;&lt; 'PRE_INSTALL_DISTRIBUTION_SPECIFIC'*give config a chance to act before install_distribution_specific*Called after `create_rootfs_cache` (_prepare basic rootfs: unpack cache or create from scratch_) but before `install_distribution_specific` (_install distribution and board specific applications_).PRE_INSTALL_DISTRIBUTION_SPECIFIC # stage: install kernel and u-boot packages # install distribution and board specific applications if [[ ${RELEASE} == &quot;raspi&quot; ]]; then install_opi_specific else install_distribution_specific install_common # install locally built packages or install pre-built packages from orangepi [[ $EXTERNAL_NEW == compile || $EXTERNAL_NEW == prebuilt ]] &amp;&amp; chroot_installpackages_local #[[ $EXTERNAL_NEW == prebuilt ]] &amp;&amp; chroot_installpackages &quot;yes&quot; # stage: user customization script # NOTE: installing too many packages may fill tmpfs mount customize_image # remove packages that are no longer needed. Since we have intrudoced uninstall feature, we might want to clean things that are no longer needed display_alert &quot;No longer needed packages&quot; &quot;purge&quot; &quot;info&quot; chroot $SDCARD /bin/bash -c &quot;apt-get autoremove -y&quot; &gt;/dev/null 2&gt;&amp;1 # create list of installed packages for debug purposes chroot $SDCARD /bin/bash -c &quot;dpkg --get-selections&quot; | grep -v deinstall | awk '{print $1}' | cut -f1 -d':' &gt; $DEST/${LOG_SUBPATH}/installed-packages-${RELEASE}$([[ ${BUILD_MINIMAL} == yes ]] &amp;&amp; echo &quot;-minimal&quot;)$([[ ${BUILD_DESKTOP} == yes ]] &amp;&amp; echo &quot;-desktop&quot;).list 2&gt;&amp;1 fi # clean up / prepare for making the image umount_chroot &quot;$SDCARD&quot; post_debootstrap_tweaks if [[ $ROOTFS_TYPE == fel ]]; then FEL_ROOTFS=$SDCARD/ display_alert &quot;Starting FEL boot&quot; &quot;$BOARD&quot; &quot;info&quot; source $SRC/scripts/fel-load.sh else prepare_partitions create_image fi # stage: unmount tmpfs umount $SDCARD 2&gt;&amp;1 if [[ $use_tmpfs = yes ]]; then while grep -qs &quot;$SDCARD&quot; /proc/mounts do umount $SDCARD sleep 5 done fi rm -rf $SDCARD # remove exit trap trap - INT TERM EXIT} #############################################################################bootstrap(){ local BOOTSTRAP_CMD=debootstrap local BOOTSTRAP_ARGS=() export CAPSH_ARG=&quot;--drop=cap_setfcap&quot; export http_proxy=${APT_PROXY} BOOTSTRAP_ARGS+=(--arch arm64) BOOTSTRAP_ARGS+=(--include gnupg) #BOOTSTRAP_ARGS+=(--components &quot;main,contrib,non-free&quot;) BOOTSTRAP_ARGS+=(--components &quot;main&quot;) BOOTSTRAP_ARGS+=(--exclude=info) BOOTSTRAP_ARGS+=(--include=ca-certificates) BOOTSTRAP_ARGS+=(&quot;$@&quot;) printf -v BOOTSTRAP_STR '%q ' &quot;${BOOTSTRAP_ARGS[@]}&quot; ${BOOTSTRAP_CMD} $BOOTSTRAP_STR || true}export -f bootstrap# create_rootfs_cache## unpacks cached rootfs for $RELEASE or creates one#create_rootfs_cache(){ local packages_hash=$(get_package_list_hash &quot;$ROOTFSCACHE_VERSION&quot;) local cache_type=&quot;cli&quot; [[ ${BUILD_DESKTOP} == yes ]] &amp;&amp; local cache_type=&quot;xfce-desktop&quot; [[ -n ${DESKTOP_ENVIRONMENT} ]] &amp;&amp; local cache_type=&quot;${DESKTOP_ENVIRONMENT}&quot; [[ ${BUILD_MINIMAL} == yes ]] &amp;&amp; local cache_type=&quot;minimal&quot; local cache_name=${RELEASE}-${cache_type}-${ARCH}.$packages_hash.tar.lz4 local cache_fname=${EXTER}/cache/rootfs/${cache_name} local display_name=${RELEASE}-${cache_type}-${ARCH}.${packages_hash:0:3}...${packages_hash:29}.tar.lz4 if [[ -f $cache_fname &amp;&amp; &quot;$ROOT_FS_CREATE_ONLY&quot; != &quot;force&quot; ]]; then local date_diff=$(( ($(date +%s) - $(stat -c %Y $cache_fname)) / 86400 )) display_alert &quot;Extracting $display_name&quot; &quot;$date_diff days old&quot; &quot;info&quot; pv -p -b -r -c -N &quot;[ .... ] $display_name&quot; &quot;$cache_fname&quot; | lz4 -dc | tar xp --xattrs -C $SDCARD/ [[ $? -ne 0 ]] &amp;&amp; rm $cache_fname &amp;&amp; exit_with_error &quot;Cache $cache_fname is corrupted and was deleted. Restart.&quot; rm $SDCARD/etc/resolv.conf echo &quot;nameserver $NAMESERVER&quot; &gt;&gt; $SDCARD/etc/resolv.conf create_sources_list &quot;$RELEASE&quot; &quot;$SDCARD/&quot; elif [[ $RELEASE == &quot;raspi&quot; ]]; then display_alert &quot;local not found&quot; &quot;Creating new rootfs cache for $RELEASE&quot; &quot;info&quot; cd $SDCARD # this will prevent error sh: 0: getcwd() failed bootstrap bullseye &quot;$SDCARD&quot; &quot;https://mirrors.ustc.edu.cn/debian/&quot; mount_chroot &quot;$SDCARD&quot; display_alert &quot;Diverting&quot; &quot;initctl/start-stop-daemon&quot; &quot;info&quot; # policy-rc.d script prevents starting or reloading services during image creation printf '#!/bin/sh\\nexit 101' &gt; $SDCARD/usr/sbin/policy-rc.d LC_ALL=C LANG=C chroot $SDCARD /bin/bash -c &quot;dpkg-divert --quiet --local --rename --add /sbin/initctl&quot; &amp;&gt; /dev/null LC_ALL=C LANG=C chroot $SDCARD /bin/bash -c &quot;dpkg-divert --quiet --local --rename --add /sbin/start-stop-daemon&quot; &amp;&gt; /dev/null printf '#!/bin/sh\\necho &quot;Warning: Fake start-stop-daemon called, doing nothing&quot;' &gt; $SDCARD/sbin/start-stop-daemon printf '#!/bin/sh\\necho &quot;Warning: Fake initctl called, doing nothing&quot;' &gt; $SDCARD/sbin/initctl chmod 755 $SDCARD/usr/sbin/policy-rc.d chmod 755 $SDCARD/sbin/initctl chmod 755 $SDCARD/sbin/start-stop-daemon install_raspi_specific umount_chroot &quot;$SDCARD&quot; tar cp --xattrs --directory=$SDCARD/ --exclude='./dev/*' --exclude='./proc/*' --exclude='./run/*' --exclude='./tmp/*' \\ --exclude='./sys/*' . | pv -p -b -r -s $(du -sb $SDCARD/ | cut -f1) -N &quot;$display_name&quot; | lz4 -5 -c &gt; $cache_fname else display_alert &quot;local not found&quot; &quot;Creating new rootfs cache for $RELEASE&quot; &quot;info&quot; # stage: debootstrap base system if [[ $NO_APT_CACHER != yes ]]; then # apt-cacher-ng apt-get proxy parameter local apt_extra=&quot;-o Acquire::http::Proxy=\\&quot;http://${APT_PROXY_ADDR:-localhost:3142}\\&quot;&quot; local apt_mirror=&quot;http://${APT_PROXY_ADDR:-localhost:3142}/$APT_MIRROR&quot; else local apt_mirror=&quot;http://$APT_MIRROR&quot; fi # fancy progress bars [[ -z $OUTPUT_DIALOG ]] &amp;&amp; local apt_extra_progress=&quot;--show-progress -o DPKG::Progress-Fancy=1&quot; # Ok so for eval+PIPESTATUS. # Try this on your bash shell: # ONEVAR=&quot;testing&quot; eval 'bash -c &quot;echo value once $ONEVAR &amp;&amp; false &amp;&amp; echo value twice $ONEVAR&quot;' '| grep value' '| grep value' ; echo ${PIPESTATUS[*]} # Notice how PIPESTATUS has only one element. and it is always true, although we failed explicitly with false in the middle of the bash. # That is because eval itself is considered a single command, no matter how many pipes you put in there, you'll get a single value, the return code of the LAST pipe. # Lets export the value of the pipe inside eval so we know outside what happened: # ONEVAR=&quot;testing&quot; eval 'bash -e -c &quot;echo value once $ONEVAR &amp;&amp; false &amp;&amp; echo value twice $ONEVAR&quot;' '| grep value' '| grep value' ';EVALPIPE=(${PIPESTATUS[@]})' ; echo ${EVALPIPE[*]} display_alert &quot;Installing base system&quot; &quot;Stage 1/2&quot; &quot;info&quot; cd $SDCARD # this will prevent error sh: 0: getcwd() failed eval 'debootstrap --variant=minbase --include=${DEBOOTSTRAP_LIST// /,} ${PACKAGE_LIST_EXCLUDE:+ --exclude=${PACKAGE_LIST_EXCLUDE// /,}} \\ --arch=$ARCH --components=${DEBOOTSTRAP_COMPONENTS} $DEBOOTSTRAP_OPTION --foreign $RELEASE $SDCARD/ $apt_mirror' \\ ${PROGRESS_LOG_TO_FILE:+' | tee -a $DEST/${LOG_SUBPATH}/debootstrap.log'} \\ ${OUTPUT_DIALOG:+' | dialog --backtitle &quot;$backtitle&quot; --progressbox &quot;Debootstrap (stage 1/2)...&quot; $TTY_Y $TTY_X'} \\ ${OUTPUT_VERYSILENT:+' &gt;/dev/null 2&gt;/dev/null'} ';EVALPIPE=(${PIPESTATUS[@]})' [[ ${EVALPIPE[0]} -ne 0 || ! -f $SDCARD/debootstrap/debootstrap ]] &amp;&amp; exit_with_error &quot;Debootstrap base system for ${BRANCH} ${BOARD} ${RELEASE} ${DESKTOP_APPGROUPS_SELECTED} ${DESKTOP_ENVIRONMENT} ${BUILD_MINIMAL} first stage failed&quot; cp /usr/bin/$QEMU_BINARY $SDCARD/usr/bin/ mkdir -p $SDCARD/usr/share/keyrings/ cp /usr/share/keyrings/*-archive-keyring.gpg $SDCARD/usr/share/keyrings/ display_alert &quot;Installing base system&quot; &quot;Stage 2/2&quot; &quot;info&quot; eval 'LC_ALL=C LANG=C chroot $SDCARD /bin/bash -e -c &quot;/debootstrap/debootstrap --second-stage&quot;' \\ ${PROGRESS_LOG_TO_FILE:+' | tee -a $DEST/${LOG_SUBPATH}/debootstrap.log'} \\ ${OUTPUT_DIALOG:+' | dialog --backtitle &quot;$backtitle&quot; --progressbox &quot;Debootstrap (stage 2/2)...&quot; $TTY_Y $TTY_X'} \\ ${OUTPUT_VERYSILENT:+' &gt;/dev/null 2&gt;/dev/null'} ';EVALPIPE=(${PIPESTATUS[@]})' [[ ${EVALPIPE[0]} -ne 0 || ! -f $SDCARD/bin/bash ]] &amp;&amp; exit_with_error &quot;Debootstrap base system for ${BRANCH} ${BOARD} ${RELEASE} ${DESKTOP_APPGROUPS_SELECTED} ${DESKTOP_ENVIRONMENT} ${BUILD_MINIMAL} second stage failed&quot; mount_chroot &quot;$SDCARD&quot; display_alert &quot;Diverting&quot; &quot;initctl/start-stop-daemon&quot; &quot;info&quot; # policy-rc.d script prevents starting or reloading services during image creation printf '#!/bin/sh\\nexit 101' &gt; $SDCARD/usr/sbin/policy-rc.d LC_ALL=C LANG=C chroot $SDCARD /bin/bash -c &quot;dpkg-divert --quiet --local --rename --add /sbin/initctl&quot; &amp;&gt; /dev/null LC_ALL=C LANG=C chroot $SDCARD /bin/bash -c &quot;dpkg-divert --quiet --local --rename --add /sbin/start-stop-daemon&quot; &amp;&gt; /dev/null printf '#!/bin/sh\\necho &quot;Warning: Fake start-stop-daemon called, doing nothing&quot;' &gt; $SDCARD/sbin/start-stop-daemon printf '#!/bin/sh\\necho &quot;Warning: Fake initctl called, doing nothing&quot;' &gt; $SDCARD/sbin/initctl chmod 755 $SDCARD/usr/sbin/policy-rc.d chmod 755 $SDCARD/sbin/initctl chmod 755 $SDCARD/sbin/start-stop-daemon # stage: configure language and locales display_alert &quot;Configuring locales&quot; &quot;$DEST_LANG&quot; &quot;info&quot; [[ -f $SDCARD/etc/locale.gen ]] &amp;&amp; sed -i &quot;s/^# $DEST_LANG/$DEST_LANG/&quot; $SDCARD/etc/locale.gen eval 'LC_ALL=C LANG=C chroot $SDCARD /bin/bash -c &quot;locale-gen $DEST_LANG&quot;' ${OUTPUT_VERYSILENT:+' &gt;/dev/null 2&gt;/dev/null'} eval 'LC_ALL=C LANG=C chroot $SDCARD /bin/bash -c &quot;update-locale LANG=$DEST_LANG LANGUAGE=$DEST_LANG LC_MESSAGES=$DEST_LANG&quot;' \\ ${OUTPUT_VERYSILENT:+' &gt;/dev/null 2&gt;/dev/null'} if [[ -f $SDCARD/etc/default/console-setup ]]; then sed -e 's/CHARMAP=.*/CHARMAP=&quot;UTF-8&quot;/' -e 's/FONTSIZE=.*/FONTSIZE=&quot;8x16&quot;/' \\ -e 's/CODESET=.*/CODESET=&quot;guess&quot;/' -i $SDCARD/etc/default/console-setup eval 'LC_ALL=C LANG=C chroot $SDCARD /bin/bash -c &quot;setupcon --save --force&quot;' fi # stage: create apt-get sources list create_sources_list &quot;$RELEASE&quot; &quot;$SDCARD/&quot; # add armhf arhitecture to arm64, unless configured not to do so. if [[ &quot;a${ARMHF_ARCH}&quot; != &quot;askip&quot; ]]; then [[ $ARCH == arm64 ]] &amp;&amp; eval 'LC_ALL=C LANG=C chroot $SDCARD /bin/bash -c &quot;dpkg --add-architecture armhf&quot;' fi # this should fix resolvconf installation failure in some cases chroot $SDCARD /bin/bash -c 'echo &quot;resolvconf resolvconf/linkify-resolvconf boolean false&quot; | debconf-set-selections' # stage: update packages list display_alert &quot;Updating package list&quot; &quot;$RELEASE&quot; &quot;info&quot; eval 'LC_ALL=C LANG=C chroot $SDCARD /bin/bash -e -c &quot;apt-get -q -y $apt_extra update&quot;' \\ ${PROGRESS_LOG_TO_FILE:+' | tee -a $DEST/${LOG_SUBPATH}/debootstrap.log'} \\ ${OUTPUT_DIALOG:+' | dialog --backtitle &quot;$backtitle&quot; --progressbox &quot;Updating package lists...&quot; $TTY_Y $TTY_X'} \\ ${OUTPUT_VERYSILENT:+' &gt;/dev/null 2&gt;/dev/null'} ';EVALPIPE=(${PIPESTATUS[@]})' [[ ${EVALPIPE[0]} -ne 0 ]] &amp;&amp; display_alert &quot;Updating package lists&quot; &quot;failed&quot; &quot;wrn&quot; # stage: upgrade base packages from xxx-updates and xxx-backports repository branches display_alert &quot;Upgrading base packages&quot; &quot;Orange Pi&quot; &quot;info&quot; eval 'LC_ALL=C LANG=C chroot $SDCARD /bin/bash -e -c &quot;DEBIAN_FRONTEND=noninteractive apt-get -y -q \\ $apt_extra $apt_extra_progress upgrade&quot;' \\ ${PROGRESS_LOG_TO_FILE:+' | tee -a $DEST/${LOG_SUBPATH}/debootstrap.log'} \\ ${OUTPUT_DIALOG:+' | dialog --backtitle &quot;$backtitle&quot; --progressbox &quot;Upgrading base packages...&quot; $TTY_Y $TTY_X'} \\ ${OUTPUT_VERYSILENT:+' &gt;/dev/null 2&gt;/dev/null'} ';EVALPIPE=(${PIPESTATUS[@]})' # Myy: Dividing the desktop packages installation steps into multiple # ones. We first install the &quot;ADDITIONAL_PACKAGES&quot; in order to get # access to software-common-properties installation. # THEN we add the APT sources and install the Desktop packages. # TODO : Find a way to add APT sources WITHOUT software-common-properties [[ ${EVALPIPE[0]} -ne 0 ]] &amp;&amp; display_alert &quot;Upgrading base packages&quot; &quot;failed&quot; &quot;wrn&quot; # stage: install additional packages display_alert &quot;Installing the main packages for&quot; &quot;Orange Pi&quot; &quot;info&quot; eval 'LC_ALL=C LANG=C chroot $SDCARD /bin/bash -e -c &quot;DEBIAN_FRONTEND=noninteractive apt-get -y -q \\ $apt_extra $apt_extra_progress --no-install-recommends install $PACKAGE_MAIN_LIST&quot;' \\ ${PROGRESS_LOG_TO_FILE:+' | tee -a $DEST/${LOG_SUBPATH}/debootstrap.log'} \\ ${OUTPUT_DIALOG:+' | dialog --backtitle &quot;$backtitle&quot; --progressbox &quot;Installing Orange Pi main packages...&quot; $TTY_Y $TTY_X'} \\ ${OUTPUT_VERYSILENT:+' &gt;/dev/null 2&gt;/dev/null'} ';EVALPIPE=(${PIPESTATUS[@]})' [[ ${PIPESTATUS[0]} -ne 0 ]] &amp;&amp; exit_with_error &quot;Installation of Orange Pi main packages for ${BRANCH} ${BOARD} ${RELEASE} ${DESKTOP_APPGROUPS_SELECTED} ${DESKTOP_ENVIRONMENT} ${BUILD_MINIMAL} failed&quot; if [[ $BUILD_DESKTOP == &quot;yes&quot; ]]; then # FIXME Myy : Are we keeping this only for Desktop users, # or should we extend this to CLI users too ? # There might be some clunky boards that require Debian packages from # specific repos... display_alert &quot;Adding apt sources for Desktop packages&quot; add_desktop_package_sources local apt_desktop_install_flags=&quot;&quot; if [[ ! -z ${DESKTOP_APT_FLAGS_SELECTED+x} ]]; then for flag in ${DESKTOP_APT_FLAGS_SELECTED}; do apt_desktop_install_flags+=&quot; --install-${flag}&quot; done else # Myy : Using the previous default option, if the variable isn't defined # And ONLY if it's not defined ! apt_desktop_install_flags+=&quot; --no-install-recommends&quot; fi display_alert &quot;Installing the desktop packages for&quot; &quot;Orange Pi&quot; &quot;info&quot; eval 'LC_ALL=C LANG=C chroot $SDCARD /bin/bash -e -c &quot;DEBIAN_FRONTEND=noninteractive apt-get -y -q \\ $apt_extra $apt_extra_progress install ${apt_desktop_install_flags} $PACKAGE_LIST_DESKTOP&quot;' \\ ${PROGRESS_LOG_TO_FILE:+' | tee -a $DEST/${LOG_SUBPATH}/debootstrap.log'} \\ ${OUTPUT_DIALOG:+' | dialog --backtitle &quot;$backtitle&quot; --progressbox &quot;Installing Orange Pi desktop packages...&quot; $TTY_Y $TTY_X'} \\ ${OUTPUT_VERYSILENT:+' &gt;/dev/null 2&gt;/dev/null'} ';EVALPIPE=(${PIPESTATUS[@]})' [[ ${PIPESTATUS[0]} -ne 0 ]] &amp;&amp; exit_with_error &quot;Installation of Orange Pi desktop packages for ${BRANCH} ${BOARD} ${RELEASE} ${DESKTOP_APPGROUPS_SELECTED} ${DESKTOP_ENVIRONMENT} ${BUILD_MINIMAL} failed&quot; fi # Remove packages from packages.uninstall display_alert &quot;Uninstall packages&quot; &quot;$PACKAGE_LIST_UNINSTALL&quot; &quot;info&quot; eval 'LC_ALL=C LANG=C chroot $SDCARD /bin/bash -e -c &quot;DEBIAN_FRONTEND=noninteractive apt-get -y -qq \\ $apt_extra $apt_extra_progress purge $PACKAGE_LIST_UNINSTALL&quot;' \\ ${PROGRESS_LOG_TO_FILE:+' &gt;&gt; $DEST/${LOG_SUBPATH}/debootstrap.log'} \\ ${OUTPUT_DIALOG:+' | dialog --backtitle &quot;$backtitle&quot; --progressbox &quot;Removing packages.uninstall packages...&quot; $TTY_Y $TTY_X'} \\ ${OUTPUT_VERYSILENT:+' &gt;/dev/null 2&gt;/dev/null'} ';EVALPIPE=(${PIPESTATUS[@]})' [[ ${EVALPIPE[0]} -ne 0 ]] &amp;&amp; exit_with_error &quot;Installation of Orange Pi packages failed&quot; # stage: purge residual packages display_alert &quot;Purging residual packages for&quot; &quot;Orange Pi&quot; &quot;info&quot; PURGINGPACKAGES=$(chroot $SDCARD /bin/bash -c &quot;dpkg -l | grep \\&quot;^rc\\&quot; | awk '{print \\$2}' | tr \\&quot;\\n\\&quot; \\&quot; \\&quot;&quot;) eval 'LC_ALL=C LANG=C chroot $SDCARD /bin/bash -e -c &quot;DEBIAN_FRONTEND=noninteractive apt-get -y -q \\ $apt_extra $apt_extra_progress remove --purge $PURGINGPACKAGES&quot;' \\ ${PROGRESS_LOG_TO_FILE:+' | tee -a $DEST/${LOG_SUBPATH}/debootstrap.log'} \\ ${OUTPUT_DIALOG:+' | dialog --backtitle &quot;$backtitle&quot; --progressbox &quot;Purging residual Orange Pi packages...&quot; $TTY_Y $TTY_X'} \\ ${OUTPUT_VERYSILENT:+' &gt;/dev/null 2&gt;/dev/null'} ';EVALPIPE=(${PIPESTATUS[@]})' [[ ${EVALPIPE[0]} -ne 0 ]] &amp;&amp; exit_with_error &quot;Purging of residual Orange Pi packages failed&quot; # stage: remove downloaded packages chroot $SDCARD /bin/bash -c &quot;apt-get -y autoremove; apt-get clean&quot; # DEBUG: print free space local freespace=$(LC_ALL=C df -h) echo $freespace &gt;&gt; $DEST/${LOG_SUBPATH}/debootstrap.log display_alert &quot;Free SD cache&quot; &quot;$(echo -e &quot;$freespace&quot; | grep $SDCARD | awk '{print $5}')&quot; &quot;info&quot; display_alert &quot;Mount point&quot; &quot;$(echo -e &quot;$freespace&quot; | grep $MOUNT | head -1 | awk '{print $5}')&quot; &quot;info&quot; # create list of installed packages for debug purposes chroot $SDCARD /bin/bash -c &quot;dpkg --get-selections&quot; | grep -v deinstall | awk '{print $1}' | cut -f1 -d':' &gt; ${cache_fname}.list 2&gt;&amp;1 # creating xapian index that synaptic runs faster if [[ $BUILD_DESKTOP == yes ]]; then display_alert &quot;Recreating Synaptic search index&quot; &quot;Please wait&quot; &quot;info&quot; chroot $SDCARD /bin/bash -c &quot;[[ -f /usr/sbin/update-apt-xapian-index ]] &amp;&amp; /usr/sbin/update-apt-xapian-index -u&quot; fi # this is needed for the build process later since resolvconf generated file in /run is not saved rm $SDCARD/etc/resolv.conf echo &quot;nameserver $NAMESERVER&quot; &gt;&gt; $SDCARD/etc/resolv.conf # stage: make rootfs cache archive display_alert &quot;Ending debootstrap process and preparing cache&quot; &quot;$RELEASE&quot; &quot;info&quot; sync # the only reason to unmount here is compression progress display # based on rootfs size calculation umount_chroot &quot;$SDCARD&quot; tar cp --xattrs --directory=$SDCARD/ --exclude='./dev/*' --exclude='./proc/*' --exclude='./run/*' --exclude='./tmp/*' \\ --exclude='./sys/*' --exclude='./home/*' --exclude='./root/*' . | pv -p -b -r -s $(du -sb $SDCARD/ | cut -f1) -N &quot;$display_name&quot; | lz4 -5 -c &gt; $cache_fname # sign rootfs cache archive that it can be used for web cache once. Internal purposes if [[ -n &quot;${GPG_PASS}&quot; &amp;&amp; &quot;${SUDO_USER}&quot; ]]; then [[ -n ${SUDO_USER} ]] &amp;&amp; sudo chown -R ${SUDO_USER}:${SUDO_USER} &quot;${DEST}&quot;/images/ echo &quot;${GPG_PASS}&quot; | sudo -H -u ${SUDO_USER} bash -c &quot;gpg --passphrase-fd 0 --armor --detach-sign --pinentry-mode loopback --batch --yes ${cache_fname}&quot; || exit 1 fi # needed for backend to keep current only touch $cache_fname.current fi # used for internal purposes. Faster rootfs cache rebuilding if [[ -n &quot;$ROOT_FS_CREATE_ONLY&quot; ]]; then umount --lazy &quot;$SDCARD&quot; rm -rf $SDCARD display_alert &quot;Rootfs build done&quot; &quot;@host&quot; &quot;info&quot; display_alert &quot;Target directory&quot; &quot;${EXTER}/cache/rootfs&quot; &quot;info&quot; display_alert &quot;File name&quot; &quot;${cache_name}&quot; &quot;info&quot; # remove exit trap trap - INT TERM EXIT exit fi mount_chroot &quot;$SDCARD&quot;} ############################################################################## prepare_partitions## creates image file, partitions and fs# and mounts it to local dir# FS-dependent stuff (boot and root fs partition types) happens here#prepare_partitions() { display_alert &quot;Preparing image file for rootfs&quot; &quot;$BOARD $RELEASE&quot; &quot;info&quot; # possible partition combinations # /boot: none, ext4, ext2, fat (BOOTFS_TYPE) # root: ext4, btrfs, f2fs, nfs (ROOTFS_TYPE) # declare makes local variables by default if used inside a function # NOTE: mountopts string should always start with comma if not empty # array copying in old bash versions is tricky, so having filesystems as arrays # with attributes as keys is not a good idea declare -A parttype mkopts mkopts_label mkfs mountopts parttype[ext4]=ext4 parttype[ext2]=ext2 parttype[fat]=fat16 parttype[f2fs]=ext4 # not a copy-paste error parttype[btrfs]=btrfs parttype[xfs]=xfs # parttype[nfs] is empty # metadata_csum and 64bit may need to be disabled explicitly when migrating to newer supported host OS releases if [[ $HOSTRELEASE =~ buster|bullseye|bookworm|bionic|focal|jammy|kinetic|sid ]]; then mkopts[ext4]=&quot;-q -m 2 -O ^64bit,^metadata_csum&quot; fi # mkopts[fat] is empty mkopts[ext2]='-q' # mkopts[f2fs] is empty mkopts[btrfs]='-m dup' # mkopts[xfs] is empty # mkopts[nfs] is empty mkopts_label[ext4]='-L ' mkopts_label[ext2]='-L ' mkopts_label[fat]='-n ' mkopts_label[f2fs]='-l ' mkopts_label[btrfs]='-L ' mkopts_label[xfs]='-L ' # mkopts_label[nfs] is empty mkfs[ext4]=ext4 mkfs[ext2]=ext2 mkfs[fat]=vfat mkfs[f2fs]=f2fs mkfs[btrfs]=btrfs mkfs[xfs]=xfs # mkfs[nfs] is empty mountopts[ext4]=',commit=600,errors=remount-ro' # mountopts[ext2] is empty # mountopts[fat] is empty # mountopts[f2fs] is empty mountopts[btrfs]=',commit=600' # mountopts[xfs] is empty # mountopts[nfs] is empty # default BOOTSIZE to use if not specified DEFAULT_BOOTSIZE=1024 # MiB # size of UEFI partition. 0 for no UEFI. Don't mix UEFISIZE&gt;0 and BOOTSIZE&gt;0 UEFISIZE=${UEFISIZE:-0} BIOSSIZE=${BIOSSIZE:-0} UEFI_MOUNT_POINT=${UEFI_MOUNT_POINT:-/boot/efi} UEFI_FS_LABEL=&quot;${UEFI_FS_LABEL:-opi_efi}&quot; ROOT_FS_LABEL=&quot;${ROOT_FS_LABEL:-opi_root}&quot; BOOT_FS_LABEL=&quot;${BOOT_FS_LABEL:-opi_boot}&quot; call_extension_method &quot;pre_prepare_partitions&quot; &quot;prepare_partitions_custom&quot; &lt;&lt; 'PRE_PREPARE_PARTITIONS'*allow custom options for mkfs*Good time to change stuff like mkfs opts, types etc.PRE_PREPARE_PARTITIONS # stage: determine partition configuration local next=1 # Check if we need UEFI partition if [[ $UEFISIZE -gt 0 ]]; then # Check if we need BIOS partition [[ $BIOSSIZE -gt 0 ]] &amp;&amp; local biospart=$((next++)) local uefipart=$((next++)) fi # Check if we need boot partition if [[ -n $BOOTFS_TYPE || $ROOTFS_TYPE != ext4 || $CRYPTROOT_ENABLE == yes ]]; then local bootpart=$((next++)) local bootfs=${BOOTFS_TYPE:-ext4} [[ -z $BOOTSIZE || $BOOTSIZE -le 8 ]] &amp;&amp; BOOTSIZE=${DEFAULT_BOOTSIZE} else BOOTSIZE=0 fi # Check if we need root partition [[ $ROOTFS_TYPE != nfs ]] &amp;&amp; local rootpart=$((next++)) # stage: calculate rootfs size export rootfs_size=$(du -sm $SDCARD/ | cut -f1) # MiB display_alert &quot;Current rootfs size&quot; &quot;$rootfs_size MiB&quot; &quot;info&quot; call_extension_method &quot;prepare_image_size&quot; &quot;config_prepare_image_size&quot; &lt;&lt; 'PREPARE_IMAGE_SIZE'*allow dynamically determining the size based on the $rootfs_size*Called after `${rootfs_size}` is known, but before `${FIXED_IMAGE_SIZE}` is taken into account.A good spot to determine `FIXED_IMAGE_SIZE` based on `rootfs_size`.UEFISIZE can be set to 0 for no UEFI partition, or to a size in MiB to include one.Last chance to set `USE_HOOK_FOR_PARTITION`=yes and then implement create_partition_table hook_point.PREPARE_IMAGE_SIZE if [[ -n $FIXED_IMAGE_SIZE &amp;&amp; $FIXED_IMAGE_SIZE =~ ^[0-9]+$ ]]; then display_alert &quot;Using user-defined image size&quot; &quot;$FIXED_IMAGE_SIZE MiB&quot; &quot;info&quot; local sdsize=$FIXED_IMAGE_SIZE # basic sanity check if [[ $ROOTFS_TYPE != nfs &amp;&amp; $sdsize -lt $rootfs_size ]]; then exit_with_error &quot;User defined image size is too small&quot; &quot;$sdsize &lt;= $rootfs_size&quot; fi else local imagesize=$(($rootfs_size + $OFFSET + $BOOTSIZE + $UEFISIZE + $EXTRA_ROOTFS_MIB_SIZE)) # MiB # Hardcoded overhead +25% is needed for desktop images, # for CLI it could be lower. Align the size up to 4MiB if [[ $BUILD_DESKTOP == yes ]]; then local sdsize=$(bc -l &lt;&lt;&lt; &quot;scale=0; ((($imagesize * 1.35) / 1 + 0) / 4 + 1) * 4&quot;) else local sdsize=$(bc -l &lt;&lt;&lt; &quot;scale=0; ((($imagesize * 1.30) / 1 + 0) / 4 + 1) * 4&quot;) fi fi # stage: create blank image display_alert &quot;Creating blank image for rootfs&quot; &quot;$sdsize MiB&quot; &quot;info&quot; if [[ $FAST_CREATE_IMAGE == yes ]]; then truncate --size=${sdsize}M ${SDCARD}.raw # sometimes results in fs corruption, revert to previous know to work solution sync else dd if=/dev/zero bs=1M status=none count=$sdsize | pv -p -b -r -s $(($sdsize * 1024 * 1024)) -N &quot;[ .... ] dd&quot; | dd status=none of=${SDCARD}.raw fi # stage: create partition table display_alert &quot;Creating partitions&quot; &quot;${bootfs:+/boot: $bootfs }root: $ROOTFS_TYPE&quot; &quot;info&quot; if [[ &quot;${USE_HOOK_FOR_PARTITION}&quot; == &quot;yes&quot; ]]; then { [[ &quot;$IMAGE_PARTITION_TABLE&quot; == &quot;msdos&quot; ]] &amp;&amp; echo &quot;label: dos&quot; || echo &quot;label: $IMAGE_PARTITION_TABLE&quot; } | sfdisk ${SDCARD}.raw &gt;&gt; &quot;${DEST}/${LOG_SUBPATH}/install.log&quot; 2&gt;&amp;1 || exit_with_error &quot;Create partition table fail. Please check&quot; &quot;${DEST}/${LOG_SUBPATH}/install.log&quot; call_extension_method &quot;create_partition_table&quot; &lt;&lt;- 'CREATE_PARTITION_TABLE' *only called when USE_HOOK_FOR_PARTITION=yes to create the complete partition table* Finally, we can get our own partition table. You have to partition ${SDCARD}.raw yourself. Good luck. CREATE_PARTITION_TABLE else { [[ &quot;$IMAGE_PARTITION_TABLE&quot; == &quot;msdos&quot; ]] &amp;&amp; echo &quot;label: dos&quot; || echo &quot;label: $IMAGE_PARTITION_TABLE&quot; local next=$OFFSET if [[ -n &quot;$biospart&quot; ]]; then # gpt: BIOS boot local type=&quot;21686148-6449-6E6F-744E-656564454649&quot; echo &quot;$biospart : name=\\&quot;bios\\&quot;, start=${next}MiB, size=${BIOSSIZE}MiB, type=${type}&quot; local next=$(($next + $BIOSSIZE)) fi if [[ -n &quot;$uefipart&quot; ]]; then # dos: EFI (FAT-12/16/32) # gpt: EFI System [[ &quot;$IMAGE_PARTITION_TABLE&quot; != &quot;gpt&quot; ]] &amp;&amp; local type=&quot;ef&quot; || local type=&quot;C12A7328-F81F-11D2-BA4B-00A0C93EC93B&quot; echo &quot;$uefipart : name=\\&quot;efi\\&quot;, start=${next}MiB, size=${UEFISIZE}MiB, type=${type}&quot; local next=$(($next + $UEFISIZE)) fi if [[ -n &quot;$bootpart&quot; ]]; then # Linux extended boot [[ &quot;$IMAGE_PARTITION_TABLE&quot; != &quot;gpt&quot; ]] &amp;&amp; local type=&quot;ea&quot; || local type=&quot;BC13C2FF-59E6-4262-A352-B275FD6F7172&quot; if [[ -n &quot;$rootpart&quot; ]]; then echo &quot;$bootpart : name=\\&quot;bootfs\\&quot;, start=${next}MiB, size=${BOOTSIZE}MiB, type=${type}&quot; local next=$(($next + $BOOTSIZE)) else # no `size` argument mean &quot;as much as possible&quot; echo &quot;$bootpart : name=\\&quot;bootfs\\&quot;, start=${next}MiB, type=${type}&quot; fi fi if [[ -n &quot;$rootpart&quot; ]]; then # dos: Linux # gpt: Linux filesystem [[ &quot;$IMAGE_PARTITION_TABLE&quot; != &quot;gpt&quot; ]] &amp;&amp; local type=&quot;83&quot; || local type=&quot;0FC63DAF-8483-4772-8E79-3D69D8477DE4&quot; # no `size` argument mean &quot;as much as possible&quot; echo &quot;$rootpart : name=\\&quot;rootfs\\&quot;, start=${next}MiB, type=${type}&quot; fi } | sfdisk ${SDCARD}.raw &gt;&gt; &quot;${DEST}/${LOG_SUBPATH}/install.log&quot; 2&gt;&amp;1 || exit_with_error &quot;Partition fail. Please check&quot; &quot;${DEST}/${LOG_SUBPATH}/install.log&quot; fi call_extension_method &quot;post_create_partitions&quot; &lt;&lt;- 'POST_CREATE_PARTITIONS' *called after all partitions are created, but not yet formatted* POST_CREATE_PARTITIONS # stage: mount image # lock access to loop devices exec {FD}&gt; /var/lock/orangepi-debootstrap-losetup flock -x $FD LOOP=$(losetup -f) [[ -z $LOOP ]] &amp;&amp; exit_with_error &quot;Unable to find free loop device&quot; check_loop_device &quot;$LOOP&quot; losetup $LOOP ${SDCARD}.raw # loop device was grabbed here, unlock flock -u $FD partprobe $LOOP # stage: create fs, mount partitions, create fstab rm -f $SDCARD/etc/fstab if [[ -n $rootpart ]]; then local rootdevice=&quot;${LOOP}p${rootpart}&quot; if [[ $CRYPTROOT_ENABLE == yes ]]; then display_alert &quot;Encrypting root partition with LUKS...&quot; &quot;cryptsetup luksFormat $rootdevice&quot; &quot;&quot; echo -n $CRYPTROOT_PASSPHRASE | cryptsetup luksFormat $CRYPTROOT_PARAMETERS $rootdevice - echo -n $CRYPTROOT_PASSPHRASE | cryptsetup luksOpen $rootdevice $ROOT_MAPPER - display_alert &quot;Root partition encryption complete.&quot; &quot;&quot; &quot;ext&quot; # TODO: pass /dev/mapper to Docker rootdevice=/dev/mapper/$ROOT_MAPPER # used by `mkfs` and `mount` commands fi check_loop_device &quot;$rootdevice&quot; display_alert &quot;Creating rootfs&quot; &quot;$ROOTFS_TYPE on $rootdevice&quot; mkfs.${mkfs[$ROOTFS_TYPE]} ${mkopts[$ROOTFS_TYPE]} ${mkopts_label[$ROOTFS_TYPE]:+${mkopts_label[$ROOTFS_TYPE]}&quot;$ROOT_FS_LABEL&quot;} $rootdevice &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 [[ $ROOTFS_TYPE == ext4 ]] &amp;&amp; tune2fs -o journal_data_writeback $rootdevice &gt; /dev/null if [[ $ROOTFS_TYPE == btrfs &amp;&amp; $BTRFS_COMPRESSION != none ]]; then local fscreateopt=&quot;-o compress-force=${BTRFS_COMPRESSION}&quot; fi mount ${fscreateopt} $rootdevice $MOUNT/ # create fstab (and crypttab) entry if [[ $CRYPTROOT_ENABLE == yes ]]; then # map the LUKS container partition via its UUID to be the 'cryptroot' device echo &quot;$ROOT_MAPPER UUID=$(blkid -s UUID -o value ${LOOP}p${rootpart}) none luks&quot; &gt;&gt; $SDCARD/etc/crypttab local rootfs=$rootdevice # used in fstab else local rootfs=&quot;UUID=$(blkid -s UUID -o value $rootdevice)&quot; fi echo &quot;$rootfs / ${mkfs[$ROOTFS_TYPE]} defaults,noatime${mountopts[$ROOTFS_TYPE]} 0 1&quot; &gt;&gt; $SDCARD/etc/fstab else # update_initramfs will fail if /lib/modules/ doesn't exist mount --bind --make-private $SDCARD $MOUNT/ echo &quot;/dev/nfs / nfs defaults 0 0&quot; &gt;&gt; $SDCARD/etc/fstab fi if [[ -n $bootpart ]]; then display_alert &quot;Creating /boot&quot; &quot;$bootfs on ${LOOP}p${bootpart}&quot; check_loop_device &quot;${LOOP}p${bootpart}&quot; mkfs.${mkfs[$bootfs]} ${mkopts[$bootfs]} ${mkopts_label[$bootfs]:+${mkopts_label[$bootfs]}&quot;$BOOT_FS_LABEL&quot;} ${LOOP}p${bootpart} &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 mkdir -p $MOUNT/boot/ mount ${LOOP}p${bootpart} $MOUNT/boot/ echo &quot;UUID=$(blkid -s UUID -o value ${LOOP}p${bootpart}) /boot ${mkfs[$bootfs]} defaults${mountopts[$bootfs]} 0 2&quot; &gt;&gt; $SDCARD/etc/fstab fi if [[ -n $uefipart ]]; then display_alert &quot;Creating EFI partition&quot; &quot;FAT32 ${UEFI_MOUNT_POINT} on ${LOOP}p${uefipart} label ${UEFI_FS_LABEL}&quot; check_loop_device &quot;${LOOP}p${uefipart}&quot; mkfs.fat -F32 -n &quot;${UEFI_FS_LABEL}&quot; ${LOOP}p${uefipart} &gt;&gt; &quot;${DEST}&quot;/debug/install.log 2&gt;&amp;1 mkdir -p &quot;${MOUNT}${UEFI_MOUNT_POINT}&quot; mount ${LOOP}p${uefipart} &quot;${MOUNT}${UEFI_MOUNT_POINT}&quot; echo &quot;UUID=$(blkid -s UUID -o value ${LOOP}p${uefipart}) ${UEFI_MOUNT_POINT} vfat defaults 0 2&quot; &gt;&gt; $SDCARD/etc/fstab fi echo &quot;tmpfs /tmp tmpfs defaults,nosuid 0 0&quot; &gt;&gt; $SDCARD/etc/fstab call_extension_method &quot;format_partitions&quot; &lt;&lt;- 'FORMAT_PARTITIONS' *if you created your own partitions, this would be a good time to format them* The loop device is mounted, so ${LOOP}p1 is it's first partition etc. FORMAT_PARTITIONS # stage: adjust boot script or boot environment if [[ -f $SDCARD/boot/orangepiEnv.txt ]]; then if [[ $CRYPTROOT_ENABLE == yes ]]; then echo &quot;rootdev=$rootdevice cryptdevice=UUID=$(blkid -s UUID -o value ${LOOP}p${rootpart}):$ROOT_MAPPER&quot; &gt;&gt; $SDCARD/boot/orangepiEnv.txt else echo &quot;rootdev=$rootfs&quot; &gt;&gt; $SDCARD/boot/orangepiEnv.txt fi echo &quot;rootfstype=$ROOTFS_TYPE&quot; &gt;&gt; $SDCARD/boot/orangepiEnv.txt elif [[ $rootpart != 1 ]] &amp;&amp; [[ $SRC_EXTLINUX != yes ]]; then local bootscript_dst=${BOOTSCRIPT##*:} sed -i 's/mmcblk0p1/mmcblk0p2/' $SDCARD/boot/$bootscript_dst sed -i -e &quot;s/rootfstype=ext4/rootfstype=$ROOTFS_TYPE/&quot; \\ -e &quot;s/rootfstype \\&quot;ext4\\&quot;/rootfstype \\&quot;$ROOTFS_TYPE\\&quot;/&quot; $SDCARD/boot/$bootscript_dst fi # if we have boot.ini = remove orangepiEnv.txt and add UUID there if enabled if [[ -f $SDCARD/boot/boot.ini ]]; then sed -i -e &quot;s/rootfstype \\&quot;ext4\\&quot;/rootfstype \\&quot;$ROOTFS_TYPE\\&quot;/&quot; $SDCARD/boot/boot.ini if [[ $CRYPTROOT_ENABLE == yes ]]; then local rootpart=&quot;UUID=$(blkid -s UUID -o value ${LOOP}p${rootpart})&quot; sed -i 's/^setenv rootdev .*/setenv rootdev &quot;\\/dev\\/mapper\\/'$ROOT_MAPPER' cryptdevice='$rootpart':'$ROOT_MAPPER'&quot;/' $SDCARD/boot/boot.ini else sed -i 's/^setenv rootdev .*/setenv rootdev &quot;'$rootfs'&quot;/' $SDCARD/boot/boot.ini fi if [[ $LINUXFAMILY != meson64 ]]; then [[ -f $SDCARD/boot/orangepiEnv.txt ]] &amp;&amp; rm $SDCARD/boot/orangepiEnv.txt fi fi # if we have a headless device, set console to DEFAULT_CONSOLE if [[ -n $DEFAULT_CONSOLE &amp;&amp; -f $SDCARD/boot/orangepiEnv.txt ]]; then if grep -lq &quot;^console=&quot; $SDCARD/boot/orangepiEnv.txt; then sed -i &quot;s/^console=.*/console=$DEFAULT_CONSOLE/&quot; $SDCARD/boot/orangepiEnv.txt else echo &quot;console=$DEFAULT_CONSOLE&quot; &gt;&gt; $SDCARD/boot/orangepiEnv.txt fi fi # recompile .cmd to .scr if boot.cmd exists if [[ -f $SDCARD/boot/boot.cmd ]]; then if [ -z $BOOTSCRIPT_OUTPUT ]; then BOOTSCRIPT_OUTPUT=boot.scr; fi mkimage -C none -A arm -T script -d $SDCARD/boot/boot.cmd $SDCARD/boot/$BOOTSCRIPT_OUTPUT &gt; /dev/null 2&gt;&amp;1 fi # create extlinux config if [[ -f $SDCARD/boot/extlinux/extlinux.conf ]]; then echo &quot; append root=$rootfs $SRC_CMDLINE $MAIN_CMDLINE&quot; &gt;&gt; $SDCARD/boot/extlinux/extlinux.conf [[ -f $SDCARD/boot/orangepiEnv.txt ]] &amp;&amp; rm $SDCARD/boot/orangepiEnv.txt fi}# update_initramfs## this should be invoked as late as possible for any modifications by# customize_image (userpatches) and prepare_partitions to be reflected in the# final initramfs## especially, this needs to be invoked after /etc/crypttab has been created# for cryptroot-unlock to work:# https://serverfault.com/questions/907254/cryproot-unlock-with-dropbear-timeout-while-waiting-for-askpass## since Debian buster, it has to be called within create_image() on the $MOUNT# path instead of $SDCARD (which can be a tmpfs and breaks cryptsetup-initramfs).#update_initramfs(){ local chroot_target=$1 local target_dir=$( find ${chroot_target}/lib/modules/ -maxdepth 1 -type d -name &quot;*${VER}*&quot; ) if [ &quot;$target_dir&quot; != &quot;&quot; ]; then update_initramfs_cmd=&quot;update-initramfs -uv -k $(basename $target_dir)&quot; else exit_with_error &quot;No kernel installed for the version&quot; &quot;${VER}&quot; fi display_alert &quot;Updating initramfs...&quot; &quot;$update_initramfs_cmd&quot; &quot;&quot; cp /usr/bin/$QEMU_BINARY $chroot_target/usr/bin/ mount_chroot &quot;$chroot_target/&quot; chroot $chroot_target /bin/bash -c &quot;$update_initramfs_cmd&quot; &gt;&gt; $DEST/${LOG_SUBPATH}/install.log 2&gt;&amp;1 || { display_alert &quot;Updating initramfs FAILED, see:&quot; &quot;$DEST/${LOG_SUBPATH}/install.log&quot; &quot;err&quot; exit 23 } display_alert &quot;Updated initramfs.&quot; &quot;for details see: $DEST/${LOG_SUBPATH}/install.log&quot; &quot;info&quot; display_alert &quot;Re-enabling&quot; &quot;initramfs-tools hook for kernel&quot; chroot $chroot_target /bin/bash -c &quot;chmod -v +x /etc/kernel/postinst.d/initramfs-tools&quot; &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 umount_chroot &quot;$chroot_target/&quot; rm $chroot_target/usr/bin/$QEMU_BINARY} ############################################################################## create_image## finishes creation of image from cached rootfs#create_image(){ # stage: create file name if [[ $SELECTED_CONFIGURATION == &quot;cli_standard&quot; ]]; then IMAGE_TYPE=server elif [[ $SELECTED_CONFIGURATION == &quot;cli_minimal&quot; ]]; then IMAGE_TYPE=minimal else IMAGE_TYPE=desktop fi if [[ ${MEM_TYPE} == &quot;1500MB&quot; ]]; then local version=&quot;${BOARD^}_${REVISION}_${DISTRIBUTION,}_${RELEASE}_${IMAGE_TYPE}&quot;${DESKTOP_ENVIRONMENT:+_$DESKTOP_ENVIRONMENT}&quot;_linux$(grab_version &quot;$LINUXSOURCEDIR&quot;)_1.5gb&quot; else local version=&quot;${BOARD^}_${REVISION}_${DISTRIBUTION,}_${RELEASE}_${IMAGE_TYPE}&quot;${DESKTOP_ENVIRONMENT:+_$DESKTOP_ENVIRONMENT}&quot;_linux$(grab_version &quot;$LINUXSOURCEDIR&quot;)&quot; fi if [[ ${RELEASE} == &quot;raspi&quot; ]]; then local version=&quot;${BOARD^}_${REVISION}_raspios_bullseye_${IMAGE_TYPE}&quot;${DESKTOP_ENVIRONMENT:+_$DESKTOP_ENVIRONMENT}&quot;_linux$(grab_version &quot;$LINUXSOURCEDIR&quot;)&quot; fi [[ $ROOTFS_TYPE == nfs ]] &amp;&amp; version=${version}_nfsboot destimg=$DEST/images/${version} rm -rf $destimg mkdir -p $destimg if [[ $ROOTFS_TYPE != nfs ]]; then display_alert &quot;Copying files to&quot; &quot;/&quot; echo -e &quot;\\nCopying files to [/]&quot; &gt;&gt;&quot;${DEST}&quot;/${LOG_SUBPATH}/install.log rsync -aHWXh \\ --exclude=&quot;/boot/*&quot; \\ --exclude=&quot;/dev/*&quot; \\ --exclude=&quot;/proc/*&quot; \\ --exclude=&quot;/run/*&quot; \\ --exclude=&quot;/tmp/*&quot; \\ --exclude=&quot;/sys/*&quot; \\ --info=progress0,stats1 $SDCARD/ $MOUNT/ &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 else display_alert &quot;Creating rootfs archive&quot; &quot;rootfs.tgz&quot; &quot;info&quot; tar cp --xattrs --directory=$SDCARD/ --exclude='./boot/*' --exclude='./dev/*' --exclude='./proc/*' --exclude='./run/*' --exclude='./tmp/*' \\ --exclude='./sys/*' . | pv -p -b -r -s $(du -sb $SDCARD/ | cut -f1) -N &quot;rootfs.tgz&quot; | gzip -c &gt; $destimg/${version}-rootfs.tgz fi # stage: rsync /boot display_alert &quot;Copying files to&quot; &quot;/boot&quot; echo -e &quot;\\nCopying files to [/boot]&quot; &gt;&gt;&quot;${DEST}&quot;/${LOG_SUBPATH}/install.log if [[ $(findmnt --target $MOUNT/boot -o FSTYPE -n) == vfat ]]; then # fat32 rsync -rLtWh \\ --info=progress0,stats1 \\ --log-file=&quot;${DEST}&quot;/${LOG_SUBPATH}/install.log $SDCARD/boot $MOUNT &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 else # ext4 rsync -aHWXh \\ --info=progress0,stats1 \\ --log-file=&quot;${DEST}&quot;/${LOG_SUBPATH}/install.log $SDCARD/boot $MOUNT &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 fi call_extension_method &quot;pre_update_initramfs&quot; &quot;config_pre_update_initramfs&quot; &lt;&lt; 'PRE_UPDATE_INITRAMFS'*allow config to hack into the initramfs create process*Called after rsync has synced both `/root` and `/root` on the target, but before calling `update_initramfs`.PRE_UPDATE_INITRAMFS # stage: create final initramfs [[ -n $KERNELSOURCE ]] &amp;&amp; { update_initramfs $MOUNT } # DEBUG: print free space local freespace=$(LC_ALL=C df -h) echo $freespace &gt;&gt; $DEST/${LOG_SUBPATH}/debootstrap.log display_alert &quot;Free SD cache&quot; &quot;$(echo -e &quot;$freespace&quot; | grep $SDCARD | awk '{print $5}')&quot; &quot;info&quot; display_alert &quot;Mount point&quot; &quot;$(echo -e &quot;$freespace&quot; | grep $MOUNT | head -1 | awk '{print $5}')&quot; &quot;info&quot; # stage: write u-boot write_uboot $LOOP # fix wrong / permissions chmod 755 $MOUNT call_extension_method &quot;pre_umount_final_image&quot; &quot;config_pre_umount_final_image&quot; &lt;&lt; 'PRE_UMOUNT_FINAL_IMAGE'*allow config to hack into the image before the unmount*Called before unmounting both `/root` and `/boot`.PRE_UMOUNT_FINAL_IMAGE # unmount /boot/efi first, then /boot, rootfs third, image file last sync [[ $UEFISIZE != 0 ]] &amp;&amp; umount -l &quot;${MOUNT}${UEFI_MOUNT_POINT}&quot; [[ $BOOTSIZE != 0 ]] &amp;&amp; umount -l $MOUNT/boot [[ $ROOTFS_TYPE != nfs ]] &amp;&amp; umount -l $MOUNT [[ $CRYPTROOT_ENABLE == yes ]] &amp;&amp; cryptsetup luksClose $ROOT_MAPPER call_extension_method &quot;post_umount_final_image&quot; &quot;config_post_umount_final_image&quot; &lt;&lt; 'POST_UMOUNT_FINAL_IMAGE'*allow config to hack into the image after the unmount*Called after unmounting both `/root` and `/boot`.POST_UMOUNT_FINAL_IMAGE # to make sure its unmounted while grep -Eq '(${MOUNT}|${DESTIMG})' /proc/mounts do display_alert &quot;Wait for unmount&quot; &quot;${MOUNT}&quot; &quot;info&quot; sleep 5 done losetup -d $LOOP rm -rf --one-file-system $DESTIMG $MOUNT mkdir -p $DESTIMG mv ${SDCARD}.raw $DESTIMG/${version}.img FINALDEST=${destimg} # custom post_build_image_modify hook to run before fingerprinting and compression [[ $(type -t post_build_image_modify) == function ]] &amp;&amp; display_alert &quot;Custom Hook Detected&quot; &quot;post_build_image_modify&quot; &quot;info&quot; &amp;&amp; post_build_image_modify &quot;${DESTIMG}/${version}.img&quot; if [[ $BUILD_ALL != yes ]]; then if [[ $COMPRESS_OUTPUTIMAGE == &quot;&quot; || $COMPRESS_OUTPUTIMAGE == no ]]; then COMPRESS_OUTPUTIMAGE=&quot;sha,gpg,img&quot; elif [[ $COMPRESS_OUTPUTIMAGE == yes ]]; then COMPRESS_OUTPUTIMAGE=&quot;sha,gpg,7z&quot; fi if [[ $COMPRESS_OUTPUTIMAGE == *gz* ]]; then display_alert &quot;Compressing&quot; &quot;${DESTIMG}/${version}.img.gz&quot; &quot;info&quot; pigz -3 &lt; $DESTIMG/${version}.img &gt; $DESTIMG/${version}.img.gz compression_type=&quot;.gz&quot; fi if [[ $COMPRESS_OUTPUTIMAGE == *xz* ]]; then display_alert &quot;Compressing&quot; &quot;${DESTIMG}/${version}.img.xz&quot; &quot;info&quot; # compressing consumes a lot of memory we don't have. Waiting for previous packing job to finish helps to run a lot more builds in parallel available_cpu=$(grep -c 'processor' /proc/cpuinfo) [[ ${BUILD_ALL} == yes ]] &amp;&amp; available_cpu=$(( $available_cpu * 30 / 100 )) # lets use 20% of resources in case of build-all [[ ${available_cpu} -gt 8 ]] &amp;&amp; available_cpu=8 # using more cpu cores for compressing is pointless available_mem=$(LC_ALL=c free | grep Mem | awk '{print $4/$2 * 100.0}' | awk '{print int($1)}') # in percentage # build optimisations when memory drops below 5% if [[ ${BUILD_ALL} == yes &amp;&amp; ( ${available_mem} -lt 15 || $(ps -uax | grep &quot;pixz&quot; | wc -l) -gt 4 )]]; then while [[ $(ps -uax | grep &quot;pixz&quot; | wc -l) -gt 2 ]] do echo -en &quot;#&quot; sleep 20 done fi pixz -7 -p ${available_cpu} -f $(expr ${available_cpu} + 2) &lt; $DESTIMG/${version}.img &gt; ${DESTIMG}/${version}.img.xz compression_type=&quot;.xz&quot; fi if [[ $COMPRESS_OUTPUTIMAGE == *img* || $COMPRESS_OUTPUTIMAGE == *7z* ]]; then# mv $DESTIMG/${version}.img ${FINALDEST}/${version}.img || exit 1 compression_type=&quot;&quot; fi if [[ $COMPRESS_OUTPUTIMAGE == *sha* ]]; then cd ${DESTIMG} display_alert &quot;SHA256 calculating&quot; &quot;${version}.img${compression_type}&quot; &quot;info&quot; sha256sum -b ${version}.img${compression_type} &gt; ${version}.img${compression_type}.sha fi if [[ $COMPRESS_OUTPUTIMAGE == *gpg* ]]; then cd ${DESTIMG} if [[ -n $GPG_PASS ]]; then display_alert &quot;GPG signing&quot; &quot;${version}.img${compression_type}&quot; &quot;info&quot; [[ -n ${SUDO_USER} ]] &amp;&amp; sudo chown -R ${SUDO_USER}:${SUDO_USER} &quot;${DESTIMG}&quot;/ echo &quot;${GPG_PASS}&quot; | sudo -H -u ${SUDO_USER} bash -c &quot;gpg --passphrase-fd 0 --armor --detach-sign --pinentry-mode loopback --batch --yes ${DESTIMG}/${version}.img${compression_type}&quot; || exit 1 #else # display_alert &quot;GPG signing skipped - no GPG_PASS&quot; &quot;${version}.img&quot; &quot;wrn&quot; fi fi #fingerprint_image &quot;${DESTIMG}/${version}.img${compression_type}.txt&quot; &quot;${version}&quot; if [[ $COMPRESS_OUTPUTIMAGE == *7z* ]]; then display_alert &quot;Compressing&quot; &quot;${DESTIMG}/${version}.7z&quot; &quot;info&quot; 7za a -t7z -bd -m0=lzma2 -mx=3 -mfb=64 -md=32m -ms=on \\ ${DESTIMG}/${version}.7z ${version}.key ${version}.img* &gt;/dev/null 2&gt;&amp;1 find ${DESTIMG}/ -type \\ f \\( -name &quot;${version}.img&quot; -o -name &quot;${version}.img.asc&quot; -o -name &quot;${version}.img.txt&quot; -o -name &quot;${version}.img.sha&quot; \\) -print0 \\ &gt;/dev/null 2&gt;&amp;1 fi fi #display_alert &quot;Done building&quot; &quot;${DESTIMG}/${version}.img&quot; &quot;info&quot; display_alert &quot;Done building&quot; &quot;${FINALDEST}/${version}.img&quot; &quot;info&quot; # call custom post build hook [[ $(type -t post_build_image) == function ]] &amp;&amp; post_build_image &quot;${DESTIMG}/${version}.img&quot; # move artefacts from temporally directory to its final destination [[ -n $compression_type ]] &amp;&amp; rm $DESTIMG/${version}.img mv $DESTIMG/${version}* ${FINALDEST} rm -rf $DESTIMG # write image to SD card if [[ $(lsblk &quot;$CARD_DEVICE&quot; 2&gt;/dev/null) &amp;&amp; -f ${FINALDEST}/${version}.img ]]; then # make sha256sum if it does not exists. we need it for comparisson if [[ -f &quot;${FINALDEST}/${version}&quot;.img.sha ]]; then local ifsha=$(cat ${FINALDEST}/${version}.img.sha | awk '{print $1}') else local ifsha=$(sha256sum -b &quot;${FINALDEST}/${version}&quot;.img | awk '{print $1}') fi display_alert &quot;Writing image&quot; &quot;$CARD_DEVICE ${readsha}&quot; &quot;info&quot; # write to SD card pv -p -b -r -c -N &quot;[ .... ] dd&quot; ${FINALDEST}/${version}.img | dd of=$CARD_DEVICE bs=1M iflag=fullblock oflag=direct status=none call_extension_method &quot;post_write_sdcard&quot; &lt;&lt;- 'POST_BUILD_IMAGE' *run after writing img to sdcard* After the image is written to `$CARD_DEVICE`, but before verifying it. You can still set SKIP_VERIFY=yes to skip verification. POST_BUILD_IMAGE if [[ &quot;${SKIP_VERIFY}&quot; != &quot;yes&quot; ]]; then # read and compare display_alert &quot;Verifying. Please wait!&quot; local ofsha=$(dd if=$CARD_DEVICE count=$(du -b ${FINALDEST}/${version}.img | cut -f1) status=none iflag=count_bytes oflag=direct | sha256sum | awk '{print $1}') if [[ $ifsha == $ofsha ]]; then display_alert &quot;Writing verified&quot; &quot;${version}.img&quot; &quot;info&quot; else display_alert &quot;Writing failed&quot; &quot;${version}.img&quot; &quot;err&quot; fi fi elif [[ `systemd-detect-virt` == 'docker' &amp;&amp; -n $CARD_DEVICE ]]; then # display warning when we want to write sd card under Docker display_alert &quot;Can't write to $CARD_DEVICE&quot; &quot;Enable docker privileged mode in config-docker.conf&quot; &quot;wrn&quot; fi} ############################################################################# 6 distributions.sh分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987988989990991992993994995996997998999100010011002100310041005100610071008100910101011101210131014101510161017101810191020102110221023102410251026102710281029103010311032103310341035103610371038103910401041104210431044104510461047104810491050105110521053105410551056105710581059106010611062106310641065106610671068106910701071107210731074107510761077107810791080108110821083108410851086108710881089109010911092109310941095109610971098109911001101110211031104110511061107110811091110111111121113111411151116111711181119112011211122112311241125112611271128112911301131113211331134113511361137113811391140114111421143114411451146114711481149115011511152#!/bin/bash## Copyright (c) 2013-2021 Igor Pecovnik, igor.pecovnik@gma**.com## This file is licensed under the terms of the GNU General Public# License version 2. This program is licensed &quot;as is&quot; without any# warranty of any kind, whether express or implied.# Functions:# install_common# install_rclocal# install_distribution_specific# post_debootstrap_tweaksinstall_common(){ display_alert &quot;Applying common tweaks&quot; &quot;&quot; &quot;info&quot; # install rootfs encryption related packages separate to not break packages cache if [[ $CRYPTROOT_ENABLE == yes ]]; then display_alert &quot;Installing rootfs encryption related packages&quot; &quot;cryptsetup&quot; &quot;info&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;apt-get -y -qq --no-install-recommends install cryptsetup&quot; \\ &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 if [[ $CRYPTROOT_SSH_UNLOCK == yes ]]; then display_alert &quot;Installing rootfs encryption related packages&quot; &quot;dropbear-initramfs&quot; &quot;info&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;apt-get -y -qq --no-install-recommends install dropbear-initramfs cryptsetup-initramfs&quot; \\ &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 fi fi # add dummy fstab entry to make mkinitramfs happy echo &quot;/dev/mmcblk0p1 / $ROOTFS_TYPE defaults 0 1&quot; &gt;&gt; &quot;${SDCARD}&quot;/etc/fstab # required for initramfs-tools-core on Stretch since it ignores the / fstab entry echo &quot;/dev/mmcblk0p2 /usr $ROOTFS_TYPE defaults 0 2&quot; &gt;&gt; &quot;${SDCARD}&quot;/etc/fstab # adjust initramfs dropbear configuration # needs to be done before kernel installation, else it won't be in the initrd image if [[ $CRYPTROOT_ENABLE == yes &amp;&amp; $CRYPTROOT_SSH_UNLOCK == yes ]]; then # Set the port of the dropbear ssh daemon in the initramfs to a different one if configured # this avoids the typical 'host key changed warning' - `WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!` [[ -f &quot;${SDCARD}&quot;/etc/dropbear-initramfs/config ]] &amp;&amp; \\ sed -i 's/^#DROPBEAR_OPTIONS=/DROPBEAR_OPTIONS=&quot;-p '&quot;${CRYPTROOT_SSH_UNLOCK_PORT}&quot;'&quot;/' \\ &quot;${SDCARD}&quot;/etc/dropbear-initramfs/config # setup dropbear authorized_keys, either provided by userpatches or generated if [[ -f $USERPATCHES_PATH/dropbear_authorized_keys ]]; then cp &quot;$USERPATCHES_PATH&quot;/dropbear_authorized_keys &quot;${SDCARD}&quot;/etc/dropbear-initramfs/authorized_keys else # generate a default ssh key for login on dropbear in initramfs # this key should be changed by the user on first login display_alert &quot;Generating a new SSH key pair for dropbear (initramfs)&quot; &quot;&quot; &quot;&quot; ssh-keygen -t ecdsa -f &quot;${SDCARD}&quot;/etc/dropbear-initramfs/id_ecdsa \\ -N '' -O force-command=cryptroot-unlock -C 'AUTOGENERATED_BY_ARMBIAN_BUILD' &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 # /usr/share/initramfs-tools/hooks/dropbear will automatically add 'id_ecdsa.pub' to authorized_keys file # during mkinitramfs of update-initramfs #cat &quot;${SDCARD}&quot;/etc/dropbear-initramfs/id_ecdsa.pub &gt; &quot;${SDCARD}&quot;/etc/dropbear-initramfs/authorized_keys # The version of the Linux kernel CRYPTROOT_SSH_UNLOCK_KEY_NAME=&quot;${BOARD^}_${REVISION}_${DISTRIBUTION,}_${RELEASE}_${SELECTED_CONFIGURATION}_linux&quot;$(grab_version &quot;$LINUXSOURCEDIR&quot;)&quot;&quot;.key # copy dropbear ssh key to image output dir for convenience cp &quot;${SDCARD}&quot;/etc/dropbear-initramfs/id_ecdsa &quot;${DEST}/images/${CRYPTROOT_SSH_UNLOCK_KEY_NAME}&quot; display_alert &quot;SSH private key for dropbear (initramfs) has been copied to:&quot; \\ &quot;$DEST/images/$CRYPTROOT_SSH_UNLOCK_KEY_NAME&quot; &quot;info&quot; fi fi # create modules file local modules=MODULES_${BRANCH^^} if [[ -n &quot;${!modules}&quot; ]]; then tr ' ' '\\n' &lt;&lt;&lt; &quot;${!modules}&quot; &gt; &quot;${SDCARD}&quot;/etc/modules elif [[ -n &quot;${MODULES}&quot; ]]; then tr ' ' '\\n' &lt;&lt;&lt; &quot;${MODULES}&quot; &gt; &quot;${SDCARD}&quot;/etc/modules fi # create blacklist files local blacklist=MODULES_BLACKLIST_${BRANCH^^} if [[ -n &quot;${!blacklist}&quot; ]]; then tr ' ' '\\n' &lt;&lt;&lt; &quot;${!blacklist}&quot; | sed -e 's/^/blacklist /' &gt; &quot;${SDCARD}/etc/modprobe.d/blacklist-${BOARD}.conf&quot; elif [[ -n &quot;${MODULES_BLACKLIST}&quot; ]]; then tr ' ' '\\n' &lt;&lt;&lt; &quot;${MODULES_BLACKLIST}&quot; | sed -e 's/^/blacklist /' &gt; &quot;${SDCARD}/etc/modprobe.d/blacklist-${BOARD}.conf&quot; fi # configure MIN / MAX speed for cpufrequtils cat &lt;&lt;-EOF &gt; &quot;${SDCARD}&quot;/etc/default/cpufrequtils ENABLE=true MIN_SPEED=$CPUMIN MAX_SPEED=$CPUMAX GOVERNOR=$GOVERNOR EOF # remove default interfaces file if present # before installing board support package rm -f &quot;${SDCARD}&quot;/etc/network/interfaces # disable selinux by default mkdir -p &quot;${SDCARD}&quot;/selinux [[ -f &quot;${SDCARD}&quot;/etc/selinux/config ]] &amp;&amp; sed &quot;s/^SELINUX=.*/SELINUX=disabled/&quot; -i &quot;${SDCARD}&quot;/etc/selinux/config # remove Ubuntu's legal text [[ -f &quot;${SDCARD}&quot;/etc/legal ]] &amp;&amp; rm &quot;${SDCARD}&quot;/etc/legal # Prevent loading paralel printer port drivers which we don't need here. # Suppress boot error if kernel modules are absent if [[ -f &quot;${SDCARD}&quot;/etc/modules-load.d/cups-filters.conf ]]; then sed &quot;s/^lp/#lp/&quot; -i &quot;${SDCARD}&quot;/etc/modules-load.d/cups-filters.conf sed &quot;s/^ppdev/#ppdev/&quot; -i &quot;${SDCARD}&quot;/etc/modules-load.d/cups-filters.conf sed &quot;s/^parport_pc/#parport_pc/&quot; -i &quot;${SDCARD}&quot;/etc/modules-load.d/cups-filters.conf fi # console fix due to Debian bug sed -e 's/CHARMAP=&quot;.*&quot;/CHARMAP=&quot;'$CONSOLE_CHAR'&quot;/g' -i &quot;${SDCARD}&quot;/etc/default/console-setup # add the /dev/urandom path to the rng config file echo &quot;HRNGDEVICE=/dev/urandom&quot; &gt;&gt; &quot;${SDCARD}&quot;/etc/default/rng-tools # ping needs privileged action to be able to create raw network socket # this is working properly but not with (at least) Debian Buster chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;chmod u+s /bin/ping&quot; # change time zone data echo &quot;${TZDATA}&quot; &gt; &quot;${SDCARD}&quot;/etc/timezone chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;dpkg-reconfigure -f noninteractive tzdata &gt;/dev/null 2&gt;&amp;1&quot; # set root password chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;(echo $ROOTPWD;echo $ROOTPWD;) | passwd root &gt;/dev/null 2&gt;&amp;1&quot; # enable automated login to console(s) #mkdir -p &quot;${SDCARD}&quot;/etc/systemd/system/getty@.service.d/ #mkdir -p &quot;${SDCARD}&quot;/etc/systemd/system/serial-getty@.service.d/ #cat &lt;&lt;-EOF &gt; &quot;${SDCARD}&quot;/etc/systemd/system/serial-getty@.service.d/override.conf #[Service] #ExecStartPre=/bin/sh -c 'exec /bin/sleep 10' #ExecStart= #ExecStart=-/sbin/agetty --noissue --autologin root %I \\$TERM #Type=idle #EOF #cp &quot;${SDCARD}&quot;/etc/systemd/system/serial-getty@.service.d/override.conf &quot;${SDCARD}&quot;/etc/systemd/system/getty@.service.d/override.conf # force change root password at first login #chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;chage -d 0 root&quot; # change console welcome text echo -e &quot;${VENDOR} ${REVISION} ${RELEASE^} \\\\l \\n&quot; &gt; &quot;${SDCARD}&quot;/etc/issue echo &quot;${VENDOR} ${REVISION} ${RELEASE^}&quot; &gt; &quot;${SDCARD}&quot;/etc/issue.net sed -i &quot;s/^PRETTY_NAME=.*/PRETTY_NAME=\\&quot;${VENDOR} $REVISION &quot;${RELEASE^}&quot;\\&quot;/&quot; &quot;${SDCARD}&quot;/etc/os-release # enable few bash aliases enabled in Ubuntu by default to make it even sed &quot;s/#alias ll='ls -l'/alias ll='ls -l'/&quot; -i &quot;${SDCARD}&quot;/etc/skel/.bashrc sed &quot;s/#alias la='ls -A'/alias la='ls -A'/&quot; -i &quot;${SDCARD}&quot;/etc/skel/.bashrc sed &quot;s/#alias l='ls -CF'/alias l='ls -CF'/&quot; -i &quot;${SDCARD}&quot;/etc/skel/.bashrc # root user is already there. Copy bashrc there as well cp &quot;${SDCARD}&quot;/etc/skel/.bashrc &quot;${SDCARD}&quot;/root # display welcome message at first root login touch &quot;${SDCARD}&quot;/root/.not_logged_in_yet if [[ ${DESKTOP_AUTOLOGIN} != no ]]; then # set desktop autologin touch &quot;${SDCARD}&quot;/root/.desktop_autologin fi # NOTE: this needs to be executed before family_tweaks local bootscript_src=${BOOTSCRIPT%%:*} local bootscript_dst=${BOOTSCRIPT##*:} # create extlinux config file if [[ $SRC_EXTLINUX == yes ]]; then mkdir -p $SDCARD/boot/extlinux cat &lt;&lt;-EOF &gt; &quot;$SDCARD/boot/extlinux/extlinux.conf&quot; label ${VENDOR} kernel /boot/$NAME_KERNEL initrd /boot/$NAME_INITRD EOF if [[ -n $BOOT_FDT_FILE ]]; then if [[ $BOOT_FDT_FILE != &quot;none&quot; ]]; then echo &quot; fdt /boot/dtb/$BOOT_FDT_FILE&quot; &gt;&gt; &quot;$SDCARD/boot/extlinux/extlinux.conf&quot; fi else echo &quot; fdtdir /boot/dtb/&quot; &gt;&gt; &quot;$SDCARD/boot/extlinux/extlinux.conf&quot; fi else if [[ &quot;${BOOTCONFIG}&quot; != &quot;none&quot; ]]; then if [ -f &quot;${USERPATCHES_PATH}/bootscripts/${bootscript_src}&quot; ]; then cp &quot;${USERPATCHES_PATH}/bootscripts/${bootscript_src}&quot; &quot;${SDCARD}/boot/${bootscript_dst}&quot; else cp &quot;${EXTER}/config/bootscripts/${bootscript_src}&quot; &quot;${SDCARD}/boot/${bootscript_dst}&quot; fi fi if [[ -n $BOOTENV_FILE ]]; then if [[ -f $USERPATCHES_PATH/bootenv/$BOOTENV_FILE ]]; then cp &quot;$USERPATCHES_PATH/bootenv/${BOOTENV_FILE}&quot; &quot;${SDCARD}&quot;/boot/orangepiEnv.txt elif [[ -f $EXTER/config/bootenv/$BOOTENV_FILE ]]; then cp &quot;${EXTER}/config/bootenv/${BOOTENV_FILE}&quot; &quot;${SDCARD}&quot;/boot/orangepiEnv.txt fi fi # TODO: modify $bootscript_dst or orangepiEnv.txt to make NFS boot universal # instead of copying sunxi-specific template if [[ $ROOTFS_TYPE == nfs ]]; then display_alert &quot;Copying NFS boot script template&quot; if [[ -f $USERPATCHES_PATH/nfs-boot.cmd ]]; then cp &quot;$USERPATCHES_PATH&quot;/nfs-boot.cmd &quot;${SDCARD}&quot;/boot/boot.cmd else cp &quot;${EXTER}&quot;/config/templates/nfs-boot.cmd.template &quot;${SDCARD}&quot;/boot/boot.cmd fi fi [[ -n $OVERLAY_PREFIX &amp;&amp; -f &quot;${SDCARD}&quot;/boot/orangepiEnv.txt &amp;&amp; ($BRANCH =~ current|next || $BOARDFAMILY =~ &quot;rockchip-rk3588&quot;|&quot;rockchip-rk356x&quot;) ]] &amp;&amp; \\ echo &quot;overlay_prefix=$OVERLAY_PREFIX&quot; &gt;&gt; &quot;${SDCARD}&quot;/boot/orangepiEnv.txt [[ -n $DEFAULT_OVERLAYS &amp;&amp; -f &quot;${SDCARD}&quot;/boot/orangepiEnv.txt &amp;&amp; ($BRANCH =~ current|next || $BOARDFAMILY =~ &quot;rockchip-rk3588&quot;|&quot;rockchip-rk356x&quot;) ]] &amp;&amp; \\ echo &quot;overlays=${DEFAULT_OVERLAYS//,/ }&quot; &gt;&gt; &quot;${SDCARD}&quot;/boot/orangepiEnv.txt [[ -n $BOOT_FDT_FILE &amp;&amp; -f &quot;${SDCARD}&quot;/boot/orangepiEnv.txt ]] &amp;&amp; \\ echo &quot;fdtfile=${BOOT_FDT_FILE}&quot; &gt;&gt; &quot;${SDCARD}/boot/orangepiEnv.txt&quot; fi # initial date for fake-hwclock date -u '+%Y-%m-%d %H:%M:%S' &gt; &quot;${SDCARD}&quot;/etc/fake-hwclock.data echo &quot;${HOST}&quot; &gt; &quot;${SDCARD}&quot;/etc/hostname # set hostname in hosts file cat &lt;&lt;-EOF &gt; &quot;${SDCARD}&quot;/etc/hosts 127.0.0.1 localhost 127.0.1.1 $HOST ::1 localhost $HOST ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters EOF cd $SRC # Prepare and export caching-related params common to all apt calls below, to maximize apt-cacher-ng usage export APT_EXTRA_DIST_PARAMS=&quot;&quot; [[ $NO_APT_CACHER != yes ]] &amp;&amp; APT_EXTRA_DIST_PARAMS=&quot;-o Acquire::http::Proxy=\\&quot;http://${APT_PROXY_ADDR:-localhost:3142}\\&quot; -o Acquire::http::Proxy::localhost=\\&quot;DIRECT\\&quot;&quot; display_alert &quot;Cleaning&quot; &quot;package lists&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;apt-get clean&quot; display_alert &quot;Updating&quot; &quot;package lists&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;apt-get ${APT_EXTRA_DIST_PARAMS} update&quot; &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 display_alert &quot;Temporarily disabling&quot; &quot;initramfs-tools hook for kernel&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;chmod -v -x /etc/kernel/postinst.d/initramfs-tools&quot; &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 # install family packages if [[ -n ${PACKAGE_LIST_FAMILY} ]]; then display_alert &quot;Installing PACKAGE_LIST_FAMILY packages&quot; &quot;${PACKAGE_LIST_FAMILY}&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;DEBIAN_FRONTEND=noninteractive apt-get ${APT_EXTRA_DIST_PARAMS} -yqq --no-install-recommends install $PACKAGE_LIST_FAMILY&quot; &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log fi # install board packages if [[ -n ${PACKAGE_LIST_BOARD} ]]; then display_alert &quot;Installing PACKAGE_LIST_BOARD packages&quot; &quot;${PACKAGE_LIST_BOARD}&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;DEBIAN_FRONTEND=noninteractive apt-get ${APT_EXTRA_DIST_PARAMS} -yqq --no-install-recommends install $PACKAGE_LIST_BOARD&quot; &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log || { display_alert &quot;Failed to install PACKAGE_LIST_BOARD&quot; &quot;${PACKAGE_LIST_BOARD}&quot; &quot;err&quot;; exit 2; } fi # remove family packages if [[ -n ${PACKAGE_LIST_FAMILY_REMOVE} ]]; then display_alert &quot;Removing PACKAGE_LIST_FAMILY_REMOVE packages&quot; &quot;${PACKAGE_LIST_FAMILY_REMOVE}&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;DEBIAN_FRONTEND=noninteractive apt-get ${APT_EXTRA_DIST_PARAMS} -yqq remove --auto-remove $PACKAGE_LIST_FAMILY_REMOVE&quot; &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log fi # remove board packages if [[ -n ${PACKAGE_LIST_BOARD_REMOVE} ]]; then display_alert &quot;Removing PACKAGE_LIST_BOARD_REMOVE packages&quot; &quot;${PACKAGE_LIST_BOARD_REMOVE}&quot; for PKG_REMOVE in ${PACKAGE_LIST_BOARD_REMOVE}; do chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;DEBIAN_FRONTEND=noninteractive apt-get ${APT_EXTRA_DIST_PARAMS} -yqq remove --auto-remove ${PKG_REMOVE}&quot; &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log done fi # install u-boot # @TODO: add install_bootloader() extension method, refactor into u-boot extension [[ &quot;${BOOTCONFIG}&quot; != &quot;none&quot; ]] &amp;&amp; { if [[ &quot;${REPOSITORY_INSTALL}&quot; != *u-boot* ]]; then UBOOT_VER=$(dpkg --info &quot;${DEB_STORAGE}/u-boot/${CHOSEN_UBOOT}_${REVISION}_${ARCH}.deb&quot; | grep Descr | awk '{print $(NF)}') install_deb_chroot &quot;${DEB_STORAGE}/u-boot/${CHOSEN_UBOOT}_${REVISION}_${ARCH}.deb&quot; else UBOOT_VER=$(dpkg --info &quot;${DEB_ORANGEPI}/u-boot/${CHOSEN_UBOOT}_${REVISION}_${ARCH}.deb&quot; | grep Descr | awk '{print $(NF)}') install_deb_chroot &quot;${DEB_ORANGEPI}/u-boot/${CHOSEN_UBOOT}_${REVISION}_${ARCH}.deb&quot; &quot;orangepi&quot; fi } call_extension_method &quot;pre_install_kernel_debs&quot; &lt;&lt; 'PRE_INSTALL_KERNEL_DEBS'*called before installing the Armbian-built kernel deb packages*It is not too late to `unset KERNELSOURCE` here and avoid kernel install.PRE_INSTALL_KERNEL_DEBS # install kernel [[ -n $KERNELSOURCE ]] &amp;&amp; { if [[ &quot;${REPOSITORY_INSTALL}&quot; != *kernel* ]]; then VER=$(dpkg --info &quot;${DEB_STORAGE}/${CHOSEN_KERNEL}_${REVISION}_${ARCH}.deb&quot; | awk -F&quot;-&quot; '/Source:/{print $2}') install_deb_chroot &quot;${DEB_STORAGE}/${CHOSEN_KERNEL}_${REVISION}_${ARCH}.deb&quot; if [[ -f ${DEB_STORAGE}/${CHOSEN_KERNEL/image/dtb}_${REVISION}_${ARCH}.deb ]]; then install_deb_chroot &quot;${DEB_STORAGE}/${CHOSEN_KERNEL/image/dtb}_${REVISION}_${ARCH}.deb&quot; fi if [[ $INSTALL_HEADERS == yes ]]; then install_deb_chroot &quot;${DEB_STORAGE}/${CHOSEN_KERNEL/image/headers}_${REVISION}_${ARCH}.deb&quot; else cp &quot;${DEB_STORAGE}/${CHOSEN_KERNEL/image/headers}_${REVISION}_${ARCH}.deb&quot; &quot;${SDCARD}&quot;/opt/ fi else VER=$(dpkg --info &quot;${DEB_ORANGEPI}/${CHOSEN_KERNEL}_${REVISION}_${ARCH}.deb&quot; | grep Descr | awk '{print $(NF)}') VER=&quot;${VER/-$LINUXFAMILY/}&quot; install_deb_chroot &quot;${DEB_ORANGEPI}/${CHOSEN_KERNEL}_${REVISION}_${ARCH}.deb&quot; &quot;orangepi&quot; if [[ -f ${DEB_ORANGEPI}/${CHOSEN_KERNEL/image/dtb}_${REVISION}_${ARCH}.deb ]]; then install_deb_chroot &quot;${DEB_ORANGEPI}/${CHOSEN_KERNEL/image/dtb}_${REVISION}_${ARCH}.deb&quot; &quot;orangepi&quot; fi if [[ $INSTALL_HEADERS == yes ]]; then install_deb_chroot &quot;${DEB_ORANGEPI}/${CHOSEN_KERNEL/image/headers}_${REVISION}_${ARCH}.deb&quot; &quot;orangepi&quot; fi fi } call_extension_method &quot;post_install_kernel_debs&quot; &lt;&lt; 'POST_INSTALL_KERNEL_DEBS'*allow config to do more with the installed kernel/headers*Called after packages, u-boot, kernel and headers installed in the chroot, but before the BSP is installed.If `KERNELSOURCE` is (still?) unset after this, Armbian-built firmware will not be installed.POST_INSTALL_KERNEL_DEBS # install board support packages if [[ &quot;${REPOSITORY_INSTALL}&quot; != *bsp* ]]; then install_deb_chroot &quot;${DEB_STORAGE}/$RELEASE/${BSP_CLI_PACKAGE_FULLNAME}.deb&quot; else install_deb_chroot &quot;${DEB_ORANGEPI}/$RELEASE/${CHOSEN_ROOTFS}_${BSP_CLI_PACKAGE_FULLNAME}.deb&quot; &quot;orangepi&quot; fi # install orangepi-desktop if [[ &quot;${REPOSITORY_INSTALL}&quot; != *orangepi-desktop* ]]; then if [[ $BUILD_DESKTOP == yes ]]; then install_deb_chroot &quot;${DEB_STORAGE}/${RELEASE}/${CHOSEN_DESKTOP}_${REVISION}_all.deb&quot; install_deb_chroot &quot;${DEB_STORAGE}/${RELEASE}/${BSP_DESKTOP_PACKAGE_FULLNAME}.deb&quot; # install display manager and PACKAGE_LIST_DESKTOP_FULL packages if enabled per board desktop_postinstall fi else if [[ $BUILD_DESKTOP == yes ]]; then install_deb_chroot &quot;${CHOSEN_DESKTOP}&quot; &quot;orangepi&quot; # install display manager and PACKAGE_LIST_DESKTOP_FULL packages if enabled per board desktop_postinstall fi fi # install orangepi-firmware if [[ &quot;${REPOSITORY_INSTALL}&quot; != *orangepi-firmware* ]]; then if [[ -f ${DEB_STORAGE}/orangepi-firmware_${REVISION}_all.deb ]]; then install_deb_chroot &quot;${DEB_STORAGE}/orangepi-firmware_${REVISION}_all.deb&quot; fi else if [[ -f ${DEB_STORAGE}/orangepi-firmware_${REVISION}_all.deb ]]; then install_deb_chroot &quot;${DEB_ORANGEPI}/orangepi-firmware_${REVISION}_all.deb&quot; &quot;orangepi&quot; fi fi # install orangepi-config if [[ &quot;${PACKAGE_LIST_RM}&quot; != *orangepi-config* ]]; then if [[ &quot;${REPOSITORY_INSTALL}&quot; != *orangepi-config* ]]; then if [[ $BUILD_MINIMAL != yes ]]; then install_deb_chroot &quot;${DEB_STORAGE}/orangepi-config_${REVISION}_all.deb&quot; fi else if [[ $BUILD_MINIMAL != yes ]]; then install_deb_chroot &quot;${DEB_ORANGEPI}/orangepi-config_${REVISION}_all.deb&quot; &quot;orangepi&quot; fi fi fi # install orangepi-zsh if [[ &quot;${PACKAGE_LIST_RM}&quot; != *orangepi-zsh* ]]; then if [[ &quot;${REPOSITORY_INSTALL}&quot; != *orangepi-zsh* ]]; then if [[ $BUILD_MINIMAL != yes ]]; then install_deb_chroot &quot;${DEB_STORAGE}/orangepi-zsh_${REVISION}_all.deb&quot; fi else if [[ $BUILD_MINIMAL != yes ]]; then install_deb_chroot &quot;orangepi-zsh&quot; &quot;remote&quot; fi fi fi # install plymouth-theme-orangepi if [[ $PLYMOUTH == yes &amp;&amp; $BUILD_DESKTOP == yes &amp;&amp; $RELEASE != buster ]]; then if [[ &quot;${REPOSITORY_INSTALL}&quot; != *plymouth-theme-orangepi* ]]; then install_deb_chroot &quot;${DEB_STORAGE}/orangepi-plymouth-theme_${REVISION}_all.deb&quot; else install_deb_chroot &quot;orangepi-plymouth-theme&quot; &quot;remote&quot; fi fi # install kernel sources if [[ -f ${DEB_STORAGE}/${CHOSEN_KSRC}_${REVISION}_all.deb &amp;&amp; $INSTALL_KSRC == yes ]]; then install_deb_chroot &quot;${DEB_STORAGE}/${CHOSEN_KSRC}_${REVISION}_all.deb&quot; elif [[ $INSTALL_KSRC == yes ]]; then display_alert &quot;Please set BUILD_KSRC=yes to generate the kernel source package&quot; &quot;&quot; &quot;wrn&quot; fi # install wireguard tools if [[ $WIREGUARD == yes ]]; then chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;apt-get -y -qq install wireguard-tools --no-install-recommends&quot; &gt;&gt; &quot;${DEST}&quot;/debug/install.log 2&gt;&amp;1 fiinstall_wiringop # freeze orangepi packages if [[ $BSPFREEZE == yes ]]; then display_alert &quot;Freezing Orange Pi packages&quot; &quot;$BOARD&quot; &quot;info&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;apt-mark hold ${CHOSEN_KERNEL} ${CHOSEN_KERNEL/image/headers} \\ linux-u-boot-${BOARD}-${BRANCH} ${CHOSEN_KERNEL/image/dtb}&quot; &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 fi # add orangepi user chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;adduser --quiet --disabled-password --shell /bin/bash --home /home/${OPI_USERNAME} --gecos ${OPI_USERNAME} ${OPI_USERNAME}&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;(echo ${OPI_PWD};echo ${OPI_PWD};) | passwd &quot;${OPI_USERNAME}&quot; &gt;/dev/null 2&gt;&amp;1&quot; for additionalgroup in sudo netdev audio video disk tty users games dialout plugdev input bluetooth systemd-journal ssh; do chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;usermod -aG ${additionalgroup} ${OPI_USERNAME} 2&gt;/dev/null&quot; done # fix for gksu in Xenial touch ${SDCARD}/home/${OPI_USERNAME}/.Xauthority chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;chown ${OPI_USERNAME}:${OPI_USERNAME} /home/${OPI_USERNAME}/.Xauthority&quot; # set up profile sync daemon on desktop systems chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;which psd &gt;/dev/null 2&gt;&amp;1&quot; if [ $? -eq 0 ]; then echo -e &quot;${OPI_USERNAME} ALL=(ALL) NOPASSWD: /usr/bin/psd-overlay-helper&quot; &gt;&gt; ${SDCARD}/etc/sudoers touch ${SDCARD}/home/${OPI_USERNAME}/.activate_psd chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;chown $OPI_USERNAME:$OPI_USERNAME /home/${OPI_USERNAME}/.activate_psd&quot; fi # remove deb files rm -f &quot;${SDCARD}&quot;/root/*.deb # copy boot splash images cp &quot;${EXTER}&quot;/packages/blobs/splash/orangepi-u-boot.bmp &quot;${SDCARD}&quot;/boot/boot.bmp cp &quot;${EXTER}&quot;/packages/blobs/splash/logo.bmp &quot;${SDCARD}&quot;/boot/logo.bmp # copy audio.wav and mute.wav cp &quot;${EXTER}&quot;/packages/blobs/audio_wav/audio.wav &quot;${SDCARD}&quot;/usr/share/sounds/alsa/ cp &quot;${EXTER}&quot;/packages/blobs/audio_wav/mute.wav &quot;${SDCARD}&quot;/usr/share/sounds/alsa/ cp &quot;${EXTER}&quot;/packages/blobs/test.mp4 &quot;${SDCARD}&quot;/usr/local/ # copy watchdog test programm cp &quot;${EXTER}&quot;/packages/blobs/watchdog/watchdog_test_${ARCH} &quot;${SDCARD}&quot;/usr/local/bin/watchdog_test [[ -f &quot;${SDCARD}&quot;/usr/bin/gnome-session ]] &amp;&amp; sed -i &quot;s/user-session.*/user-session=ubuntu-wayland/&quot; ${SDCARD}/etc/lightdm/lightdm.conf.d/22-orangepi-autologin.conf [[ -f &quot;${SDCARD}&quot;/usr/bin/startplasma-x11 ]] &amp;&amp; sed -i &quot;s/user-session.*/user-session=plasma-x11/&quot; ${SDCARD}/etc/lightdm/lightdm.conf.d/22-orangepi-autologin.conf # execute $LINUXFAMILY-specific tweaks [[ $(type -t family_tweaks) == function ]] &amp;&amp; family_tweaks call_extension_method &quot;post_family_tweaks&quot; &lt;&lt; 'FAMILY_TWEAKS'*customize the tweaks made by $LINUXFAMILY-specific family_tweaks*It is run after packages are installed in the rootfs, but before enabling additional services.It allows implementors access to the rootfs (`${SDCARD}`) in its pristine state after packages are installed.FAMILY_TWEAKS # enable additional services chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl --no-reload enable orangepi-firstrun.service &gt;/dev/null 2&gt;&amp;1&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl --no-reload enable orangepi-firstrun-config.service &gt;/dev/null 2&gt;&amp;1&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl --no-reload enable orangepi-zram-config.service &gt;/dev/null 2&gt;&amp;1&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl --no-reload enable orangepi-hardware-optimize.service &gt;/dev/null 2&gt;&amp;1&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl --no-reload enable orangepi-ramlog.service &gt;/dev/null 2&gt;&amp;1&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl --no-reload enable orangepi-resize-filesystem.service &gt;/dev/null 2&gt;&amp;1&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl --no-reload enable orangepi-hardware-monitor.service &gt;/dev/null 2&gt;&amp;1&quot; # copy &quot;first run automated config, optional user configured&quot; cp ${EXTER}/packages/bsp/orangepi_first_run.txt.template &quot;${SDCARD}&quot;/boot/orangepi_first_run.txt.template ## switch to beta repository at this stage if building nightly images #[[ $IMAGE_TYPE == nightly ]] \\ #&amp;&amp; echo &quot;deb http://beta.orangepi.com $RELEASE main ${RELEASE}-utils ${RELEASE}-desktop&quot; \\ #&gt; &quot;${SDCARD}&quot;/etc/apt/sources.list.d/orangepi.list # Cosmetic fix [FAILED] Failed to start Set console font and keymap at first boot [[ -f &quot;${SDCARD}&quot;/etc/console-setup/cached_setup_font.sh ]] \\ &amp;&amp; sed -i &quot;s/^printf '.*/printf '\\\\\\033\\%\\%G'/g&quot; &quot;${SDCARD}&quot;/etc/console-setup/cached_setup_font.sh [[ -f &quot;${SDCARD}&quot;/etc/console-setup/cached_setup_terminal.sh ]] \\ &amp;&amp; sed -i &quot;s/^printf '.*/printf '\\\\\\033\\%\\%G'/g&quot; &quot;${SDCARD}&quot;/etc/console-setup/cached_setup_terminal.sh [[ -f &quot;${SDCARD}&quot;/etc/console-setup/cached_setup_keyboard.sh ]] \\ &amp;&amp; sed -i &quot;s/-u/-x'/g&quot; &quot;${SDCARD}&quot;/etc/console-setup/cached_setup_keyboard.sh # fix for https://bugs.launchpad.net/ubuntu/+source/blueman/+bug/1542723 chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;chown root:messagebus /usr/lib/dbus-1.0/dbus-daemon-launch-helper&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;chmod u+s /usr/lib/dbus-1.0/dbus-daemon-launch-helper&quot; # disable samba NetBIOS over IP name service requests since it hangs when no network is present at boot chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl --quiet disable nmbd 2&gt; /dev/null&quot; # disable low-level kernel messages for non betas if [[ -z $BETA ]]; then sed -i &quot;s/^#kernel.printk*/kernel.printk/&quot; &quot;${SDCARD}&quot;/etc/sysctl.conf fi # disable repeated messages due to xconsole not being installed. [[ -f &quot;${SDCARD}&quot;/etc/rsyslog.d/50-default.conf ]] &amp;&amp; \\ sed '/daemon\\.\\*\\;mail.*/,/xconsole/ s/.*/#&amp;/' -i &quot;${SDCARD}&quot;/etc/rsyslog.d/50-default.conf # disable deprecated parameter sed '/.*$KLogPermitNonKernelFacility.*/,// s/.*/#&amp;/' -i &quot;${SDCARD}&quot;/etc/rsyslog.conf # enable getty on multiple serial consoles # and adjust the speed if it is defined and different than 115200 # # example: SERIALCON=&quot;ttyS0:15000000,ttyGS1&quot; # ifs=$IFS for i in $(echo &quot;${SERIALCON:-'ttyS0'}&quot; | sed &quot;s/,/ /g&quot;) do IFS=':' read -r -a array &lt;&lt;&lt; &quot;$i&quot; [[ &quot;${array[0]}&quot; == &quot;tty1&quot; ]] &amp;&amp; continue # Don't enable tty1 as serial console. display_alert &quot;Enabling serial console&quot; &quot;${array[0]}&quot; &quot;info&quot; # add serial console to secure tty list [ -z &quot;$(grep -w '^${array[0]}' &quot;${SDCARD}&quot;/etc/securetty 2&gt; /dev/null)&quot; ] &amp;&amp; \\ echo &quot;${array[0]}&quot; &gt;&gt; &quot;${SDCARD}&quot;/etc/securetty if [[ ${array[1]} != &quot;115200&quot; &amp;&amp; -n ${array[1]} ]]; then # make a copy, fix speed and enable cp &quot;${SDCARD}&quot;/lib/systemd/system/serial-getty@.service \\ &quot;${SDCARD}/lib/systemd/system/serial-getty@${array[0]}.service&quot; sed -i &quot;s/--keep-baud 115200/--keep-baud ${array[1]},115200/&quot; \\ &quot;${SDCARD}/lib/systemd/system/serial-getty@${array[0]}.service&quot; fi chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl daemon-reload&quot; &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl --no-reload enable serial-getty@${array[0]}.service&quot; \\ &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 if [[ &quot;${array[0]}&quot; == &quot;ttyGS0&quot; &amp;&amp; $LINUXFAMILY == sun8i &amp;&amp; $BRANCH == legacy ]]; then mkdir -p &quot;${SDCARD}&quot;/etc/systemd/system/serial-getty@ttyGS0.service.d cat &lt;&lt;-EOF &gt; &quot;${SDCARD}&quot;/etc/systemd/system/serial-getty@ttyGS0.service.d/10-switch-role.conf [Service] ExecStartPre=-/bin/sh -c &quot;echo 2 &gt; /sys/bus/platform/devices/sunxi_usb_udc/otg_role&quot; EOF fi done IFS=$ifs [[ $LINUXFAMILY == sun*i ]] &amp;&amp; mkdir -p &quot;${SDCARD}&quot;/boot/overlay-user # to prevent creating swap file on NFS (needs specific kernel options) # and f2fs/btrfs (not recommended or needs specific kernel options) [[ $ROOTFS_TYPE != ext4 ]] &amp;&amp; touch &quot;${SDCARD}&quot;/var/swap # install initial asound.state if defined mkdir -p &quot;${SDCARD}&quot;/var/lib/alsa/ [[ -n $ASOUND_STATE ]] &amp;&amp; cp &quot;${EXTER}/packages/blobs/asound.state/${ASOUND_STATE}&quot; &quot;${SDCARD}&quot;/var/lib/alsa/asound.state # save initial orangepi-release state cp &quot;${SDCARD}&quot;/etc/orangepi-release &quot;${SDCARD}&quot;/etc/orangepi-image-release # DNS fix. package resolvconf is not available everywhere if [ -d /etc/resolvconf/resolv.conf.d ] &amp;&amp; [ -n &quot;$NAMESERVER&quot; ]; then echo &quot;nameserver $NAMESERVER&quot; &gt; &quot;${SDCARD}&quot;/etc/resolvconf/resolv.conf.d/head fi # permit root login via SSH for the first boot sed -i 's/#\\?PermitRootLogin .*/PermitRootLogin yes/' &quot;${SDCARD}&quot;/etc/ssh/sshd_config # enable PubkeyAuthentication sed -i 's/#\\?PubkeyAuthentication .*/PubkeyAuthentication yes/' &quot;${SDCARD}&quot;/etc/ssh/sshd_config if [ -f &quot;${SDCARD}&quot;/etc/NetworkManager/NetworkManager.conf ]; then # configure network manager sed &quot;s/managed=\\(.*\\)/managed=true/g&quot; -i &quot;${SDCARD}&quot;/etc/NetworkManager/NetworkManager.conf # remove network manager defaults to handle eth by default rm -f &quot;${SDCARD}&quot;/usr/lib/NetworkManager/conf.d/10-globally-managed-devices.conf # most likely we don't need to wait for nm to get online chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl disable NetworkManager-wait-online.service&quot; &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 # Just regular DNS and maintain /etc/resolv.conf as a file sed &quot;/dns/d&quot; -i &quot;${SDCARD}&quot;/etc/NetworkManager/NetworkManager.conf sed &quot;s/\\[main\\]/\\[main\\]\\ndns=default\\nrc-manager=file/g&quot; -i &quot;${SDCARD}&quot;/etc/NetworkManager/NetworkManager.conf if [[ -n $NM_IGNORE_DEVICES ]]; then mkdir -p &quot;${SDCARD}&quot;/etc/NetworkManager/conf.d/ cat &lt;&lt;-EOF &gt; &quot;${SDCARD}&quot;/etc/NetworkManager/conf.d/10-ignore-interfaces.conf [keyfile] unmanaged-devices=$NM_IGNORE_DEVICES EOF fi elif [ -d &quot;${SDCARD}&quot;/etc/systemd/network ]; then # configure networkd rm &quot;${SDCARD}&quot;/etc/resolv.conf ln -s /run/systemd/resolve/resolv.conf &quot;${SDCARD}&quot;/etc/resolv.conf # enable services chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl enable systemd-networkd.service systemd-resolved.service&quot; &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 if [ -e /etc/systemd/timesyncd.conf ]; then chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl enable systemd-timesyncd.service&quot; &gt;&gt; &quot;${DEST}&quot;/${LOG_SUBPATH}/install.log 2&gt;&amp;1 fi umask 022 cat &gt; &quot;${SDCARD}&quot;/etc/systemd/network/eth0.network &lt;&lt;- __EOF__ [Match] Name=eth0 [Network] #MACAddress= DHCP=ipv4 LinkLocalAddressing=ipv4 #Address=192.168.1.100/24 #Gateway=192.168.1.1 #DNS=192.168.1.1 #Domains=example.com NTP=0.pool.ntp.org 1.pool.ntp.org __EOF__ fi # avahi daemon defaults if exists [[ -f &quot;${SDCARD}&quot;/usr/share/doc/avahi-daemon/examples/sftp-ssh.service ]] &amp;&amp; \\ cp &quot;${SDCARD}&quot;/usr/share/doc/avahi-daemon/examples/sftp-ssh.service &quot;${SDCARD}&quot;/etc/avahi/services/ [[ -f &quot;${SDCARD}&quot;/usr/share/doc/avahi-daemon/examples/ssh.service ]] &amp;&amp; \\ cp &quot;${SDCARD}&quot;/usr/share/doc/avahi-daemon/examples/ssh.service &quot;${SDCARD}&quot;/etc/avahi/services/ # nsswitch settings for sane DNS behavior: remove resolve, assure libnss-myhostname support sed &quot;s/hosts\\:.*/hosts: files mymachines dns myhostname/g&quot; -i &quot;${SDCARD}&quot;/etc/nsswitch.conf # build logo in any case boot_logo # disable MOTD for first boot - we want as clean 1st run as possible chmod -x &quot;${SDCARD}&quot;/etc/update-motd.d/*}install_rclocal(){ if [[ $BURN_IMAGE == yes ]]; then cat &lt;&lt;-EOF &gt; &quot;${SDCARD}&quot;/etc/rc.local #!/bin/sh -e # # rc.local # # This script is executed at the end of each multiuser runlevel. # Make sure that the script will &quot;exit 0&quot; on success or any other # value on error. # # In order to enable or disable this script just change the execution # bits. # # By default this script does nothing. burn_to_emmc exit 0 EOF else cat &lt;&lt;-EOF &gt; &quot;${SDCARD}&quot;/etc/rc.local #!/bin/sh -e # # rc.local # # This script is executed at the end of each multiuser runlevel. # Make sure that the script will &quot;exit 0&quot; on success or any other # value on error. # # In order to enable or disable this script just change the execution # bits. # # By default this script does nothing. exit 0 EOF fi chmod +x &quot;${SDCARD}&quot;/etc/rc.local}install_distribution_specific(){ display_alert &quot;Applying distribution specific tweaks for&quot; &quot;$RELEASE&quot; &quot;info&quot; case $RELEASE in xenial) # remove legal info from Ubuntu [[ -f &quot;${SDCARD}&quot;/etc/legal ]] &amp;&amp; rm &quot;${SDCARD}&quot;/etc/legal # ureadahead needs kernel tracing options that AFAIK are present only in mainline. disable chroot &quot;${SDCARD}&quot; /bin/bash -c \\ &quot;systemctl --no-reload mask ondemand.service ureadahead.service &gt;/dev/null 2&gt;&amp;1&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c \\ &quot;systemctl --no-reload mask setserial.service etc-setserial.service &gt;/dev/null 2&gt;&amp;1&quot; ;; stretch|buster|sid) # remove doubled uname from motd [[ -f &quot;${SDCARD}&quot;/etc/update-motd.d/10-uname ]] &amp;&amp; rm &quot;${SDCARD}&quot;/etc/update-motd.d/10-uname # rc.local is not existing but one might need it install_rclocal ;; bullseye) # remove doubled uname from motd [[ -f &quot;${SDCARD}&quot;/etc/update-motd.d/10-uname ]] &amp;&amp; rm &quot;${SDCARD}&quot;/etc/update-motd.d/10-uname # rc.local is not existing but one might need it install_rclocal # fix missing versioning [[ $(grep -L &quot;VERSION_ID=&quot; &quot;${SDCARD}&quot;/etc/os-release) ]] &amp;&amp; echo 'VERSION_ID=&quot;11&quot;' &gt;&gt; &quot;${SDCARD}&quot;/etc/os-release [[ $(grep -L &quot;VERSION=&quot; &quot;${SDCARD}&quot;/etc/os-release) ]] &amp;&amp; echo 'VERSION=&quot;11 (bullseye)&quot;' &gt;&gt; &quot;${SDCARD}&quot;/etc/os-release ;; bookworm) # remove doubled uname from motd [[ -f &quot;${SDCARD}&quot;/etc/update-motd.d/10-uname ]] &amp;&amp; rm &quot;${SDCARD}&quot;/etc/update-motd.d/10-uname # rc.local is not existing but one might need it install_rclocal # fix missing versioning [[ $(grep -L &quot;VERSION_ID=&quot; &quot;${SDCARD}&quot;/etc/os-release) ]] &amp;&amp; echo 'VERSION_ID=&quot;12&quot;' &gt;&gt; &quot;${SDCARD}&quot;/etc/os-release [[ $(grep -L &quot;VERSION=&quot; &quot;${SDCARD}&quot;/etc/os-release) ]] &amp;&amp; echo 'VERSION=&quot;11 (bookworm)&quot;' &gt;&gt; &quot;${SDCARD}&quot;/etc/os-release # remove security updates repository since it does not exists yet sed '/security/ d' -i &quot;${SDCARD}&quot;/etc/apt/sources.list ;; bionic|focal|hirsute|impish|jammy) # by using default lz4 initrd compression leads to corruption, go back to proven method sed -i &quot;s/^COMPRESS=.*/COMPRESS=gzip/&quot; &quot;${SDCARD}&quot;/etc/initramfs-tools/initramfs.conf # cleanup motd services and related files chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl disable motd-news.service &gt;/dev/null 2&gt;&amp;1&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl disable motd-news.timer &gt;/dev/null 2&gt;&amp;1&quot; rm -f &quot;${SDCARD}&quot;/etc/update-motd.d/{10-uname,10-help-text,50-motd-news,80-esm,80-livepatch,90-updates-available,91-release-upgrade,95-hwe-eol} # remove motd news from motd.ubuntu.com [[ -f &quot;${SDCARD}&quot;/etc/default/motd-news ]] &amp;&amp; sed -i &quot;s/^ENABLED=.*/ENABLED=0/&quot; &quot;${SDCARD}&quot;/etc/default/motd-news # rc.local is not existing but one might need it install_rclocal if [ -d &quot;${SDCARD}&quot;/etc/NetworkManager ]; then local RENDERER=NetworkManager else local RENDERER=networkd fi # Basic Netplan config. Let NetworkManager/networkd manage all devices on this system [[ -d &quot;${SDCARD}&quot;/etc/netplan ]] &amp;&amp; cat &lt;&lt;-EOF &gt; &quot;${SDCARD}&quot;/etc/netplan/orangepi-default.yaml network: version: 2 renderer: $RENDERER EOF # DNS fix if [ -n &quot;$NAMESERVER&quot; ]; then sed -i &quot;s/#DNS=.*/DNS=$NAMESERVER/g&quot; &quot;${SDCARD}&quot;/etc/systemd/resolved.conf fi # Journal service adjustements sed -i &quot;s/#Storage=.*/Storage=volatile/g&quot; &quot;${SDCARD}&quot;/etc/systemd/journald.conf sed -i &quot;s/#Compress=.*/Compress=yes/g&quot; &quot;${SDCARD}&quot;/etc/systemd/journald.conf sed -i &quot;s/#RateLimitIntervalSec=.*/RateLimitIntervalSec=30s/g&quot; &quot;${SDCARD}&quot;/etc/systemd/journald.conf sed -i &quot;s/#RateLimitBurst=.*/RateLimitBurst=10000/g&quot; &quot;${SDCARD}&quot;/etc/systemd/journald.conf # Chrony temporal fix https://bugs.launchpad.net/ubuntu/+source/chrony/+bug/1878005 sed -i '/DAEMON_OPTS=/s/&quot;-F -1&quot;/&quot;-F 0&quot;/' &quot;${SDCARD}&quot;/etc/default/chrony # disable conflicting services chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl --no-reload mask ondemand.service &gt;/dev/null 2&gt;&amp;1&quot; ;; esac # use list modules INITRAMFS if [ -f &quot;${EXTER}&quot;/config/modules/&quot;${MODULES_INITRD}&quot; ]; then display_alert &quot;Use file list modules INITRAMFS&quot; &quot;${MODULES_INITRD}&quot; sed -i &quot;s/^MODULES=.*/MODULES=list/&quot; &quot;${SDCARD}&quot;/etc/initramfs-tools/initramfs.conf cat &quot;${EXTER}&quot;/config/modules/&quot;${MODULES_INITRD}&quot; &gt;&gt; &quot;${SDCARD}&quot;/etc/initramfs-tools/modules fi}post_debootstrap_tweaks(){ # remove service start blockers and QEMU binary rm -f &quot;${SDCARD}&quot;/sbin/initctl &quot;${SDCARD}&quot;/sbin/start-stop-daemon chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;dpkg-divert --quiet --local --rename --remove /sbin/initctl&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;dpkg-divert --quiet --local --rename --remove /sbin/start-stop-daemon&quot; rm -f &quot;${SDCARD}&quot;/usr/sbin/policy-rc.d &quot;${SDCARD}/usr/bin/${QEMU_BINARY}&quot; call_extension_method &quot;post_post_debootstrap_tweaks&quot; &quot;config_post_debootstrap_tweaks&quot; &lt;&lt; 'POST_POST_DEBOOTSTRAP_TWEAKS'*run after removing diversions and qemu with chroot unmounted*Last chance to touch the `${SDCARD}` filesystem before it is copied to the final media.It is too late to run any chrooted commands, since the supporting filesystems are already unmounted.POST_POST_DEBOOTSTRAP_TWEAKS}on_chroot(){ if [ &quot;$SETFCAP&quot; != &quot;1&quot; ]; then export CAPSH_ARG=&quot;--drop=cap_setfcap&quot; fi capsh $CAPSH_ARG &quot;--chroot=${ROOTFS_DIR}/&quot; -- -e &quot;$@&quot;}export -f on_chroot# shellcheck disable=SC2119run_sub_stage(){ log &quot;Begin ${SUB_STAGE_DIR}&quot; #pushd &quot;${SUB_STAGE_DIR}&quot; &gt; /dev/null cd ${SUB_STAGE_DIR} for i in {00..99}; do if [ -f &quot;${SUB_STAGE_DIR}/${i}-debconf&quot; ]; then display_alert &quot;Begin ${SUB_STAGE_DIR}/${i}-debconf&quot; &quot;&quot; &quot;info&quot; on_chroot &lt;&lt; EOFdebconf-set-selections &lt;&lt;SELEOF$(cat &quot;${i}-debconf&quot;)SELEOFEOF display_alert &quot;End ${SUB_STAGE_DIR}/${i}-debconf&quot; &quot;&quot; &quot;info&quot; fi if [ -f &quot;${SUB_STAGE_DIR}/${i}-packages-nr&quot; ]; then display_alert &quot;Begin ${SUB_STAGE_DIR}/${i}-packages-nr&quot; &quot;&quot; &quot;info&quot; PACKAGES=&quot;$(sed -f &quot;${EXTER}/packages/raspi/scripts/remove-comments.sed&quot; &lt; &quot;${SUB_STAGE_DIR}/${i}-packages-nr&quot;)&quot; if [ -n &quot;$PACKAGES&quot; ]; then on_chroot &lt;&lt; EOFapt-get -o Acquire::Retries=3 install --no-install-recommends -y $PACKAGESEOF fi display_alert &quot;End ${SUB_STAGE_DIR}/${i}-packages-nr&quot; &quot;&quot; &quot;info&quot; fi if [ -f &quot;${SUB_STAGE_DIR}/${i}-packages&quot; ]; then display_alert &quot;Begin ${SUB_STAGE_DIR}/${i}-packages&quot; &quot;&quot; &quot;info&quot; PACKAGES=&quot;$(sed -f &quot;${EXTER}/packages/raspi/scripts/remove-comments.sed&quot; &lt; &quot;${SUB_STAGE_DIR}/${i}-packages&quot;)&quot; if [ -n &quot;$PACKAGES&quot; ]; then on_chroot &lt;&lt; EOFapt-get -o Acquire::Retries=3 install -y $PACKAGESEOF fi display_alert &quot;End ${SUB_STAGE_DIR}/${i}-packages&quot; &quot;&quot; &quot;info&quot; fi# if [ -d &quot;${SUB_STAGE_DIR}/${i}-patches&quot; ]; then# log &quot;Begin ${SUB_STAGE_DIR}/${i}-patches&quot;# pushd &quot;${STAGE_WORK_DIR}&quot; &gt; /dev/null# #cd ${STAGE_WORK_DIR}## QUILT_PATCHES=&quot;${SUB_STAGE_DIR}/${i}-patches&quot;# SUB_STAGE_QUILT_PATCH_DIR=&quot;$(basename &quot;$SUB_STAGE_DIR&quot;)-pc&quot;# mkdir -p &quot;$STAGE_WORK_DIR/$SUB_STAGE_QUILT_PATCH_DIR&quot;# ln -snf &quot;$STAGE_WORK_DIR/$SUB_STAGE_QUILT_PATCH_DIR&quot; .pc# ln -snfv &quot;${ROOTFS_DIR}&quot; ${STAGE_WORK_DIR}/rootfs# quilt upgrade# if [ -e &quot;${SUB_STAGE_DIR}/${i}-patches/EDIT&quot; ]; then# echo &quot;Dropping into bash to edit patches...&quot;# bash# fi# RC=0# quilt push -a || RC=$?# case &quot;$RC&quot; in# 0|2)# ;;# *)# false# ;;# esac# #popd &gt; /dev/null# cd -# log &quot;End ${SUB_STAGE_DIR}/${i}-patches&quot;# fi if [ -x ${i}-run.sh ]; then display_alert &quot;Begin ${SUB_STAGE_DIR}/${i}-run.sh&quot; &quot;&quot; &quot;info&quot; ./${i}-run.sh display_alert &quot;End ${SUB_STAGE_DIR}/${i}-run.sh&quot; &quot;&quot; &quot;info&quot; fi if [ -f ${i}-run-chroot.sh ]; then display_alert &quot;Begin ${SUB_STAGE_DIR}/${i}-run-chroot.sh&quot; &quot;&quot; &quot;info&quot; on_chroot &lt; ${i}-run-chroot.sh display_alert &quot;End ${SUB_STAGE_DIR}/${i}-run-chroot.sh&quot; &quot;&quot; &quot;info&quot; fi done #popd &gt; /dev/null log &quot;End ${SUB_STAGE_DIR}&quot;}run_stage(){ rm -rf &quot;${SRC}&quot;/output/raspi [[ ! -d &quot;${SRC}&quot;/output/raspi ]] &amp;&amp; mkdir -p &quot;${SRC}&quot;/output/raspi STAGE_WORK_DIR=&quot;${SRC}/output/raspi&quot; if [ ! -f ${STAGE_DIR}/SKIP ]; then if [ -x ${STAGE_DIR}/prerun.sh ]; then display_alert &quot;Begin ${STAGE_DIR}/prerun.sh&quot; &quot;&quot; &quot;info&quot; source ${STAGE_DIR}/prerun.sh display_alert &quot;End ${STAGE_DIR}/prerun.sh&quot; &quot;&quot; &quot;info&quot; fi for SUB_STAGE_DIR in &quot;${STAGE_DIR}&quot;/*; do if [ -d &quot;${SUB_STAGE_DIR}&quot; ] &amp;&amp; [ ! -f &quot;${SUB_STAGE_DIR}/SKIP&quot; ]; then run_sub_stage fi done fi}log (){ date +&quot;[%T] $*&quot;}install_opi_specific(){ cd $SRC # install u-boot UBOOT_VER=$(dpkg --info &quot;${InstallingDEB_STORAGE}/u-boot/${CHOSEN_UBOOT}_${REVISION}_${ARCH}.deb&quot; | grep Descr | awk '{print $(NF)}') install_deb_chroot &quot;${DEB_STORAGE}/u-boot/${CHOSEN_UBOOT}_${REVISION}_${ARCH}.deb&quot; # install kernel VER=$(dpkg --info &quot;${DEB_STORAGE}/${CHOSEN_KERNEL}_${REVISION}_${ARCH}.deb&quot; | awk -F&quot;-&quot; '/Source:/{print $2}') install_deb_chroot &quot;${DEB_STORAGE}/${CHOSEN_KERNEL}_${REVISION}_${ARCH}.deb&quot; if [[ -f ${DEB_STORAGE}/${CHOSEN_KERNEL/image/dtb}_${REVISION}_${ARCH}.deb ]]; then install_deb_chroot &quot;${DEB_STORAGE}/${CHOSEN_KERNEL/image/dtb}_${REVISION}_${ARCH}.deb&quot; fi if [[ $INSTALL_HEADERS == yes ]]; then install_deb_chroot &quot;${DEB_STORAGE}/${CHOSEN_KERNEL/image/headers}_${REVISION}_${ARCH}.deb&quot; else cp &quot;${DEB_STORAGE}/${CHOSEN_KERNEL/image/headers}_${REVISION}_${ARCH}.deb&quot; &quot;${SDCARD}&quot;/opt/ fi dpkg_install_deb_chroot &quot;$EXTER/packages/raspi/orangepi/debs/raspi-config_20230214_all.deb&quot; case ${BOARDFAMILY} in &quot;rockchip-rk356x&quot;) rk356x_gpu_vpu_tweaks_for_raspios esac [[ ! -d &quot;${SDCARD}/lib/firmware&quot; ]] &amp;&amp; mkdir -p &quot;${SDCARD}/lib/firmware&quot; cp -rfa ${EXTER}/cache/sources/orangepi-firmware-git/* ${SDCARD}/lib/firmware/ # NOTE: this needs to be executed before family_tweaks local bootscript_src=${BOOTSCRIPT%%:*} local bootscript_dst=${BOOTSCRIPT##*:} if [[ &quot;${BOOTCONFIG}&quot; != &quot;none&quot; ]]; then if [ -f &quot;${USERPATCHES_PATH}/bootscripts/${bootscript_src}&quot; ]; then cp &quot;${USERPATCHES_PATH}/bootscripts/${bootscript_src}&quot; &quot;${SDCARD}/boot/${bootscript_dst}&quot; else cp &quot;${EXTER}/config/bootscripts/${bootscript_src}&quot; &quot;${SDCARD}/boot/${bootscript_dst}&quot; fi fi if [[ -n $BOOTENV_FILE ]]; then if [[ -f $USERPATCHES_PATH/bootenv/$BOOTENV_FILE ]]; then cp &quot;$USERPATCHES_PATH/bootenv/${BOOTENV_FILE}&quot; &quot;${SDCARD}&quot;/boot/orangepiEnv.txt elif [[ -f $EXTER/config/bootenv/$BOOTENV_FILE ]]; then cp &quot;${EXTER}/config/bootenv/${BOOTENV_FILE}&quot; &quot;${SDCARD}&quot;/boot/orangepiEnv.txt fi fi [[ -n $OVERLAY_PREFIX &amp;&amp; -f &quot;${SDCARD}&quot;/boot/orangepiEnv.txt &amp;&amp; ($BRANCH =~ current|next || $BOARDFAMILY =~ &quot;rockchip-rk3588&quot;|&quot;rockchip-rk356x&quot;) ]] &amp;&amp; \\ echo &quot;overlay_prefix=$OVERLAY_PREFIX&quot; &gt;&gt; &quot;${SDCARD}&quot;/boot/orangepiEnv.txt [[ -n $DEFAULT_OVERLAYS &amp;&amp; -f &quot;${SDCARD}&quot;/boot/orangepiEnv.txt &amp;&amp; ($BRANCH =~ current|next || $BOARDFAMILY =~ &quot;rockchip-rk3588&quot;|&quot;rockchip-rk356x&quot;) ]] &amp;&amp; \\ echo &quot;overlays=${DEFAULT_OVERLAYS//,/ }&quot; &gt;&gt; &quot;${SDCARD}&quot;/boot/orangepiEnv.txt [[ -n $BOOT_FDT_FILE &amp;&amp; -f &quot;${SDCARD}&quot;/boot/orangepiEnv.txt ]] &amp;&amp; \\ echo &quot;fdtfile=${BOOT_FDT_FILE}&quot; &gt;&gt; &quot;${SDCARD}/boot/orangepiEnv.txt&quot; # install initial asound.state if defined mkdir -p &quot;${SDCARD}&quot;/var/lib/alsa/ [[ -n $ASOUND_STATE ]] &amp;&amp; cp &quot;${EXTER}/packages/blobs/asound.state/${ASOUND_STATE}&quot; &quot;${SDCARD}&quot;/var/lib/alsa/asound.state # create modules file local modules=MODULES_${BRANCH^^} if [[ -n &quot;${!modules}&quot; ]]; then tr ' ' '\\n' &lt;&lt;&lt; &quot;${!modules}&quot; &gt; &quot;${SDCARD}&quot;/etc/modules elif [[ -n &quot;${MODULES}&quot; ]]; then tr ' ' '\\n' &lt;&lt;&lt; &quot;${MODULES}&quot; &gt; &quot;${SDCARD}&quot;/etc/modules fi # create blacklist files local blacklist=MODULES_BLACKLIST_${BRANCH^^} if [[ -n &quot;${!blacklist}&quot; ]]; then tr ' ' '\\n' &lt;&lt;&lt; &quot;${!blacklist}&quot; | sed -e 's/^/blacklist /' &gt; &quot;${SDCARD}/etc/modprobe.d/blacklist-${BOARD}.conf&quot; elif [[ -n &quot;${MODULES_BLACKLIST}&quot; ]]; then tr ' ' '\\n' &lt;&lt;&lt; &quot;${MODULES_BLACKLIST}&quot; | sed -e 's/^/blacklist /' &gt; &quot;${SDCARD}/etc/modprobe.d/blacklist-${BOARD}.conf&quot; fi cat &lt;&lt;-EOF &gt; &quot;${SDCARD}&quot;/etc/orangepi-release # PLEASE DO NOT EDIT THIS FILE BOARD=${BOARD} BOARD_NAME=&quot;$BOARD_NAME&quot; BOARDFAMILY=${BOARDFAMILY} BUILD_REPOSITORY_URL=${BUILD_REPOSITORY_URL} BUILD_REPOSITORY_COMMIT=${BUILD_REPOSITORY_COMMIT} DISTRIBUTION_CODENAME=${RELEASE} DISTRIBUTION_STATUS=${DISTRIBUTION_STATUS} VERSION=${REVISION} LINUXFAMILY=${LINUXFAMILY} ARCH=${ARCHITECTURE} IMAGE_TYPE=$IMAGE_TYPE BOARD_TYPE=$BOARD_TYPE INITRD_ARCH=${INITRD_ARCH} KERNEL_IMAGE_TYPE=${KERNEL_IMAGE_TYPE} BRANCH=${BRANCH} EOF install -d &quot;${SDCARD}/etc/initramfs/post-update.d/&quot; install -m 755 &quot;${EXTER}/packages/bsp/common/etc/initramfs/post-update.d/99-uboot&quot; &quot;${SDCARD}/etc/initramfs/post-update.d/&quot; install -m 755 &quot;${EXTER}/packages/raspi/orangepi/common/files/hciattach_opi&quot; &quot;${SDCARD}/usr/bin/&quot; install -m 755 &quot;${EXTER}/packages/raspi/orangepi/common/files/brcm_patchram_plus&quot; &quot;${SDCARD}/usr/bin/&quot; install -d &quot;${SDCARD}/usr/lib/orangepi/&quot; install -m 755 &quot;${EXTER}/packages/raspi/orangepi/common/files/orangepi-hardware-optimization&quot; &quot;${SDCARD}/usr/lib/orangepi/&quot; install -m 755 &quot;${EXTER}/packages/raspi/orangepi/common/files/orangepi-hardware-optimize.service&quot; &quot;${SDCARD}/usr/lib/systemd/system/&quot; chroot &quot;${SDCARD}&quot; /bin/bash -c &quot;systemctl --no-reload enable orangepi-hardware-optimize.service &gt;/dev/null 2&gt;&amp;1&quot; install_wiringop rm $SDCARD/root/*.deb &gt;/dev/null 2&gt;&amp;1}install_raspi_specific(){ export TARGET_HOSTNAME=${TARGET_HOSTNAME:-raspberrypi} export FIRST_USER_NAME=${FIRST_USER_NAME:-pi} export FIRST_USER_PASS export DISABLE_FIRST_BOOT_USER_RENAME=${DISABLE_FIRST_BOOT_USER_RENAME:-0} export WPA_ESSID export WPA_PASSWORD export WPA_COUNTRY export ENABLE_SSH=&quot;${ENABLE_SSH:-0}&quot; export PUBKEY_ONLY_SSH=&quot;${PUBKEY_ONLY_SSH:-0}&quot; export LOCALE_DEFAULT=&quot;${LOCALE_DEFAULT:-en_GB.UTF-8}&quot; export KEYBOARD_KEYMAP=&quot;${KEYBOARD_KEYMAP:-gb}&quot; export KEYBOARD_LAYOUT=&quot;${KEYBOARD_LAYOUT:-English (UK)}&quot; export TIMEZONE_DEFAULT=&quot;${TIMEZONE_DEFAULT:-Europe/London}&quot; export PUBKEY_SSH_FIRST_USER export APT_PROXY export STAGE export STAGE_DIR export STAGE_WORK_DIR export PREV_STAGE export PREV_STAGE_DIR export ROOTFS_DIR=${SDCARD} export PREV_ROOTFS_DIR export IMG_SUFFIX export NOOBS_NAME export NOOBS_DESCRIPTION export EXPORT_DIR export EXPORT_ROOTFS_DIR export QUILT_PATCHES export QUILT_NO_DIFF_INDEX=1 export QUILT_NO_DIFF_TIMESTAMPS=1 export QUILT_REFRESH_ARGS=&quot;-p ab&quot; #check username is valid if [[ ! &quot;$FIRST_USER_NAME&quot; =~ ^[a-z][-a-z0-9_]*$ ]]; then echo &quot;Invalid FIRST_USER_NAME: $FIRST_USER_NAME&quot; exit 1 fi if [[ &quot;$DISABLE_FIRST_BOOT_USER_RENAME&quot; == &quot;1&quot; ]] &amp;&amp; [ -z &quot;${FIRST_USER_PASS}&quot; ]; then echo &quot;To disable user rename on first boot, FIRST_USER_PASS needs to be set&quot; echo &quot;Not setting FIRST_USER_PASS makes your system vulnerable and open to cyberattacks&quot; exit 1 fi if [[ &quot;$DISABLE_FIRST_BOOT_USER_RENAME&quot; == &quot;1&quot; ]]; then echo &quot;User rename on the first boot is disabled&quot; echo &quot;Be advised of the security risks linked to shipping a device with default username/password set.&quot; fi if [[ -n &quot;${APT_PROXY}&quot; ]] &amp;&amp; ! curl --silent &quot;${APT_PROXY}&quot; &gt;/dev/null ; then echo &quot;Could not reach APT_PROXY server: ${APT_PROXY}&quot; exit 1 fi if [[ -n &quot;${WPA_PASSWORD}&quot; &amp;&amp; ${#WPA_PASSWORD} -lt 8 || ${#WPA_PASSWORD} -gt 63 ]] ; then echo &quot;WPA_PASSWORD&quot; must be between 8 and 63 characters exit 1 fi if [[ &quot;${PUBKEY_ONLY_SSH}&quot; = &quot;1&quot; &amp;&amp; -z &quot;${PUBKEY_SSH_FIRST_USER}&quot; ]]; then echo &quot;Must set 'PUBKEY_SSH_FIRST_USER' to a valid SSH public key if using PUBKEY_ONLY_SSH&quot; exit 1 fi RASPI_DIR=&quot;${EXTER}/packages/raspi&quot; if [[ ${BUILD_DESKTOP} == &quot;yes&quot; ]]; then rm -r ${RASPI_DIR}/stage3/SKIP ${RASPI_DIR}/stage4/SKIP ${RASPI_DIR}/stage5/SKIP 2&gt;/dev/null touch ${RASPI_DIR}/stage5/SKIP else rm -r ${RASPI_DIR}/stage1/SKIP ${RASPI_DIR}/stage2/SKIP 2&gt;/dev/null touch ${RASPI_DIR}/stage3/SKIP ${RASPI_DIR}/stage4/SKIP ${RASPI_DIR}/stage5/SKIP export FIRST_USER_PASS=&quot;pi&quot; fi STAGE_LIST=${RASPI_DIR}/stage* for STAGE_DIR in $STAGE_LIST; do STAGE_DIR=$(realpath &quot;${STAGE_DIR}&quot;) run_stage done STAGE_DIR=${RASPI_DIR}/export-image run_stage rm -rf ${SDCARD}/boot/* rm -rf ${SDCARD}/lib/firmware rm -rf ${SDCARD}/lib/modules/*} 7 整理的包123456789101112131415161718192021222324252627282930313233343536373839404142camera-engine-rkaiq_arm64.deblibrga2_2.2.0-1_arm64.deblibrga-dev_2.2.0-1_arm64.deblibrockchip-mpp1_1.5.0-1_arm64.deblibrockchip-mpp-dev_1.5.0-1_arm64.deblibrockchip-vpu0_1.5.0-1_arm64.debrockchip-mpp-demos_1.5.0-1_arm64.deblibmali-valhall-g610-g6p0-x11_1.9-1_arm64.debgstreamer1.0-rockchip1_1.14-4_arm64.deblibgstreamer1.0-0_1.16.3-0ubuntu1.1_arm64.deblibgstreamer1.0-dev_1.16.3-0ubuntu1.1_arm64.debgir1.2-gstreamer-1.0_1.16.3-0ubuntu1.1_arm64.debgstreamer1.0-tools_1.16.3-0ubuntu1.1_arm64.deblibgstreamer-gl1.0-0_1.16.3-0ubuntu1.1_arm64.debgir1.2-gst-plugins-base-1.0_1.16.3-0ubuntu1.1_arm64.debgstreamer1.0-alsa_1.16.3-0ubuntu1.1_arm64.debgstreamer1.0-plugins-base_1.16.3-0ubuntu1.1_arm64.debgstreamer1.0-plugins-base-apps_1.16.3-0ubuntu1.1_arm64.debgstreamer1.0-x_1.16.3-0ubuntu1.1_arm64.debgstreamer1.0-gl_1.16.3-0ubuntu1.1_arm64.deblibgstreamer-plugins-base1.0-0_1.16.3-0ubuntu1.1_arm64.deblibgstreamer-plugins-base1.0-dev_1.16.3-0ubuntu1.1_arm64.debgstreamer1.0-plugins-good_1.16.3-0ubuntu1.1_arm64.debgstreamer1.0-pulseaudio_1.16.3-0ubuntu1.1_arm64.debgstreamer1.0-gtk3_1.16.3-0ubuntu1.1_arm64.debgstreamer1.0-qt5_1.16.3-0ubuntu1.1_arm64.deblibgstreamer-plugins-good1.0-0_1.16.3-0ubuntu1.1_arm64.deblibgstreamer-plugins-good1.0-dev_1.16.3-0ubuntu1.1_arm64.deblibdvbv5-0_1.18.0-2build1_arm64.debdvb-tools_1.18.0-2build1_arm64.debir-keytable_1.18.0-2build1_arm64.deblibdvbv5-dev_1.18.0-2build1_arm64.deblibdvbv5-doc_1.18.0-2build1_all.deblibv4l-0_1.18.0-2build1_arm64.deblibv4l2rds0_1.18.0-2build1_arm64.deblibv4lconvert0_1.18.0-2build1_arm64.deblibv4l-dev_1.18.0-2build1_arm64.deblibv4l-rkmpp_1.4.0-1_arm64.debv4l-utils_1.18.0-2build1_arm64.debqv4l2_1.18.0-2build1_arm64.debxserver-xorg-core_1.20.13-1ubuntu1~20.04.2_arm64.debchromium-x11_91.0.4472.164_arm64.deb","link":"/2023/12/02/16-%E9%A6%99%E6%A9%99%E6%B4%BE%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E8%84%9A%E6%9C%AC%E5%88%86%E6%9E%90/"},{"title":"ubuntu和debian文件系统构建详解","text":"第7章 Ubuntu和Debian系统构建在前面的几个章节中，我们利用了busybox，buildroot，yocto工具构建文件系统。我们也可以使用Linux发行版来直接作为文件系统，比如Ubuntu系统和Debian系统。由于Ubuntu和Debian系统的构建方法相同，所以作者将他们两个系统的构建放到了一起。 注意：必须要在ubuntu20等更高版本的系统上进行本章节的文件系统构建，经测试在ubutnu18上因为一些工具的版本问题，会出现很多意想不到的问题。 7.1 安装所需的工具使用如下命令安装所需的工具 1sudo apt-get install binfmt-support qemu qemu-user-static debootstrap binfmt-support：提供了对二进制格式解释器的支持。允许在Linux系统中执行非本机二进制文件，例如在ARM架构上运行x86二进制文件。它为Linux内核添加了解释器注册表和执行文件的解析逻辑。 qemu：是一个开源的硬件虚拟化和仿真软件，允许在一个平台上模拟另一个平台的运行。它支持多种体系结构和硬件设备，并可以用于开发和测试操作系统、应用程序等。 qemu-user-static：这是QEMU的用户态静态二进制文件。允许在主机平台上运行不同体系结构的可执行文件，而无需运行完整的虚拟机。这对于交叉编译和在本地主机上模拟其他体系结构的应用程序非常有用。 debootstrap：用于在Linux系统中创建基于Debian的最小文件系统的工具。可以帮助你从零开始构建一个基本的和Ubuntu和Debian系统，并可以用于创建chroot环境或构建自定义的Linux发行版。 7.2根文件系统制作首先来学习一下debootstrap命令的基本语法： 1debootstrap arch &lt;架构&gt; &lt;发行版&gt; &lt;目标目录&gt; [镜像地址] –arch &lt;架构&gt;：指定目标系统的架构，例如 amd64、armhf、arm64 等。根据目标系统的架构选择合适的值。 &lt;发行版&gt;：指定要创建的Debian发行版，流行系统的版本号如下所示： （1）Ubuntu 20.04：focal （2）Ubuntu 22.04：jammy （3）Debian 10： buster （4）Debian 11：bullseye &lt;目标目录&gt;：指定要创建的目标文件系统的目录路径。所有的Debian软件包和配置文件将安装到该目录中。 [镜像地址]（可选）：指定用于下载Ubuntu和Debian软件包的镜像地址。如果不提供镜像地址，将使用默认的镜像地址进行下载,这里建议选择国内源，例如华为源、阿里源等。 注意：debootstrap 命令的使用需要在root用户下。 首先创建一个镜像存放的目录，这里作者起名为binary，大家随意即可，创建完成如下图所示： 然后使用以下命令制作根文件系统，每个系统的制作命令都已经列了出来：（1）Ubuntu 20.04：focal 12345arch=arm64release=focalchroot_dir=binarymirror=https://mirrors.huaweicloud.com/repository/ubuntu-ports/debootstrap --arch ${arch} ${release} ${chroot_dir} ${mirror} （2）Ubuntu 22.04：jammy 12345arch=arm64release=jammychroot_dir=binarymirror=https://mirrors.huaweicloud.com/repository/ubuntu-ports/sudo debootstrap --arch ${arch} ${release} ${chroot_dir} ${mirror} （3）Debian 10： buster 12345arch=arm64release=busterchroot_dir=mirror=https://mirrors.huaweicloud.com/repository/debian/debootstrap --arch ${arch} ${release} ${chroot_dir} ${mirror} （4）Debian 11：bullseye 12345arch=arm64release=bullseyechroot_dir=binarymirror=https://mirrors.huaweicloud.com/repository/debian/debootstrap --arch ${arch} ${release} ${chroot_dir} ${mirror} 这里作者以ubuntu20为例进行演示，命令输入之后会开始文件系统的构建，构建构成如下所示： 然后等待构建完成，构建完成之后如下图所示： 可以看到Linux的一些基本目录就都已经生成了。 7.3挂载根文件系统在构建Ubuntu和Debian文件系统时，需要将主机的/proc、/sys/、dev/、dev/pts这些虚拟文件系统挂载到要构建的系统中通过挂载这些临时文件系统，构建文件系统的过程中的命令可以正常访问和操作系统的进程、内核、硬件以及临时文件和进程。这些挂载操作为构建过程提供了必要的运行环境和资源。 挂载操作这里通过mount.sh脚本来完成，该脚本的具体内容如下所示： 12345678910111213141516171819202122232425262728293031323334#!/bin/bashmnt() { echo &quot;MOUNTING&quot; sudo mount -t proc /proc ${2}proc sudo mount -t sysfs /sys ${2}sys sudo mount -o bind /dev ${2}dev sudo mount -o bind /dev/pts ${2}dev/pts}umnt() { echo &quot;UNMOUNTING&quot; sudo umount ${2}proc sudo umount ${2}sys sudo umount ${2}dev/pts sudo umount ${2}dev}if [ &quot;$1&quot; == &quot;-m&quot; ] &amp;&amp; [ -n &quot;$2&quot; ] ;then mnt $1 $2elif [ &quot;$1&quot; == &quot;-u&quot; ] &amp;&amp; [ -n &quot;$2&quot; ];then umnt $1 $2else echo &quot;&quot; echo &quot;Either 1'st, 2'nd or both parameters were missing&quot; echo &quot;&quot; echo &quot;1'st parameter can be one of these: -m(mount) OR -u(umount)&quot; echo &quot;2'nd parameter is the full path of rootfs directory(with trailing '/')&quot; echo &quot;&quot; echo &quot;For example: ch-mount -m /media/sdcard/&quot; echo &quot;&quot; echo 1st parameter : ${1} echo 2nd parameter : ${2}fi 创建该文件，添加相应的内容并赋予可执行权限，具体操作如下图所示： 该脚本既可以用来挂载，也可以用来解除挂载，挂载的命令如下所示： 1./mount.sh -m binary/ 挂载成功之后使用以下命令改变根目录，将根目录修改为刚刚创建好的文件系统中，如下图所示： 1chroot binary/ 接下来就可以进入下一个小节，开始文件系统的定制了。 7.4 定制根文件系统7.4.1 apt换源由于构建出系统的软件源在国外，因为网络问题而不稳定导致下载速度缓慢，所以这里先将默认源更换为国内源。 Ubuntu和Debian系统的软件源文件为“/etc/apt/sources.list”，而不同的文件系统他们的软件源也各不相同，所以这里罗列了不同系统的国内软件源，如下所示：（1）Ubuntu 20.04：focal 12345678deb https://mirrors.ustc.edu.cn/ubuntu-ports/ focal main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu-ports/ focal main main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu-ports/ focal-updates main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu-ports/ focal-updates main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu-ports/ focal-backports main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu-ports/ focal-backports main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu-ports/ focal-security main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu-ports/ focal-security main restricted universe multiverse （2）Ubuntu 22.04：jammy 12345678deb https://mirrors.huaweicloud.com/repository/ubuntu-ports/ jammy main restricted universe multiversedeb-src https://mirrors.huaweicloud.com/repository/ubuntu-ports/ jammy main restricted universe multiversedeb https://mirrors.huaweicloud.com/repository/ubuntu-ports/ jammy-updates main restricted universe multiversedeb-src https://mirrors.huaweicloud.com/repository/ubuntu-ports/ jammy-updates main restricted universe multiversedeb https://mirrors.huaweicloud.com/repository/ubuntu-ports/ jammy-backports main restricted universe multiversedeb-src https://mirrors.huaweicloud.com/repository/ubuntu-ports/ jammy-backports main restricted universe multiversedeb https://mirrors.huaweicloud.com/repository/ubuntu-ports/ jammy-security main restricted universe multiversedeb-src https://mirrors.huaweicloud.com/repository/ubuntu-ports/ jammy-security main restricted universe multiverse （3）Debian 10： buster 12345678deb https://mirrors.huaweicloud.com/repository/debian/ buster main contrib non-freedeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster main contrib non-freedeb https://mirrors.huaweicloud.com/repository/debian/ buster-updates main contrib non-freedeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-updates main contrib non-freedeb https://mirrors.huaweicloud.com/repository/debian/ buster-backports main contrib non-freedeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-backports main contrib non-freedeb https://mirrors.huaweicloud.com/repository/debian-security buster/updates main contrib non-freedeb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security buster/updates main contrib non-free （4）Debian 11：bullseye 12345678deb https://mirrors.huaweicloud.com/debian/ bullseye main non-free contribdeb-src https://mirrors.huaweicloud.com/debian/ bullseye main non-free contribdeb https://mirrors.huaweicloud.com/debian-security/ bullseye-security maindeb-src https://mirrors.huaweicloud.com/debian-security/ bullseye-security maindeb https://mirrors.huaweicloud.com/debian/ bullseye-updates main non-free contribdeb-src https://mirrors.huaweicloud.com/debian/ bullseye-updates main non-free contribdeb https://mirrors.huaweicloud.com/debian/ bullseye-backports main non-free contribdeb-src https://mirrors.huaweicloud.com/debian/ bullseye-backports main non-free contrib 然后使用vim命令修改/etc/apt/sources.list为上面提供的国内源，修改完成如下所示： 1vi /etc/apt/sources.list 然后使用以下命令进行软件源的更新，更新过程如下图所示： 1apt update 等待更新完成即可。默认的dns源在烧写到开发板之后可能也无法正常解析域名，所以需要使用以下命令更换镜像的dns源，如下图所示： 123rm -rf /etc/resolv.confecho &quot;nameserver 8.8.8.8&quot; &gt; /etc/resolv.confecho &quot;nameserver 114.114.114.114&quot; &gt;&gt; /etc/resolv.conf 7.4.2安装常用工具然后使用以下命令安装必备的软件包，安装过程如下所示： 12345678apt-get -y install dmidecode mtd-utils i2c-tools u-boot-tools \\bash-completion man-db manpages nano gnupg initramfs-tools sudo \\dosfstools mtools parted ntfs-3g zip atop \\p7zip-full htop iotop pciutils lshw lsof exfat-fuse hwinfo \\net-tools wireless-tools openssh-client openssh-server wpasupplicant ifupdown \\pigz wget curl lm-sensors bluez gdisk usb-modeswitch usb-modeswitch-data make \\gcc libc6-dev bison libssl-dev flex fake-hwclock rfkill wireless-regdb toilet cmake locales \\openssh-server openssh-client network-manager fonts-wqy-zenhei xfonts-intl-chinese alsa-utils vim blueman 等待安装完成即可，每个安装包的具体作用如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445dmidecode：用于获取系统的DMI（Desktop Management Interface）信息，包括硬件设备、BIOS和固件等。mtd-utils：提供对嵌入式闪存设备（MTD）的管理和操作工具，用于读取、擦除和编程闪存芯片。i2c-tools：用于配置和调试I2C总线设备的工具集。u-boot-tools：提供与U-Boot引导加载程序相关的工具，用于配置和管理嵌入式系统的引导过程。bash-completion：为Bash shell提供自动补全功能，可以快速补全命令、选项和文件名。man-db和manpages：man-db是一个用于管理和浏览man页面（Linux帮助文档）的工具，manpages则是包含常见命令和函数的man页面集合。nano：一个简单易用的文本编辑器，适用于终端环境。gnupg：GNU隐私保护工具，用于加密、签名和认证数据和通信。initramfs-tools：用于创建和管理初始内存文件系统（initramfs），通常用于启动Linux系统前的初始化过程。sudo：允许普通用户以超级用户（root）权限执行命令的工具。dosfstools：用于创建、检查和维护DOS/Windows文件系统（FAT）的工具集。mtools：用于在Linux系统上管理DOS/Windows文件系统（FAT）的工具。parted：磁盘分区工具，用于创建、调整和管理磁盘分区。ntfs-3g：用于在Linux系统上读写NTFS文件系统的驱动程序。zip和p7zip-full：用于创建和提取ZIP和7z等压缩文件的工具。htop和iotop：用于监视系统资源使用情况的命令行工具，分别监视进程和磁盘I/O的情况。pciutils：用于查询和配置PCI总线设备的工具。lshw：显示系统硬件信息的工具。lsof：列出打开的文件和进程的工具。exfat-fuse：用于在Linux系统上访问exFAT文件系统的驱动程序。hwinfo：用于获取和显示硬件信息的工具。net-tools：包含一些基本的网络工具，如ifconfig和netstat。wireless-tools：用于配置和管理无线网络接口的工具。openssh-client和openssh-server：提供SSH客户端和服务器，用于远程安全登录和文件传输。wpasupplicant：用于配置和连接无线网络的工具。ifupdown：用于配置和管理网络接口的工具。pigz：并行压缩/解压缩工具，用于加快压缩速度。wget和curl：用于从网络上下载文件的命令行工具。lm-sensors：用于监测硬件传感器（如温度、风扇速度）的工具。bluez：提供蓝牙协议栈的工具和库。gdisk：用于创建和管理GUID分区表（GPT）的工具。usb-modeswitch和usb-modeswitch-data：用于在Linux系统上切换和配置USB移动宽带设备的工具和数据。make和gcc：编译和构建软件的工具和编译器。libc6-dev：C语言标准库的开发文件，用于编译和链接C语言程序。bison和flex：用于生成词法分析器和语法分析器的生成工具。fake-hwclock：用于在系统没有硬件时钟的情况下，模拟保存和恢复时间的工具。rfkill：用于管理射频设备的软件屏蔽开关状态的工具。wireless-regdb：无线电设备的法规数据库，用于配置无线电频率和功率限制。toilet：用于在终端中生成彩色的ASCII艺术字的工具。cmake：一个跨平台的开源构建工具，用于管理软件项目的构建过程。locales：用于配置系统的本地化设置，包括语言、日期、时间等。network-manager：用于配置和管理网络连接的工具。fonts-wqy-zenhei和xfonts-intl-chinese：提供中文字体支持，用于显示中文字符。alsa-utils：用于配置和管理Advanced Linux Sound Architecture (ALSA)的工具。vim：一个功能强大的文本编辑器，适用于终端环境 7.4.3配置root密码输入“passwd root”命令，然后连续输入两次root 用户密码，如图所示： 7.4.4添加topeet用户然后输入以下命令添加名字为topeet的用户，并将topeet用户的登录密码设置为topeet，并授予该用户以管理员（root）权限执行所有命令，如下图所示： 123adduser topeet --gecos &quot;First Last,RoomNumber,WorkPhone,HomePhone&quot; --disabled-passwordecho &quot;topeet:topeet&quot; | chpasswdecho &quot;topeet ALL=(ALL:ALL) ALL&quot; &gt;&gt; /etc/sudoers 至此，topeet用户就创建完成了，如果想要修改创建的用户修改命令中的topeet即可。 7.4.5配置主机名接下来使用如下命令设置主机名称和本机 IP： 1234export HOST=topeetecho $HOST &gt; /etc/hostnameecho &quot;127.0.0.1 localhost.localdomain localhost&quot; &gt;&gt; /etc/hostsecho &quot;127.0.0.1 $HOST&quot; &gt;&gt; /etc/hosts 7.4.6中文设置目前的终端交互仍旧使用的是英文，为了便于交互和查看打印信息，可以根据以下步骤修改为中文。 首先使用sed 工具修改 /etc/locale.gen 文件的内容，将以 zh_CN.UTF-8 开头的行中的注释符号 # 去除。 然后设置系统的默认语言环境为中文（中国），如下图所示： 12sed -i 's/^# *\\(zh_CN.UTF-8\\)/\\1/' /etc/locale.genecho &quot;LANG=zh_CN.UTF-8&quot; &gt;&gt; /etc/default/locale 然后使用以下命令生成 zh_CN.UTF-8 语言环境所需的配置文件，执行过程如下所示： 1locale-gen zh_CN.UTF-8 最后执行以下命令将LC_ALL 、LANG和LANGUAGE追加到root和topeet用户的环境变量中，如下图所示： 1234567echo &quot;export LC_ALL=zh_CN.UTF-8&quot; &gt;&gt; ~/.bashrcecho &quot;export LANG=zh_CN.UTF-8&quot; &gt;&gt; ~/.bashrcecho &quot;export LANGUAGE=zh_CN.UTF-8&quot; &gt;&gt; ~/.bashrcecho &quot;export LC_ALL=zh_CN.UTF-8&quot; &gt;&gt; /home/topeet/.bashrcecho &quot;export LANG=zh_CN.UTF-8&quot; &gt;&gt; /home/topeet/.bashrcecho &quot;export LANGUAGE=zh_CN.UTF-8&quot; &gt;&gt; /home/topeet/.bashrc 至此，中文环境就设置完成了，可以使用apt-get update命令来查看中文是否设置成功，设置成功如下所示： 可以看到打印信息已经设置为了中文。 7.4.7安装桌面上面只是对系统进行了一些基本设置，本小节将进行桌面系统的安装，在Linux的发行版中以GNOME、KDE、Xfce和LXQt的使用最为广泛，考虑到3568的性能这里选用Xfce桌面进行安装，如果想要安装其他桌面可以自行搜索其他桌面的安装命令。Xfce桌面及一些其他的配置软件安装命令如下所示： 1apt-get install -y xubuntu-core lightdm 在安装过程中可能要选择默认显示管理器，选择lightmd即可，如下图所示： 安装完成之后使用以下命令删除gdm3 ubuntu-session两个软件，如下图所示： 1apt-get remove -y gdm3 ubuntu-session 至此，关于桌面的安装就完成了。 7.4.8配置硬盘自动扩展为了尽可能的让烧写的镜像小，所以在构建烧写镜像的时候只是在原有的基础上扩大了300M（后面讲到），但系统烧写进去之后，会因为空间所以无法启动桌面环境等，所以硬盘自动扩展也是必不可少的一个步骤。 首先在usr/bin目录下创建一个名为disk-helper的文件，该文件内容如下所示： 12cd usr/binvim disk-helper 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449#!/bin/sh# Uncomment below to see more logs# set -xMISC_DEV=$(realpath /dev/block/by-name/misc 2&gt;/dev/null)BUSYBOX_MOUNT_OPTS=&quot;loop (a|)sync (no|)atime (no|)diratime (no|)relatime (no|)dev (no|)exec (no|)suid (r|)shared (r|)slave (r|)private (un|)bindable (r|)bind move remount ro&quot;NTFS_3G_MOUNT_OPTS=&quot;ro uid=[0-9]* gid=[0-9]* umask=[0-9]* fmask=[0-9]* dmask=[0-9]*&quot;check_tool(){ TOOL=$(echo $1 | grep -o &quot;^[^ ]*&quot;) BR2_CONFIG=$2 type $TOOL &gt;/dev/null &amp;&amp; return 0 if grep -wq &quot;ID=buildroot&quot; /etc/os-release 2&gt;/dev/null; then [ -n &quot;$BR2_CONFIG&quot; ] &amp;&amp; \\ echo &quot;You may need to enable $BR2_CONFIG&quot; else echo &quot;Missing tool: $TOOL&quot; fi return 1}prepare_ubi(){ # Only support ubi for mtd device if echo $DEV | grep -vq /dev/mtd; then echo &quot;$DEV is not a mtd device!&quot; return 1 fi [ &quot;$PART_NO&quot; ] || { echo &quot;No valid part number!&quot; &amp;&amp; return 1; } if [ &quot;$FSGROUP&quot; = ubifs ]; then DEV=/dev/ubi${PART_NO}_0 else DEV=/dev/ubiblock${PART_NO}_0 fi MTDDEV=/dev/mtd${PART_NO} echo &quot;Preparing $DEV from $MTDDEV&quot; echo &quot;Remove ubi block device&quot; if echo $DEV | grep -q ubiblock; then check_tool ubiblock BR2_PACKAGE_MTD_UBIBLOCK || return 1 ubiblock -r /dev/ubi${PART_NO}_0 &amp;&gt;/dev/null fi echo &quot;Detach ubi device&quot; check_tool ubidetach BR2_PACKAGE_MTD_UBIDETACH || return 1 ubidetach -p $MTDDEV &amp;&gt;/dev/null echo &quot;Attach ubi device&quot; check_tool ubiattach BR2_PACKAGE_MTD_UBIATTACH || return 1 ubiattach /dev/ubi_ctrl -m $PART_NO -d $PART_NO || return 1 echo &quot;Check for valid volume&quot; if [ ! -e /dev/ubi${PART_NO}_0 ]; then echo &quot;No valid ubi volume&quot; return 1 fi echo &quot;Create ubi block device&quot; if echo $DEV | grep -q ubiblock; then check_tool ubiblock BR2_PACKAGE_MTD_UBIBLOCK || return 1 ubiblock -c /dev/ubi${PART_NO}_0 || return 1 fi return 0}format_ubifs(){ echo &quot;Formatting $MTDDEV for $DEV&quot; echo &quot;Remove ubi block device&quot; if echo $DEV | grep -q ubiblock; then check_tool ubiblock BR2_PACKAGE_MTD_UBIBLOCK || return 1 ubiblock -r /dev/ubi${PART_NO}_0 &amp;&gt;/dev/null fi echo &quot;Detach ubi device&quot; check_tool ubidetach BR2_PACKAGE_MTD_UBIDETACH || return 1 ubidetach -p $MTDDEV &amp;&gt;/dev/null echo &quot;Format device&quot; check_tool ubiformat BR2_PACKAGE_MTD_UBIFORMAT || return 1 ubiformat -yq $MTDDEV || return 1 echo &quot;Attach ubi device&quot; ubiattach /dev/ubi_ctrl -m $PART_NO -d $PART_NO || return 1 echo &quot;Create ubi volume&quot; check_tool ubimkvol BR2_PACKAGE_MTD_UBIMKVOL || return 1 ubimkvol /dev/ubi$PART_NO -N $PART_NAME -m || return 1 echo &quot;Create ubi block device&quot; if echo $DEV | grep -q ubiblock; then check_tool ubiblock BR2_PACKAGE_MTD_UBIBLOCK || return 1 ubiblock -c /dev/ubi${PART_NO}_0 || return 1 fi}is_rootfs(){ [ $MOUNT_POINT = &quot;/&quot; ]}remount_part(){ mountpoint -q $MOUNT_POINT || return if touch $MOUNT_POINT &amp;&gt;/dev/null; then [ &quot;$1&quot; = ro ] &amp;&amp; mount -o remount,ro $MOUNT_POINT else [ &quot;$1&quot; = rw ] &amp;&amp; mount -o remount,rw $MOUNT_POINT fi}format_part(){ echo &quot;Formatting $DEV($FSTYPE)&quot; case $FSGROUP in ext2) # Set max-mount-counts to 0, and disable the time-dependent checking. check_tool mke2fs BR2_PACKAGE_E2FSPROGS &amp;&amp; \\ mke2fs -F -L $PART_NAME $DEV &amp;&amp; \\ tune2fs -c 0 -i 0 $DEV ;; vfat) # Use fat32 by default check_tool mkfs.vfat BR2_PACKAGE_DOSFSTOOLS_MKFS_FAT &amp;&amp; \\ mkfs.vfat -I -F 32 -n $PART_NAME $DEV ;; ntfs) # Enable compression check_tool mkntfs BR2_PACKAGE_NTFS_3G_NTFSPROGS &amp;&amp; \\ mkntfs -FCQ -L $PART_NAME $DEV ;; ubifs) format_ubifs ;; squashfs) # check_tool mksquashfs BR2_PACKAGE_SQUASHFS &amp;&amp; \\ # mksquashfs $DEV echo &quot;It's pointness to format a squashfs partition...&quot; ;; jffs2) echo &quot;It's pointness to format a jffs2 partition...&quot; ;; auto) echo &quot;Unable to format a auto partition...&quot; ;; *) echo Unsupported file system $FSTYPE for $DEV false ;; esac}format_resize(){ BACKUP=$1 SRC=$(realpath $MOUNT_POINT) echo &quot;Format-resizing $DEV($FSTYPE)&quot; echo &quot;Backup original data&quot; cp -a &quot;$SRC&quot; &quot;$BACKUP/&quot; || return 1 umount &quot;$SRC&quot; || return 1 echo &quot;Format and mount rw&quot; format_part || return 1 mount_part || return 1 remount_part rw echo &quot;Restore backup data&quot; cp -a &quot;$BACKUP/$SRC&quot; $(dirname &quot;$SRC&quot;) || return 1}resize_ext2(){ check_tool resize2fs BR2_PACKAGE_E2FSPROGS_RESIZE2FS || return 1 resize2fs $DEV}resize_vfat(){ check_tool fatresize BR2_PACKAGE_FATRESIZE || return 1 SIZE=$(fatresize -i $DEV | grep &quot;Size:&quot; | grep -o &quot;[0-9]*$&quot;) # Somehow fatresize only works for 256M+ fat [ &quot;$SIZE&quot; -gt $((256 * 1024 * 1024)) ] &amp;&amp; return 1 MAX_SIZE=$(( $(cat $SYS_PATH/size) * 512)) MIN_SIZE=$(($MAX_SIZE - 16 * 1024 * 1024)) [ $MIN_SIZE -lt $SIZE ] &amp;&amp; return 0 # Large enough! while [ $MAX_SIZE -gt $MIN_SIZE ];do # Somehow fatresize cannot resize to max size MAX_SIZE=$(($MAX_SIZE - 512 * 1024)) # Try to resize with fatresize, not always work fatresize -s $MAX_SIZE $DEV &amp;&amp; return done return 1}resize_ntfs(){ check_tool ntfsresize BR2_PACKAGE_NTFS_3G_NTFSPROGS || return 1 echo y | ntfsresize -f $DEV}resize_part(){ # Fixed size or already resized [ -f $MOUNT_POINT/.fixed -o -f $MOUNT_POINT/.resized ] &amp;&amp; return if [ -z &quot;$FSRESIZE&quot; ]; then echo &quot;No resize for $FSTYPE&quot; return fi echo &quot;Resizing $DEV($FSTYPE)&quot; # Online resize needs read-write remount_part rw if eval $FSRESIZE; then touch $MOUNT_POINT/.resized return fi echo &quot;Done with rootfs&quot; is_rootfs &amp;&amp; return echo &quot;Fallback to format resize&quot; TEMP_BACKUP=$(mktemp -d) format_resize $TEMP_BACKUP &amp;&amp; touch $MOUNT_POINT/.resized rm -rf $TEMP_BACKUP}erase_oem_command(){ CMD=$1 FILE=$2 echo &quot;OEM: Erasing $CMD in $FILE&quot; COUNT=$(echo $CMD | wc -c) OFFSETS=$(strings -t d $FILE | grep -w &quot;$CMD&quot; | awk '{ print $1 }') for offset in $OFFSETS; do dd if=/dev/zero of=$FILE bs=1 count=$COUNT seek=$offset conv=notrunc 2&gt;/dev/null done}done_oem_command(){ CMD=$1 echo &quot;OEM: Done with $CMD&quot; if [ -b &quot;$MISC_DEV&quot; ]; then erase_oem_command $CMD $MISC_DEV else echo &quot;OEM: Erase $CMD from mtd device&quot; check_tool nanddump BR2_PACKAGE_MTD_NANDDUMP || return check_tool nandwrite BR2_PACKAGE_MTD_NANDWRITE || return check_tool flash_erase BR2_PACKAGE_MTD_FLASH_ERASE || return TEMP=$(mktemp) nanddump $MISC_DEV -f $TEMP erase_oem_command $CMD $TEMP flash_erase $MISC_DEV 0 0 nandwrite $MISC_DEV $TEMP fi}handle_oem_command(){ [ &quot;$OEM_CMD&quot; ] || return for cmd in $OEM_CMD; do case $cmd in cmd_wipe_$PART_NAME) is_rootfs &amp;&amp; continue echo &quot;OEM: $cmd - Wiping $DEV&quot; format_part &amp;&amp; done_oem_command $cmd ;; esac done}convert_mount_opts(){ # Accept all opts by default for standard mount tool if [ -z &quot;$@&quot; ] &amp;&amp; [ &quot;$(readlink $(which mount))&quot; != busybox ]; then echo $OPTS return fi # Filter out unsupported opts for opt in ${@:-$BUSYBOX_MOUNT_OPTS}; do echo ${OPTS//,/ } | xargs -n 1 | grep -oE &quot;^$opt$&quot; done | tr &quot;\\n&quot; &quot;,&quot;}prepare_part(){ # Ignore external storages echo $MOUNT_POINT | grep -q &quot;^\\/mnt\\/&quot; &amp;&amp; return 1 # Find real dev for root dev if is_rootfs; then DEV=$(findmnt -n -o source /) # Fallback to the by-name link [ &quot;$DEV&quot; ] || DEV=/dev/block/by-name/rootfs fi DEV=$(realpath $DEV 2&gt;/dev/null) PART_NO=$(echo $DEV | grep -oE &quot;[0-9]*$&quot;) # Unknown device [ -b &quot;$DEV&quot; -o -c &quot;$DEV&quot; ] || return 1 SYS_PATH=$(echo /sys/class/*/${DEV##*/}) if [ -f &quot;$SYS_PATH/name&quot; ]; then PART_NAME=$(cat $SYS_PATH/name) else PART_NAME=$(grep PARTNAME ${SYS_PATH}/uevent | cut -d '=' -f 2) fi PART_NAME=${PART_NAME:-${DEV##*/}} case $FSTYPE in ext[234]) FSGROUP=ext2 FSCK=&quot;fsck.$FSTYPE -y&quot; FSCK_CONFIG=BR2_PACKAGE_E2FSPROGS_FSCK FSRESIZE=resize_ext2 ;; msdos|fat|vfat) FSGROUP=vfat FSCK=&quot;fsck.vfat -y&quot; FSCK_CONFIG=BR2_PACKAGE_DOSFSTOOLS_FSCK_FAT FSRESIZE=resize_vfat ;; ntfs) FSGROUP=ntfs FSCK=ntfsfix FSCK_CONFIG=BR2_PACKAGE_NTFS_3G_NTFSPROGS FSRESIZE=resize_ntfs ;; ubi|ubifs) FSGROUP=ubifs unset FSCK unset FSRESIZE ;; squashfs) FSGROUP=squashfs unset FSCK unset FSRESIZE ;; jffs2) FSGROUP=jffs2 unset FSCK unset FSRESIZE ;; auto) FSGROUP=auto echo &quot;Running fsck on a random fs is dangerous&quot; unset FSCK unset FSRESIZE ;; *) echo &quot;Unsupported file system $FSTYPE for $DEV&quot; return esac # Setup mount tool and opts case $FSGROUP in ntfs) MOUNT=ntfs-3g check_tool ntfs-3g BR2_PACKAGE_NTFS_3G || return 1 OPTS=$(convert_mount_opts &quot;$NTFS_3G_MOUNT_OPTS&quot;) ;; ubifs) MOUNT=&quot;mount -t ubifs&quot; OPTS=$(convert_mount_opts) ;; *) MOUNT=mount OPTS=$(convert_mount_opts) ;; esac MOUNT_OPTS=${OPTS:+&quot; -o ${OPTS%,}&quot;} # Prepare for ubi (consider /dev/mtdX as ubiblock) if [ &quot;$FSGROUP&quot; = ubifs ] || echo $DEV | grep -q &quot;/dev/mtd[0-9]&quot;;then if ! prepare_ubi; then echo &quot;Failed to prepare ubi for $DEV&quot; [ &quot;$AUTO_MKFS&quot; ] || return echo &quot;Auto formatting&quot; format_ubifs || return fi fi}check_part(){ [ &quot;$SKIP_FSCK&quot; -o &quot;$PASS&quot; -eq 0 ] &amp;&amp; return if [ -z &quot;$FSCK&quot; ]; then echo &quot;No fsck for $FSTYPE&quot; return fi echo &quot;Checking $DEV($FSTYPE)&quot; check_tool &quot;$FSCK&quot; $FSCK_CONFIG || return # Fsck needs read-only remount_part ro $FSCK $DEV}mount_part(){ echo &quot;Mounting $DEV($FSTYPE) on $MOUNT_POINT ${MOUNT_OPTS:+with$MOUNT_OPTS}&quot; $MOUNT $DEV $MOUNT_POINT $MOUNT_OPTS &amp;&amp; return [ &quot;$AUTO_MKFS&quot; ] || return echo &quot;Failed to mount $DEV, try to format it&quot; format_part &amp;&amp; \\ $MOUNT $DEV $MOUNT_POINT $MOUNT_OPTS} ​ 然后继续创建一个名为resize-helper的脚本文件，向该文件添加以下内容： 1vim resize-helper 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#!/bin/sh### BEGIN INIT INFO# Provides: resize-all# Default-Start: S# Default-Stop:# Description: 调整所有已挂载的内部分区的大小### END INIT INFO# 不在错误状态下退出set +e# 取消以下注释以查看更多日志# set -x# 包含 disk-helper 脚本. $(dirname $0)/disk-helperLOGFILE=/tmp/resize-all.logdo_part(){ DEV=$1 MOUNT_POINT=$2 FSTYPE=$3 OPTS=$4 echo &quot;处理 $DEV $MOUNT_POINT $FSTYPE $OPTS&quot; # 设置检查/挂载工具并进行一些准备工作 prepare_part || return # 存储 ro/rw MOUNTED_RO_RW=$(touch $MOUNT_POINT &amp;&gt;/dev/null &amp;&amp; echo rw || echo ro) # 如果需要，调整分区大小 resize_part # 恢复 ro/rw remount_part $MOUNTED_RO_RW}resize_all(){ echo &quot;将调整 /proc/mounts 中的所有分区大小&quot; while read LINE; do do_part $LINE done &lt; /proc/mounts}case &quot;$1&quot; in start|&quot;&quot;) resize_all 2&gt;&amp;1 | tee $LOGFILE echo &quot;日志保存至 $LOGFILE&quot; ;; *) echo &quot;用法: resize-helper start&quot; &gt;&amp;2 exit 3 ;;esac ​ 该脚本的主要功能是在系统引导时调整所有已挂载的内部分区的大小，保存退出之后，使用以下命令给予两个脚本的可执行权限，如下图所示： 1chmod 777 resize-helper disk-helper 然后在etc/init.d目录下创建一个名为resize-disk.sh的开机启动项，内容如下所示： 12345678910111213141516171819202122#!/bin/bash -e# Description: 调整 Rockchip 平台环境下的磁盘大小PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bincase &quot;$1&quot; in start) if [ ! -e /var/lib/misc/firstrun ]; then /usr/bin/resize-helper # 调用 resize-helper 脚本来调整磁盘大小 mkdir -p /var/lib/misc # 创建目录 /var/lib/misc touch /var/lib/misc/firstrun # 创建文件 /var/lib/misc/firstrun fi ;; stop) ;; restart|reload) ;; *) echo &quot;用法: $0 {start|stop|restart}&quot; exit 1esacexit $? 该脚本是一个初始化脚本（init script），用于在第一次启动系统时，运行/usr/bin/resize-helper调整磁盘大小。现在只是创建了该脚本，接下来向系统中添加相应的服务，让该脚本开机自动运行，首先来到/usr/lib/systemd/system目录下，创建一个名为resize-disk.service的服务，然后向该服务中添加以下内容 12cd /usr/lib/systemd/systemvi resize-disk.service 123456789101112#start[Unit]Description=Resize disk for rockchcip platformAfter=lighdm.service[Service]Type=simpleExecStart=/etc/init.d/resize-disk.sh start[Install]WantedBy=multi-user.target#end 该服务会运行/etc/init.d/resize-disk.sh脚本，该脚本 保存退出之后，使用以下命令创建该文件的软链接到/etc/systemd/system/sysinit.target.wants/目录下 1ln -s /usr/lib/systemd/system/resize-disk.service /etc/systemd/system/sysinit.target.wants/resize-disk.service ​ 至此，关于自动扩容相关的配置也就完成了，这时候如果制作烧写镜像进入系统之后会自动扩容，最终效果如下所示： 7.4.9配置ADB瑞芯微在很多地方要用到adb服务，例如在RKNPU中要用到的连扳推理，PC端向开发板传输文件都要使用adb服务，所以在本小节将对adb服务进行适配。 本小节要用到了文件已经放在了“iTOP-3568开发板\\03_【iTOP-RK3568开发板】指南教程\\03_文件系统构建配套资料\\04_Ubuntu和Debian系统构建配套资料\\02_配置ADB”目录下，如下图所示： 首先进入/usr/lib/systemd/system/目录，创建一个名为usbdevice.service的服务，该服务的内容如下所示： 1234567891011[Unit]Description=Manage USB device functionsDefaultDependencies=noAfter=local-fs.target[Service]Type=forkingExecStart=/usr/bin/usbdevice start ExecStop=/usr/bin/usbdevice stop[Install]WantedBy=sysinit.target 保存退出之后，继续使用以下命令创建该文件的软链接到/etc/systemd/system/sysinit.target.wants/目录下，如下图所示 ln -s /usr/lib/systemd/system/usbdevice.service /etc/systemd/system/sysinit.target.wants/usbdevice.service 然后进入/usr/lib/udev/rules.d目录下，创建一个名为61-usbdevice.rules的规格，具体内容如下所示： 1SUBSYSTEM==&quot;android_usb&quot;,ACTION==&quot;change&quot;,RUN+=&quot;/usr/bin/usbdevice update&quot; 这个规则定义了一个触发条件，即当系统中的Android USB设备发生更改时（例如插入或拔出设备），将运行一个特定的命令/usr/bin/usbdevice update，然后将提供资料里的usbdevice脚本和adbd拷贝到/usr/bin目录下（需要打开一个终端进行操作），拷贝完成如下图所示： 然后使用以下命令赋予两个文件可执行权限，如下图所示： 1chmod 777 adbd usbdevice 最后来到/etc/profile.d/目录下创建一个名为usbdevice.sh的文件，/etc/profile.d/目录是用于存放系统级别的配置文件的目录。当用户登录时，系统会自动执行/etc/profile文件，然后向usbdevice.sh文件写入以下内容： 123456789101112#!/bin/sh # The env variables below can be overridden# option: adb acm hid mtp ntb rndis uac1 uac2 ums uvcexport USB_FUNCS=&quot;adb&quot; export UMS_FILE=/userdata/ums_shared.imgexport UMS_SIZE=256Mexport UMS_FSTYPE=vfatexport UMS_MOUNT=0export UMS_MOUNTPOINT=/mnt/umsexport UMS_RO=0 其中要注意的是第6行的内容，表示默认模式为ADB，也有其他的几种模式，如果后续用到会进行说明，至此，关于adb的配置就完成了，镜像打包之后烧写到开发板上，在RK的烧写软件中会显示“发现了一个ADB设备”，如下图所示： 然后将ADB设备连接到虚拟机ubuntu上，连接成功之在左侧后会有一个手机的图标，如下图所示： 首先输入“adb devices”命令查看adb设备如下图所示： 然后使用以下命令将测试文件test通过adb传输到开发板的根目录，传输过程如下所示： 然后查看开发板的根目录，可以看到test文件已经成功传输，如下图所示： 至此，关于adb的测试就完成了。 7.4.10配置终端和桌面自动登录本小节要用到的文件路径为“iTOP-3568开发板\\03_【iTOP-RK3568开发板】指南教程\\03_文件系统构建配套资料\\04_Ubuntu和Debian系统构建配套资料\\03_终端和桌面自动登录”，如下图所示： 为了方便，本小节将取消ubuntu启动时的终端登录和桌面的登录，默认让终端登录进root用户，桌面默认登录topeet用户，首先输入以下命令修改终端设置选项： 1vim /lib/systemd/system/serial-getty\\@.service 然后将ExecStart选项修改为以下内容，修改完成如下图所示： 1ExecStart= -/sbin/agetty --autologin root --noclear %I $TERM 至此，串口终端自动登录root用户就设置完成了，然后设置桌面自动登录，在安装桌面章节默认显示管理器使用的是lightdm，所以这里需要将提供资料里面的lightdm.conf拷贝到/etc/lightdm目录下，拷贝完成如下图所示： 涉及到自动登录的内容为该配置文件的126行和127行，具体内容如下所示： 这里默认登录的为topeet用户，如果想要自动登录其他用户自行修改即可，打包镜像，烧写到开发板上之后，可以看到终端已经自动登录进入了系统，如下图所示： 在图形界面也跳过了登录界面，自动进入了桌面，进入桌面之后如下图所示： 至此终端和桌面自动登录的设置就完成了。 7.4.11配置以太网络本小节要用到的文件路径为“iTOP-3568开发板\\03_【iTOP-RK3568开发板】指南教程\\03_文件系统构建配套资料\\04_Ubuntu和Debian系统构建配套资料\\05_以太网配置”，如下图所示： 现在系统启动之后如果使用“ifconfig”命令查看网络可以发现只有一个本地回环生效了，其他的并未生效，如下图所示： 所以需要对网络进行一些配置，首先对“/etc/NetworkManager/NetworkManager.conf”文件进行修改，将ifupdown从false设置为true，修改完成如下图所示： 通过将[ifupdown]部分中的managed选项设置为true，可以启用 NetworkManager 对 ifupdown 工具的集成。这意味着 NetworkManager 将读取和解释 /etc/network/interfaces 文件中的配置，并使用自己的机制来管理这些网络接口。 然后修改/usr/lib/NetworkManager/conf.d/10-globally-managed-devices.conf配置文件，修改为以下内容 12[keyfile] unmanaged-devices=*,except:type:wifi,except:type:ethernet,except:type:gsm,except:type:cdma 这个规则的作用是告诉 NetworkManager 不要自动管理除了Wi-Fi、以太网、GSM 和 CDMA 设备之外的其他类型的网络设备。这样可以确保这些设备不受 NetworkManager 的干预，并允许其他工具或配置来处理它们。 至此关于网络相关的配置就完成了。打包镜像重新烧写之后，重新使用“ifconfig”命令查看网络配置，可以看到eth0和eth1已经出现了，由于现在只是插着一根网线，所以只有eth1获取到了ip，如下图所示： 当使用“apt-get update”命令进行软件源更新的时候可能出现以下打印，这是因为证书过期所导致的： 该问题可以通过输入下面两条命令来解决，如下图所示： 123touch /etc/apt/apt.conf.d/99verify-peer.confecho &gt;&gt;/etc/apt/apt.conf.d/99verify-peer.conf &quot;Acquire { https::Verify-Peer false }&quot; 至此，关于网络相关的配置就完成了。 7.4.12配置蓝牙WIFI本小节要用到的文件路径为“iTOP-3568开发板\\03_【iTOP-RK3568开发板】指南教程\\03_文件系统构建配套资料\\04_Ubuntu和Debian系统构建配套资料\\06_配置蓝牙WIFI”，如下图所示： 由于迅为使用的蓝牙WIFI模块为8723du，该模块若想正常使用，需要在系统启动之后通过ko的形式进行加载，所以本小节将会讲解如何让模块开机之后自动被加载。 首先进入到/usr/local/bin目录下，创建一个名为wifi_blue.sh的脚本文件，然后向该脚本中添加以下内容： 12345#!/bin/bashinsmod /usr/local/modules/8723du.koinsmod /usr/local/modules/rtk_btusb.ko rfkill unblock bluetoothhciconfig hci0 up 该脚本的作用就是加载蓝牙和WIFI两个KO模块，保存退出之后使用chmod命令给予该脚本可执行权限，如下图所示： 这时候只是有了可以加载驱动的脚本，然后来到/usr/lib/systemd/system目录下创建一个名为wifibt.service的开机自动运行服务，向该服务中添加以下内容 123456789101112#start[Unit]Description=insmod topeet wifi_blue modulesAfter=lighdm.service[Service]Type=forkingExecStart=/usr/local/bin/wifi_blue.sh[Install]WantedBy=multi-user.target#end 该服务的目的就是开机运行/usr/local/bin/wifi_blue.sh脚本，从而加载WIFI和蓝牙模块，让两个功能正常使用，然后使用以下命令创建该服务的软链接，创建完成如下图所示： 1ln -s /usr/lib/systemd/system/wifibt.service /etc/systemd/system/sysinit.target.wants/ 接下来需要在/usr/local/目录下创建一个名为modules的目录，然后将提供资料里的两个ko文件拷贝到该目录下，拷贝完成如下图所示： 需要注意的是，在资料中提供的这两个ko文件只适用于内核版本为4.19的系统，如果是其他版本的系统可以自行替换对应的ko文件。 初次之外蓝牙的正常运行还需要相应的固件，所以还需要资料中提供的rtl8723du_config和rtl8723du_fw两个固件拷贝到/usr/lib/firmware目录下，拷贝完成如下图所示： 至此，关于蓝牙WIFI相关的配置就完成了。打包镜像并烧写到开发板上，来到图形界面，可以看到蓝牙已经可以正常的搜索到设备了，如下图所示： 在右上角的网络设置中也可以搜索到相应的WIFI，如下图所示： 至此，关于蓝牙WIFI 的相关配置就完成了。 7.4.13配置ssh允许root登录本小节要用到的文件路径为“iTOP-3568开发板\\03_【iTOP-RK3568开发板】指南教程\\03_文件系统构建配套资料\\04_Ubuntu和Debian系统构建配套资料\\04_ssh 允许root登录”，如下图所示： 默认情况下ssh是不能root用户登录的，为了方便调试，可以通过修改sshd的配置文件来允许ssh root登录。 sshd的配置文件为“/etc/ssh/sshd_config”，打开该文件找到下图所示的内容： 然后修改为以下内容，修改完成如下图所示：】 1PermitRootLogin yes 至此，关于ssh有关的配置就修改完成了。然后打包镜像烧写到开发板，进入系统之后查看开发板的ip地址为192.168.1.168，如下图所示： 然后通过ssh软件通过root用户连接，连接设置如下所示： 连接成功如下图所示： 至此，关于ssh允许root登录的设置就完成了。 7.4.14安装rga deb包本小节要用到的文件路径为“iTOP-3568开发板\\03_【iTOP-RK3568开发板】指南教程\\03_文件系统构建配套资料\\04_Ubuntu和Debian系统构建配套资料\\07_rga”，如下图所示： 注：这里提供的仅仅只是ubuntu20 rga相关的deb包，如果是其他系统并不适用。 RGA是Rockchip（瑞芯微电子）公司开发的图像处理技术，主要应用于他们的系统芯片中。RGA技术在Rockchip的芯片中集成了一个专门的硬件模块，用于加速2D图形操作。这个硬件模块通常被称为RGA硬件加速器。 RGA会对图形界面有一定的加速效果，而且后面在安装GPU相关库的部分也会用到RGA，所以这里先来安装一下RGA相关的deb包。 首先将deb包拷贝到构建的ubuntu文件系统中，拷贝完成如下图所示： 然后使用以下命令进行安装,安装过程如下所示： 123dpkg -i librga-dev_2.2.0-1_arm64.debdpkg -i librga2_2.2.0-1_arm64.debdpkg -i librga2-dbgsym_2.2.0-1_arm64.deb 至此，RGA相关的库就安装完成了。 7.4.15 安装mpp deb包本小节要用到的文件路径为“iTOP-3568开发板\\03_【iTOP-RK3568开发板】指南教程\\03_文件系统构建配套资料\\04_Ubuntu和Debian系统构建配套资料\\08_mpp”，如下图所示： 注：这里提供的仅仅只是ubuntu20 mpp相关的deb包，如果是其他系统并不适用。 MPP（Media Processing Platform）是一种多媒体处理平台，用于实现音频和视频数据的处理、编解码和处理。MPP 提供了一组丰富的功能和算法，用于处理各种多媒体数据，并且能够在硬件加速的环境下提供高效的处理性能。 以下是 MPP 的主要作用： （1）视频编解码：MPP 提供了各种视频编解码器，如 H.264、H.265、MPEG-2 等。这些编解码器能够将视频数据进行压缩（编码）和解压缩（解码），以满足不同应用场景对视频数据的存储和传输需求。通过硬件加速，MPP 可以提供高效的视频编解码性能，减轻 CPU 的负担。 （2）图像处理：MPP 包含了一系列图像处理算法，如图像缩放、旋转、裁剪、色彩空间转换等。这些算法可以对图像进行各种操作和转换，以满足不同应用场景对图像处理的需求。MPP 的硬件加速能力可以加快图像处理的速度，并提供更高的效率。 （3）音频编解码：除了视频编解码，MPP 还提供了音频编解码的功能。它支持常见的音频编码格式，如 AAC、MP3、AC3 等。通过 MPP，可以对音频数据进行高效的压缩和解压缩，实现音频的存储、传输和处理。 （4）多媒体处理流程管理：MPP 提供了一个统一的框架和接口，用于管理和控制多媒体处理流程。它可以对多个媒体处理单元进行调度和协调，实现复杂的多媒体处理任务。MPP 还提供了丰富的配置选项和参数设置，以满足不同应用场景的需求。 MPP包的安装方法跟上面RGA包的安装方法相同，首先将资料中提供的MPP包拷贝到构建的ubuntu文件系统中，拷贝完成如下图所示： 然后使用以下命令进行安装,安装过程如下所示： dpkg -i librockchip-mpp1_1.5.0-1_arm64.deb dpkg -i librockchip-mpp-dev_1.5.0-1_arm64.deb dpkg -i librockchip-vpu0_1.5.0-1_arm64.deb dpkg -i rockchip-mpp-demos_1.5.0-1_arm64.deb 至此，MPP相关的库就安装完成了，打包镜像，然后烧写到开发板，开发板启动之后，在开发板终端输入以下命令用来监控系统打印，如下图所示： tail -f /var/log/syslog &amp; 然后输入以下命令通过mpi_dec_test命令调用mpp进行视频的解码，将h264转为yuv，解码过程如下图所示： mpi_dec_test -i /oem/200frames_count.h264 -t 7 -n 250 -o /home/topeet/test.yuv -w 640 -h 480 解码完成之后在/home/topeet/目录下生成了解码为yuv格式的test.yuv文件，如下图所示： 然后继续使用mpi_enc_test命令进行视频的编码，将上面解码出来的yuv转为h264格式，编码过程如下图所示： mpi_enc_test -i /home/topeet/test.yuv -t 7 -n 250 -o /home/topeet/test.h264 -w 640 -h 480 -fps 25 编码完成之后在/home/topeet/目录下生成了编码为h264格式的test.h26文件，如下图所示： 至此，关于MPP的相关测试就完成了。 7.4.16 安装gpu deb包本小节要用到的文件路径为“iTOP-3568开发板\\03_【iTOP-RK3568开发板】指南教程\\03_文件系统构建配套资料\\04_Ubuntu和Debian系统构建配套资料\\09_gpu”，如下图所示： 注：这里提供的仅仅只是ubuntu20 gpu相关的deb包，如果是其他系统并不适用。 首先将上面提供资料里的xserver相关deb包拷贝到要构建的ubuntu系统中，拷贝完成如下图所示： 然后使用以下命令进行deb包的安装，安装过程如下所示：dpkg -i xserver-common_1.20.13-1ubuntu1~20.04.9_all.deb dpkg -i xserver-xorg-core_1.20.13-1ubuntu1~20.04.9_arm64.deb dpkg -i xserver-xorg-dev_1.20.13-1ubuntu1~20.04.9_arm64.deb dpkg -i xserver-xorg-legacy_1.20.13-1ubuntu1~20.04.9_arm64.deb 中间在安装xserver-xorg-core_1.20.13-1ubuntu1~20.04.9_arm64.deb包时出现了错误，这里我们使用“apt-get install -f”命令进行修复即可，修复过程如下所示： 修复完成之后将提供资料中的libmali库同样拷贝构建的ubuntu系统中，拷贝完成如下图所示： 然后使用以下命令进行安装，安装过程如下所示： dpkg -i libmali-bifrost-g52-g13p0-x11-gbm_1.9-1_arm64.deb 至此，关于GPU 相关库的安装就完成了， 7.4.17 清除安装的软件包经过了上面的一些步骤已经对构建的ubuntu进行了简单的配置，但在配置的过程中也下载了很多的软件包，这些软件包会占用很多的空间，所以在配置完成之后运行下面的命令清除安装的软件包，如下图所示： apt-get -y clean &amp;&amp; apt-get -y autoclean 7.4.18 退出chroot环境设置好以后就可以退出根文件系统了，输入命令“exit”退出。如下图所示： 然后通过以下命令取消binary目录的挂载，如下图所示： ./mount.sh -u binary/ 7.5 文件系统镜像的制作本小节要用到的文件路径为“iTOP-3568开发板\\03_【iTOP-RK3568开发板】指南教程\\03_文件系统构建配套资料\\04_Ubuntu和Debian系统构建配套资料\\10_制作烧写镜像”，如下图所示： 首先将上述资料中提供的mk-image.sh和post-build.sh脚本拷贝到虚拟机ubutnu上，而且要跟构建的binary目录放到同一目录下，拷贝完成如下所示： 然后使用以下命令赋予两个脚本可执行权限，如下图所示： chmod 777 mk-image.sh post-build.sh 然后运行mk-image.sh脚本即可完成烧写镜像的制作了，制作过程如下图所示： 制作完成之后会在当前目录生成一个名为rootfs.img的烧写镜像，只需要根据烧写手册进行单独烧写即可。至此，关于Ubuntu和Debian文件系统的构建就讲解完成了。","link":"/2023/11/20/10%20debian%E5%92%8Cubuntu%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E8%AF%A6%E8%A7%A3/"},{"title":"显示硬件发展与视频开发知识点扫盲","text":"电脑上炫酷的展示，生动的形象，离不开硬件的支持，硬件是音视频编程文化的一部分。开发者有必要对相关硬件大概了解。本专题涉及视频硬件相关话题，音频相关以后讲述。 ​ 视频编程的本质是图形图像编程，本专题以时间为主线，以公司硬件发展为点位，以图像图像开发接口为切面，宏观进行介绍，希望对视频编程开发者进行有益的启示。 ​ 本系列文章依发展顺序，从早期起源开始，再到2D时代，3D时代，移动时代，智能时代，最后到显示标准与专业视频处理单元，大体分为6部分。 ​ 早期概述回顾286之前的电脑，以及一些图形图像工作站。那个年代图形图像编程起源于欧美发达国家。毫不夸张的说，欧美打开了计算机世界的大门，后面简单描述了VGA早期图形编程。 ​ 2D时代回顾了当年硬件产品、2D编程接口。GDI、GDI+、D2D、AGG、Cairo、Cocoa Drawing等。2D时代的到来，迈出了图形图像编程的第一步，拉开了多媒体编程的序幕。 ​ 3D时代是计算机图形学大发展的年代，3D引擎的出现，为图形学的发展注入了活力。可以说，3D时代的降临，音视频技术的春天到来了。 ​ 移动时代是图形图像技术在嵌入式设备上拓展的年代，多媒体引擎也发生了一些变化。多媒体功能是手机最重要的功能之一，未来音视频技术在手机上将会有大的发展。 ​ 人工智能的发展，智能时代到来了，音视频方面是人工智能应用最广泛的分支。音视频技术是人工智能最重要的方向，未来，人工智能技术是音视频技术最核心的技术之一。 ​ 技术的发展没有穷尽，硬件技术的进步，显示标准和工业化硬件的出现。给技术的发发展指明了方向。 1、早期概述​ 早期图形图像处理主要靠一些工作站来完成。286之前的电脑仅进行基本的双色文本显示。显示主要靠显示器和主板显示原器件做支持。下图是1973年的Alto和1980年的Perq图形工作站，其中Alto是地球上第一台图形工作站。 ​ 286之前，国内谈不上电脑的视频编程。专业的音视频处理主要靠图形图像工作站完成，设备全靠进口，图形图像软件的开发是国外专业芯片公司、计算机设备公司开发，当年的视频编程没有走向民间。后来，在消费级领域，一些图形加速卡出现，为图形图像编程做了前期的准备。 ​ 286之前的图形图像工作站编程，历史已经久远，本专题不做阐述。 ​ 技术的发展推动了显示标准的改变，从MDA—CGA—EGA—VGA。显示标准对硬件厂商做了规格的约束，指引着显示技术的方向，影响着图形图像技术的发展，对视频研发产生影响，推动末端技术应用。 ​ 历史的烽烟过去，年代已经久远，广袤的互联网上，很难找到工作站编程的资料。 2、VGA编程​ VGA的出现，显卡作为独立功能部件，从主板上剥离。这个改变，图形图像编程的曙光出现了，当年的图形图像编程还必须依靠厂家提供的视频驱动。视频驱动的完备程度，很大程度决定了硬件厂商的生存。 ​ 下面的代码，老一代程序员应该对此并不陌生。也就是这样的代码，拉开了图形编程的序幕，迈出了视频编程的第一步。 12345678//调用VGA驱动程序int gdriver=DETECT， gmode;initgraph ( &amp;gdriver， &amp;gmode， “c:\\\\tc\\\\bgi”);setbkcolor ( BLACK); //设定背景颜色为黑色setcolor ( WHITE); //设定画线的颜色为白色setlinestyle (0， 4444， 4); //设置当前线型 实线 线图样 线宽四个像素line ( x1， y1， x2，y2); //画线 x1 y1起点 x2y2终点lineto( x， y); //当前位置到xy坐标画直线 ​ 计算机发展过程中，显示部件在设计上发生着变化，下图是从70年代到今天显卡发展过程图。 ​ 自从计算的出现，相比其它领域，计算机领域发展更快，对社会影响更远，厂商竞争更为激烈。下面从公司、产品、技术的角度探讨。 2d时代 3、2D时代​ 几十年工艺改进，解决了基本制造问题，计算机开始向应用过渡。显示问题是首当其冲的问题，多年的思辨与实践，2D技术横空出世，完善发展，为计算机的应用推广做出了卓越的贡献。双色显示的星星之火，在2D时代终于熊熊燃烧，计算机走向民间的时代到来了。 ​ 下面从公司产品的角度，回顾2D时代的图形图像编程。 3.1、公司3.1.1、Amiga​ Amiga是80年代图形性能最强大的电脑之一，拥有专门处理图形的芯片。杰.迈纳是当年显卡芯片设计的灵魂人物。下图Amiga500拆机，红圈内的denise芯片就是专门用来负责处理图形的，denise是真正意义上的2d加速卡。 ​ 这家公司在音视频多媒体领域超越当年的IBM与Apple，遗憾的是，最好的技术也被市场所淘汰。 3.1.2、IBM​ 1981年， IBM推出个人电脑，提供了两种显卡，一种是“单色显卡”(简称 MDA)， 一种是 “彩色绘图卡” (简称 CGA)。 ​ 1982年，IBM又推出了MGA（Monochrome Graphic Adapter）， 又称Hercules Card (大力士卡)， 除了显示图形外，还保留了原来MDA的功能，IBM是世界第一块显卡制造商。 3.1.3、S3​ S3在1989年开始造显卡，2D画质领域无人能及，盛极一时的Trident也无奈败下阵来。S3最经典的产品当属Trio64V+，有着高速的2D性能和强大的VCD软解实力，支持1024×768的分辨率，在低分辨率下支持最高32Bit真彩色。 ​ 那是一个VCD满天飞的年代，显卡的VCD解压能力是视频底层技术的一个突破。S3几经被转卖，先被威盛收编，后被HTC揽入囊中。今天，HTC步履蹒跚，生死一线。 3.1.4、Trident​ Trident，这家公司当年在2D显卡领域红极一时，在当年的产品专柜里，多次看到其身影，后期由于技术方向原因，在3D显卡年代被淘汰。最终在2003年被XGI收购。而XGI最终在后来被ATI纳入麾下。 3.1.5、Matrox（迈创）​ 曾经独显领域的主要玩家，2D显卡时代声名显赫，3D时代落寞，最终转向小众视频市场。如今说起显卡GPU，很多人脑海里只会浮现NVIDIA、AMD两个名字，在上个世纪末，Matrox(迈创)的名字如雷贯耳。它的资格比NVIDIA、AMD要老得多。迈创来自加拿大(ATI也是)，Matrox成立于1976年，比ATI早9年，比NVIDIA早17年。 3.2、图形技术​ 1976年~1995年是沉闷寂寥的2D时代，显示技术发展缓慢，，图形图像编程近乎停滞。市场期待着集成电路的发展、微电子技术的爆发。 ​ 1995年之后，硬件技术的春天到来了，3D显卡涌现，性能和技术有很大提升，鸟语花香，百家争鸣。厂商不断推陈出新才能生存，跟不上节奏的企业，逃不了被收购的命运。缅怀过去，继往开来，2D技术多年的发展为3D技术做了20年的铺垫。 ​ 结合过去历史，回顾当年2D编程的技术。 3.2.1、GDI编程​ 当时图形图像编程多使用GDI技术。 ​ 代码示例： 123CDC *pDC = GetDC();pDC-&gt;SelectObject(&amp;…);ReleaseDC(pDC); ​ GDI编程的出现，代表了消费级图像编程的兴起。 3.2.2、GDI+编程​ GDI+是GDI的增强版，想当年，Windows平台的上的图形图像技术，走在各个平台的前端。 ​ GDI编程为OpenGL和DirectX做了铺垫。 ​ 代码示例： 12345678910111213141516171819202122232425262728HINSTANCE hInst = AfxGetResourceHandle();HRSRC hRsrc = ::FindResource (hInst，MAKEINTRESOURCE(nID)，sTR); // typeif (!hRsrc)return FALSE;// load resource into memoryDWORD len = SizeofResource(hInst， hRsrc);BYTE* lpRsrc = (BYTE*)LoadResource(hInst， hRsrc);if (!lpRsrc)return FALSE;// Allocate global memory on which to create streamHGLOBAL m_hMem = GlobalAlloc(GMEM_FIXED， len);BYTE* pmem = (BYTE*)GlobalLock(m_hMem);memcpy(pmem，lpRsrc，len);IStream* pstm;CreateStreamOnHGlobal(m_hMem，FALSE，&amp;pstm);// load from streampImg=Gdiplus::Image::FromStream(pstm);// free/release stuffGlobalUnlock(m_hMem);pstm-&gt;Release();FreeResource(lpRsrc); ​ 无论GDI还是GDI+技术，都代表着图形图像编程的年代到来了。 3.2.3、Direct 2D​ Direct2D的出现代表着引擎技术的到来，体现了市场对图形图像、音视频技术的强烈需求，在引擎的背后，封装了图形图像技术的专业性与复杂性。 ​ 代码示例： 123456789101112131415161718192021222324252627282930313233#include &lt;windows.h&gt; #include &lt;d2d1.h&gt; #include &lt;d2d1helper.h&gt; #include &lt;dwrite.h&gt; #pragma comment(lib,&quot;dwrite.lib&quot;) #pragma comment(libd&quot;d2d1.lib&quot;) static HINSTANCE g_hinst; static HWND g_hwnd;static bool g_flag_app_exit;static ID2D1Factory * g_factory; static ID2D1HwndRenderTarget * g_render_target; g_render_target-&gt;Resize(D2D1::SizeU(LOWORD(lparam)，HIWORD(lparam))); D2D1CreateFactory(D2D1_FACTORY_TYPE_SINGLE_THREADED， &amp;g_factory); RECT rc; GetClientRect(g_hwnd， &amp;rc); g_factory-&gt;CreateHwndRenderTarget( D2D1::RenderTargetProperties()， D2D1::HwndRenderTargetProperties(g_hwnd，D2D1::SizeU(rc。right - rc。left， rc。bottom - rc。top) )， &amp;g_render_target); g_render_target-&gt;BeginDraw(); g_render_target-&gt;Clear(D2D1::ColorF(0。63， 0。84， 0。00)); g_render_target-&gt;EndDraw(); g_render_target-&gt;Release(); g_factory-&gt;Release(); 3.2.4、AGG​ AGG，全名：Anti-Grain Geometry，一个开源的、高效2D图形库。AGG的功能与GDI+的功能类似，提供了比GDI+更灵活的编程接口，产生的图形的质量非常高，跨平台的2D图形引擎，可在Windows、Wince、Linux等平台上运行。 ​ 设计上，师出Boost库，使用了大量的C++语法规则，包括模板、仿函数等处理。为了能在更多平台上使用，并没有直接使用Boost和STL库，自己实现了部分STL功能。” 3.2.5、Cairo​ cairo 是一个免费的矢量绘图软件库，可以绘制多种输出格式。cairo支持许多平台，包括 Linux、BSD、Windows等。Linux 绘图可以通过 X Window 系统、Quartz、图像缓冲格式或 OpenGL 上下文来实现。 ​ cairo 的主要设计目标是提供尽可能接近的输出。这种一致的输出使 cairo 非常适合 GUI 工具集编程和跨平台应用程序开发。使用同一个绘图库打印高分辨率的屏幕和绘制屏幕内容，这种功能具有显著的优点。 ​ 在支持的目标平台上，cairo 尝试智能化地使用底层硬件和软件支持。高质量矢量图形和高性能的结合使cairo成为优秀的绘图系统。 ​ cairo 用C编写的，为大多数常用的语言提供了绑定。选用C语言有助于创建新的绑定，在进行C语言调用时提供高性能。和Python绑定，支持快速原型开发，降低了学习 cairo绘图API的门槛。 ​ 代码示例： 123456789101112131415161718192021222324#include &lt;cairo.h&gt; int main (int argc， char *argv[]) { cairo_surface_t *surface; cairo_t *cr; int width = 640; int height = 480; surface = cairo_image_surface_create (CAIRO_FORMAT_ARGB32， width， height); cr = cairo_create (surface); /* Drawing code goes here */ cairo_set_line_width (cr， 10); cairo_set_source_rgb (cr， 0， 0， 0); cairo_rectangle (cr， width/4， height/4， width/2， height/2); cairo_stroke (cr); /* Write output and clean up */ cairo_surface_write_to_png (surface， &quot;rectangle。png&quot;); cairo_destroy (cr); cairo_surface_destroy (surface); return 0; } 3.2.6、Cocoa Drawing​ Cocoa Drawing是苹果公司的2D图形图像开发类库，在XCode下运用，旨在推广苹果公司的技术。纵然苹果一直有着很强的图形图像处理能力，但仅局限于苹果公司本身的软件，苹果在早期一直没有很好的图形图像编程引擎。 ​ 近些年苹果的Metal技术，才可以算作苹果公司真正的技术创举。 ​ 代码示例： 123456789101112[NSGraphicsContext saveGraphicsState];// Create the path and add the shapesNSBezierPath* clipPath = [NSBezierPath bezierPath];[clipPath appendBezierPathWithRect:NSMakeRect(0.0，0.0，100.0，100.0)];[clipPath appendBezierPathWithOvalInRect:NSMakeRect(50.0，50.0，100.0，100.0)];// Add the path to the clip shape。[clipPath addClip];// Draw the image。[NSGraphicsContext restoreGraphicsState]; 3.3、总结​ 计算机功能的强大，代表本身的强大，本身的强大代表体系的复杂，模块的组合，视频技术也不例外，从宏观角度来看，图形图像编程框架如下图。 ​ 软硬件技术是紧密结合的，硬件技术的进步推动了软件编程的繁荣，软件技术的应用促进了硬件的推广。早期的硬件公司驱动设计、专业级的编程接口研发，到后期消费级市场软件技术的繁荣。图形图像编程形成独立的软件阵地，呼唤着3D时代的到来。 4、3D时代​ 历史长河中，科技进步是人类文明的主要推动力。沧海桑田，天下多变，人类对科技的研究与探索从未停止，计算显示技术也不例外。 ​ 现实是3D的，显示硬件注定也是3D的。透过历史的云烟，得到岁月的启示，硬件对3D技术的支持是显卡厂商存活的根本。硬件对图形图像引擎的支持，是显示芯片公司做大做强的基础。引擎支持主要包括OpenGL和D3D引擎支持，在2000年前尤为明显。 ​ 科技的风风雨雨，面临着技术的抉择和选型，无论辉煌黯淡，时光默然前行，那些远行的技术，做了科学的辩证。 4.1、公司4.1.1、3Dfx​ 1994年，3Dfx成立，在当时是一家小公司，定位明确，很快就推出了业界的第一块真正意义的3D图形加速卡：Voodoo。在当年，Voodoo在速度以及色彩方面的表现让喜欢游戏的用户为之疯狂，Voodoo几乎是玩家们唯一的选择，当年3Dfx的专用Glide引擎接口统治了整个3D世界。当年一个专业图形引擎，可拯救一系列产品，成就一家硬件厂商。 ​ Glide引擎提供了专业的3D图形显示接口，Glide可以说是一套3D接口库，3Dfx凭借硬件与引擎的结合创造了发展历史上的奇迹。3Dfx的成功就是在3D硬件支持和相关引擎支持良好的表现。 ​ 3Dfx从硬件上实现了Z缓存和双缓存，可进行光栅化之类的操作，实现了DirectX 6的特征集。CPU从繁重的像素填充任务中解脱出来。当然，当年的技术不成熟，顶点变换必须在CPU中完成，光栅化之后的像素操作也很有限。 4.1.2、ATI​ 说起显卡，我们不能不提ATI，由于对3D技术支持较好以及紧跟OpenGL和DirectX步伐。多年和英伟达齐名。后来由于显卡驱动问题，造就了A卡追击N卡的局面。ATI提供了良好的编程接口，成为推广的一个重要因素。 ​ ATI的欻创始人何国源先生，广东新会人，在很多年间都是芯片界的顶级人物。AMD在2006年以54亿美元收购ATI，何国源从此退出显卡芯片行业。今天世界上很多电脑的显卡都有ATI的技术。下面是显卡领域的两个风云人物，何先生已金盆洗手，退出江湖，黄药师依然皮衣挂帅，征战一线。 ​ 市场风云变幻，毫无疑问，ATI是幸运的，当年潜图问鼎，雄霸天下。直至后来被高价收购，多年后的今天，A卡依然笑傲江湖。 4.1.3、NVIDIA​ 提起显卡，必须提及另外一个厂家NViDia，英伟达的创始人黄仁勋先生，台湾台北人，江湖人称黄药师（老黄）。近20年以来，世界顶级芯片巨头。在图形处理芯片上，何国源和黄仁勋都做出了不可磨灭的贡献，图形处理芯片的前身，就是今天的GPU，GPU是英伟达推出的。 ​ NVIDIA 通过NV系列产品小试牛刀，通过GeForce 系列产品出征江湖，屡战屡胜，战功显赫，今天稳坐显示领域第一把交椅，无人出其左右。在人工智能数据分析方面，英伟达依然战功显赫。 ​ 想当年，显示领域是英伟达和ATI的天下，两者相互竞争，推动了显示技术的发展。成就了今天的显示规范。当年的竞争本质是显示指令、Shader编程、效率的竞争。 ​ 英伟达的NV3开始支持OpenGL，取得了巨大的成功。后期开始支持Direct3D。也就是前期对这些框架支持不足，导致经营举步维艰。 ​ 1999年8月，NVIDIA公司发布了一款代号为NV10的图形芯片Geforce 256。Geforce 256是图形芯片领域开天辟地的产品，因为它是第一款提出GPU概念的产品。 ​ Geforce 256所采用的核心技术有“T&amp;L”硬件、立方环境材质贴图和顶点混合、纹理压缩和凹凸映射贴图、双重纹理四像素、256位渲染引擎等。“T&amp;L”硬件的出现，让显示芯片具备了以前只有高端工作站才有的顶点变换能力，同时期的OpenGL和DirectX 7都提供了硬件顶点变换的编程接口。1999年，GPU的概念就这样出现了。 ​ GPU的推出，不仅仅是硬件体系的革命性变化，更是对显示标准的强大支持。今天3D引擎编程，核心主要也是面向GPU的编程。 ​ 后期ATI被AMD收购，纵然没有英伟达耀眼，但整体发展还算顺利，形成了A卡和N卡竞争的格局。 ​ 2020年，英伟达收购ARM，市值超过3300亿美元，超过INTEL 1000亿美元，成为全球市值排名TOP10。在西方的土地上，一个黄种人，一个台湾人，战功显赫。 4.1.4、3DLabs​ 3D技术飞速发展，专业显卡需求增大。专业公司应运而生。3DLabs就是这样的公司，开发高端绘图芯片，对OpenGL的完美支持，性能强大，当时的OpenGL普通显卡难以完全支持。 ​ 当年在专业显卡市场，3DLabs的产品几乎是唯一选择。面对瞬息万变的世界，3DLabs还是落后了，对D3D技术重视不足和对OpenGL过度依赖，最终被黄药师的Quadro干掉。于2002年被创新科技收购，成为旗下子公司。 ​ 对D3D的支持程度不仅仅影响民间显卡，对专业显卡也有很大的影响。显卡的发展不仅仅要考虑OpenGL，更要考虑D3D。D3D是微软的，操作系统是微软的，Windows垄断操作系统的存在，对D3D是一个强大的支持。公司决定软件，软件决定硬件又一次得到体现。 4.1.5、Video Logic​ Video Logic前期主打产品是PowerVR，当年PowerVR也涉足桌面显卡市场，比较有名的就是PCX2芯片，性能强大，支持D3D、OpenGL，然而驱动程序兼容性较差，游戏运行有问题，对CPU要求较高，影响了销售。即使如此，在很长时间内，市场占有率一直保持第二。 ​ 对图形图像引擎的支持、驱动的友好程度决定了硬件的发展。后期由于优化不好，兼容性问题、软件冲突等，容易引起渲染错误或性能下降。离不开最终被转卖的命运。 ​ 相比太多厂商，PowerVR是幸运的，桌面市场失败了，但PowerVR睿智的转向了移动图形市场，避免了桌面市场的残酷竞争，发挥了自己的技术优势，移动端成为未来的趋势，PowerVR成为移动显示领域的重要力量。 ​ PC端计算机图形学发展的同时，移动端技术的兴起，移动端细分专业显示芯片的出现，进而发展成为独立的领域，计算机图形学向精细化发展。 4.1.6、intel​ 英特尔是美国一家以研制CPU为主的公司，是全球最大的个人计算机零件和CPU制造商，成立于1968年，具有52年产品创新和市场领导的历史。 ​ 1971年，英特尔推出了全球第一个微处理器。微处理器所带来的计算机和互联网革命，改变了整个世界。 ​ 2016年4月，英特尔推出处理器至强7290F采用了多达72个处理器核心，成为英特尔核心数最多的处理器。2019年2月，英特尔推出至强铂金9282，它有112个线程，是线程最多的处理器。 ​ 2020年7月，福布斯2020全球品牌价值100强发布，英特尔排名第12位。9月3日，英特尔推出了新的极简主义 Logo。 ​ 谈到显卡，不能回避intel，由于特殊的地位，相比其它厂商，在显卡的道路上，走的相对平稳与踏实。i740就是Intel推出的第一款产品，极大的推动了AGP标准的发展。 ​ intel专注于集成显卡领域，从i740之后，再也没有推出过独立显卡，i740成了Intel独立显卡的绝唱。纵然在显卡领域没有大的建树，但intel一直在坚守。 4.1.7、AMD​ AMD显卡即ATI(被AMD收购)显卡，俗称A卡。搭载AMD公司的显示芯片。与NVIDIA齐名，同为世界两大显示芯片厂商之一。由于收购关系，在本专题中，不做过多讲述。 ​ AMD是目前业内唯一一个可以提供高性能CPU、高性能独立显卡、主板芯片组三大组件的半导体公司，为明确其优势，提出3A平台新标志，在笔记本领域有“AMD VISION”标志的就表示该电脑采用3A构建方案。 ​ 今天显卡市场，是A卡与N卡的天下，19年第四季度，AMD出货量环比大增22.6%，份额19%，NVIDIA减少1.9%，份额18%，Intel微增0.2%，份额63%。由于计算将Intel核显、APU算在内，NVIDIA并无优势。 ​ 在独显方面，AMD出货量占比27%，较上季度的24%和去年的26%均有增加，但NVIDIA仍旧以73%垄断剩余市场。今年，Intel Xe架构独显将面世，对独显格局有一定冲击。 ​ AMD显卡与NVIDIA显卡相比，有更高的功耗与更高的性能。AMD显卡的子品牌有 ATI 和 Radeon，显卡型号众多。今天，AMD(ATI)显卡技术坚挺，依然耀眼。 4.2、软件与硬件4.2.1、接口与硬件​ 专业图形图像领域，Z缓存和双缓存称为了3D图形技术的标配。在今天的流行图形图像API里，当年的Z缓冲和双缓冲，仅仅是今天图形图像引擎的一个参数或者一个函数而已，参数和函数的背后，是硬件的支持。 ​ 显卡插口有PCI和AGP两种。在数据处理上，逐渐支持高速和并行。具有着更大的传输速率，更复杂数据的处理能力。硬件技术的变革推动了软件技术的进步。 ​ 任何技术的发展都不是一帆风顺的，显示技术也不例外。每一次技术的革新，都可能带来革命性的变化。那些曾经被淘汰、被边缘化的技术，为主流技术的发展做了助攻。在显卡技术发展过程中，硬件的升级，架构的改变，都代表着功能的提升。 ​ 下图从另外一个角度，展现显卡发展的过程。 4.2.2、3D引擎​ 遥想当年，视频编程主要靠专业引擎来体现，各家公司雄心勃勃，开宗立派，在数家公司的专业图形图像接口里，OpenGL和DirectX最终胜出。今天，消费级市场主要通过OpenGL和DirectX来体现。 ​ 可悲的是，早期在linux上很少有图形图像编程的处理。一直到今天，图形图像工作主要还是在Windows和Mac上进行。 ​ 时光的河流，流淌着一个真理，对3D的支持，以及对3D相关图形系统的支持，是硬件厂商存活的根本。这里的3D支持，就是3D引擎。 ​ 当年的图形图像编程，OpenGL刚刚起步，很多公司提供的应用引擎都是对OpenGL和D3D的封装。 4.2.2.1．OpenGL​ OpenGL是渲染2D、3D数字图形的跨语言、跨平台的应用程序编程接口（API）。由近350个函数组成，绘制简单图形和复杂三维景象。OpenGL常用于CAD、虚拟现实、科学可视化和游戏开发等。OpenGL直接操纵图形硬件，高效进行图形图像编程，实现一般由显示设备厂商提供。OpenGL是对显卡编程的工业接口。 ​ OpenGL规范由1992年成立的OpenGL架构评审委员会（ARB）维护。ARB由业界顶级软硬件公司组成，下图是OpenGL的发展过程。 ​ OpenGL API定义了若干被客户端程序调用的函数，以及一些整型常量。这些实现方便了开发者调用。 ​ OpenGL与语言平台无关。规范没有获得和管理OpenGL上下文相关的内容，将这些细节交给底层窗口系统。OpenGL专注图像渲染，不提供输入、音频及窗口相关的API。 ​ OpenGL不断进化API。新版规范定期由Khronos Group发布，新版本通过扩展API来支持各种新功能。每个版本细节由Khronos Group成员一致决定，包括显卡厂商、操作系统设计人员以及类似Mozilla和谷歌的技术性公司。 ​ 除了核心API功能，GPU供应商通过扩展的形式提供额外功能。扩展引入新功能和新常量，增加或取消现有OpenGL功能。 ​ 每个扩展与一个标识符联系，标识符基于开发公司的名称。例如，英伟达（nVidia）的标识符是NV。如果多个供应商同意使用相同的API来实现相同功能，那么就用EXT标志符。这种情况更进一步，Khronos Group的架构评审委员（Architecture Review Board，ARB）正式批准该扩展，那么就被称为一个“标准扩展”，标识符使用ARB。第一个ARB扩展是GL_ARB_multitexture。 ​ OpenGL每个新版本中引入的功能，特别是ARB和EXT类型的扩展，通常由数个被广泛实现的扩展功能组合而成。 ​ 代码示例： 12345678910111213141516171819#include &lt;GLTools。h&gt; // OpenGL toolkit#include &lt;GLShaderManager。h&gt; // Shader Manager ClassGLBatch triangleBatch;GLShaderManager shaderManager;void ChangeSize(int w， int h);void SetupRC();void RenderScene(void);gltSetWorkingDirectory(argv[0]);glutInit(&amp;argc， argv);glutInitDisplayMode(GLUT_DOUBLE | GLUT_RGBA | GLUT_DEPTH | GLUT_STENCIL);glutInitWindowSize(800， 600);glutCreateWindow(&quot;Triangle&quot;);glutReshapeFunc(ChangeSize);glutDisplayFunc(RenderScene);SetupRC();glutMainLoop(); 4.2.2.2、DirectX​ 微软在业界的大哥地位，影响力不言而喻。在发展史上，多次和IBM对博公堂，微软宣布，凡是IBM的电脑，不能安装Windows操作系统。软件厂商要挟硬件厂商，在微软发展历史上，留下了光辉的一页。 ​ 音视频是电脑最核心的功能之一，作为系统供应商，微软推出了自己的DirectX产品，该产品在1995年前后十几年间，决定了很多硬件厂商的生死。 ​ 示例代码： 1234567891011121314#pragma comment(lib，&quot;d3d9.lib&quot;)#pragma comment(lib，&quot;d3dx9.lib&quot;)#include &lt;d3dx9。h&gt;LPDIRECT3D9 g_pD3D = NULL;LPDIRECT3DDEVICE9 g_pD3DDevice = NULL;LPDIRECT3DVERTEXBUFFER9 g_pVertexBuffer = NULL; HRESULT InitialiseD3D(HWND hWnd)HRESULT InitialiseVertexBuffer()void SetupRotation()void SetupCamera()void SetupPerspective()void Render()void CleanUp() ​ 当我们平心静气面对这些技术和代码时，深刻的感受到，尤其在早期，当年的D3D技术对显卡厂家的影响是可怕的，对D3D技术的支持程度代表了显卡的受欢迎程度。当年的D3D技术应用最主要是游戏领域。 ​ 从D3D的发展，得到岁月的启示，垄断阻碍了技术的发展，相信在某一天，D3D也终究会退出技术的舞台。 4.2.3、Shader编程​ Shader在3D编程里面占据着重要的地位，是OpenGL、DirectX、Unity等引擎中最核心的概念。成了3D图形图像编程的核心标配。 ​ 示例代码： 12345678910111213141516171819202122232425262728293031#version 130in vec4 vVertex;in vec3 vNormal;uniform vec4 ambientColor;uniform vec4 diffuseColor; uniform vec4 specularColor;uniform vec3 vLightPosition;uniform mat4 mvpMatrix;uniform mat4 mvMatrix;uniform mat3 normalMatrix;smooth out vec4 vVaryingColor;void main(void) { vec3 vEyeNormal = normalMatrix * vNormal; vec4 vPosition4 = mvMatrix * vVertex; vec3 vPosition3 = vPosition4。xyz / vPosition4。w; vec3 vLightDir = normalize(vLightPosition - vPosition3); float diff = max(0。0， dot(vEyeNormal， vLightDir)); vVaryingColor = diff * diffuseColor; vVaryingColor += ambientColor; vec3 vReflection = normalize(reflect(-vLightDir， vEyeNormal)); float spec = max(0。0， dot(vEyeNormal， vReflection));if(diff != 0) { float fSpec = pow(spec， 128。0); vVaryingColor。rgb += vec3(fSpec， fSpec， fSpec); } gl_Position = mvpMatrix * vVertex;} 4.2.2.1、Metal​ Metal是苹果公司的图形编程库，近两年取得了巨大的发展。在Mac平台和IOS平台音视频开发上，Metal是一个很好的选择。 ​ Metal提供对GPU的直接访问，技术人员最大程度地发挥 iOS、macOS和Apple tvOS app中的图形硬件计算潜能。Metal构建于易用的低开销架构之上，提供预编译的GPU 着色器和精细的资源控制。 ​ Metal支持多线程，支持 GPU 驱动命令创建。支持GPU阵列编程，充分利用 Mac Pro 和 Pro Display XDR 的专业级多媒体功能。 ​ 渲染示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344#import &quot;Renderer.h&quot;typedef struct { float red, green , blue, alpha;}Color;@implementation Renderer{ id&lt;MTLDevice&gt; _device; id&lt;MTLCommandQueue&gt; _commandQueue;}//画view的内容，这个代理方法会按帧率执行-(void)drawInMTKView:(MTKView *)view{ //获取颜色 Color color = [self makeFancyColor]; //设置背景色 view.clearColor = MTLClearColorMake(color.red, color.green, color.blue, color.alpha); //创建一个命令缓冲区 id&lt;MTLCommandBuffer&gt; commandBuffer = [_commandQueue commandBuffer]; commandBuffer.label = @&quot;mycommand&quot;; //渲染过程，用于保存渲染过程的结果 MTLRenderPassDescriptor *renderPassDescriptor = view.currentRenderPassDescriptor; if (renderPassDescriptor != nil) { id&lt;MTLRenderCommandEncoder&gt; renderEncoder = [commandBuffer renderCommandEncoderWithDescriptor:renderPassDescriptor]; renderEncoder.label = @&quot;myrenderEncoder&quot;; //结束编码 [renderEncoder endEncoding]; //注册一个可绘制图像 [commandBuffer presentDrawable:view.currentDrawable]; } //提交命令到GPU [commandBuffer commit];}//视口发生变化会被调用- (void)mtkView:(nonnull MTKView *)view drawableSizeWillChange:(CGSize)size {}@end 4.2.2.2、Vulkan​ Vulkan是一个跨平台的2D和3D绘图应用程序接口（API），科纳斯组织（Khronos Group）在2015年游戏开发者大会（GDC）上发布。 ​ Khronos Group目前是世界多媒体、音视频、图形图像领域的核心协会，拥有世界顶级会员单元，拥有世界级的技术标准。 ​ 科纳斯把Vulkan API称为“下一代OpenGL行动”（next generation OpenGL initiative）或“glNext”。就像OpenGL，Vulkan针对实时3D程序（如电子游戏）设计，Vulkan并计划提供高性能和低CPU管理负担（overhead），这也是Direct3D12和AMD的Mantle的目标。Vulkan兼容Mantle的一个分支，并使用了Mantle的一些组件。 ​ Vulkan 是 AMD Mantle 的后续版本，继承了强大的低开销架构，使软件开发能够全面获取 Radeo GPU 与多核 CPU 的性能、效率和功能。 ​ Vulkan 支持深入硬件底层的控制，为各种系统带来更快的性能和更高的影像质量。Vulkan API 还提供超高的 OS 兼容性、渲染特性和硬件效率。 ​ 基于GCN架构的Radeon 显卡拥有强大的“异步计算”功能，使显卡并行处理3D几何图形与计算工作量。当游戏需要同时计算复杂照明与渲染人物时，这种功能就找到了用武之地。这些任务并不需要在Radeon显卡上串行运行，节约时间、提升整体帧速率。Vulkan在近期Windows和Linux系统上都有很好的应用。 ​ 目前，Vulkan得到广泛的的支持，在硬件上，无论是服务器、桌面、移动端，都进行了完好的支持。在系统层面上，Linux、Windows、Mac、Android、IOS都为Vulkan提供了完备的接口。 ​ 示例代码： 1234567891011121314151617181920212223242526272829303132#include &lt;vulkan/vulkan.h&gt;#include &lt;stdexcept&gt;#include &lt;functional&gt;class HelloTriangleApplication {public:void run() { initVulkan(); mainLoop(); cleanup(); }private:void initVulkan() {}void mainLoop() {}void cleanup() {}};int main() { HelloTriangleApplication app;try { app.run();}catch (const std::runtime_error&amp; e) { std::cerr &lt;&lt; e.what() &lt;&lt; std::endl; return EXIT_FAILURE; } return EXIT_SUCCESS;} 4.3、启示​ 计算机图形学的发展不是一蹴而就的，前期发展过程中，百花齐放，百家争鸣。各家接口不一，处于蓬勃不稳定发展期，系统厂商、硬件厂商、软件厂商、行业协会一起，共同推出软硬件规范，OpenGL就是一个成功的表现。 ​ 技术发展过程中，一些厂商没有明确的规范或没有明确的支持规范，进而失败了。没有硬件厂商支持的规范同样是可悲的，很快被淘汰了。软件运行在硬件之上，硬件在一定程度上决定着软件。软件反过来影响着硬件。 ​ 3D时代绚丽多彩，现实生活姹紫嫣红，多年技术积淀，在3D时代五彩斑斓，应用辈出。显示技术的应用发挥到了极致，对计算技术的发展做出了卓越的贡献。 ​ 3D时代的到来，为显示技术的精细化发展吹响了号角。在计算机图形图像技术发展史上，承前启后，继往开来。 5、移动时代​ 移动时代可以追踪到很远，从古老的电台到1948年贝尔实验室的Bell boy，到1956年摩托罗拉的BP机。寻呼机的发展历史，主要是通讯技术的进步。和主题有一定偏差，不做阐述。翻开半个多世纪的画卷，历史没有想到的是，通讯技术在今天有如此傲娇的成绩。 ​ 早期电脑至上，后来移动至上。不可怀疑的是，移动互联网高速发展的今天，手机成为应用系统最重要的终端。 ​ 移动端图形系统的研究，是移动应用终端开发的重中之重，也是手机底层技术的核心要素。 ​ 本篇从手机发展史起笔，到移动显示芯片厂家、移动芯片技术与流行图形库讲述，希望给移动端音视频开发带来有益的启示。 5.1、手机时代​ 那年的“hello moto”，能否勾起你绵绵的情思。这颗圆圆的行星，”hello moto”之声奏响了银河系无线通讯的号角。那个年代手提电话(也叫移动电话)，还不叫手机，绰号大哥大，也叫板砖。当年的大哥大仅仅局限通话，短信功能也不具备。有了大哥大，不学数理化，大哥大成为了身份的象征。 ​ 硬件技术的进步，手机向小型化发展。两个企业的高光时刻带来了，当年的摩托罗拉和诺基亚堪称业界大哥，赚钱赚到罗马。从早期的单色屏逐渐发展到彩色屏。从1990年到2005年，那是诺基亚和摩托罗拉的时代。昨日年少英雄，指点江山，今天英雄白发，美人谢幕。互联网给我们多少唏嘘。 ​ 工艺的提升不仅推动硬件设计的进步，更推动软件系统的发展，手机应该拥有更强大的功能。在这一大环境下，SmartPhone、Symbian、Linux手机操作系统不断涌现，为智能手机系统发展发起了前期的火力侦察。 ​ 乔布斯担负着上帝赋予的伟大使命，2007年，Iphone诞生了。伴随着Iphone的诞生，Android的出现，智能时代到来了。完成了伟大使命的乔帮主，这位天选之子，4年之后，撒手人寰，魂归天堂。而他，留下了这颗行星上市值最高的公司。 ​ 智能手机的兴起，促进移动端硬件提升，显示技术也有很大变化。移动时代硬件发展同样精彩,充满了竞争与杀戮，野蛮和邪恶，和PC端同样精彩。软件方面相对平滑平淡，没有大的开开合合。 ​ 手机的发展史，也是一部无线技术的发展史。硬件技术与通讯规范密切相关，翻开移动通讯的日记，从1G到5G，感时光如梭，叹技术神速。通讯技术规范不属于本主题内容，不做阐述。 ​ 移动时代芯片科技，看到了中国企业的影子，东方用资本开始了买买买的过程。对芯片技术的渴求，资本是最直接的倾诉。期望不远的未来，有一家拥有核心技术的东方芯片厂商。在技术的长河中，书写浓重的一笔。在芯片的交响乐中，奏出中国的声音。 ​ 波澜壮阔的手机应用，后台是芯片技术的驱动。下一节，我们从芯片的角度回顾。 5.2、移动端主流显示芯片5.2.1、ARM​ ARM不仅进行嵌入式CPU架构授权，也进行GPU架构授权。在芯片架构设计上，ARM稳坐头把交椅。2006年，ARM 完成对挪威Falanx公司的收购，获得其移动GPU技术，完成对原有IP技术的扩展。也就是从那个年代开始，ARM闪亮登场。 ​ ARM是有先见之明的，15年后，GPU广泛用于智能手机、DTV和平板电脑等多种设备。15年时间，ARM Mali技术成为全球出货量第一的GPU，预计2020年总计出货量就超过15亿。在移动图形硬件发展史上，ARM mail是必谈的技术。 ​ Mali GPU架构发展了3代，Utgard、Midgard和Bifrost。Utgard的代表是Mali-400 MP，三星的Exynos4412用的就是这款GPU，Mali-450至今的一些电视芯片还在使用（例如小米电视）。Midgard的型号是Mali-T系列，联发科Helio X20就用的是Mali-T880，而Bifrost的型号是Mali-G系列。 ​ ARM的Mali可以说是ARM CPU的“黄金搭档”，架构上不是最先进，普及率非常高，低廉的授权费是芯片厂商比较喜欢的。ARM科技与方案的授权，保证了技术纯粹，降低了经营风险。 ​ Mali是一款高端GPU，将图形IP视觉娱乐变为现实，市场占安卓智能手机30%以上，可与PowerVR SGX系列GPU对比。 ​ 应用基于ARM体系结构的移动设备上，得益于CPU占有率发展迅猛。ARM® Mali™ 系列 GPU 为所有嵌入式图形 IP 和视频 IP 提供完善的解决方案，使设备制造商和内容开发商能够为最广泛的消费类设备（手机、游戏机、智能本、HDTV）提供最高质量的尖端多媒体解决方案。GPU是近些年硬件最重要的应用之一，当年ARM收购Falanx简直是神来之笔，为ARM的做大做强埋下了伏笔。 ​ Mali 嵌入式图形 IP 设计用于提高能源效率和解决性能问题，包括世界上最小的 GPU、完整多核可扩展性（最高可达 1080p）、用于可视计算的 GPU 的通用计算 (GPGPU) 以及多用途应用程序。所有 Mali GPU 都受预先集成的 Mali 图形驱动程序软件支持。 ​ 灵活性是要考虑的一个重要因素，支持的业界标准开放式 API 包括OpenVG、OpenGL ES、OpenCL以及DirectX®。这些是ARM成功的基础。 ​ ARM在芯片架构设计上，有多见的经验积累。高通在通讯领域里，有最好的技术产品。 5.2.2、Qualcomm​ 高通（Qualcomm）的英文是Quality Communications，翻译就是高质量通信。创始人雅各布斯是搞通信工程搞到卫星领域的男人，高通今天“连接万物”的使命从创立那天就奠定了。这是一家超强的公司，其技术延续性与强大性首屈一指。在这个年代的人，都用过高通的产品或者技术。 ​ 1985年成立的公司，在1989开始推广CDMA。业界的注意力都在TDMA技术上（后来演变成GSM），高通靠着自己的实验和测试，让CDMA在1993年成为行业标准并和GSM分庭抗礼，这就是高通的水平。 ​ 高通研发投入占比常年在收入的20%以上。前30年，高通累计投入了超过440亿美元的研发经费，获得了超过13万项全球专利。 ​ 2007年，那一年发生了两件改变世界的事情：乔布斯发布iPhone，高通推出了骁龙芯片Snapdragon S1。 ​ 13年间，高通在移动SoC领域打赢过两次重大战役，第一次让德州仪器、英伟达这些业界大厂退出了移动高端市场。第二次则是让联发科败走中高端。中途还插播过英特尔靠着Atom+补贴，打了几年酱油的历史。这些恐怖成绩的存在，是高通对硬件技术的不懈追求。 ​ 时间线调回2007年，从那时开始，高通每年的SoC，都会带着新的制程、新的CPU、GPU和调制解调器亮相。高通在调制解调器上的优势，犹如不可逾越的鸿沟，把其它大厂排挤在千里之外。高通把调制解调器分为两种，一种骁龙，一种其它。 ​ 2007年安卓和Windows Mobile的蛮荒时代，高通MSM7225/7625这些上古的SoC连GPU都已经支持3G了，比国内称为3G元年的2009年还早了整整2年。作为移动技术的顶级元老，这个不让人意外。 ​ 移动GPU，特别是Adreno系列，在近10几年一直维持着远超摩尔定律的性能增速。这个故事出现得最密集的词，就是“暴涨”二字。在众多公司中，高通像一个工程师一样，坚守硬件设计的阵地。 ​ 2009年，MSM7227（隶属骁龙S1）搭载的Adreno 200，其浮点性能是2.1GFLOPS。而2012年初的Adreno 225上，浮点性能已经暴涨了10数倍，达到25 GFLOPS。 ​ 手机GPU和电脑有一定的区别，手机GPU是整合到SoC内的，电脑可以有独立显卡。高通的adreno的技术部分源自高通从AMD收购的移动GPU部门。 ​ 高通的GPU市场占有率很高，adreno的表现也足够优秀，支持足够多的新特性，性能比较强，功耗表现也很理想。 ​ 如果说2015年之前，其他厂商的GPU还算和高通追得很紧的话，那在骁龙820/821的Adreno 530开始，高通就进入了无人之境。或是从绝对性能，或是从能耗比上，拉开了和苹果、三星、海思、联发科的差距。现在唯一能在GPU性能上跟着高通的，就只剩苹果了。但同代产品上，高通总是能在能耗比上压苹果一头。 ​ 让人疯狂的是，除了能耗比其它公司占优之外，高通的Adreno几乎常年都是用着同代面积最小的GPU芯片面积。三星Exynos 9810上的GPU面积达到了25 mm2，Kirin 970上也有18 mm2，但高通硬生生只用了10 mm2出头的芯片面积，做到了更强的性能更低的能耗。 ​ 高通在嵌入式技术上的能力是有目共睹的，嵌入式硬件对移动端提供了核心的支持。在图形图像视频硬件技术上，高通道高一丈。、 ​ 在互联网众多科技公司中，高通算是厚积薄发。在企业发展上，稳健踏实，在芯片领域具有举足轻重的地位。在互联网、人工智能高速发展的今天，高通的硬实力展现出来。 ​ 苹果感谢高通，高通的存在，阻击了一线科技公司对苹果的围剿。在技术大潮中，高通不断为苹果输送技术的血液，成就了苹果的万亿帝国。 5.2.3、Apple​ 2006年到2013年，AMD和NVIDIA在移动市场竞争中完全失策。丢掉全球移动GPU主要供应商的同时，苹果一步步取代他们并成为最强大、最主流的GPU处理器的生产者。AMD和NVIDIA重蹈Intel的覆辙，丢掉移动GPU市场。 ​ 当年Intel未能预料iPhone的潜力，忽视了移动市场。让ARM从一家基础移动处理器生产商一跃成为智能手机和平板处理器的主要生产商，而移动GPU的发展也十分相似。历史不断的给苹果机会，并给与其把握机会的能力。 ​ iOS符合用户知觉，视觉美观，图形环境(归功于GPU加速)，这是iPhone销量居高不下的因素。Google完全没有意识到iPhone成功的关键。 ​ iPhone对GPU的重视，让iPhone适合游戏。从一开始，游戏是苹果应用商店里的主角，改变了大众对苹果“没有游戏”的印象。iPhone、iPod touch还有2010年的iPad，均作为独立的移动游戏设备颠覆了游戏市场。 ​ 苹果推出了新的API：Metal。很多优秀的开发者都利用了这套新的API开发新应用。Metal可以让游戏和其他需要图形性能的应用绕过OpenGL，利用苹果64位处理器的强大GPU。苹果在图形处理速度上有很大优势，在移动游戏方面尤其明显；而Metal则让优势进一步增加。 ​ 苹果把Imagination的人挖了之后自研了GPU，然后把这帮人解散了。这件事情告诉我们，苹果是靠不住的，不知道哪天又会卸磨杀驴。 ​ 近些年苹果GPU走向自研道路。未来谁掌握了最强的手机图形性能，谁就可以在市场上获得更大主动权，苹果深谙此道。在进行技术拓展的同时，进一步巩固A系列芯片的性能优势。 ​ A11尽管采用的是和骁龙835一样的10nm工艺，整体性能仍然强于骁龙835。GPU相比A10提升了30%，三核心设计，并对沉浸式 3D 游戏和 AR 增强现实进行了优化。这是苹果第一代自研GPU，苹果真正能把自己的GPU完善起来还需要1-2年时间。那时A系列GPU和CPU融合的会更加紧密，在性能和能耗上会有更大的突破。 ​ 发展的关键时刻，上帝偏爱苹果。面临技术抉择时，苹果往往押宝成功。看似孤傲独行，重大战役到来时，总有友军出现。这些因素的综合，使苹果稳坐科技公司第一宝座。 5.2.4、Imagination Technologies​ Imagination Technologies前身是video logic公司。曾经的全球移动 GPU IP龙头，深耕GPU 内核研发和设计，曾是苹果御用图形技术提供商，总部位于英国。2018年被中资背景企业收购，未来发展不明。 ​ Imagination Technologies的核心产品是IMG A系列产品，被设计为可应用于各种场景的GPU，支持自动驾驶、AIoT、数字电视、机顶盒、移动设备等智能应用。 ​ IMG A系列在多个市场中授权客户，这点和ARM相像。首批搭载该IP的SoC器件在2020年供货。Imagination Technologies宣布，紫光已获得最新一代神经网络加速器（NNA）PowerVR Series3NX半导体IP授权许可，是面向中高端移动设备市场的系统级芯片。 ​ 散热条件限制，大多数移动GPU很难提供持续一致的游戏体验，芯片发热其性能下降到不可接受的水平。IMG A系列则以一致的帧速提供持续可靠的性能以及更长游戏时间，避免了因芯片过热导致时钟降频甚至故障等过热情况，IMG A系列有一定的技术优势。 ​ IMG A系列采用Imagination的HyperLane技术，独立的硬件控制通道被隔离在内存中，将不同的任务同时提交给GPU，实现GPU多任务处理。 ​ 通过AI Synergy，GPU在可以提供图形处理功能的同时，使用备用资源支持可编程AI以及固定功能，即高度优化的Imagination神经网络加速器。AI Synergy在最小的芯片面积中提供可编程的人工智能，统一的软件栈可实现灵活出色的性能。 ​ PowerVR曾经是苹果“御用”的GPU，性能表现强大、架构先进，不仅在iOS领域，在安卓领域使用也很广泛。当年的一代神U联发科MT6577就使用了大幅度超频的SGX531，性能是低端机里的翘楚。 ​ 但是，因为较高的授权费用，PVR逐渐失去了安卓市场，客户纷纷转向更廉价的ARM Mali。虽然有联发科Helio X30等的支持，PVR仍然是强弩之末。再加上苹果的抛弃（苹果宣布自研GPU）和挖墙脚，等待Imagination的只有卖身的悲惨命运。 ​ GPU技术的选择，是很多芯片公司做强做大的基础。尤其是智能时代的带来，GPU的应用汹涌澎湃，风卷云涌。 5.2.5、Vivante​ Vivante(图芯)曾经是嵌入式图形处理器（GPU）的技术先行者。总部位于加州，为全球移动设备和家庭娱乐市场提供顶级应用，超级处理器解决方案。曾经拥有种类繁多的2D/3D图形处理器。 ​ 用硅印模，为业界标准应用程序接口提供强大支持。图芯芯片技术将桌面质量图象和性能带入汽车、手掌中的屏幕。优秀可升级的嵌入式解决方案是可升级的，建立在业界标准之上，且优化功耗、性能和大小。 ​ 图芯不断增长的产品系列，与全球多家公司成功合作。对移动视觉逼真和高清视觉逼真的核心技术，成为当年顶级移动端图形图像技术供应商。 ​ 2016年01月08日，图芯被中国芯原收购，产品开始沉默。对OpenGL ES、OpenVG、DirectX的成功支持，是图芯前期成功的核心要素。 5.2.6、NVIDIA、AMD、Intel​ 移动端图形技术的快速发展，加速了移动时代的到来。当年PC端显示技术的大佬们，变得孤单与寂寞，这能告诉我们什么呢？ ​ 手机gpu不能单卖，需要可用的基带，NVIDIA并没有基带。在不需要基带的移动gpu上，NVIDIA做的很好，例如switch gpu。 ​ 英伟达开发过手机芯片——Tegra系列，现在Tegra已经谢幕，当年使用Tegra芯片手机风行一时。 ​ 英伟达在Tegra4及之前的GPU架构叫GeForce ULP，Tegra4号称“72核GPU”，但架构十分老旧，是DX9时代的分离渲染架构。Tegra因为基带芯片问题退出手机市场，后来推出了Tegra K1用上先进的Kepler架构，但是一切都太晚了。 ​ NVIDIA现在和可预见的将来都没有手机产品，这是NVIDIA不能接受的。期望有一天，在移动端显示芯片上，上演王者归来。AMD不仅缺少移动GPU，还几乎没有市场份额。Intel在补贴硬件厂商让它们使用Intel产品(造成了每年400亿美元的损失)。 ​ 世界上影响力最大的两个GPU厂家，AMD和NVIDIA。两个微处理器的发明者Intel和德州仪器，几乎全都被苹果逐出了移动市场。现在市场中只有低端零件厂商、苹果高端、高销量的iOS设备竞争。这令人感叹，苹果跳出了时代的局限性，在桌面端和移动端成为最成功的企业，上帝太偏爱苹果了。 ​ 当年Nvidia买了Icera，i500之后，折腾SoC，没有下文。15年宣告放弃，现在想用只能外挂基带。黄药师仰天长啸，移动端报国无门。 ​ 外挂是可以的，DrivePX2上接GPU用PCIE 4x，然后GPU有自己显存，这个不是手机能接受的。如果用CCI，访问内存没有问题，但有其它局限性。Tegra X1后黄总就不用CCI互联了。 ​ AMD、INTEL和英伟达道路相似，3D时代雄起，移动时代沉寂，智能时代奋起。每一家公司都有各自的领地。那些成功的跨界，成就了技术的艳遇。 ​ 就工艺而言，相对于CPU，GPU技术难度低一些。这也是众多小厂开始向GPU迈进的原因。在移动时代，科技的发展创造机会，很多传统的CPU、GPU大厂由于固守轨道，错过了GPU发展的黄金时代。 5.3、移动图形库​ 移动手机图形接口上，没有桌面端的万马奔腾、百舸争流，整体相对平稳与自然。无论Android还是IOS，都是Linux的内核。所以在移动图形库的选型与发展上，和桌面端图形库有一个很好的承接。OpenGL桌面端不可撼动的地位，移动端，OpenGL的简化版OpenGL ES应运而生。 5.3.1、OpenGL ES​ OpenGL ES 是 OpenGL三维图形 API 的子集，针对手机、PDA和游戏主机等嵌入式设备而设计。 ​ OpenGL ES 是 OpenGL 裁剪定制而来，去除了复杂图元等非绝对必要的特性。OpenGL ES 2.0 参照 OpenGL 2.0 规范定义。 ​ OpenGL ES 免授权并且跨平台，强大的2D和3D图形应用程序接口API，针对多种嵌入式系统专门设计，包括控制台、移动电话、手持设备、家电设备和汽车。由精心定义的桌面OpenGL子集组成，实现了软件与图形加速间灵活强大的底层交互接口。 5.3.1.1、OpenGL ES 版本与功能​ OpenGL ES包含浮点运算和顶点运算，及EGL便携设备的本地视窗系统规范。 ​ OpenGL ES 1.X 面向功能固定的硬件所设计，并提供加速支持、图形质量及性能标准，也就是固定管线编程。OpenGL ES 2.X 提供包括遮盖器技术在内的全可编程3D图形算法。OpenGL ES 3.x则在可编程管线上进行了增强。 ​ OpenGL ES提高了不同消费电子设备的3D图形渲染速度，在嵌入式系统上实现了全面可编程的3D图形。 ​ OpenGL ES工作组在六个月内更新OpenGL ES采纳者项目，提供兼容性测试，并提供相关源代码。目前 Corporation、Imagination、NVIDIA、高通、ZiiLABS等都表达了对OpenGL ES 3.0的大力支持。最新GPU就支持OpenGL ES 3.0。 5.3.1.2、OpenGL ES 3.0新功能​ 1、渲染管线多重增强，实现先进视觉效果的加速，包括遮挡查询(Occlusion Query)、变缓反馈(Transform Feedback)、实例渲染(Instanced Rendering)、更多渲染目标支持。 ​ 2、高质量ETC2/EAC纹理压缩格式成为一项标准功能，不同平台上不再需要不同的纹理集。 ​ 3、新版GLSL ES 3.0着色语言，全面支持整数和32位浮点操作。 ​ 4、纹理功能增强，支持浮点纹理、3D纹理、深度纹理、顶点纹理、NPOT纹理、R/RG单双通道纹理、不可变纹理、2D阵列纹理、无二次幂限制纹理、阴影对比、调配(swizzle)、LOD与mip level clamps、无缝立方体贴图、采样对象、纹理MSAA抗锯齿渲染器。 ​ 5、更多精确尺寸纹理和渲染缓冲格式，便携移动应用更简单。 5.3.1.3、OpenGL ES 示例代码1234567891011121314151617181920212223242526272829303132333435363738public class MainActivity extends Activity { private final int CONTEXT_CLIENT_VERSION = 3; private GLSurfaceView mGLSurfaceView; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); mGLSurfaceView = new GLSurfaceView(this); if (detectOpenGLES30()) { mGLSurfaceView.setEGLContextClientVersion(CONTEXT_CLIENT_VERSION); mGLSurfaceView.setRenderer(new RendererJNI(this)); } else { Log.e(&quot;opengles30&quot;, &quot;OpenGL ES 3.0 not supported on device. Exiting...&quot;); finish(); } setContentView(mGLSurfaceView); } @Override protected void onResume() { super.onResume(); mGLSurfaceView.onResume(); } @Override protected void onPause() { super.onPause(); mGLSurfaceView.onPause(); } private boolean detectOpenGLES30() { ActivityManager am = (ActivityManager)getSystemService(Context.ACTIVITY_SERVICE); ConfigurationInfo info = am.getDeviceConfigurationInfo(); return (info.reqGlEsVersion &gt;= 0x30000); }} 5.3.2、其它​ Vulkan和Metal不仅是3D时代的图形框架，也是移动领域的核心图形图像框架。关于Metal和Vulkan的知识，参考前面主题。 5.4、启示​ 梳理这段历史时，我们发现，信息科技的核心是芯片，芯片技术被国外巨头垄断。偶尔有中资公司的影子，大多昙花一现。芯片技术是百年大计，很难实现弯道超车。 ​ 在计算科技白皮书里，大多是欧美科技的影子，东方公司比重较低。这注定了科技赶超是一个长期的过程。 ​ 在软件规范制定上，面临同样的情况。未来几十年，在软件规范上，我们埋头苦干，奋勇向前。 ​ 通讯核心技术上，依然有很大不足。但在市场应用上，我们拔得头筹。在移动商务、移动支付、短视频应用上，捷报频传。 ​ 美摄科技坚持音视频核心技术研究，底层硬件技术研发。在技术接口，产业应用上乘风破浪，激流勇进。在祖国图形图像技术建设上，做出应有的贡献。 ​ 缘聚缘散，时空变换。1978年之后，科技的春天再次到来了。从基础芯片，软件规范，到行业应用。我们流年笑掷，坚信未来可期。 6 人工智能时代6.1、人工智能发展历史​ 人工智能是科技永久的话题，计算机本身是一个工具，人工智能发展史上，计算机的出现，是人工智能发展的伟大节点。21世纪仅仅是人工智能的开端，人工智能的发展方兴未艾。 ​ 早期的人工智能偏重于理论，西方的神学大师、哲学先驱、数学巨匠一起，为人工智能奠定了文化基础，下面我们开始与大师的对话。 6.1.1、大事记​ 200年前，巴贝奇，一个英国数学家，设计了第一台计算二次多项式的计算机器，叫做差分机，摇动手柄，计算出x*x+a式子的值。当时的东方，大清皇朝，即将面临血色的辉煌。 ​ 1956年，几个科学家，聚会在美国汉诺思小镇宁静的达特茅斯学院，利用暑假的两个月进行封闭式的讨论研究，主题是“达特茅斯夏季人工智能研究计划”。首次提出“人工智能（Artificial Intelligence，简称AI）”这一概念，人工智能学科应运而生了。当年简单的两个单词，成为今天科技的主旋律。 ​ 1959年，塞缪尔讲到，计算机可以比人更好地编程，进行国际象棋游戏时，创造了“机器学习”(Machine Learning)一词。上承接人工智能，下承接自然语言与机器视觉。编程邂逅人工智能，人工智能青梅竹马的年代开始了。 ​ 1965年，Joseph Weizenbaum，开发ELIZA，一个交互式计算机程序，用英语与人交谈。Weizenbaum有一个目标，证明人工智能思维与人类思维之间的沟通是肤浅的。这是第一个通过图灵测试的软件程序，“对话就是模式匹配”，代表着自然语言技术的开端。60年后的今天，自然语言技术应用广泛。 ​ 1978年，卡耐基梅隆大学，开发自动选配计算机配件的程序XCON，1980年投入工厂使用，包含2500条规则，后续几年处理了超过80000条订单，准确度超过95%，每年节省超过2500万美元。这是早期的专家系统，开始于生产应用。我们今天进行自动购物时，很少有人知道半个世纪以前，在大洋彼岸已被广泛应用。 ​ 1979年，斯坦福大学，制造了无人驾驶车Stanford Cart，这是汽车的第一次，依靠视觉感应器，在没有人工干预的情况下，自主穿过散乱扔着椅子的房间，需要几个小时才能完成。当年的视觉感应器，就是今天的机器视觉，当年的无人工干预，就是今天的自动驾驶。 ​ 1982年，英国科学家霍普菲尔德几乎同时与杰弗里·辛顿，发现了具有学习能力的神经网络算法，沉寂10年之后，神经网络有了新的进展。从此神经网络高速发展，90年代开始商业化，用于文字图像识别和语音识别。今天的神经网络工程师们，鲜有人知道这两位大师的名字。 ​ 1986年，梅赛德斯 - 奔驰，Ernst Dickmanns的指导下建造并发布了一辆配备摄像头和传感器的无人驾驶厢式货车。能够在没有人类驾驶员的道路上行驶高达55英里/小时。当年的神奇幻想，今天的美好现实。Ernst Dickmanns，成为了自动驾驶的鼻祖，当年的奔驰货车，也称了自动驾驶的先驱。 ​ 1998年，Dave Hampton和Caleb Chung。发明了Furby，第一款玩具机器人。2000年前后，日本科技公司凭借着较好的工业基础，在早期智能时代占据着不可或缺的位置。 ​ 1999年，索尼。推出AIBO，价值2000美元的机器人宠物狗，与环境，所有者和其它AIBO的互动来“学习”。功能包括能解和响应100多个语音命令并与人类所有者进行对话。 ​ 2002年，Roomba，自动机器人真空吸尘器，避开障碍物进行清洁。 ​ 2006年，杰弗里辛顿。出版《Learning Multiple Layers of Representation》，奠定神经网络的全新架构，今天人工智能的核心技术。短短10年间，数学冰山背后，春风化雨，夏露凝香。 ​ 2007年，Fei Fei Li。出生于北京，美国国家工程院院士，Twitter独立董事。组建ImageNet，一个注释图像数据库，帮助物体识别。 ​ 2009年，吴恩达，使用图形处理器（GPU而不是CPU）进行大规模无监督式机器学习。取得了惊人的成就，向世人展示了一个超强的神经网络，它在自主观看千万张图片之后，识别小猫的图像。这是历史上在没有人工干预下，自主强化学习的里程碑式事件。向世人展示了无监督学习的价值，自此AI识别，温柔了岁月，惊艳了时光。 ​ 2011年，Watson，电视游戏中。回答IBM创建的计算机自然语言问题，击败了两个前Jeopardy冠军，肯詹宁斯和布拉德鲁特。自然语言处理逐步开始步入人类生活。 ​ 2015-2017，AlphaGo，谷歌Go的计算机程序，击败了各种（人类）冠军。当时名噪一时，为人工智能做了最好的技术营销。 ​ 2015年，谷歌。发力自动驾驶，Waymo今天是自动驾驶排行第一名。当年满头青丝的Ernst Dickmanns，今天已是白发苍苍。下图右为Ernst Dickmanns。 ​ 2015 年，沈向洋，微软亚洲研究院视觉计算组开发的基于深度卷积神经网络（CNN）的计算机视觉系统，在 ImageNet1000 这项视觉识别挑战中第一个超越人类视觉能力的计算机系统。2019年，沈向洋离开微软，成为清华大学双聘教授。这位来自南京，人工智能国际巨人，把中国的人工智能技术推向一个新的高度。 ​ 2016，微软。组建“微软人工智能与研究事业部”(MicrosoftAI and Research Group)。人工智能是微软的梦想，1991年，盖茨先生就做过人工智能的预言。 ​ 人工智能在模拟、仿真、游戏方面也有着广泛的应用，国内2015年以前，仿真领域是人工智能最核心的领域，以后逐渐向其它领域过渡。 6.1.2、启示​ 2020年前后，人工智能迎来了高速发展期，2019年，人工智能元年。大数据、数据挖掘、机器学习等理论百花齐放，人工智能的时代终于到来了。 ​ 凝视这段历史时，早期的人工智能偏重于模拟仿真，没有实时性。摄像与视频技术的进步，人工智能向实时性发展，实时性有着重要意义，开启了人工智能社会应用新篇章。 ​ 人工智能代表着大数据量的到来，没有大的数据量无法进行有效的分析，数据处理是人工智能的核心要素，数据处理今天由并行计算来完成。 ​ 大的数据量不仅对算法有要求，对算力也是一个考验。人工智能需要巨大的算力，没有算力谈不上人工智能。目前在人工智能初级阶段，科技公司算力主要靠CPU、GPU。大的科技公司靠超算中心、VPG、APU、TPU、NPU等来解决。大数据的超强能力，为人工智能的算力提供强有力的支持。 ​ 人工智能目前阶段两个主要表现，第一个是自然语言处理，第二个是机器视觉。自然文字符号和音视频是人类信息两个重要的载体。 ​ 机器视觉，很多年前，国外有一些公司在做，仅限于一些专业领域。90年代进入国内后，中科院物理所引进国外专业相机，结合国内应用，开发出相关检测系统。 ​ 新的硬件与显示标准对智能视觉处理有着很大推动，随着并行计算的发展。可以坚信的是，视觉智能是未来人工智能发展的重要方向。 6.2、硬件发展​ 人工智能时代需要硬件的支持，不仅仅是外设，更是数据计算。在此需求下，不仅外设的繁荣，更是芯片技术的爆发。 ​ 芯片技术为智能处理提供了基础，在数据阶段处理，为CPU、GPU提供物理计算基础，在此基础上，有了并行计算架构。无论云平台、大数据、机器学习、区块链无一不是建立在并行计算的基础上。 ​ 60年代，中国挥剑斩芯片，丧失发展先机。今天，倾国之力，十万亿级投资，发展芯片，留给我们多少启示。 ​ 下面通过芯片、相机传感器硬件角度讲述，其它层面参考相关资料。智能时代的机器视觉视频来自于相机，考虑了相机因素。 6.2.1、AI/AR/VR芯片​ 人工智能首先是硬件技术的进步，硬件技术的核心是芯片。芯片技术是集成电路的高度封装。芯片技术是半导体技术的体现，整个生产过程与产业链较长，需要多家公司合作才能完成。 ​ 顶级科技公司钟情于芯片研发，包括AI/AR/VR芯片研发。微软、特斯拉、英伟达、facebook、谷歌、NXP、华为等。人工智能时代的到来，芯片的多样性与功能性都有很大变化。技术的风起云涌，为芯片制造提供了契机。 ​ 人工智能时代，AI/AR/VR芯片快速发展，为人工智能提供澎湃动力支持。芯片技术是人工智能后续阶段的关键技术，没有芯片技术的进步，人工智能将会举步不前。 6.2.2、相机芯片​ 相机，记录着社会文明。相机，留存着社会点滴。相机，助力着生产生活。相机，是机器视觉第一步的表达。 ​ 整个视频处理流程，相机是前端，机器视觉部分处理在前端实现。学习机器视觉，有必要对相机简单了解。 ​ 对于工业视频而言，相机是重中之重，相机技术有很多分类。本部分通过传统相机和工业相机进行讲述。 6.2.2.1、传统相机​ 相机技术发展多年，主要是图像传感器的发展，目前分为CCD和CMOS两种。 6.2.2.1.1、CCD​ CCD芯片是将光信号转换成电信号的芯片，在数码相机、摄像机中，光信号转换成电信号，然后处理，编程数码照片文件。 ​ CCD芯片，使用高感光度的半导体材料制成，把光线转变成电荷，通过模数转换器芯片转换成数字信号，数字信号经过压缩后由相机内部的存储设备保存，然后把数据传输给计算机，借助于计算机的处理手段，根据需要和想像来修改图像。 ​ CCD芯片由感光单位组成，通常以百万像素为单位。CCD表面受到光线照射时，每个感光单位会将电荷反映在组件上，所有的感光单位所产生的信号加在一起，构成了一幅完整的画面。 ​ CCD图像传感器是按一定规律排列的mos（金属—氧化物—半导体）电容器组成的阵列，在p型或n型硅衬底上生长一层很薄（约120nm）的二氧化硅，再在二氧化硅薄层上依次序沉积金属或掺杂多晶硅电极（栅极），形成规则的mos电容器阵列，再加上两端的输入及输出二极管就构成了CCD芯片。 6.2.2.1.2、CMOS​ CMOS相机采用CMOS图像传感器的设备。CMOS一般应用在普通数码设备中，CCD一般应用高档数码设备中，CCD比CMOS单位成像的效果要好。CCD镜头比CMOS分辨率要高。 ​ CCD和CMOS在制造上的主要区别是CCD是集成在半导体单晶材料上，而CMOS是集成在被称做金属氧化物的半导体材料上。CCD只有少数几个厂商索尼、松下等掌握这种技术。CCD制造工艺较复杂，采用CCD的摄像头价格昂贵。 ​ 相同像素下CCD的成像通透性、明锐度都很好，色彩还原、曝光可以保证基本准确。CMOS由于低廉的价格以及高度的整合性，因此在摄像头领域还是得到了广泛的应用。 ​ CMOS的信号是以点为单位的电荷信号，而CCD是以行为单位的电流信号，前者更为敏感，速度也更快，更为省电。高级的CMOS并不比一般CCD差，CMOS工艺还不是十分成熟，普通的CMOS一般分辨率低而成像较差。 ​ CCD或CMOS，基本上都是利用矽感光二极体进行光与电的转换。光线越强、电力越强；反之，光线越弱、电力也越弱的道理，将光影像转换为电子数字信号。 ​ CCD每曝光一次，在快门关闭后进行像素转移处理，将每一行中每一个像素（pixel）的电荷信号依序传入“缓冲器”中，由底端的线路引导输出至CCD旁的放大器进行放大，再串联ADC输出；相对地，CMOS的设计中每个像素旁就直接连着ADC（放大兼类比数字信号转换器），信号直接放大并转换成数字信号。 ​ CCD的充分保持信号传输时不失真，透过每一个像素集合至单一放大器上再做统一处理，保持资料的完整性；CMOS制程简单，没有专属通道，必须先放大再整合各个像素资料。 ​ 由于CMOS每个像素包含了放大器与A/D转换电路，过多的额外设备压缩单一像素的感光区域的表面积，因此相同像素下，同样大小之感光器尺寸，CMOS的感光度会低于CCD。 ​ CMOS应用半导体工业常用的MOS制程，一次整合全部周边设施于单晶片中，节省加工晶片所需负担的成本和良率的损失；CCD采用电荷传递的方式输出资讯，必须另辟传输通道，如果通道中有一个像素故障（Fail），就会导致一整排的讯号壅塞，无法传递。 ​ CMOS每个感光二极体旁都搭配一个ADC放大器，如果以百万像素计，需要百万个以上的ADC放大器，虽然是统一制造下的产品，每个放大器或多或少都有些微的差异存在，很难达到同步放大的效果，对比单一个放大器的CCD，CMOS最终计算出的噪点就比较多。 ​ 市场销售的数码摄像头中以CMOS感光器件的为主。在采用CMOS为感光元器件的产品中，采用影像光源自动增益补强技术，自动亮度、白平衡控制技术，色饱和度、对比度、边缘增强以及伽马矫正等先进的影像控制技术，完全可以达到与CCD摄像头相媲美的效果。 ​ 尽管CCD在影像品质等方面均优于CMOS，不可否认的CMOS具有低成本、低耗电以及高整合度的特性。CMOS的低成本和稳定供货，所以广泛使用，制造技术不断地改良更新，使得CCD与CMOS两者的差异逐渐缩小。 6.2.2.2、工业相机​ 工业相机是机器视觉系统中的关键组件，本质功能就是将光信号转变成有序的电信号。选择合适的相机也是机器视觉系统设计中的重要环节，相机的选择不仅直接决定所采集到的图像分辨率、图像质量等，同时与整个视觉系统的运行模式直接相关。 ​ 工业相机俗称摄像机，相比于传统的民用相机（摄像机）而言，它具有高的图像稳定性、高传输能力和高抗干扰能力等，市面上工业相机大多是基于CCD（Charge Coupled Device）或CMOS（Complementary Metal Oxide Semiconductor）芯片的相机。 ​ CCD是目前机器视觉常用的图像传感器。它集光电转换及电荷存贮、电荷转移、信号读取于一体，是典型的固体成像器件。突出特点是以电荷作为信号，不同于其它器件是以电流或者电压为信号。通过光电转换形成电荷包，而后在驱动脉冲的作用下转移、放大输出图像信号。典型的CCD相机由光学镜头、时序及同步信号发生器、垂直驱动器、模拟/数字信号处理电路组成。CCD作为一种功能器件，与真空管相比，具有无灼伤、无滞后、低电压工作、低功耗等优点。 ​ CMOS图像传感器的开发最早出现在20世纪70 年代初，90 年代初期，超大规模集成电路 (VLSI)制造工艺技术的发展，CMOS图像传感器得到迅速发展。CMOS图像传感器将光敏元阵列、图像信号放大器、信号读取电路、模数转换电路、图像信号处理器及控制器集成在一块芯片上，还具有局部像素的编程随机访问的优点。CMOS图像传感器以其良好的集成性、低功耗、高速传输和宽动态范围等特点得到了广泛的应用。 ​ 工业视觉离不开相机的支持，在一些高端领域，必须用工业相机来处理。工业相机是民用相机的增强版，本质依然采用CCD或者CMOS技术。相对民用相机，用更高的软硬件配置，更大的功耗获得更好的质量。 6.2.2.3、总结​ 人工智能图像处理，工业上，对高清晰照片进行处理。其它领域，是消费级的处理。技术的进步，高清晰相机在消费级市场应用，高清照片的消费级技术处理将会显现。 ​ 工业视频的处理靠高端硬件实现，消费级高清视频的处理，还需要新的技术框架支持。在未来几年将有新的机会出现。 6.3、机器视觉​ 机器视觉是人工智能快速发展的一个分支，也是智能视觉重要的一部分。机器视觉就是用机器代替人眼来做测量和判断。 ​ 机器视觉系统通过机器视觉产品(即图像摄取装置，分CMOS和CCD两种)将被摄取目标转换成图像信号，传送给专用的图像处理系统，得到被摄目标的形态信息。根据像素分布和亮度、颜色等信息，转变成数字化信号;图像系统对这些信号进行各种运算来抽取目标的特征，进而根据判别的结果控制现场的设备动作。 ​ 机器视觉是一项综合技术，包括图像处理、机械工程技术、控制、电光源照明、光学成像、传感器、模拟与数字视频技术、计算机软硬件技术(图像增强和分析算法、图像卡、 I/O卡等)。 ​ 很多年前，机器视觉就在广泛应用。目前，在深度和广度方面拓展。未来10年，机器视觉对人类生活，将会有革命性的变化。 ​ 机器视觉是一门技术，机器视觉系统是技术的应用，下一主题，我们讲述机器视觉系统。 6.4、机器视觉系统​ 一个典型的机器视觉应用系统包括图像捕捉、光源系统、图像数字化模块、数字图像处理模块、智能判断决策模块和机械控制执行模块。 ​ 机器视觉系统基本的特点就是提高生产的灵活性和自动化程度。在不适于人工作业的危险工作环境或者人工视觉难以满足要求的场合，用机器视觉来替代人工视觉。在大批量重复性工业生产中，用机器视觉检测方法提高生产的效率和自动化程度。 ​ 机器视觉系统提高生产的柔性和自动化程度。在一些不适合人工作业的危险工作环境或人工视觉难以满足要求的场合，常用机器视觉来替代人工视觉；同时在大批量工业生产过程中，用人工视觉检查产品质量效率低且精度不高，用机器视觉检测方法大大提高生产效率和自动化程度。机器视觉易于实现信息集成，是实现计算机集成制造的基础技术之一。 ​ 工业机器视觉系统包括：光源、镜头（定焦镜头、变倍镜头、远心镜头、显微镜头）、 相机（包括CCD相机和COMS相机）、图像处理单元（或图像捕获卡）、图像处理软件、监视器、通讯 / 输入输出单元等。 ​ 机器视觉检测系统采用CCD照相机将被检测的目标转换成图像信号，传送给专用的图像处理系统，依据像素分布和亮度、颜色等信息，转变成数字化信号，图像处理系统对这些信号进行各种运算来抽取目标的特征，如面积、数量、位置、长度，再根据预设的允许度和其它条件输出结果，包括尺寸、角度、个数、合格/不合格、有/无等，实现自动识别功能。 ​ 目前，机器视觉系统主要应用在工业生产领域，互联网应用正在兴起，在居家生活应用上方兴未艾。 6.5、计算机视觉​ 计算机视觉是研究如何使机器“看”的科学，用摄影机和电脑代替人眼对目标进行识别、跟踪和测量等，并进一步做图形处理，使电脑处理更适合人眼观察或传送给仪器检测的图像。计算机视觉可以看作，如何使人工系统从图像或多维数据中“感知”的科学。 ​ 计算机视觉是一门关于如何运用照相机和计算机来获取我们所需的，被拍摄对象的数据与信息的学问。形象地说，就是给计算机安装上眼睛（照相机）和大脑（算法），让计算机能够感知环境。 ​ 计算机视觉既是工程领域，也是科学领域中重要研究领域。计算机视觉是一门综合性的学科，吸引了众多研究者参加到对它的研究之中。包括计算机科学和工程、信号处理、物理学、应用数学和统计学，神经生理学和认知科学等。 ​ 计算机视觉开始于60年代初，80年代取得很多重大进展。计算机视觉与人类视觉密切相关，对人类视觉有正确的认识对计算机视觉的研究非常有益。 ​ 计算机视觉用各种成像系统代替视觉器官作为输入敏感手段，由计算机来代替大脑完成处理和解释。计算机视觉的研究目标就是使计算机象人那样通过视觉观察和理解世界，具有自主适应环境的能力。 ​ 计算机视觉根据计算机系统的特点进行视觉信息处理。迄今为止人类视觉系统，是功能最强大和完善的视觉系统。对人类视觉处理机制的研究将给计算机视觉的研究提供启发和指导。 ​ 计算机信息处理的方法是研究人类视觉的机理，建立人类视觉计算理论。称为计算视觉（Computational Vision）。计算视觉是计算机视觉中的一个研究领域。 ​ 计算机视觉和机器视觉的定义有很多认知的区别，很多文献中有不同的论述，笔者认为，两者都是人工智能的分支，侧重点不一样。在今天学术领域，都没有严格的定义。 6.6、智能时代软件发展​ 天下事物发展一分为二，软硬件技术也不例外，第二次工业革命电磁理论，石破天惊，在后期推动了计算机技术的进步。为第四次科技革命的发展做好了硬件的铺垫。在硬件大力发展背后，智能时代软件的号角吹响了。 ​ 人类在智能科技方面的探索没有终点，也很难找到起点。人工智能探索过程中，软件方面有着天翻地覆的变化，下面从编程语言、运算平台、机器学习库等方面分别进行阐述。 6.6.1、人工智能编程语言​ 人工智能编程语言是一类适应于人工智能和知识工程领域的、具有符号处理和逻辑推理能力的计算机程序设计语言。能够用它来编写程序求解非数值计算、知识处理、推理、规划、决策等具有智能的各种复杂问题。 ​ 事实上，已经有多种对应于各种不同知识表示方式的人工智能编程语言。按所对应的知识表示方式不同。可以区分为以下几类： ​ A、对应于产生式规则知识表示的语言。例如，由美国卡耐基·梅农大学的C·L·福基（C。L。Forgy）等人1977年开发的OPS(official production system)，当时用它来为DEC公司开发了一个解决VAX计算机系统配置问题的专家系统X1/XCON。 ​ B、对应于逻辑公式知识表示的语言。一种已广为应用的逻辑语言就是PROLOG。1970年由法国马塞大学的 A。柯迈豪埃(Alain Colmerauer)所开发的。 ​ C、对应于框架或语义网知识表示的语言。这是“面向对象”的(object-oriented)语言。其中一个有代表性的语种就是Smalltalk。1980年首创，后来版本不断更新。 ​ D、对应于函数知识表示或函数式程序设计风格的语言的列表处理语言。函数式编程语言，理论上很完美，建立在坚实的数学基础之上，对于人工智能问题，在常规计算机上很难实现。20世纪50年代末，麻省理工学院的约翰·麦卡锡等人首先开发的列表处理语言LISP（LISt Processing）迄今仍然广泛用于编写人工智能应用程序，特别是用于开发专家系统。 ​ 人工智能编程语言有共同特点，语言都面向要解决的问题、结合知识表示、完全脱离当代计算机的诺依曼结构特性而独立设计的；处于比面向过程的高级编程语言更高的抽象层次。 ​ 用这些语言编写的程序，在现代计算机环境中，无论是解释或编译执行，往往效率很低。尤其程序规模很大、复杂时，浪费大量系统资源，系统性能往往会下降到难以容忍的地步。 6.6.1.1、LISP​ 20世纪50年代后期，麻省理工学院的John McCarthy就开始了人工智能的研究，当时致力于设计一个用表处理的递归系统，在20世纪60年代初研制出了LISP语言。 ​ LISP语言是一个用于处理符号表达式的、相当简单的函数式程序设计语言，以数学中的函数与函数作用的概念作为设计原理，奠定了函数式语言的基础。 ​ LISP语言是完全非von Neumann风格的，它没有使用ALGOL60等语言中所采用的可修改变量、赋值语句、转向语句等von Neumann结构语言中的有关概念。LISP程序与其数据结构采用了相同的结构形式与处理方式。 ​ LISP方便地编写解释程序。LISP语言除了用s一表达式来统一处理数据与程序外，还引入了前缀运算符表示法、递归数据结构、递归控制结构以及新的条件表达式形式。 6.6.1.2、Prolog​ Prolog(Programming in Logic)是一种逻辑编程语言，建立在逻辑学的理论基础之上，最初被运用于自然语言等研究领域。现已广泛应用在人工智能的研究中，可以用来建造专家系统、自然语言理解、智能知识库等。 ​ 对一些应用程序的编写很有帮助，能够比其它语言更快速开发程序，Prolog的编程方法更像是使用逻辑语言来描述程序。 ​ Prolog具有鲜明的逻辑编程语言特色，包括：没有特定的运行顺序，运行顺序是由计算机决定的，而不是程序员；程序中没有if、when、case、for这样的控制流程语句；Prolog程序和数据高度统一，其程序实际上是一个智能数据库；具有强大的递归功能。 ​ 1981年日本政府宣布第5代计算机系统(FGCS)项目以Prolog为基础语言以来，Prolog成为了人工智能研究领域的主导语言。 6.6.1.3、OPS83​ OPS83是应用于专家系统的程序设计语言，支持OPS早期版本，也支持PASCAL或C这些常规程序设计语言所具有的过程设计能力。它不是对所有程序设计任务都适宜，OPS83较之OPS的早期版本，对许多问题处理的更目然、更有效。 ​ OPS是由美国宾夕法尼亚州卡内基一梅隆大学的C.L.Forgy等人开发。最早版本是在1975年开发的，之后几经修改形成了OPSl、OPS2(1978)、OPS4(1979)、OPS5(1981)多种版本，1986年出现了OPS83。 ​ OSP83采用产生式系统的知识表示模式和正向精确推理方式。它提供了两种交互环境：一是和用户的界面；二是和知识工程师的界面(调试环境)。OPS83包括三个主要部分：知识库、推理机和工作存贮器。 ​ 知识库又称规则库。每条规则均以0PS83语言来表示。OPS83的推理过程由若干“识别一动作”周期组成。每个周期包括三个动作或阶段：匹配、冲突解决(或选择)和执行。 ​ 匹配是数据和已有规则的匹配。匹配的结果形成了冲突集。是所有满足条件的规则的集合。然后，推理机从冲突集中选择规则执行。工作存贮器(Work Memory，WM)用来存贮推理机在推理过程中的初始状态、中间状态和目标等信息。 ​ 各个模块可作为独立的文件存放在存贮器中，单独编译，然后连接在一起运行。数据类型、语句、子程序等与一般程序设计语言类似，使用OPS83的知识工程师有一个类似于过程描述型语言的编程环境。 6.6.1.4、Python​ 1989年圣诞节期间，荷兰人吉多·范罗苏姆（Guido van Rossum），在阿姆斯特丹，为了打发圣诞节的无趣，决心开发一个新的脚本解释程序，作为ABC语言的继承。还受到了Modula-3的影响，结合了Unix shell和C的习惯。 ​ Guido本人看来，ABC语言优美强大，为非专业程序员设计。但是ABC语言并没有成功，究其原因，Guido认为是其非开放造成的。Guido在Python中避免这一错误。同时，他还想实现在ABC中闪现过但未曾实现的东西。 ​ Python语法和动态类型，以及解释型语言的本质，使它成为多数平台上写脚本和快速开发应用的编程语言，随着版本的更新和语言新功能的添加，逐渐被用于独立的、大型项目的开发。 ​ Python解释器易于扩展，可以使用C或C++（或者其它可以通过C调用的语言）扩展新的功能和数据类型。Python 也可用于可定制化软件中的扩展程序语言。丰富的标准库，提供了适用于各个主要系统平台的源码或机器码。 ​ 由于Python语言的简洁性、易读性以及可扩展性，在国内外用Python做科学计算的研究机构日益增多，很多知名大学已经采用Python来教授程序设计课程。例如卡耐基梅隆大学、麻省理工学院等。 ​ 众多开源的科学计算软件包都提供了Python的调用接口，例如著名的计算机视觉库OpenCV、三维可视化库VTK、医学图像处理库ITK。Python专用的科学计算扩展库十分流行，例如如下3个经典的科学计算扩展库：NumPy、SciPy和matplotlib，它们分别为Python提供了快速数组处理、数值运算以及绘图功能。 ​ Python语言及其众多的扩展库所构成的开发环境适合工程技术、科研人员处理实验数据、制作图表，甚至开发科学计算应用程序，并可用于机器学习领域。 ​ 让人惊奇的是，Python今天成为人工智能应用层上最主要的外部接口，尤其在图形图像领域，使用尤其广泛，例如TensorFlow和PyTorch等。这应该是Guido所不曾想到的。 6.6.1.4、启示​ 诚然，编程语言很多，描述这段历史时，应该认识到的是，不同的编程语言与当时的硬件环境、软件理论相照应。在今天，只需要一概而过，对于深度研发，有一定认知的必要。 ​ 人工智能是一场科技革命，不仅仅是理论的发展，更是实践的应用，随着硬件技术的进步，人工智能理念的变幻，软件方面也将有很大的发展。 ​ 编程语言发展上，人工智能有很大的发展，编程语言与硬件系统紧密结合，编程语言与框架模式协作并行，才会有更大的突破。在未来，人工智能方面编程语言的发展，有这样三个思索。 ​ A、研制与某种语言完全适应的新一代计算机。例如LlSP机、数据流机、PROLOG机、面向对象的体系结构等。但举步维艰、前景渺茫。以诺依曼机为核心的现代通用计算机已经广泛普及而且性能不断提高，积累了巨大的软件资源。任何与现代计算机不兼容的专用机，最多满足特殊需求，难以与现代通用计算机抗衡。在没有很大商业机会的前提下，这种办法是不可能实现的。 ​ B、把不同风格的编程语言结合起来，发展复合语言或嵌入式语言，取长补短，使系统性能得以进一步提高。把面向对象语言的设计思路融汇到常用的面向过程的高级语言中。C++语言就是一个突出的例子。这种改变相对来说影响较小，毕竟不是脱胎换骨。 ​ C、用面向问题的人工智能编程语言的特点，先选择某种语言编写出一个简洁明了而易于调试的程序原型。通过验证、调试，再仿照这个原型，改编为某种面向过程的高级语言程序，例如C或C++，达到提高最终应用系统开发质量和执行效率的目的。用PROLOG、 LISP、OPS等来开发专家系统原型，已有不少先例。在技术变幻的前提下，这种方式有一定的价值。 ​ 计算机发展史上，基于冯·诺伊曼的硬件系统很难发生变化，计算机编程语言的发展从未停止。我们得到一个启示，思想最容易在软件方面实现，而计算机编程语言的发展也就不足为奇。 ​ 关于计算机体系结构的发展，有一定价值的是，在未来，量子计算机的体系结构将会是一个重要的方向。随着量子技术的进步，对于商业而言，再次掀起市场的沧海桑田，腥风血雨。 6.6.3、机器学习库​ 机器学习是人工智能的重要组成部分，机器学习是一个完善的生态环境，对于人工智能而言，算法库是重中之重。降低了智能视觉分析的门槛，加大了人工智能的应用。人工智能算法库有很多，本部分重点讨论应用广泛的两个神经网络库，TensorFlow和PyTorch。 ​ 神经网络可以指向两种，一个是生物神经网络，一个是人工神经网络。 6.6.3.1、生物神经网络​ 生物神经网络：一般指生物的大脑神经元，细胞，触点等组成的网络，用于产生生物的意识，帮助生物进行思考和行动。 6.6.3.2、人工神经网络​ 人工神经网络（Artificial Neural Networks，简写为ANNs）也简称为神经网络（NNs）或称作连接模型（Connection Model），它是一种模仿动物神经网络行为特征，进行分布式并行信息处理的算法数学模型。这种网络依靠系统的复杂程度，通过调整内部大量节点之间相互连接的关系，从而达到处理信息的目的。 ​ 人工神经网络：是一种应用类似于大脑神经突触联接的结构进行信息处理的数学模型。在工程与学术界也常直接简称为“神经网络”或类神经网络。 ​ 人工神经网络（Artificial Neural Network，即ANN ），是20世纪80 年代以来人工智能领域兴起的研究热点。它从信息处理角度对人脑神经元网络进行抽象， 建立某种简单模型，按不同的连接方式组成不同的网络。在工程与学术界也常直接简称为神经网络或类神经网络。神经网络是一种运算模型，由大量的节点（或称神经元）之间相互联接构成。 ​ 每个节点代表一种特定的输出函数，称为激励函数（activation function）。每两个节点间的连接都代表一个对于通过该连接信号的加权值，称之为权重，这相当于人工神经网络的记忆。网络的输出则依网络的连接方式，权重值和激励函数的不同而不同。而网络自身通常都是对自然界某种算法或者函数的逼近，也可能是对一种逻辑策略的表达。 6.6.3.3、TensorFlow​ TensorFlow™是基于数据流编程（dataflow programming）的符号数学系统，在人工智能领域，有这广泛的应用。TensorFlow是今天神经网络训练的主要平台，成就了TensorFlow在今天庞大的用户群。 ​ 用于各类机器学习（machine learning），前身是谷歌的神经网络算法库DistBelief 。谷歌不仅在大数据领域有着重要的位置，在人工智能方面，谷歌也名列前茅。 ​ Tensorflow拥有多层级结构，使用面向各种场景，可部署于各类服务器、PC终端和网页，支持GPU和TPU高性能数值计算，开发环境友好。应用于谷歌内部的产品开发和各领域的科学研究 。 6.6.3.3.1、发展​ TensorFlow由谷歌人工智能团队谷歌大脑（Google Brain）开发和维护，是谷歌核心的人工智能项目。拥有很多子项目：TensorFlow Hub、TensorFlow Lite、TensorFlow Research Cloud、各类应用程序接口。 ​ 谷歌大脑2011年成立，开展面向大规模深度学习应用研究，谷歌大脑具有自我学习功能，将1.6万处理器连接。TensorFlow的前身DistBelief。DistBelief构建各尺度下的神经网络分布式学习和交互系统，被称为“第一代机器学习系统”，为世界人工智能发展做出了卓越的贡献。 ​ DistBelief在谷歌和Alphabet旗下公司的产品开发中广泛使用，成果颇丰。TensorFlow拥有生态系统，从数据训练，接口导出，到工程应用。2018年4月的TensorFlow开发者峰会，有21个TensorFlow项目非常有价值和意义 。 6.6.3.3.2、核心组件​ TensorFlow利用GPU做数据训练，可以进行单机也可以进行分布式部署。 ​ 合作组件互相配合，保证了TensorFlow的运转。分布式TensorFlow的核心组件如下： ​ 分发中心（distributed master）； ​ 执行器（dataflow executor/worker service）； ​ 内核应用（kernel implementation） ​ 最底端的设备层（device layer）/网络层（networking layer）。 ​ 分发中心从输入的数据流图中剪取子图（subgraph），将其划分为操作片段并启动执行器。分发中心处理数据流图时会进行预设定的操作优化，包括公共子表达式消去（common subexpression elimination）、常量折叠（constant folding）等。 ​ 执行器负责图操作（graph operation）在进程和设备中的运行、收发其它执行器的结果。分布式TensorFlow拥有参数器（parameter server）以汇总和更新其它执行器返回的模型参数。执行器在调度本地设备时会选择进行并行计算和GPU加速 。 ​ 内核应用负责单一的图操作，包括数学计算、数组操作（array manipulation）、控制流（control flow）和状态管理操作（state management operations）。内核应用使用Eigen执行张量的并行计算、cuDNN库等执行GPU加速、gemmlowp执行低数值精度计算，此外用户可以在内核应用中注册额外的内核（fused kernels）以提升基础操作，例如激励函数和其梯度计算的运行效率。 ​ 单进程TensorFlow相对简单，整体部署训练与方便，和分布式相比，维护也很方便。没有分发中心和执行器，使用特殊的会话应用（Session implementation）联系本地设备。 ​ TensorFlow的内核是C语言的，提供的原始接口也是C语言的。其它组件/API均通过C语言API与核心组件进行交互。 6.6.3.3.3、组件​ TensorFlow Hub是一个允许用户发布、共享和使用TensorFlow模块的库开发项目。用户可以将TensorFlow数据流图或其部分使用Hub进行封装并移植到其它问题中再次利用。TensorFlow Hub页面列出了由谷歌和DeepMind提供的封装模型，其主题包括字符嵌入、视频分类和图像处理。 ​ TensorFlow Extended (TFX)，TFX是谷歌基于TensorFlow开发的产品级机器学习平台，其目标是是对产品开发中的模型实现、分析验证和业务化操作进行整合，在实时数据下完成机器学习产品的标准化生产。TFX包含三个算法库：TensorFlow Data Validation对机器学习数据进行统计描述和验证、TensorFlow Transform对模型数据进行预处理、 TensorFlow Model Analysis对机器学习模型进行分析，提供表现评分。另有TensorFlow Serving作为模型业务化的高性能系统，提供模型接口和管理。 ​ TensorFlow Probability (TFP)，TFP是在TensorFlow Python API基础上开发的统计学算法库，其目标是方便用户将概率模型和深度学习模型相结合使用。TFP包含大量概率分布的生成器、支持构建深度网络的概率层（probabilistic layers）、提供变分贝叶斯推断（Variational inference）和马尔可夫链蒙特卡罗方法（Markov chain Monte Carlo）和一些特殊的优化器，包括Nelder-Mead方案、BFGS算法（Broyden-Fletcher-Goldfarb-Shanno algorithm）和SGLD（Stochastic Gradient Langevin Dynamics）。 ​ TensorFlow.js是TensorFlow的JavaScript API，主要用于网页端的机器学习应用开发。方便网页用户进行人工智能数据训练。 ​ TensorFlow Lite是为移动和嵌入式设备提供人工智能支持，在Android、iOS系统下机器学习模型的响应时间并降低文件大小。TensorFlow Lite部署了大部分人工智能算法，具有很好的参考价值。 ​ Swift for TensorFlow是开源版Swift的TensorFlow API开发项目，在深度学习和微分计算方面应用。和Eager Execution很相像，可直接执行数据流图，具备更好的性能。 ​ TensorFlow Research Cloud是面向科学研究的机器学习TPU云计算平台。该项目拥有1000个云TPU和总计180千万亿次计算力，每个TPU拥有64 GB的高带宽内存 。可以通过互联网申请使用，进行有价值的人工智能数据训练。 6.6.3.3.4、其它​ Magenta是在艺术领域使用机器学习的研究项目，该项目使用深度学习网络和强化学习算法学习生成音乐、绘画和其它艺术作品，以帮助艺术人员拓展其创作过程 。Magenta项目的研究成果包括音乐创作工具NSynth和混音工具MusicVAE。 ​ Nucleus是将TensorFlow应用于基因组文件，例如SAM和VCF格式文件的读写和分析的库开发项目 。Nucleus使用Python和C++进行开发。 6.6.3.2、PyTorch​ PyTorch是一个开源的Python机器学习库，基于Torch，用于自然语言处理等应用程序。 ​ 2017年1月，由Facebook人工智能研究院（FAIR）基于Torch推出了PyTorch。它是一个基于Python的计算包，提供两个高级功能：1、具有强大的GPU加速的张量计算（如NumPy）。2、包含自动求导系统的深度神经网络。 ​ PyTorch使用Python重写了很多内容，更加灵活，支持动态图，提供了Python接口。它是由Torch7团队开发，是一个以Python优先的深度学习框架，实现强大的GPU加速，支持动态神经网络。 ​ PyTorch可以看作加入了GPU支持的numpy，也可以看成拥有自动求导功能的强大的深度神经网络。除Facebook外，已经被Twitter、CMU和Salesforce等机构采用。 ​ PyTorch简洁高效，快速应用的框架，设计追求最少封装，符合人类思维，让用户尽可能地专注于实现自己的想法，与google的Tensorflow类似，FAIR的支持足以确保PyTorch获得持续的开发更新。 无论对于机器视觉，还是人工智能，相对从前，数据量发生了地覆天翻的变化。传统的运算框架不能满足现实的发展。人工智能影响不是一点一线，而是整个计算体系。 ​ 从AI/AR/VR芯片，到GPU数据处理，再到平台架构，框架编程，外部接口调用，都有巨大的变革。今天我们谈一下基于大批量数据的运算框架。 ​ GPU的参与数据处理已经多年，多年发展过程中，GPU不过是硬件的支持(如下图)，指令的提供，传统的工程师很难进行指令级的开发。所以，运算平台出现了，拓展了技术应用，便捷了软件开发。 ​ 下面讲述目前最广泛的两个运算平台，英伟达的CUDA和开放的OPENCL平台。 6.6.2.1、CUDA​ CUDA（Compute Unified Device Architecture），CUDA™是由NVIDIA推出的并行计算架构，该架构使GPU解决复杂的计算问题。包含了CUDA指令集架构（ISA）以及GPU内部的并行计算引擎。 ​ 开发人员可以使用C语言来为CUDA™架构编写程序，C语言是应用最广泛的一种高级编程语言。编写出的程序可以在支持CUDA™的处理器上以超高性能运行。 ​ 计算行业从只使用CPU的“中央处理”向CPU与GPU并用的“协同处理”发展。为打造这一全新的计算典范，NVIDIA™（英伟达™）发明了CUDA（Compute Unified Device Architecture，统一计算设备架构）这一编程模型。 6.6.2.1.1、应用​ 在应用程序中充分利用CPU和GPU各自的优点。该架构已应用于GeForce™（精视™）、ION™（翼扬™）、Quadro以及Tesla GPU（图形处理器）上，对应用程序开发人员来说，这是一个巨大的市场。 ​ 在消费级市场上，几乎每一款重要的消费级视频应用程序都已经使用CUDA加速或很快将会利用CUDA来加速，其中包括Elemental Technologies公司、MotionDSP公司以及LoiLo公司的产品。 ​ 在科研界，CUDA一直受到热捧。例如，CUDA现已能够对AMBER进行加速。AMBER是一款分子动力学模拟程序，全世界在学术界与制药企业中有超过60，000名研究人员使用该程序来加速新药的探索工作。 ​ 在金融市场，Numerix以及CompatibL针对一款全新的对手风险应用程序发布了CUDA支持并取得了18倍速度提升。Numerix为近400家金融机构所广泛使用。 ​ CUDA的广泛应用造就了GPU计算专用Tesla GPU的崛起。全球财富五百强企业已经安装了700多个GPU集群，这些企业涉及各个领域，例如能源领域的斯伦贝谢与雪佛龙以及银行业的法国巴黎银行，包括阿里云。 ​ GPU计算目前成为主流。在显卡硬件上，GPU将不仅仅是图形处理器，还是应用程序均可使用的通用并行处理器。 ​ 随着显卡的发展，GPU越来越强大，GPU为图像处理做了优化。计算上超越了通用的CPU。强大的芯片不能仅仅进行显示，因此NVIDIA推出CUDA，让显卡可以用于图像计算以外的目的。 ​ CUDA架构可以使用GPU来解决商业、工业以及科学方面的复杂计算问题。它是一个完整的GPGPU解决方案，提供了硬件的直接访问接口，而不必像传统方式一样必须依赖图形API接口来实现GPU的访问。 6.6.2.1.2、系统结构​ 在架构上采用了一种全新的计算体系结构来使用GPU提供的硬件资源，从而给大规模的数据计算应用提供了一种比CPU更加强大的计算能力。CUDA采用C语言作为编程语言提供大量的高性能计算指令开发能力，使开发者能够在GPU的强大计算能力的基础上建立起一种效率更高的密集数据计算解决方案。 ​ CUDA体系结构包含三部分：开发库、运行期环境和驱动。 ​ 开发库是基于CUDA技术提供的应用开发库。CUDA1。1版提供了两个标准的数学运算库——CUFFT（离散快速傅立叶变换）和CUBLAS（离散基本线性计算）的实现。这两个数学运算库解决的是典型的大规模并行计算问题，也是在密集数据计算中非常常见的计算类型。开发人员在开发库的基础上快速、方便的建立起自己的计算应用。此外，开发人员也可以在CUDA的技术基础上实现出更多的开发库。 ​ 运行期环境提供了应用开发接口和运行期组件，包括基本数据类型的定义和各类计算、类型转换、内存管理、设备访问和执行调度等函数。基于CUDA开发的程序代码在实际执行中分为两种，一种是运行在CPU上的宿主代码（Host Code），一种是运行在GPU上的设备代码（Device Code）。不同类型代码运行的物理位置不同，访问的资源不同，对应的运行期组件也分为公共组件、宿主组件和设备组件三个部分，囊括了所有在GPGPU开发中所需要的功能和能够使用到的资源接口，开发人员通过运行期环境的编程接口实现各种类型的计算。 ​ 由于存在着多种GPU版本的NVidia显卡，不同版本的GPU之间都有不同的差异，因此驱动部分基本上可以理解为是CUDA-enable的GPU的设备抽象层，提供硬件设备的抽象访问接口。CUDA提供运行期环境通过这一层来实现各种功能。基于CUDA开发的应用必须有NVIDIA CUDA-enable的硬件支持。 ​ NVIDIA公司GPU运算事业部总经理Andy Keane在活动中表示：一个充满生命力的技术平台应该是开放的，CUDA未来也会向这个方向发展。由于CUDA的体系结构中有硬件抽象层的存在，因此今后也有可能发展成为一个通用的GPGPU标准接口，兼容不同厂商的GPU产品。 ​ 支持CUDA的GPU销量逾10亿，数以万计的开发人员正在使用免费的CUDA软件开发工具来解决各种问题。从视频与音频处理和物理效果模拟到石油天然气勘探、产品设计、医学成像以及科学研究，涵盖了各个领域。 6.6.2.1.3、核心​ CUDA的核心有三个重要抽象概念： 线程组层次结构、共享存储器、屏蔽同步（barriersynchronization），轻松将其作为C语言的最小扩展级公开给程序员。 ​ CUDA 软件堆栈由几层组成，一个硬件驱动程序，一个应用程序编程接口（API）和它的Runtime，还有二个高级的通用数学库，CUFFT 和CUBLAS。硬件被设计成支持轻量级的驱动和Runtime 层面，因而提高性能。 6.6.2.1.4、其它​ NVIDIA进军高性能计算领域，推出了Tesla&amp;CUDA高性能计算系列解决方案，CUDA技术，一种基于NVIDIA图形处理器（GPU）上全新的并行计算体系架构，让科学家、工程师和其它专业技术人员能够解决以前无法解决的问题，作为一个专用高性能GPU计算解决方案，NVIDIA把超级计算能够带给任何工作站或服务器，以及标准、基于CPU的服务器集群。 ​ CUDA是用于GPU计算的开发环境，是一个全新的软硬件架构，可以将GPU视为一个并行数据计算的设备，对计算分配和管理。CUDA的架构中，计算不再像过去所谓的GPGPU架构那样必须将计算映射到图形API（OpenGL和Direct 3D）中，对于开发者来说，CUDA的开发门槛大大降低。CUDA编程基于C语言，任何有C语言基础的用户都很容易地开发CUDA的应用程序。 ​ GPU的特点是处理密集型数据和并行数据计算，因此CUDA非常适合需要大规模并行计算的领域。CUDA除了可以用C、C++、JAVA、Python语言开发。广泛的应用在图形动画、科学计算、地质、生物、物理模拟等领域。 ​ 计算正在从CPU”中央处理”向CPU与GPU”协同处理”的方向发展。对应用程序开发商来说，英伟达™ CUDA™ 架构拥有庞大的用户群。 6.6.2.2、OPENCL​ OpenCL（Open Computing Language，开放运算语言）是第一个面向异构系统并行编程的开放式、免费标准，也是一个统一的编程环境。 ​ 便于软件开发人员为高性能计算服务器、桌面计算系统、手持设备编写高效轻便的代码，而且广泛适用于多核心处理器(CPU)、图形处理器(GPU)、Cell类型架构以及数字信号处理器(DSP)等其它并行处理器，在游戏、娱乐、科研、医疗等各种领域都有广阔的发展前景。 ​ OpenCL平台可由CPU，GPU或其它类型的处理器组成。OpenCL用于编写kernels （在OpenCL设备上运行的函数）的语言（基于C99）和一组用于定义并控制平台的API组成。OpenCL提供了基于任务分割和数据分割的并行计算机制。 ​ OpenCL类似于另外两个开放的工业标准OpenGL和OpenAL，这两个标准分别用于三维图形和计算机音频方面。OpenCL扩展了GPU用于图形生成之外的能力。OpenCL由非盈利性技术组织Khronos Group掌管。 6.6.2.2.1、发展​ OpenCL最初苹果公司开发，拥有其商标权，并在与AMD，IBM，英特尔和NVIDIA技术团队的合作之下初步完善。随后，苹果将这一草案提交至Khronos Group。 ​ 2008年6月的WWDC大会上，苹果提出了OpenCL规范，旨在提供一个通用的开放API，在此基础上开发GPU通用计算软件。随后，Khronos Group宣布成立GPU通用计算开放行业标准工作组，以苹果的提案为基础创立OpenCL行业规范。5个月后的2008年11月18日，该工作组完成了OpenCL 1。0规范的技术细节。2010年6月14日，OpenCL 1。1 发布。2011年11月15日，OpenCL 1。2 发布。2013年11月19日，OpenCL 2。0发布。目前，OpenCL最新版本是3。0。 ​ 2009年6月NVIDIA首家发布了支持OpenCL 1。0通用计算规范的驱动程序，支持Windows和Linux操作系统。 ​ 2009年8月初AMD首次发布了可支持IA处理器(x86和amd64/x64)的OpenCL SDK——ATI Stream SDK v2。0Beta，交由业界标准组织Khronos 进行审核。目前，该SDK更名为AMD APP SDK。 ​ 2012年2月，intel发布了The Intel&reg; SDK for OpenCL* Applications 2012，支持OpenCL 1。1基于带HD4000/2500的显示核心的第三代酷睿CPU（i3，i5，i7)和GPU。 ​ 2013年6月，intel发布了第四代酷睿CPU haswell 其内置的HD4600/4400/4200 Iris（锐矩）5000/5100/pro 5200（自带eDRAM缓存）支持OpenCL 1。2（未来可能升级到OpenCL 2。0） ​ NVIDIA显卡方面 Geforce 8000\\9000\\100、GTX200-1000，RTX2000均支持OpenCL 1。0-1。2 ​ AMD显卡方面 Radeon HD 4000-7000\\Rx 200\\Rx 300\\RX 400-500/Fury系列，Vega系列 均支持OpenCL 1。0-1。2，除Radeon HD4000-6000系列外，其余均会支持OpenCL 2。0 ​ 移动平台方面目前高通adreno320/330/400系列/500系列提供了Android上的OpenCL1。2或者2。0支持，NVIDIA的Tegra K1也提供了OpenCL 支持。 6.6.2.2.2、支持​ OpenCL工作组的成员包括：3Dlabs、AMD、苹果、ARM、Codeplay、爱立信、飞思卡尔、华为、HSA基金会、GraphicRemedy、IBM、Imagination Technologies、Intel、诺基亚、NVIDIA、摩托罗拉、QNX、高通，三星、Seaweed、德州仪器、布里斯托尔大学、瑞典Ume大学。像Intel、NVIDIA和AMD都是这个标准的支持者，不过微软并不在其列。目前，NVIDIA显卡对OpenCL技术支持较好。 ​ 在NVIDIA的Quadro、Geforce系列专业显卡中，能够使用OpenCL技术。只要显卡能够达到CUDA的要求，就能够正常使用OpenCL，以获得优异的CPU运算效率。 ​ 在AMD-ATI的Stream技术中（现已经改名为AMD APP并行加速技术），已经为日常使用、办公、游戏等提供物理加速。基于OpenCL标准开发，其中，ATI Radeon HD 4000-5000、AMD Radeon HD 6000系列同时支持ATI Stream和AMD APP（由于Stream基于CAL和Brook+语言开发，更适合VLIW5和VLIW4这样的SIMD架构），AMD Radeon HD7000和Radeon Rx 200系列支持AMD APP，运算效率较老架构提升十分明显。 6.6.2.2.3、API ​ OpenCL平台API：定义了宿主机程序发现OpenCL设备所用的函数以及这些函数的功能，还定义了OpenCL应用创建上下文的函数。 ​ OpenCL运行时API：管理上下文来创建命令队列以及运行时发生的其它操作。例如，将命令提交到命令队列的函数就来自OpenCL运行时API。 ​ OpenCL编程语言：编写内核代码的编程语言。基于ISO C99标准的一个扩展子集，通常称为OpenCL C编程语言。 6.6.2.2.4、总结​ 综合上述内容，形成OpenCL全景图(如下)，首先是一个定义上下文的宿主机程序。上图中的上下文包含两个OpenCL设备、一个CPU和一个GPU。接下来定义了命令队列。 ​ 这里有两个队列，一个是面向GPU的有序命令队列，另一个是面向CPU的乱序命令队列。然后宿主机程序定义一个程序对象，这个程序对象编译后将为两个OpenCL设备（CPU和GPU）生成内核。 ​ 接下来宿主机程序定义程序所需的内存对象，并把它们映射到内核的参数。最后，宿主机程序将命令放入命令队列来执行这些内核。 6.6.4、其它相关库​ 智能时代是百花齐放的时代，芯片技术驱动硬件技术，芯片指令提供操作接口，操作接口驱动运算平台，运算平台驱动机器学习库。本主题介绍部分机器视觉和并行计算库。 6.6.4.1、OpenCV​ OpenCV是基于BSD许可（开源）发行的跨平台计算机视觉和机器学习软件库，运行在Linux、Windows、Android和Mac OS操作系统上。 轻量高效，由一系列 C 函数和少量 C++ 类构成，提供了Python、Ruby、MATLAB等编程接口，实现了图像处理和计算机视觉方面的通用算法。 6.6.4.1、简介​ OpenCV用C++语言编写，利用MMX和SSE指令，OpenCV 为Intel® Integrated Performance Primitives（IPP）提供了透明接口。意味着如果有特定处理器优化的 IPP 库，OpenCV 在运行时自动加载这些库。 ​ OpenCV 拥有 500 多个C函数的跨平台的中、高层 API。不依赖于其它的外部库。OpenCV 使用类BSDlicense，对非商业应用和商业应用免费（FREE）。 ​ OpenCV的视觉处理算法丰富，部分用C语言编写，开源的特性，处理得当，不需要外部支持可以完整编译链接生成执行程序，方便算法的移植，OpenCV的代码经过适当改写可以正常的运行在DSP系统和ARM嵌入式系统中。 6.6.4.2、应用​ OpenCV致力于真实世界的实时应用，通过优化C代码的编写对其执行速度带来了可观的提升，通过购买Intel的IPP高性能多媒体函数库（Integrated Performance Primitives）得到更快的处理速度。 ​ 应用领域：人机互动、物体识别、图像分割、人脸识别、动作识别、运动跟踪、机器人、运动分析、机器视觉、结构分析、汽车安全驾驶 6.6.4.3、接口​ OpenCV其它接口是用C++接口改编的，主要接口语言也是C++语言，依然保留了大量的C语言接口。该库也有大量的Python、Java and MATLAB/OCTAVE、GO、C#、Ch、Ruby等的接口。API接口函数通过在线文档获得。一个使用CUDA的GPU接口也于2010年9月开始实现。 ​ OpenCV可以在Windows，Android，Maemo，FreeBSD，OpenBSD，iOS，Linux 和Mac OS等平台上运行。可以在 SourceForge 获得官方版本，或者从 SVN 获得开发版本。 6.6.4.2、OpenMP​ OpenMP是OpenMP Architecture Review Board牵头提出的，已被广泛接受，用于共享内存并行系统的多处理器程序设计，并提供一套指导性编译处理方案(Compiler Directive) 。 ​ OpenMP支持的编程语言包括C、C++和Fortran；支持OpenMp的编译器包括Sun Compiler，GNU Compiler和Intel Compiler等。 6.6.4.2.1、简介​ OpenMp提供了对并行算法的专用描述，源代码中加入专用的pragma指令来指明自己的意图，由此编译器可以自动将程序进行并行化，在必要之处加入同步互斥以及通信。在进行软件开发时间，串行化到并行化是一个提高效率最有效的方法。 忽略这些pragma，或者编译器不支持OpenMp时，程序又可退化为串行程序，代码仍然可以正常运作，这是考虑CPU硬件不同而设定的方案，只是不能利用多线程来加速程序执行。根据硬件支持，进行单线程和多线程的处理。 ​ OpenMP对于并行描述的高层抽象降低了并行编程的难度和复杂度，程序员可以把更多的精力投入到并行算法本身，而非其具体实现细节，这样让程序员集中精力做某些事情。对基于数据分集的多线程程序设计，OpenMP是一个很好的选择，尤其对计算要求严格的地方。 ​ OpenMP提供了更强的灵活性，可以适应不同的并行系统配置。线程粒度和负载平衡等是传统多线程程序设计中的难题，这些问题从前主要靠中间件来进行实现，或者从程序的框架角度来进行考虑。现在，把这些和兴的处理交给程序员直接接触的框架，从而提高了效率。OpenMP中，OpenMP库从程序员手中接管了部分这两方面的工作。 ​ 作为高层抽象，OpenMP不适合复杂的线程间同步和互斥的场合，这是由于OpenMp本身的结构决定的。OpenMp不能在非共享内存系统，例如计算机集群使用，如果使用，处理效果很不理想。共享内容的系统上，MPI使用较多。在项目开发过程中，技术选型非常重要。 ​ OpenMP是作为共享存储标准而问世的。它是为在多处理机上编写并行程序而设计的一个应用编程接口。它包括一套编译指导语句和一个用来支持它的函数库。当今双核、四核的 CPU 当道，而六核的CPU也已经面世多时，所以在多处理机上编写、运行并行程序会变得相当普遍。 6.6.4.2.2、单线程与多线程​ 一般单线程（single thread）程序，多核心处理器没有办法提升处理效能；对于多线程（multi thread）的程序，就可以通过不同的核心同时计算，来达到加速的目的。程序员在进行开发时间，对效率要有一定的认知，如果效率较高的程序，建议进行并行程序涉及。 ​ 下面我们举例，单线程程序，一件事一次要十秒的话，要做十次，一颗核心，就是 10 秒 的 10 倍，这就是 100 秒；如果按照多线程的程序运行，可以把一件事，给两颗核心各自完成，每核心各做 5 次，时间就缩短为 50 秒，这样速度提高了1倍。 ​ 多线程的程序实际上也不简单，我们上面的计算是机械的。在工作的切割、结合上，也是要多花时间的。 ​ 现实中，在最佳状况，双核心的效能也不会是 1 + 1 = 2 这样的理想化情况，这个仅仅是我们不考虑其它情况时间的结果。 ​ 并不是所有任务都可以切割！很多任务关键在一起，直接切割给不同的处理核心各自并行运算，出来的结果会有问题，这是安全所不能容忍的。多线程的程序在编写、维护上，比单线程的程序复杂了很多。对于效率要求不高，要求健壮性能的程序，单线程稳定还是好的。 ​ 电脑是多处理器、多核处理器，或具备IntelHyper-ThreadingTechnology 技术，代表同一个时间处理多个线程的功能，把各自独立的工作由单线程改成多线程，执行的效率上，一般是有提升的。 ​ 微软VS，提供线程控制功能。这种方法，产生多个 thread，策略如下：主线程把工作分配，子线程去然后运算，最后主线程对结果进行整理。 ​ OpenMP 通过高阶指令，这些指令往往是对CPU指令进行调用，演化为一系列操作，这中操作在从前是不可想象的。将程序并行化、多线程化的 API，这点免去了软件工程师的大部分工作负担；并行化处理是OpenMp的核心思想，最简单情形，只加一行指令，将循环内的程序并行化处理。 6.6.4.2.3、OpenMP与MPI​ OpenMP 是针对共享内存并行编程的 API。与之前的 MPI 不同的是，OpenMP是线程级并行，比 MPI 的进程级并行要更轻量化一些。轻量级代表更少的改动，共享内容是解决共享的重要手段之一。 ​ MPI 的并行需要完全重写整个程序，这点相对麻烦很多，是很多程序员排斥的。将一个串行程序改造成 OpenMP 的并行进行的改动近乎可以忽略不计。 6.6.4.2.4、应用​ 分为Windows环境和Linux环境。 6.6.4.2.4.1、Windows环境下开发​ 在VC++中使用OpenMP，将 Project 的Properties中C/C++里Language的OpenMP Support开启（参数为 /openmp），就可以让VC++编译时支持OpenMP 的语法； ​ 编写使用OpenMP 的程序时，则需要先include OpenMP的头文件：omp.h。 ​ for 循环并行化处理，要在前面加上一行 ​ #pragma omp parallel for ​ 实例： 12345678910111213141516171819#include &lt;STDIO.H&gt;#include &lt;STDLIB。H&gt;void Test(int n){ for(int i = 0; i &lt; 10000; ++i) { //do nothing， just waste time } printf(&quot;%d， &quot;， n);}int main(int argc，char* argv[]){for(int i = 0; i &lt; 10; ++i) Test(i);system(&quot;pause&quot;);} ​ 上面的程序，在 main() 是一个很简单的循环，十次调用Test()这个函数，把循环的执行次数传进Test() 并打印。运行结果： ​ 0， 1， 2， 3， 4， 5， 6， 7， 8， 9， ​ OpenMP main() 里平行化处理，按照如下方式进行： 12345678910111213141516171819202122#include &lt;omp.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;void Test (int n){ for(int i = 0; i &lt; 10000; ++i) { //do nothing， just waste time } printf(&quot;%d， &quot;， n);}int main(int argc，char* argv[]){ #pragma omp parallel for for(int i = 0; i &lt; 10; ++i) Test( i ); system(&quot;pause&quot;);} ​ 运行结果： ​ 0， 5， 1， 6， 2， 7， 3， 8， 4， 9， ​ OpenMP把循环分成两部分，拆成 0 - 4， 5 - 9，不同的线程去跑，进行交错输出。 ​ 怎么确定真的有跑多线程呢，需要从硬件的角度来进行观察。如果本来有多处理器、多核心处理器或有 Hyper Thread 的话，一个单线程程序，最多只会把一颗核心的使用量吃完。 ​ 单线程的程序，工作管理员中看到CPU使用率最多是50%，说明CPU利用率低。利用 OpenMP 把循环进行平行化处理后，把两颗核心的 CPU 都用了！也就是CPU使用率提高了，可能达到100%，这就证明并行的结果。 6.6.4.2.4.2、Linux环境​ gcc 支持 OpenMP是这样的：使用gcc 编译时加上 -fopenmp 开关参数即可： ​ $ gcc -fopenmp &lt;source.c&gt; -o ​ $ g++ -fopenmp &lt;source.cpp&gt; -o ​ 示例： 12345678910111213141516171819202122#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;algorithm&gt;#include &lt;omp。h&gt;using namespace std;void hello(){ int my_rank = omp_get_thread_num(); int thread_count = omp_get_num_threads(); printf(&quot;Hello from thread %d of %d\\n&quot;， my_rank， thread_count);}int main(){ int thread_count = 4; #pragma omp parallel num_threads(thread_count) hello(); return 0;} ​ 上面代码首先增加了一个 omp。h 头文件，然后主函数中多出来一句串行代码中没有的预处理器指令，其它的跟正常的串行程序没什么区别。 ​ # pragma 是 C/C++ 中用以允许非 C 语言规范部分的行为，如果编译器不支持预处理器指令，那么编译时这句话就会被忽略掉。 ​ OpenMP 依靠# pragma omp 开头的预处理器指令来进行线程级并行。预处理器指令后面加的是一些子句，用来附加额外控制信息。比如说 num_threads() 子句是用来控制接下来的代码块中需要用多少个线程进行并行。 ​ 程序编译完成之后直接打开是无法运行的，需要用 mpiexec 来调用生成好的可执行文件，mpiexec 会首先得到运行的目标机器、进程数等情况，然后启动多个进程，等到多进程全部开起来之后，并行就开始了。 ​ 在 OpenMP 中，编译完成之后的可执行文件可以直接运行，程序在一开始是串行运行，到了需要并行的时候，单进程单线程会分裂成单进程多线程（其实是除了主线程以外，又启动了几个新的线程同时执行），执行完毕后又回到单线程串行。而且每次并行的线程数是可以在运行时指定的。 ​ OpenMP 可以只把其中的一部分作并行处理，而且并行的时候共享的内存、变量等都是在一起的，从串行程序的基础上改造过来非常容易，可能只要加几段预处理器指令就可以了，剩下的交给编译器和处理器去解决。 6.6.4.2.5、同步协作​ MPI 依靠进程间通信完成协作，OpenMP靠内存共享的解决线程写作。 ​ OpenMP 冲突解决有四种方法： A：Crirical 指令 / 归约指令 ​ 例如： 12345678int sum = 0;#pragma omp parallel for num_threads(100)for (int i=0;i&lt;100;i++){ sum += i;}printf(&quot;%d\\n&quot;， sum); ​ 运行的结果是每次运行，sum 最终结果可能是不同的。这是什么原因呢，运行时多个线程同时访问 sum 变量，可能前一个线程写上去的内容马上被下一个线程给覆盖掉了，数据共享出现了问题，即出现了数据冲突。 123456789int sum = 0;#pragma omp parallel for num_threads(100)for (int i=0;i&lt;100;i++){ #pragma omp critical sum += i;}printf(&quot;%d\\n&quot;， sum); ​ 加上# pragma omp critical 指令，来进行数据处理，会进行特殊的处理，编译器安排线程对下面执行的代码进行互斥访问，这是一种运行约束。每次只能够有一个线程执行下面的这一句代码。这样保证数据处理的有序与安全性能。 12345678int sum = 0;#pragma omp parallel for num_threads(100) reduction(+: sum)for (int i=0;i&lt;100;i++){ sum += i;}printf(&quot;%d\\n&quot;， sum); ​ reduction(+: sum) 是归约子句，这是一个特定的写法。加上这一句，执行并行任务时，sum 本身是共享的，但这个共享和上面是不一样的，每个线程执行时会产生一个私有变量，在并行块运算结束后，系统会将私有变量的值整合，然后传递给共享变量。这样保证数据的共享性。 B：带命名的 critical 指令 ​ 用# pragma omp critical(name) 来命名不同的临界区。 ​ 同一个临界区的访问和上面一样，一次只有一个进程操作，保证数据的安全，不同的临界区有不同的进程进行同时访问，这样保证数据的同步。安全与同步是处理时间必须考虑的因素。 C：atomic 指令： ​ 用# pragma omp atomic 的使用形式为： 12345x &lt;op&gt;= &lt;expression&gt;;x++;++x;x--;--x; ​ 这些语句用 CPU 中的特殊硬件指令来实现，加快处理结果。 D：简单锁 123omp_set_lock(&amp;lock);critical sectionomp_unset_lock(&amp;lock); ​ 锁住的区域只允许单个线程进行访问，保证数据安全。 6.6.4.3、OpenACC OpenACC，开放式并行编程标准，程序员能够轻松利用异构 CPU/GPU 计算系统的强大能力。和CUDA一样，是并行计算的主要平台架构。 6.6.4.3.1、简介 OpenACC 为并行程序员给编译器提供简单的提示，通过指令，使编译器能够识别哪些代码部分需要加速，无需程序员修改或改编底层代码本身。简化并行编程标准，把计算任务映射到加速器这方面，指令向编译器呈现出并行机制，从而让编译器能够更好执行工作。 OpenACC 指令由 PGI、Cray 以及英伟达在 CAPS 的支持下开发而成，是多家企业希望利用指令来简化 GPU 编程模型的一个共同愿景。硬件厂商和技术协会一起，这些企业均致力于支持一种共同的编程标准。共同把并行编程技术推向前进。 OpenACC指令与OpenMP指令工作方式很类似，都是指令级别编程，适用于高度数据并行代码。可插入标准的C，C + +和Fortran程序直接指导编译器进行某些代码段的并行。这些并行的代码，编译器会特别注意数据在CPU和GPU（或其它）之间来回转移的逻辑关系，并将计算映射到适当的处理器上。 这些指令由硬件支持，不需要较大的改动，相对小的改动以标示出加速并行区域。指令设计适用于一个通用并行处理器，这样相同的代码可以运行在多核CPU、GPU或任何编译器支持的其它类型的并行硬件上。 6.6.4.3.2、发展与应用 2015年7月，北京，全球视觉计算技术行业领袖NVIDIA发布了OpenACC工具套件，通过全新的套件，科学研究将可以做更多事情，并大幅提升计算效率。 虽然计算核心在短时间内不会变得更快，这是硬件的制约，但处理器的并行计算能力越来越强大。这一趋势十年里一直存在，而且还会持续下去，通过软机制提高效率。 OpenACC已在HPC行业中得到广泛支持，简化GPU等现代处理器的并行编程。2011年Cray、PGI以及NVIDIA等领先的HPC供应商推出OpenACC编程标准以来，已有8000多名研究人员和科学家采用了这一标准。并取得了卓越的成绩，免费的标准 OpenACC工具套件应用快捷，使用方便，快速对GPU编程。全新的OpenACC工具套件行业领先，获得了广泛的应用。 该工具套件中，向学术开发者和研究人员免费提供这一编译器，商业用户有90天的免费试用期，黄总还是很厚道的。 全新的OpenACC工具套件有一个特别的工具：NVProf Profiler，指导用户如何添加 OpenACC“指令”，会进行编译器提示，以加速代码实现。通过真实案例可以方便快捷的入门。 简单的指令让研究人员能够感受到并行计算，运行加速，同时不会破坏现有的CPU代码，不浪费之前所有代码编写花费的时间，这些指令与代码具有着较好的应用。 6.6.4.3.3、硬件独立性 硬件独立性代表一个标准，无论对于硬件厂商或者软件厂商，对于HPC用户来说特别重要，无论软件厂商还是硬件厂商，不愿意接受那种受供应商限制的，非便携式编程环境。 OpenACC的一大主要特性是高性能移植，这主要是硬件独立性的结果。PGI OpenACC编译器则把这一优势推向全新高度，让世人惊叹。该编译器首次能够在x86多核CPU和GPU上加速OpenACC代码，极大程度提高了效率。 没有一台配备GPU的系统时，编译器会在多个 CPU核心上完成代码并行化，进而提升性能。当系统中有GPU时，该编译器将会针对GPU做代码并行化的优化，最终与多核CPU相比可带来5~10倍的性能提升。这种提升大大提高了效率，在今天得到广泛的应用。 OpenACC代码在C语言基础上进行修改，通过添加compiler directives 编译器指令(pragmas): #pragma 来标示。这个和前面介绍的有些相似。 cuda 中 __syncthreads()进行线程同步，目前的OpenAcc还没有线程同步机制。 OpenACCDevice model OpenACCexcute model 6.6.4.3.4、实例01—parallel loops 第一段代码和第二段代码等效，在OpenAcc中一个parallel区域有一个单个loop组成。 123456#pragma acc parallel loop copyin(M[0:Mh*Mw])copyin(N[0:Mw*Nw]) copyout(P[0:Mh*Nw])for (int i=0; i&lt;Mh; i++){ 。。。} 等价于： 123456789#pragma acc parallel copyin(M[0:Mh*Mw])copyin(N[0:Mw*Nw]) copyout(P[0:Mh*Nw]){ #pragma acc loop for (int i=0; i&lt;Mh; i++) { 。。。 } }} 结果说明： copyin对应拷贝内存从host到device copyout对应拷贝内存从device到host 6.6.4.3.5、实例02—gangs and workers gangs可以类比成cuda的block； workers可以类比成thread。 123456789101112#pragma acc parallel num_gangs(1024) num_workers(32){ #pragma acc loop gang for (int i=0; i&lt;2048; i++) { #pragma acc loop worker for (int j=0; j&lt;512; j++) { foo(i，j); } }} 解释：线程分配: 102432 = 32K 个thread，两个循环题一共是执行2048512 = 1M， 每个thread执行foo()函数 1M/32K = 32 次。 另外一个代码： 结果说明：代码会分配1023*32个thread，每个gang=1024， 对于每个gang来说执行a =23 是冗余的，只需要执行一次即可。 1234#pragma acc parallel copyout(a) num_gangs(1024) num_workers(32){ a = 23;} 再看下面的例子： 123456789#pragma acc parallel num_gangs(32){ Statement 1; #pragma acc loop gang for (int i=0; i&lt;n; i++) { Statement 2; }｝ Statement 3; 12345678910#pragma acc loop gangfor (int i=0; i&lt;m; i++){ Statement 4;}Statement 5;if (condition) Statement 6; 结果说明：从循环次数上来说，gang32个，statement2的循环次数n，statement4循环次数是m， 最终到底分配多少个thread取决于编译器，有可能m&gt;n，则分配m个，实际情况可能更加复杂。 statement1， 3， 5，6 对于32gang来说是冗余的，情况和上面的相同，可以看出OpenAcc中的冗余是对于gang来说的，下面的这种写法可以消除这种冗余：取得更好的效果，在编程时间应该注意。 123456789101112131415161718192021222324#pragma acc parallel num_gangs(1)num_workers(32){ Statement 1; #pragma acc loop gang for (int i=0; i&lt;n; i++) { Statement 2; } Statement 3; #pragma acc loop gang for (int i=0; i&lt;m; i++) { Statement 4; } Statement 5; if (condition) { Statement 6; }} 6.6.4.3.6、实例03—kernel regions1234567891011121314151617181920#pragma acc kernels{ #pragma acc loop num_gangs(1024) for (int i=0; i&lt;2048; i++) { a[i] = b[i]; } #pragma acc loop num_gangs(512) for (int j=0; j&lt;2048; j++) { c[j] = a[j]*2; } for (int k=0; k&lt;2048; k++) { d[k] = c[k]; }} 结果说明： 和前面比较，区别是 acc kernel， 也就是指令不一样，前面代码用的是acc parallel。 Kernel 结构主要描述程序员意图: 当前程序适合并行，编译器根据描述会有非常灵活的表现。把决定权留给编译器。 编译器的参与避免了硬件的模糊性，为并行开发提供了便利。 6.6.4.5、OpenAL​ OpenAL，英文全称为：Open Audio Library，自由软件界的跨平台音效API，由Loki Software，主要应用是在音效缓冲和收听中编码。 ​ OpenAL设计给多通道三维位置音效的特效表现，其 API 风格模仿自OpenGL。 ​ Loki 倒闭以后，该开发接口，开始由自由软件/开放源始码社群继续维护。最大的主导者是创新科技，并得到来自 Apple 和自由软件/开放源代码爱好者的持续支援。这是今天仍在活跃的基本原因。 ​ OpenAL 主要功能是在来源物体、音效缓冲和收听者中编码。来源物体包含一个指向缓冲区的指标、声音的速度、位置和方向，以及声音强度。收听者物体包含收听者的速度、位置和方向，以及全部声音的整体增益。缓冲里包含 8 或 16 位元、单声道或立体声 PCM 格式的音效资料，表现引擎进行所有必要的计算，如距离衰减、多普勒效应等。 ​ 不同于 OpenGL 规格，OpenAL 规格包含两个API分支：这是由于OpenAL的特点决定的。以实际 OpenAL 函式组成的核心，和 ALC API，ALC 用于管理表现内容、资源使用情况，并将跨平台风格封在其中。还有ALUT库，提供高阶“易用”的功能，其定位相当于 OpenGL 的 GLUT。 ​ 支持平台包括：Mac OS X、iOS、Linux、BSD、Solaris、IRIX、Windows PlayStation、Xbox等操作系统上。在如下工具中也进行广泛的应用。Blender - 3D 建模和渲染工具。Unity - 3D 游戏引擎和 IDE。Basic4gl - 编译器和编程软件。 6.6.4.6、OpenGL​ 略（上主题已有讲述）。 6.6.5、总结​ 人工智能应用的广泛性，在机器视觉层面，不可能靠一套框架进行开发，未来在机器视觉、人工智能、音视频处理层面不排除有更多支持库的出现。 ​ 美摄SDK应用人工智能技术，在智能视觉、视音频领域进行着探索，为短视频技术的发展，写下浓重的一笔， ​ 基于工业相机的软件编程。厂商提供驱动与程序示例。工程公司参考相关示例，通过算法对相机视频媒体数据进行加工分析。 ​ 机器视觉偏向于机器学习/并行运算，运用数据挖掘技术，进行模型训练。机器视觉在硬件上往往和GPU关联，在框架支持上和大数据进行关联。 ​ 国外重点进行人工智能算法研究，人工智能方案策划，人工智能工具研发。国内重点进行工具应用。 ​ 目前，国内应用最多的是TensorFlow和PyTorch，来进行模型训练，导出接口，在应用层面调用。形成各种人工智能系统。 ​ 视频领域的人工智能系统是视频智能应用的主要标柱，国内人工智能发展日新月异，在视频方面也有一些完善的框架与接口，为人工智能视频系统提供算法支持。 6.8、启示​ 硬件是推动软件技术发展的原动力，在硬件技术进步的基础上，智能时代为图形图像、音视频领域添加了人工智能的成分。 ​ 从图形图像角度来说，不仅是硬性参数的提升，更是对图像数据的智能修复处理。从视频角度来说，不仅仅是摄影、录制、编排硬术的提升，更是对视频数据的深度挖掘。 ​ 智能修复与深度处理从前是不可想象的，当流媒体技术过渡到深度处理时，代表着人类信息加工能力的显著增强。从早期自然语言处理到今天流媒体的并行运算，代表着是技术的巨大进步。 ​ 硬件水平的进步，尤其是工业相机水平的进步，促进了高清晰领域的图形图像处理。传统相机水平的提升，必将为视频处理提供新的发展方向与发展空间。 ​ 机器视觉技术是智能时代的核心技术，机器视觉技术整体分为两部分。第一部分是基于工业相机的专业处理，第二部分是传统视频智能处理。 ​ 国外科技公司肩负着智能时代硬件发展的重任，推动GPU、TPU、NPU、专业相机等硬件功能提升。同时提供音视频、图形图像领域的算法验证，给出相关解决方案。 ​ 国内科技公司担负着人工智能终端应用的重任，以国外底层研发为基础，进行行业分类，市场整合，应用落地。 ​ 在量子计算机发展的大背景下，不远的将来，相信技术将会发生变革，行业将会重新洗牌。人工智能的基础理论将会有翻天覆地的变化，人工智能的应用将会更深刻与广泛。今天的人工智能是量子时代的一个前走而已。真正的人工智能是量子时代人工智能。 ​ 在第四次科技革命的智能时代，黄色面孔、东方公司逐渐增多，这个沉默了200年的民族，开始重新屹立于世界民族之林。 7、显示标准与视频处理单元​ 消费级视频智能处理大体有10年左右，有了巨大的发展，展望未来，对应于大厂而言，竞争是标准的竞争。包含显示标准与处理单元，竞争推动了科技的进步，市场的繁荣。 ​ 新的显示硬件也不断发展，GPU基础上，出现了GPGPU、TPU、NPU、VPU、APU等新的视频处理单元，相信未来有更多的数据硬件处理单元出现。 ​ 人工智能还处在初级阶段，标准与规范处在变化中，随着高清晰视频硬件的出现，软件算法很多方面也面临着调整。近些年各国重视人工智能的发展，资本的投入，政策的驱动增添了人工智能发展的活力。 7.1、显示标准​ 多年江湖厮杀，各路显卡被赶尽杀绝，留下英伟达和AMD，·目前显卡技术的革新，主要就是A卡与N卡技术的发展。英伟达偏重人工智能，AMD偏重于GCN与APU方向。 ​ 近期倡导的显示技术有英伟达的G-Sync和AMD的Freesync 2。在介绍G-Sync的同时，有必要介绍下V-Sync。 7.1.1、V-Sync​ 垂直同步又称场同步（Vertical synchronization），从CRT显示器的显示原理来看，单个像素组成了水平扫描线，水平扫描线在垂直方向的堆积形成了完整的画面。 ​ 屏幕的刷新过程是每一行从左到右（行刷新，水平刷新，Horizontal Scanning），从上到下（屏幕刷新，垂直刷新，Vertical Scanning）。当整个屏幕刷新完毕，即一个垂直刷新周期完成，会有短暂的空白期，此时发出 VSync 信号。所以，VSync 中的 V 指的是垂直刷新中的垂直-Vertical。 ​ 显示器的刷新率受显卡DAC控制，显卡DAC完成一帧扫描后就会产生一个垂直同步信号。打开垂直同步指的是将该信号送入显卡3D图形处理部分，这样让显卡在生成3D图形时受垂直同步信号的制约。 ​ 显示器上的图像是一线一线扫描上去的，无论隔行扫描还是逐行扫描，显示器都有2种同步参数——水平同步和垂直同步。 ​ 水平同步脉冲（Horizontal synchronization pulse， Hsync）加在两个扫描行之间。它是一个短小的脉冲，一行扫描完成之后，它就会出现，指示着这一行扫描完成，同时也指示着下一行将要开始。 ​ 水平同步脉冲出现后，会有一小段叫horizontal back porch的时间，这段时间里的像素信号不会被显示出来，过了这一小段时间之后，电子枪就开始扫描新的一行，将要显示的内容扫描到显示器上。 ​ 垂直同步脉冲（Vertical synchronization， Vsync）是加在两帧之间。跟水平同步脉冲类似，但它指示着前一帧的结束，和新一帧的开始。 垂直同步脉冲是一个持续时间比较长的脉冲，可能持续一行或几行的扫描时间，但在这段时间内，没有像素信号出现。 7.1.2、G-Sync​ G-SYNC技术可解决V-SYNC带来的取舍问题，不论画面更新率有多快，它都可以让屏幕与GPU完全同步，提供无与伦比的PC游戏体验。通过NVIDIA G-SYNC技术游戏场景可即时呈现在玩家的眼前，物件也将更清晰锐利，游戏也变得更流畅。 ​ 2013年10月18日，NVIDIA editor’s day第二天，连续发布GameStream PC Game for Shield以及ShadowPlay两项重磅技术之后，NVIDIA在加拿大蒙特利尔正式发布了全新的针对画面连贯性的新技术——G-SYNC。 ​ 作为垂直同步技术的替代以及自适应垂直同步技术的延伸，G-SYNC技术不仅解决了画面撕裂问题，同时从根本上解决了困扰垂直同步技术许久的画面视觉卡顿问题。 ​ G-SYNC技术在显示器中内置一枚可与GeForce硬件直接通讯的芯片，这枚自带缓存的芯片可以协调显示器与GPU outputbuffer之间的数据同步。 ​ 通过G-SYNC芯片的控制，显示器的刷新延迟将可以与GPU帧输出延迟保持完全一致，支持G-SYNC技术的显示器会根据GPU当前的性能水平自动调节刷新率， ​ G-SYNC芯片侦测到GPU的帧输出延迟大于16ms时，它会自动延长显示器的刷新延迟，避免传统的帧丢弃导致的视觉卡顿现象。 ​ G-Sync能够去除游戏垂直同步（VSync）开启时的画面滞后问题，也能够克服垂直同步关闭时画面失真问题。常规显示器会直接同步GPU的处理结果，借助G-Sync模块，只有当GPU完成一帧的渲染和画面优化后，显示器才会刷新显示内容。 ​ 很多公司都推出了支持G-Sync图像增强技术的显示器,消除了屏幕撕裂和垂直同步输入延迟等影响， 增强了现有显示器功能的同时屏幕画面呈现出场景及时出现、物体更加锐利以及游戏运行更加顺畅等出色的显示效果。G-Sync能强制显示器运行在GPU的帧速率下，甚至能让原生刷新率降到更低，提供更好的视觉效果。 7.1.3、FreeSync2​ FreeSync 2 是AMD力推的视觉效果增强技术，可有效消除游戏中常见的撕裂(Tearing)、卡顿(Shuttering)现象，保证画面流畅、无撕裂、无卡顿、无伪影。 ​ 图像撕裂是屏幕图像看起来不连贯，这是帧速率（显示图像帧的速率）与显示器刷新率（显示器图像刷新频率）不匹配的结果。FreeSync2为显示器提供可变刷新率，即动态刷新率（VRR / DRR）。该功能使显示器的刷新率与AMD Radeon显卡的帧速率相匹配。 ​ FreeSync2支持高达240Hz的刷新率，具体取决于显示器。这样，可以享受显卡能够达到的最大帧速率。如果眼睛够敏锐的话，你可能会发现到输入延迟，或者鼠标移动和光标实际移动之间的延迟也降低了。FreeSync基于VESA的自适应同步协议，可以在DisplayPort和HDMI上运行。 ​ FreeSync2支持高动态范围&amp;色域支持，低延迟、低刷新率补偿技术等。让游戏显示效果更加逼真。 ​ 从HDR内容到显示器传输时需要进行Tone Mapping，这个额外的计算增加了GPU处理数据，同时增加了延时。FreeSync2取消了传输过程的转换过程，降低HDR转换带来的延迟。 ​ FreeSync2引入的另一个新功能是LFC，Low Frame Rate Compensation低刷新率补偿技术，当游戏的FPS小于显示器最低刷新率时，通过额外插帧(GPU计算，类似MEMC)，让低FPS的画面更加流畅。LFC技术的应用，即时显卡渲染FPS较低时也可以显著的改善画面流畅度，提高游戏体验。 7.1.4、总结​ 显示器是显示部分的前端，显示标准对显示硬件的发展起着引导的作用，显示标准的变革通过传统硬件大厂来推动，目前而论，只有NVIDIA、AMD、INTEL才有这样的实力。 ​ 显示标准对于图形图像、视频、硬件都有着紧密的联系，发展过程中，标准的改变将推动软硬件的发展。 ​ 美摄SDK，支持G-Sync、V-Sync、FreeSync2标准，支持最新显示规范，彰显短视频价值。 7.2 VPU VPU(Video Processing Unit，视频处理单元）是一种全新的视频处理平台核心引擎，具有硬解码功能以及减少CPU负荷的能力。VPU可以减少服务器负载和网络带宽的消耗。 ​ VPU由ATI提出，区别于传统GPU（Graph Process Unit，图形处理单元）。图形处理单元又包括视频处理单元、外视频模块和后处理模块这三个主要模块。 7.2.1、VPU的基础特性​ A、支持视频编解码标准类别丰富，图像高清。 ​ B、支持多种抗误码工具、多解码和全双工多方通话同时进行。 ​ C、提供了可编程性、柔初性，以及易于升级的解码和编码或主机接口，因为在编解码处理和主接口都实现为可编程微处理中的固件。 7.2.2、VPU特色及应用​ VPU针对视觉处理应用而设计，在性能、功耗和功能性方面都有特别的强化，使之更贴近于实际的应用需求，其设计兼顾到多种用途，专门为视觉处理进行硬件系统的优化。 ​ VPU也是SoC，集成多个主控RISC的CPU、许多硬件加速器单元和矢量处理器阵列，专门为视觉海量像素设计的高性能影像信号处理器(ISP)，以及丰富的高速外围接口。 ​ 保证强大性能和功能的前提下，VPU采用更先进的集成电路工艺，大大缩小了芯片的尺寸，结合有效的技术手段，降低各个运算单元的功耗。 ​ VPU为视觉应用提供了一个强大的平台，更多的开发工作是在软件上，基于VPU的视觉应用系统开发可以充分利用片上的硬件单元及相关的软件资源。 ​ 包含工具、支持库及框架的完整VPU软件开发套件(SDK)，视频处理器中涉及视觉处理的单元得到了增强，如核心视觉处理单元、线性代数运算矩阵，还有前端影像处理单元，不仅包含ISP处理，还有ISP仿真，支持相机调试工具。 ​ 图形处理能力的提升表现在支持图形检测API，为便于多核异构芯片开发而支持OpenCL。由于在视觉应用中，与高敏感度和超高像素的传感器的接驳尤为重要，因此专门有传感器支持接口单元。 ​ VPU特有的工具单元提供视觉调试全面支持。VPU中的主控制器、BSP、HDK等通用单元以开放为主，便于客户进行更多应用开发。 7.2.3、Movidius​ 作为一个行业的平台领先者需要有足够的积累和不懈的进取，当然还要有强大的财力和物力、人力的支持，VPU平台的创建和发展也绝不轻松。 ​ Movidius在都柏林成立，位于爱尔兰，在罗马尼亚，硅谷建立研发团队。公司创始人堪称半导体和处理器行业的元老，公司设立有技术指导委员会，确立公司的技术路线和VPU平台发展总体规划。 ​ Movidius核心管理层，来源于ATI及其它知名公司资深的高管和专家。公司员工未过百人，研发人员占了九成，五分之一负责VPU芯片硬件设计，其余从事VPU上软件构建，可见VPU应用在很大程度上依赖于软件。2016年，Movidius被intel收购。 7.2.4、INTEL​ 2019年，英特尔人工智能峰会（Intel AI Summit 2019），英特尔展示了一系列新产品，旨在加速从云端到边缘的人工智能系统开发和部署，迎接人工智能浪潮的到来。 ​ 英特尔展示了面向训练 (NNP-T1000) 和面向推理 (NNP-I1000) 的英特尔Nervana神经网络处理器 (NNP)。作为英特尔为云端和数据中心客户提供的首个针对复杂深度学习的专用 ASIC芯片，英特尔Nervana NNP具备超高扩展性和超高效率。 ​ 英特尔还发布了下一代英特尔Movidius Myriad视觉处理单元 (VPU)，用于边缘媒体、计算机视觉和推理应用。 7.2.5、代码示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/* * VPUCoder.h * * Current, Only Support YUV420sp encoder and decoder * * Created on: Dec 16, 2013 * Author: henry * * Example: * * int main() * { * int ret = InitCodec(); * //===========encode video * ret = StartEnc(&quot;/sdcard/test.mkv&quot;, 1280, 720, 30); * * while(1) * { * //get data and length, //unsigned char* data; int length * ret = ProcessEnc(data, length); * } * ret = StopEnc(); * * //===========decode video * ret = ProcessDec(&quot;/sdcard/test.mkv&quot;, 1280, 720); * return 0; * } */#ifndef VPUCODER_H_#define VPUCODER_H_/** * Init encoder and decoder handle, only call once, must first call * * @return 0 is successful, another fail */int InitCodec();/** * setup encoder configure * @param filePath : save file path * @param enc_width : video width * @param enc_height : video height * @param enc_fps : video fps * * @return 0 is successful, another fail */int StartEnc(const char* filePath, uint32_t enc_width, uint32_t enc_height, uint32_t enc_fps);/** * stop encode video */void StopEnc();/** * @params data : frame data * @params length : frame length * * @return 0 is successful, another fail */int ProcessEnc(const unsigned char* data, uint32_t length);/** * setup decoder configure * @param filePath : source file path * @param enc_width : video width * @param enc_height : video height * * @return 0 is successful, another fail */int ProcessDec(const char* filePath, uint32_t dec_width, uint32_t dec_height);#endif /* VPUCODER_H_ */ 7.2.6、总结​ GPU的概念由NVIDIA公司提出，GPU英文全称 Graphic Processing Unit，中文译为“图形处理器”。 ​ VPU的概念由ATI公司提出，VPU英文全称 Visual Processing Unit，中文译为“视觉处理器”。 ​ GPU与VPU实际均为显示处理核心，GPU提供了更多图形接口，VPU提供了更多视频接口。2006年，ATI公司被AMD公司收购之后，已正式采用GPU的名字。 ​ INTEL的加入，VPU近些年取得巨大的发展，社会发展中，视频处理愈来愈重要，VPU适应实时潮流，尤其在嵌入式领域应用广泛。 ​ 美摄SDK，国际领先的视频引擎，优秀的视频运算架构，引领短视频发展的方向。 7.3 APUAPU是“Accelerated Processing Units”的简称，中文名字叫加速处理器，是AMD融聚未来理念的产品，它第一次将处理器和独显核心做在一个晶片上。 ​ CPU与APU协同计算、彼此加速，具有高性能处理器和最新支持DX11独立显卡的处理性能，大幅提升电脑运行效率，实现了CPU与GPU真正的融合。APU是处理器未来发展的趋势。 7.3.1、AMD与APU​ 从APU发展来看，AMD让CPU和GPU彻底融为一体，无论是AMD的Llano，还是Brazos，目标都是一致的。 ​ AMD认为，CPU和GPU的融合分为四步进行： ​ 第一步：物理整合(Physical Integration)，将CPU和GPU集成在同一块硅芯片上，利用高带宽的内部总线通讯，集成高性能的内存控制器，借助开放的软件系统促成异构计算。 ​ 第二步：平台优化(Optimized Platforms)，CPU和GPU之间互连接口进一步增强，统一进行双向电源管理，GPU支持高级编程语言。 ​ 第三步：架构整合(Architectural Integration)，实现统一的CPU/GPU寻址空间、GPU使用可分页系统内存、GPU硬件可调度、CPU/GPU/APU内存协同一致。 ​ 第四步：架构和系统整合(Architectural &amp; OS Integration)，主要特点包括GPU计算环境切换、GPU图形优先计算、独立显卡的PCI-E协同、任务并行运行实时整合等等。 ​ AMD Fusion系列APU将多核(x86)中央处理器、支持DX11标准的强大独立显卡性能以及高速总线融合在一块芯片上，拥有并行处理引擎和专门高清视频加速模块，实现数据在不同处理核心间的加速传递。 ​ 基于AMD Fusion APU的台式机、笔记本和高清轻薄本已经销售多年。基于AMD Fusion APU的平板电脑和嵌入式电脑有很多优点。高清视频播放效果流畅，满足多种应用的突破性的计算能力，全面支持DX以及强大的电池续航能力。 ​ AMD通过和宏碁、华硕、戴尔、富士通、惠普、联想、微星、三星、索尼、东芝等领先PC厂商合作，在电脑上推出基于AMD Fusion APU的新品。 AMD公司高级副总裁Rick Bergman表示：“简而言之，我认为AMD Fusion加速处理器是自从x86架构问世之后40余年来处理器领域最伟大的进步。通过这一跨越，我们让顾客能够随时随地体验高清视频、享受 超级个人计算体验，并且让笔记本电脑具备全天的电池续航能力。这是一个全新的产品系列，全新的视角，给消费者带来全新的精彩应用体验。” 7.3.2、VISION引擎​ 随着硬件技术的进步，高清视频的时代到来了。从YouTube视频网站到DirectX12电脑游戏再到蓝光碟片，得到广泛应用。AMD VISION引擎横空出世，一系列与高清视频相关的独特性能将使基于AMD APU的个人电脑为用户带来更加生动与逼真的高清视频体验。 ​ VISION引擎汇集了下列功能： 支持DirectX11标准 强大的并行处理能力加速应用性能提升 AMD Radeon™ HD 6800系列显卡整合UVD3视频加速模块 独特的图形驱动程序，每月更新，不断提高视频性能。 ​ 带有VISION引擎标识的电脑代表着更强大的性能。更流畅的上网体验；华丽、流畅、安静的高清视频播放；使标清视频播放出高清效果；将2D内容转换成更立体的3D格式；轻松高清应用；为用户带来3D游戏体验。 ​ 运算体验与软件密不可分，开发者受到CPU和GPU处理信息时各自为战进行独立计算的制约。今天，AMD Fusion APU消除了这一障碍，开发者可以利用GPU的并行处理能力。 ​ AMD Fusion技术全天电池续航能力，续航时间长达10小时以上。单芯片设计所带来的节电效果超过我们的预料。 7.3.3、APU新品​ 锐龙7 5700G处理器采用Cezanne（塞尚）核心，与AMD路线图中一致。其最高频率大约为4.75GHz，为8核16线程，三级缓存为16MB，只有“标准版”的一半，CPU测试成绩则绝对是锐龙5000级别的，轻松压制十代酷睿和自家的锐龙3000。 7.3.4、APU编程​ APU没有设计独立的开发环境，APU目前支持OpenCL与OpenGL、DirectX等。在并行编程领域，主要支持的是OpenCL。 下面是OpenCL示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;sstream&gt;#include &lt;CL/cl.h&gt;const int ARRAY_SIZE = 1000;//一、 选择OpenCL平台并创建一个上下文cl_context CreateContext(){ cl_int errNum; cl_uint numPlatforms; cl_platform_id firstPlatformId; cl_context context = NULL; //选择可用的平台中的第一个 errNum = clGetPlatformIDs(1, &amp;firstPlatformId, &amp;numPlatforms); if (errNum != CL_SUCCESS || numPlatforms &lt;= 0) { std::cerr &lt;&lt; &quot;Failed to find any OpenCL platforms.&quot; &lt;&lt; std::endl; return NULL; } //创建一个OpenCL上下文环境 cl_context_properties contextProperties[] = { CL_CONTEXT_PLATFORM, (cl_context_properties)firstPlatformId, 0 }; context = clCreateContextFromType(contextProperties, CL_DEVICE_TYPE_GPU, NULL, NULL, &amp;errNum); return context;}//二、 创建设备并创建命令队列cl_command_queue CreateCommandQueue(cl_context context, cl_device_id *device){ cl_int errNum; cl_device_id *devices; cl_command_queue commandQueue = NULL; size_t deviceBufferSize = -1; // 获取设备缓冲区大小 errNum = clGetContextInfo(context, CL_CONTEXT_DEVICES, 0, NULL, &amp;deviceBufferSize); if (deviceBufferSize &lt;= 0) { std::cerr &lt;&lt; &quot;No devices available.&quot;; return NULL; } // 为设备分配缓存空间 devices = new cl_device_id[deviceBufferSize / sizeof(cl_device_id)]; errNum = clGetContextInfo(context, CL_CONTEXT_DEVICES, deviceBufferSize, devices, NULL); //选取可用设备中的第一个 commandQueue = clCreateCommandQueue(context, devices[0], 0, NULL); *device = devices[0]; delete[] devices; return commandQueue;}// 三、创建和构建程序对象cl_program CreateProgram(cl_context context, cl_device_id device, const char* fileName){ cl_int errNum; cl_program program; std::ifstream kernelFile(fileName, std::ios::in); if (!kernelFile.is_open()) { std::cerr &lt;&lt; &quot;Failed to open file for reading: &quot; &lt;&lt; fileName &lt;&lt; std::endl; return NULL; } std::ostringstream oss; oss &lt;&lt; kernelFile.rdbuf(); std::string srcStdStr = oss.str(); const char *srcStr = srcStdStr.c_str(); program = clCreateProgramWithSource(context, 1, (const char**)&amp;srcStr, NULL, NULL); errNum = clBuildProgram(program, 0, NULL, NULL, NULL, NULL); return program;}//创建和构建程序对象bool CreateMemObjects(cl_context context, cl_mem memObjects[3], float *a, float *b){ memObjects[0] = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, sizeof(float) * ARRAY_SIZE, a, NULL); memObjects[1] = clCreateBuffer(context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, sizeof(float) * ARRAY_SIZE, b, NULL); memObjects[2] = clCreateBuffer(context, CL_MEM_READ_WRITE, sizeof(float) * ARRAY_SIZE, NULL, NULL); return true;}// 释放OpenCL资源void Cleanup(cl_context context, cl_command_queue commandQueue, cl_program program, cl_kernel kernel, cl_mem memObjects[3]){ for (int i = 0; i &lt; 3; i++) { if (memObjects[i] != 0) clReleaseMemObject(memObjects[i]); } if (commandQueue != 0) clReleaseCommandQueue(commandQueue); if (kernel != 0) clReleaseKernel(kernel); if (program != 0) clReleaseProgram(program); if (context != 0) clReleaseContext(context);}int main(int argc, char** argv){ cl_context context = 0; cl_command_queue commandQueue = 0; cl_program program = 0; cl_device_id device = 0; cl_kernel kernel = 0; cl_mem memObjects[3] = { 0, 0, 0 }; cl_int errNum; // 一、选择OpenCL平台并创建一个上下文 context = CreateContext(); // 二、 创建设备并创建命令队列 commandQueue = CreateCommandQueue(context, &amp;device); //创建和构建程序对象 program = CreateProgram(context, device, &quot;HelloWorld.cl&quot;); // 四、 创建OpenCL内核并分配内存空间 kernel = clCreateKernel(program, &quot;hello_kernel&quot;, NULL); //创建要处理的数据 float result[ARRAY_SIZE]; float a[ARRAY_SIZE]; float b[ARRAY_SIZE]; for (int i = 0; i &lt; ARRAY_SIZE; i++) { a[i] = (float)i; b[i] = (float)(ARRAY_SIZE - i); } //创建内存对象 if (!CreateMemObjects(context, memObjects, a, b)) { Cleanup(context, commandQueue, program, kernel, memObjects); return 1; } // 五、 设置内核数据并执行内核 errNum = clSetKernelArg(kernel, 0, sizeof(cl_mem), &amp;memObjects[0]); errNum |= clSetKernelArg(kernel, 1, sizeof(cl_mem), &amp;memObjects[1]); errNum |= clSetKernelArg(kernel, 2, sizeof(cl_mem), &amp;memObjects[2]); size_t globalWorkSize[1] = { ARRAY_SIZE }; size_t localWorkSize[1] = { 1 }; errNum = clEnqueueNDRangeKernel(commandQueue, kernel, 1, NULL, globalWorkSize, localWorkSize, 0, NULL, NULL); // 六、 读取执行结果并释放OpenCL资源 errNum = clEnqueueReadBuffer(commandQueue, memObjects[2], CL_TRUE, 0, ARRAY_SIZE * sizeof(float), result, 0, NULL, NULL); for (int i = 0; i &lt; ARRAY_SIZE; i++) { std::cout &lt;&lt; result[i] &lt;&lt; &quot; &quot;; } std::cout &lt;&lt; std::endl; std::cout &lt;&lt; &quot;Executed program succesfully.&quot; &lt;&lt; std::endl; getchar(); Cleanup(context, commandQueue, program, kernel, memObjects); return 0;} 7.3.5、总结​ APU的成功，巩固了AMD的市场，和INTEL形成有力的竞争。推动处理器技术、架构技术、并行计算技术的发展。多年以来，INTEL吊打AMD，APU的出现，这一局面得到改变。 ​ 并行计算领域，APU主要支持OpenCL技术，随着时间的推移，OpenCL技术将不断完善，驱动将不断更新。 ​ AMD有着光辉的过去，也应该有着辉煌的明天。为处理器的发展做出了卓越的贡献。图为台湾籍AMD总裁苏姿丰女士。英伟达的黄仁勋为苏姿丰的舅舅。在芯片领域，台籍华人有着卓越的贡献。 7.4 gpgpu 通用图形处理器（General-purpose computing on graphics processing units，简称GPGPU），利用处理图形任务的图形处理器来计算原本由中央处理器处理的通用计算任务。这些通用计算与图形处理没有关系。 ​ 现代图形处理器有强大的并行处理能力和可编程流水线，流处理器可以处理非图形数据。在面对单指令流多数据流（SIMD），且数据处理的运算量远大于数据调度和传输的需要时，通用图形处理器在性能上大大超越了传统的中央处理器应用程序。 7.4.1、主要功能​ 通用图形处理器是近年来出现的计算机芯片，在航空航天及防务应用中的高性能嵌入式计算中广泛应用。前一个十年里作为高端计算机游戏的图形处理引擎引入，是一种大规模并行处理器。不仅有助于复杂的浮点计算，而且容易编程。 ​ 通用图形处理器芯片的主要设计制造商：加利福尼亚州圣克拉拉的NVIDIA公司和加利福亚州桑尼维尔的先进微型器件公司（AMD公司）。 7.4.2、设计优势​ 通用图形处理器广泛使用，其设计支持：包括“开放性图形库”（Open Graphics Library， OpenGL）语言、NVIDIA公司创造的并行处理编程语言CUDA、最近出现的“开放性计算语言”（ Open Computing Language， OpenCL）。硬件平台的支持为软件开发提供了便利。 ​ 下图是中国天树之新推出的最新7NM GPGPU。 ​ 在OpenGL，CUDA和OpenCL编程技术出现之前，大规模并行处理的编程是一项困难的任务，为数不多的专家采用极其神秘(小众编程)语言才能够完成。新出现的软件编程框架，尤其是OpenCL有助于熟悉C语言和C++语言的程序编制人员接受通用图形处理器技术。 ​ 通用图形处理器中，多个处理核规则排列在一起，随着时间的推移，器件中处理核的数量会越来越多，通用图形处理器的软件没有必要随着处理器核数量的增加而重新编写。需要有较好的编程支持。软件框架应该适应硬件设计的改变。 7.4.3、技术原理​ 富兰克林说，通用图形处理器可以用来解析事物以得到可利用的信息，传递周围环境中的有用材料。通用图形处理器所擅长的是完成两方面的工作，一是表现事物，二是解析事物。 ​ 通用图形处理器芯片的应用领域从单一的图形处理装置扩展到了信号处理装置，通用图形处理器的软件编程语言也在向着信号处理和通用处理扩展。类似于“开放性图形库”（OpenGL）那样的图形处理语言就可以用于通用处理。 ​ 通用计算技术，让显卡参与原本CPU计算任务的技术，从提出到现在十余年时间，但是发展神速。 ​ 十年前，高清视频刚流行时，编码高清视频对于电脑来说，处理非常困难。视频编码过程中，大部分运算都是浮点类型的，CPU不善于做这种运算，GPU对于这种类型的计算相当拿手，计算起来量又大又快，那个年代人们在思索，能否用GPU来编码高清视频。 ​ 当时业界的研究重点转向了GPGPU，英伟达凭借着强大的技术实力，在硬件与计算机平台领域。英伟达第一个推出了一套比较完整的解决方案，将原本CPU的运算搬到了GPU之上，视频编码速度比原先快了几倍。 ​ CPU有着通用性的需求，它上面单个核心会设计的非常大而全面，并且由于CPU计算的特性，核心中很大一部分面积用来构建缓存（一个核心中往往有L1和L2两级缓存）和控制单元（解码器与分支预测等前端单元）。CPU功能的强大，代表着CPU本身体量的大，尤其对于缓存的集中。 ​ 实际用来运算的单元面积可能仅仅只占整个核心的一半甚至不到（如图）。种种原因使CPU没有办法做非常大的规模，一个核心中能塞入的东西有限，总体的核心数需要控制在一个合理范围中，多了就会发生各种问题。硬件集成是很麻烦的事情，当工艺没有足够进步的时间，集成发展的大门就关闭了。 ​ 八核Coffee Lake的核心图，可以看到，四个核心的面积已经接近右边的集成GPU。而GPU的设计理念就简单很多，图形计算是一项简单直接的“粗活”，相对单调直接。复杂度远不如CPU要负责的各种各样不同类型的工作，当年想要提高图形计算速度的一个简单办法就是扩大处理器中含有的单元数量。 ​ GPU对于特定的计算任务，有更大的计算单元，在运算能力上远超CPU，表现出来就是现在的GPU在浮点运算吞吐量上远超CPU。 ​ CPU与GPU在构造上的不同 ​ GPU适合大批量特定计算，尤其是并行计算，几大图形软硬件厂商都推出了自己的GPGPU计算解决方案，下面主题进行介绍。 7.4.4、支持方7.4.4.1、ATI Stream​ 首先提出GPGPU实现的厂商是被AMD收购前的ATI，并专门提供了一套开发工具包（SDK），让程序员用该套工具调用GPU来参与计算的能力。不过由于各种限制和AMD收购ATI后支持不足，当时管理也比较混乱，这套SDK在与Nvidia CUDA的竞争中处于下风，后来AMD官方转向支持 OpenCL，这套SDK最终停止了开发。今天很少有人听到这套并行计算框架 ​ ATI Stream Logo 7.4.4.2、CUDA​ CUDA是Nvidia在G80时代推出的一项技术，也是今天最流行的技术。全称Compute Unified Device Architechture，统一计算架构。从G80核心开始，Nvidia率先采用了一种统一设计的架构，将原本管线分工式设计转变为统一化的处理器设计。 ​ CUDA伴随着G80核心的发布一起公之于众，让程序员用C和C++来编写用GPU运行的程序，学习成本比ATI Stream要低一些。今天在并行计算集群领域，CUDA有着广泛的应用。例如TensorFlow和各种音视频引擎平台。 ​ Nvidia CUDA Logo ​ CUDA是目前应用最为广泛的一种GPGPU实现， Nvidia的强力推广之下，CUDA在许多领域大放异彩，今天拥有最光大的市场。英伟达曾经设计过无数成功的硬件，CUDA可以说是英伟达设计的最成功的并行计算平台。CUDA同时推动了英伟达硬件技术的应用 7.4.4.3、OpenCL​ 上面两个GPGPU的实现都是有平台针对性的，要想用他们的解决方案你就得用AMD和英伟达的硬件，而OpenCL就不一样了。所谓Open就是一个开放的标准，但是需要各家硬件厂商为OpenCL提供驱动程序。 ​ OpenCL最早由苹果公司开发出的异构计算框架，苹果公司将这套框架的草案提交到Khronos 组织，作为开放标准供业界使用。在2008年末，1.0版本正式公开，目前Intel、AMD与Nvidia的GPU都支持这套框架。这是除了CUDA之后，另一个流行的GPGPU计算框架。 ​ OpenCL不仅限于x86平台上提供的异构计算框架，跨平台和开放标注的特性，还可以使用专门的可编程电路来加速计算。有广泛的支持空间，业界对于它的支持非常广泛，下图是OpenCL联盟成员。 ​ OpenCL联盟 7.4.4.4、DirectCompute​ 微软是软件行业的老大，在并行计算领域，微软也在进行积极的探索。DirectCompute是微软从DirectX 10开始加入的用于通用计算目的的API集，调用GPU进行加速计算。 ​ 从Vista开始，Windows的各种桌面特效就开始采用DirectCompute来加速计算。在DirectX 11中，微软完善了这套API，并且在Windows系统上更多地使用GPU来加速计算系统界面的各种特效。 ​ 不仅仅是专业的图形图像、音视频领域，在操作系统领域，对并行计算的要求也很好。当我们在使用微软的VS技术时间，VS技术的一大技术支柱就是并行计算技术。 ​ GPU-Z显示该GPU支持的通用计算特性 7.4.5、媒体编码加速​ 十年前，H.264等面向高清应用的视频编码刚流行，CPU的性能限制，编码一段H.264的视频是一件相当耗费时间的事情，所以人们想到了用GPU来加速视频的编码。 ​ Nvidia刚推出CUDA的时候，就将加速视频编码作为该技术的一大卖点，免费提供了一个支持CUDA技术来转码的软件BadaBoom。后来，Nvidia在显卡上加入了专门用于视频编解码的硬件电路，开放了名为NVENC的编码API供软件工程师调用，通用计算也就此离开了这个距离我们最近的领域。 ​ BadaBoom加速视频转码 ​ Adobe是图形图像、音视频技术的霸主。很早就在旗下的CS和CC软件中加入了GPGPU的支持，Premiere Pro和After Effect都支持OpenCL来加速视频实时预览和特效。Adode对并行计算技术的应用走在各家公司前列。 7.4.6、视频补帧与画面优化​ 英伟达、英特尔和AMD三家相继在自己的GPU中加入专用计算电路用以加速编解码视频之后，通用计算就离开了这个领域。不满足于既有的视频品质的人们，又相继开发出了新的可以利用GPGPU的功能：视频补帧。大大改善了视频质量。 ​ 视频补帧：是原本低帧数的视频，通过上下帧的计算，渲染出一帧原本不存在的画面补在两帧之间，使其观感更加流畅。 ​ 比如将24帧的视频补帧至60帧，视频质量圆润流畅。因为这个过程计算量过于庞大，使用CPU跟不上视频播放的速度，没法做到实时补帧，开发者就将这个功能搬到了GPU上来运行，很多人都曾经使用的SVP4，就是一个利用GPGPU的补帧软件。 ​ SVP4补帧软件界面 ​ 科技发展永无止境，视频技术也不例外。视频画面优化领域，强大的视频渲染器MadVR也是利用GPGPU来优化视频画面。 ​ 比如视频播放中出现的色带、色环，在压制过程中出现的瑕疵等，可以使用GPGPU在视频播放过程中进行实时的弥补。使视频更加圆润与高清，视频技术的发展永无止境。 7.4.7、人工智能与深度学习​ 人工智能与深度学习是近年来非常热门的两个有关联的领域，训练人工智能需要非常大的数据计算量，这时候就可以利用上GPU的强大功能，谷歌的深度学习框架TensorFlow，以及FaceBook的Pytorch就使用CUDA来加速学习。 ​ Nvidia这两年不断展示了它们在机器学习方面的一些结果，在RTX系列上引入的DLSS（深度学习抗锯齿）技术就是利用机器学习来达成的。 ​ 英伟达今天在人工智能领域占据着重要的位置，在科技发展过程中，很多公司靠软件驱动技术发展，英伟达靠硬件驱动技术的发展。 ​ DLSS技术 ​ 上图是CUDA在科研领域的一些应用，可以看到GPU就在我们的身边。 7.4.8、超级计算机​ 英伟达在G80开始就推出同架构的高品质计算卡，Tesla品牌之下。诞生了很多用Tesla计算卡来组建的超级计算机。硬件技术的优势，导致英伟达在超算领域领跑全球。 ​ 人工智能是英伟达的发展方向，相信近几年，使用英伟达技术的计算机会逐渐增多。会曾经竞争贝尔·戈登奖的六个入围者中，五个使用了NVIDIA GPU提供支持的超级计算机。 ​ 英伟达联手ARM，在超级计算机领域中继续发力，预计未来采用GPGPU技术的超级计算机将会越来越多。 ​ 近些年，超级计算机硬件领域，英伟达有着强大的技术实力。在云平台上，英伟达超级计算硬件应用较多。 ​ GPGPU相对于PC，是新的概念，十余年的发展已经不仅局限于PC，还走向了其它领域，扎根于我们生活的每个角落。GPGPU已经在许多云计算平台上得到了应用，相信在以后，GPU会更加深入生活的更多方面，尤其与人工智能技术的结合，具有着巨大的应用空间。 7.4.9、示例代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#include &lt;CL/cl.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;fstream&gt;#include &quot;tool.h&quot;using namespace std;/** convert the kernel file into a string */int convertToString(const char *filename, std::string&amp; s){ size_t size; char* str; std::fstream f(filename, (std::fstream::in | std::fstream::binary)); if(f.is_open()) { size_t fileSize; f.seekg(0, std::fstream::end); size = fileSize = (size_t)f.tellg(); f.seekg(0, std::fstream::beg); str = new char[size+1]; if(!str) { f.close(); return 0; } f.read(str, fileSize); f.close(); str[size] = '\\0'; s = str; delete[] str; return 0; } cout&lt;&lt;&quot;Error: failed to open file\\n:&quot;&lt;&lt;filename&lt;&lt;endl; return -1;}/**Getting platforms and choose an available one.*/int getPlatform(cl_platform_id &amp;platform){ platform = NULL;//the chosen platform cl_uint numPlatforms;//the NO. of platforms cl_int status = clGetPlatformIDs(0, NULL, &amp;numPlatforms); if (status != CL_SUCCESS) { cout&lt;&lt;&quot;Error: Getting platforms!&quot;&lt;&lt;endl; return -1; } /**For clarity, choose the first available platform. */ if(numPlatforms &gt; 0) { cl_platform_id* platforms = (cl_platform_id* )malloc(numPlatforms* sizeof(cl_platform_id)); status = clGetPlatformIDs(numPlatforms, platforms, NULL); platform = platforms[0]; free(platforms); } else return -1;}/**Step 2:Query the platform and choose the first GPU device if has one.*/cl_device_id *getCl_device_id(cl_platform_id &amp;platform){ cl_uint numDevices = 0; cl_device_id *devices=NULL; cl_int status = clGetDeviceIDs(platform, CL_DEVICE_TYPE_GPU, 0, NULL, &amp;numDevices); if (numDevices &gt; 0) //GPU available. { devices = (cl_device_id*)malloc(numDevices * sizeof(cl_device_id)); status = clGetDeviceIDs(platform, CL_DEVICE_TYPE_GPU, numDevices, devices, NULL); } return devices;} 7.4.10、总结​ GPGPU，带CPU处理能力的GPU。主要是GPU的工作，GPU的能力，可以协助CPU进行运算力，GPGPU（通用图形处理）超出GPU的能力范围，完全具备通用的数据处理。 ​ GPU，用于图形处理的芯片。（GPU也是一种CPU，相对于显卡）早期显卡是没有专门用做图形处理的GPU的，不支持3D。 ​ CPU，用于数据处理的芯片（图形也可以认为是数据）。中央处理器，一种相对的概念。潜移默化被认定是放在主板上，通过向GPU传送指令，控制GPU。 ​ AMD-APU，加速处理器。集成GPU核心的CPU，并且融合。不同于Intel I系（GPU与CPU独立工作）。 ​ 美摄SDK，采用CUDA、OpenCL、DirectCompute并行计算技术。基于CPU、GPU、GPGPU硬件平台，优秀的音视频引擎，推动音视频技术发展。 7.5 TPU TPU（Tensor Processing Unit）张量处理单元，为机器学习定制的芯片，经过专门深度机器学习方面的训练，它有更高效能（每瓦计算能力）。 ​ ​ 谷歌，2015年6月，I/O开发者大会上推出的计算神经网络专用芯片，为优化自身的TensorFlow机器学习框架而打造，主要用于AlphaGo系统，谷歌地图、谷歌相册和谷歌翻译等应用中。进行搜索、图像、语音等模型和技术的并行处理。 ​ 7.5.1、TPU发展史​ 2016 年，AlphaGo以4:1总分打败围棋世界冠军李世石，随后独战群雄，在与排名世界第一围棋的冠军柯洁对战胜利后宣布“隐退江湖”，背后的芯片开启了芯片产业的新篇章。 ​ 地覆天翻的四年，AI芯片领域，尤其是云端AI芯片，市场规模一路扶摇直上，成为芯片巨头和新势力虎视眈眈之地。 ​ 赛迪2019年8月发布的《中国人工智能芯片产业发展白皮书》，2018年全球云端AI芯片市场规模为62.1亿美元，这一数值预计在2021年达到221.5亿美元，巨大的市场将如火山爆发般呈现在众人眼前，芯片制造的高光时刻到来了。 ​ ​ 这片蓝海中，有一个角色起到了划时代的意义，它就是谷歌TPU（Tensor Processing Unit，张量处理单元）。 ​ 与李世石、柯洁，以及中日韩数十位围棋高手的围棋对战中脱颖而出后，谷歌TPU曾一路狂飙突进，独步天下，现在已演进到了第四代。它的出现，无疑打破了GPU、GPGPU曾一度称霸神经网络推理和训练市场的局面。在大数据、人工智能领域，谷歌的王者之风逐渐显现。 ​ 2019年5月，谷歌I/O开发者大会上，万众瞩目的第四代TPU意外缺席，取而代之的是以1000个TPUv3组成的TPUv3 Pod，以及边缘AI芯片Edge TPU。即便如此，它仍通过一定程度的对外开放，以及辅助谷歌内部服务器应用深刻地影响着云端AI芯片市场。那次大会，后知后觉的人们意识到，谷歌卖的是方案与思想，谷歌已经脱离了技术。 ​ ​ 从市场角度看，未来云端AI芯片巨大的发展潜力和市场机遇为谷歌TPU提供了肥沃的土壤；另一方面，紧迫的算力瓶颈和摩尔定律放缓等问题也越来越难以忽视。谷歌属于未来科技公司，有无穷的可能。 7.5.1.1、始于算力瓶颈，首秀人类围棋界​ 区别于GPU、GPGPU，谷歌TPU是一种ASIC芯片方案。ASIC全称为Application-Specific Integrated Circuit（应用型专用集成电路），是专为某种特定应用需求而定制的芯片。但一般来说，ASIC芯片的开发不仅需要花费数年的时间，且研发成本也极高，一直是个别公司的阵地。 ​ 对于数据中心机房中AI工作负载的高算力需求，许多厂商更愿意继续采用现有的GPU集群或GPU+CPU异构计算解决方案，也甚少在ASIC领域冒险。但谷歌说不了。 ​ ​ 谷歌2006年起产生了要为神经网络研发一款专用芯片的想法，而这一需求在2013年也开始变得愈发急迫。谷歌这家超前的公司，在未雨绸缪。当时，谷歌提供的谷歌图像搜索、谷歌照片、谷歌云视觉API、谷歌翻译等多种产品和服务，都需要用到深度神经网络。 ​ 庞大的应用规模下，谷歌意识到，夜以继日运行的数百万台服务器，它们内部快速增长的计算需求，使得数据中心的数量需要再翻一倍才能得到满足。然而，从成本还是从算力上看，内部中心已不能依靠GPU和CPU来维持。制造芯片的冲动变成了现实。 ​ 种种因素的推动下，不差钱的谷歌正式开始了TPU的研发之旅。经过研发人员15个月的设计、验证和构建，TPU 2014年研发完成，率先部署在谷歌内部的数据中心。谷歌强大的财力保证了研发的成功，成功很大程度源于不差钱。 ​ 内部秘密运行了一年外，谷歌TPU还在围棋界“大杀四方”，斩获“人机大战”的神话。在今天，谷歌还有多少技术，还装在黑匣子中呢？ ​ 使用TPU之前，AlphaGo内置1202个CPU和176个GPU击败欧洲冠军范惠。2015年与李世石对战时，AlphaGo才开始使用TPU，而当时部署的TPU数量，只有48个。TPU大开杀戒，进入无人之境。 ​ 这场对战胜利的“秘密武器”也在一年后的谷歌I/O开发者大会上被揭开神秘面纱，TPU正式面世。在技术上，谷歌隐藏的太深。 ​ 7.5.1.2、谷歌TPU的迭代、云端构建、终端应用​ 面世后短短两年，谷歌TPU已经迭代到了第四代，性能亦不断跃升。随着研发的投入和广泛应用，谷歌也逐步推出可扩展云端超级计算机TPU Pod，以及Edge TPU。谷歌最终目的是超算领域与人工智能。今天，谷歌与英伟达成为超算领域的头狼。 名称 发布日期 性能 应用 TPU V1 2016年 28nm 功耗40w，主频700MHZ 深度学习推理 TPU V2 2017年 180TFLOPs浮点运算、64GB高带宽内存(HBM) 机器学习训练和推理，开始在Google Compute Engine上运行，以用于TensorFlow应用程序 TPU V3 2018年 420TFLOPs浮点运算，128GB(HBM) 扩展至更广泛的深度学习训练和推理领域，已进入Alpha测试阶段。 EDGE TPU 2018年 内建EDGE TPU、网络功能和加密芯片，具有高吞吐量。 企业中的机器学习任务而设计，主要执行AI推理。 TPU V2 POD 2019年 每秒11.5千万亿次浮点运算，4TB (HBM)、环面网状网络 深度学习领域 TPU V3 POD 2019年 每秒100千万亿次浮点运算、32TB(HBM)，环面网状网络。 深度学习领域 7.5.1.2.1、2016年：第一代TPU​ 为神经网络而研发，但谷歌最初的第一代TPU仅用于深度学习推理。从性能上看，第一代谷歌TPU采用了28nm工艺制造，功耗约为40W，主频700MHz。 ​ 研发之初，谷歌需要尽快将TPU部署到内部现有的服务器中，因此研发人员选择将处理器打包成外部加速卡，以插入SATA硬盘插槽后进行嵌入式安装。毫无疑问的是，这种设计是成功的，并很快投入了应用。 ​ TPU通过PCIe Gen3 x16总线连接到主机，实现了12.5GB/s的有效带宽。除了在AlphaGo上应用之外，谷歌第一代TPU还用于谷歌的搜索、翻译和相册等应用的机器学习模型中。 ​ ​ ▲Google第一代TPU（左），在谷歌数据中心中部署的TPU（右） 7.5.1.2.2、2017年：第二代TPU，引入Google Cloud​ 一年更新、研发和迭代，谷歌在2017年5月发布了第二代TPU，并从这一代起能够用于机器学习模型的训练和推理。 ​ 与第一代相比，第二代TPU实现180TFLOPs浮点运算的计算能力，同时其高带宽内存（HBM）也提升到了64GB，解决了第一代TPU内存受带宽限制的问题。电子硬件的发展堪称神速。 ​ 运行AI工作负载上，谷歌第二代TPU与同期的CPU、GPU相比，性能比传统的GPU高了15倍，比CPU高了30倍，每瓦性能亦提高了30至80倍。硬件有强大的提升空间，保障谷歌思想的实现。 ​ 从第二代TPU起，谷歌第二代TPU引入Google Cloud，应用在谷歌计算引擎（Google Compute Engine ，简称GCE）中，也称为Cloud TPU，进一步优化谷歌搜索引擎、Gmail、YouTube和其他服务的运行。谷歌通过K8S进行云端软件技术处理，TPU提供硬件保障。 ​ ​ 同时，Cloud TPU通过TensorFlow进行编程，并与CPU、GPU及基础设施和服务结合，以根据用户应用需求构建和优化机器学习系统。谷歌在云上的技术铺垫深厚，谷歌未来的主战场是云端。 ​ 谷歌第二代TPU的发布，新一轮的人机大战也再次揭开序幕。而这一代AlphaGo的芯片配置，仅用了4块TPUv2，击败当时的世界围棋冠军柯洁。 ​ 谷歌除了推出第二代TPU外，还宣布计划研发可扩展云端超级计算机TPU Pods，通过新的计算机网络将64块Cloud TPU相结合，能够提供约11500万亿次浮点运算能力。强大的运算能力为谷歌平台提供了技术保障。 ​ 7.5.1.2.3、2018年：第三代TPU，边缘AI芯片Edge TPU​ 2018年5月，谷歌不出意外地发布了第三代TPU，其各方面性能不仅实现了升级，也进一步扩展到更广泛的深度学习训练和推理领域。我们怀疑的是，第三代TPU应该在2017年研发完成。 ​ 谷歌表示，第三代TPU的性能均是第二代TPU的两倍，可实现420TFLOPs浮点运算，以及128GB的高带宽内存。同时，它还可部署在基于云计算的超级计算机TPU Pod中，其中的芯片数量是上一代的四倍。这些数据表明，微电子技术的发展方兴未艾。 ​ 与第二代TPU Pod的部署相比，第三代每个Pod的性能提高了8倍，且每个Pod最多拥有1024个芯片。这些TPU的集群，形成了强大的狼群并行处理能力。 ​ ​ 谷歌2018年发布了用于边缘推理的微型AI加速芯片——Edge TPU，专为企业机器学习任务而设计，用于IoT设备中。市场是细分的，技术必须根据市场变动。 ​ Edge TPU同样是一款ASIC芯片。从应用上看，它与Cloud TPU相互补，用户能够先使用Cloud TPU对机器学习模型进行加速训练，再将训练好的模型放入相关设备中，进一步用Edge TPU进行机器学习推理。TPU的芯片向纵深发展。 ​ 据了解，Edge TPU能够让IoT设备以每秒30帧以上的速度，在高分辨率视频上运行多个先进的计算机视觉模型。数据处理重要的一部分是计算机视觉，谷歌TPU这种技术，很可能在未来的某一天，这些硬件产品出现在我们身边。 ​ ​ 谷歌还为Edge TPU推出了一套名为Cloud IoT Edge的软件平台，该平台拥有Edge IoT Core和Edge ML两大主要组件，能够帮助用户将在Google Cloud上构建和训练的机器学习模型，通过Edge TPU扩展到边缘设备中运行。技术的开源是未来的发展趋势，软件平台的出现，为谷歌技术的推广推波助澜。 7.5.1.2.4、2019年：第二/三代TPU Pod​ 这一年谷歌并未发布第四代TPU，却上演了另一个重头戏——发布第二代和第三代TPU Pod，可以配置超过1000颗TPU。强大的集群带来了强大的性能，在硬件技术突破的同时，谷歌在软件集群技术上也在进行着发展。 ​ 作为TPU的“升级版”，谷歌第二代TPU Pod能够容纳512个内核，实现每秒11.5千万亿次浮点运算；第三代TPU Pod速度则更快，可实现每秒超过100千万亿次浮点运算。这次升级之后，我们期待着谷歌新一代TPU的发布，相信带来更强大的性能。 ​ ​ 据悉，在相同配置（265块TPU）下训练ResNet-50模型时，第二代TPU Pod需要11.3分钟，而第三代TPU Pod只需7.1分钟。这些数据的背后，是TPU集群快速增长的结果。让我们很难想象的是，谷歌TPU在集群技术路上还能走多远。 7.5.1.3、架构创新，掀起云端造芯大浪潮​ 谷歌TPU系列芯片的出现，不仅突破了最初深度学习硬件执行的瓶颈，还在一定程度上撼动了英伟达、英特尔等传统GPU芯片巨头的地位。英伟达、AMD、INTEL在PC市场上这些传统霸主地位受到了挑战。 ​ 2015年以来，与AI芯片相关的研发逐渐成为整个芯片行业的热点，在云端的深度学习训练和推理领域，已然不是GPU，尤其是英伟达独霸一方。 ​ 谷歌TPU的诞生，越来越多的公司前赴后继地尝试设计GPU之外的专用AI芯片，进一步实现更高效的性能。这是一条成功的路线，科技巨头都在进行着尝试。 ​ 技术层面看，谷歌TPU的出现在架构创新上也为行业带来了以下思考。这种影响，在未来几十年将会深刻的感受到。 7.5.1.3.1、大规模片上内存​ 谷歌看来，片外内存低是GPU能效比低的主要原因。一些GPU由于片上内存较少，因此在运行过程中需要不断地去访问片外动态随机存取存储器（DRAM），从而在一定程度上浪费了不必要的能耗。在从前，关于CPU与GPU上的内存是争论的喋喋不休的话题，在功耗等各方面都有考量。 ​ ​ 因此，谷歌在最初设计TPU时，总共设计了占总芯片面积37%的内存，其中包括24MB的局部内存、6MB的累加器内存，以及用于与主控处理器对接的内存。谷歌反其道而行之，用功耗换取效率。 7.5.1.3.2、用量化技术进行整数运算​ 一般来说，神经网络的预测并不需要32位或16位的浮点计算精度，因此它可以通过8位低精度运算的方法，在保证适当准确度的同时，对神经网络进行预测。这种精细化的设计，适应了神经网络技术的需求。 ​ 通过量化技术，神经网络预测的成本大大减少，相应减少了内存的使用。例如，当研发人员将量化应用于流行的图像识别模型Inception时，芯片内存从91MB压缩到了23MB，约为其原始大小的四分之一。 ​ ​ 人工智能时代每一种算法数据都有自己的特点，神经网络作为人工智能的主流算法，有自己的计算特点，谷歌深谙此道，并对硬件改进，取得了GPU的成功。 ​ 7.5.1.3.3、可编程性​ 虽然谷歌TPU是ASIC芯片，但却与FPGA又有些类似，它具备一定的可编程性能力。谷歌看来，TPU的研发并非只用于运行一种神经网络模型。因此，谷歌选择采用了复杂指令集（CISC）作为TPU指令集的基础，能够较为侧重地运行更复杂的任务。软硬件技术的结合是TPU成功的关键因素。 ​ ​ 谷歌还定义了十二个专门为神经网络推理而设计的高级指令，能够在输入数据和权重之间执行矩阵乘法，并应用激活函数。今天，国内的学习是从指令开始起步。 ​ 为了能进一步对TPU进行编程，谷歌还创建了一个编译器和软件堆栈，能够调用TensorFlow图中的API，转化成TPU指令。TPU与TensorFlow的融合，让TPU开始接底气，并为TensorFlow做大规模的神经网络数据训练打下基础。 ​ 7.5.1.3.4、并行计算​ 谷歌为TPU设计了矩阵乘法单元（MXU）的并行计算。并行计算是数据发展的要求，今天并行计算是人工智能面临的第一个问题。 ​ ​ 它能够在一个时钟周期内处理数十万次矩阵运算，相当于一次打印一个字符、一次打印一行字或一次打印一页文档。这种高效的形式，是成功的关键因素所在。 7.5.1.3.5、脉动阵列设计​ MXU具有与传统CPU和GPU截然不同的架构，又称为脉动阵列（systolic array）。不同硬件设计带来的效果是惊人的。 ​ 脉动阵列使得在每次运算过程中，谷歌TPU能够将多个运算逻辑单元（ALU）串联在一起，并复用从一个寄存器中都取得结果。脉动阵列设计形式，大大提高了效率。 ​ 这种设计，不仅能够将数据复用实现最大化，减少芯片在运算过程中的内存访问次数，同时也降低了内存带宽压力，进而降低内存访问的能耗。 ​ ​ ▲TPU的矩阵乘法器单元（MXU） ​ 谷歌TPU的一鸣惊人，不仅为AI芯片领域带来了架构创新，同时亚马逊、微软等一众科技巨头，以及寒武纪、天数智芯等新势力亦开始纷纷入局，云端AI芯片市场开始风起云涌，掀起行业云端造芯大浪潮。 ​ 这是一个芯片制造的年代，如果没有技术的积淀与雄厚资本的支持，芯片制造是水中花、镜中月，革命性芯片的研发投入在百亿以上。国内的弘芯、龙芯值得我们深思。 7.5.2、TPU与机器学习​ TPU的出现，加速了第二代人工智能系统TensorFlow的运行，效率也大大超过GPU,Google的深层神经网络由TensorFlow引擎驱动。TPU是专为机器学习量身定做，执行每个操作所需的晶体管数量更少，自然效率更高。补充说明的是，能耗也更高。 ​ TPU与同期的CPU和GPU相比，可以提供15-30倍的性能提升，以及30-80倍的效率（性能/瓦特）提升。在人工智能发展过程中，效率的提升可以对算法进行有效的测试。由于效率问题，很多算法暂时无法测试。 ​ ​ TPU每瓦能为机器学习提供比所有商用GPU和FPGA更高的量级指令，高性能计算得以在民间应用。TPU为机器学习应用特别开发，使芯片在计算精度降低的情况下更耐用。 ​ 在人工智能年代，未来，指令级编程将称为常态。对于国内大多数技术人员而言，对指令的熟悉程度影响着个人技术的发展。 ​ 每一个操作只需要更少的晶体管，用更多精密且大功率的机器学习模型，并快速应用这些模型，因此用户便能得到更正确的结果。 7.5.3、对比说明​ CPU和GPU都是较为通用的芯片，但是有句老话是这样讲的：万能工具的效率永远比不上专用工具。而TPU就是一个专业工具。 ​ 随着社会的计算需求越来越专业化，芯片的专业化需求在增强。便产生了ASIC（专用集成电路）的概念。这个概念其实很早就出现了，但是ASIC不是任何一家公司都能尝试的，其复杂程度、集成程度堪称技术的堡垒。 ​ ASIC是指依产品需求不同而定制化的特殊规格集成电路，由特定使用者要求和特定电子系统的需要而设计、制造。这些是定制化的芯片开发，定制化的芯片开发一直广泛存在。在这个领域，谷歌的TPU技术是成功的尝试。 ​ ​ 因为ASIC很“专一”，只做一件事，它就比CPU、GPU等能做很多件事的芯片在某件事上做的更好，实现更高的处理速度和更低的能耗。相应的，ASIC的生产成本也非常高。 ​ TPU就是谷歌专门为加速深层神经网络运算能力而研发的一款芯片，其实也是一款ASIC。 ​ ​ 图：谷歌第二代TPU ​ 原来很多的机器学习以及图像处理算法大部分都跑在GPU与FPGA（半定制化芯片）上面，但这两种芯片都还是一种通用性芯片，在效能与功耗上不能更紧密的适配机器学习算法。硬件改变的初衷便形成了 ​ Google一直坚信伟大的软件将在伟大的硬件的帮助下更加大放异彩，所以Google便想，可不可以做出一款专用机机器学习算法的专用芯片，TPU便诞生了。 ​ 据称，TPU与同期的CPU和GPU相比，可提供15-30倍的性能提升，以及30-80倍的效率（性能/瓦特）提升。第一代TPU只能做推理，依靠Google云实时收集数据并产生结果，训练过程还需要额外的资源；第二代TPU既可以用于训练神经网络，又可以用于推理。 ​ ​ 图：TPU 各模块的框图 ​ 如上图所示，TPU在芯片上使用了高达24MB的局部内存，6MB的累加器内存以及用于与主控处理器进行对接的内存，总共占芯片面积的37%（图中蓝色部分）。这在从前是不可想象的。 ​ ​ 图：TPU芯片布局图 ​ 这表示谷歌充分意识到了片外内存访问是GPU能效比低的问题所在，不惜成本的在芯片上放了巨大的内存。相比之下，同时期英伟达的K80只有8MB片上内存，需要不断地去访问片外DRAM。这种设计，和传统硬件设计有巨大的区别，也许只有谷歌财大气粗的公司才有如此的魄力吧。 7.5.4、TPU性能与应用​ TPU的高性能还来源于对于低运算精度的容忍。研究结果表明，低精度运算带来的算法准确率损失很小，但是在硬件实现上却可以带来巨大的便利，包括功耗更低、速度更快、占芯片面积更小的运算单元、更小的内存带宽需求等。TPU采用了8比特的低精度运算。 ​ 不同的技术有不同的应用，不同的应用有不同的算法，不同的算法有不同的精度，TPU的神经网络不需要传统的精度，这和从前的很多设计思路是有区别的。 ​ ​ 目前为止，TPU已经干了很多惊天动地的事情，并且为我们服务了很多年。并且在更多领域应用。 ​ 机器学习人工智能系统RankBrain，帮助Google用户处理搜索结果；街景Street View，提高地图与导航的准确性；下围棋的计算机程序AlphaGo。这些大事记背后，代表着人工智能时代到来了。 7.5.5、示例代码7.5.5.1、变分程序​ 7.5.5.2、并行VAE程序​ 7.5.6、总结​ 从CPU到GPU，再到如今ASIC和FPGA相继入局，云端AI芯片市场百花齐放，与谷歌TPU的推动息息相关。 ​ 今天，云端AI芯片市场杀得热火朝天，前有赛灵思和寒武纪等新老势力不断崛起，进一步蚕食非GPU领域的市场，后有科技巨头四处找寻机会“大鱼吃小鱼”，合并有潜力的新玩家，整片市场呈一派割据混战、百家争鸣之势。 ​ ​ 不容忽视的是，随着云端AI芯片不断发展，大数据、云平台持续爆发，以及摩尔定律逐渐放缓，算力也再次来到新的瓶颈。 ​ 玩家是通过先进制程再次撕开云端AI芯片的新技术领域，还是依靠研发创新架构来实现算力的飞跃，不管走向哪条路都需直面种种挑战。 ​ ​ 在AI芯片市场开辟之初，谷歌凭借TPU逐渐打开云端AI芯片市场新的竞争格局，但当云端AI芯片开始进入新时代，谷歌在云平台大数据的技术优势，相信TPU能再次延续过往辉煌，为市场开辟新的方向和路径。 ​ TPU由谷歌独家提出，独家研发，独家应用，这些能给我们多少启示呢？谷歌从一个搜索科技公司，过渡到大数据、云计算公司，进而走在人工智能、硬件科技的大道上。 ​ 7.6 npuNPU（Neural network Processing Unit）， 即神经网络处理器。用电路模拟人类的神经元和突触结构。NPU为神经网络而生，对神经网络进行硬件支持。 ​ 嵌入式神经网络处理器（NPU）采用“数据驱动并行计算”的架构，特别擅长处理视频、图像类的海量多媒体数据。视频与图像是人工智能数据的重要组成部分，在今天有着最广泛的应用。 ​ ​ NPU是网络处理器，可以认为是一个组件（或者子系统），有时候也称为NPU协处理器。NPU和TPU一样，偏向于并行架构设计。 7.6.1、生物神经网络​ 生物神经系统是一个高度组织和相互作用的数量巨大的细胞组织群体。人类大脑的神经细胞大约在1011–1013个左右。神经细胞也称神经元，是神经系统的基本单元，按不同的结合方式构成复杂的神经网络。通过神经元及其联接的可塑性，使大脑具有学习、记忆和认知等各种智能。 ​ ​ 生物神经网络由若干人工神经元结点相互连接，神经元之间通过突触两两连接，突触记录了神经元之间的联系。 ​ ​ 生物神经元主要由以下几个部分组成： ​ 胞体，是神经细胞的本体; ​ 树突，用以接受来自其它细胞元的信号; ​ 轴突，用以输出信号，与多个神经元连接; ​ 突触，是一个神经元与另一个神经元相联系的特殊部位，神经元轴突的端部靠化学接触和电接触将信号传递给下一个神经元的树突或胞体。 ​ 7.6.2、人类神经网络​ 电路模仿人类神经元，把每个神经元抽象为一个激励函数，函数输入由与其相连的神经元输出以及连接神经元的突触共同决定。 ​ 为了表达特定的知识，使用者通过某些特定的算法，调整人工神经网络中突触的取值、网络的拓扑结构等。该过程称为“学习”。学习方法有很多，这种方法，也叫算法。 ​ ​ 学习之后，人工神经网络通过习得的知识来解决特定的问题。生物神经网络的深度学习，基本操作是神经元和突触的处理。现在变成计算机处理，传统的处理器指令集（包括x86和ARM等）是为了进行通用计算发展起来的，其基本操作为算术操作（加减乘除）和逻辑操作（与或非），需要数百上千指令才能完成一个神经元的处理，深度学习的处理效率不高。 ​ 从通用计算到并行计算，再到神经网络计算，是近些年计算发展的一个重要特征。神经网络对人工智能的发展影响深远，人工智能科技公司的brain计划，神经网络往往占有较大成分。 ​ ​ 经典的冯·诺伊曼结构不能满足要求，神经网络中存储和处理是一体化的，通过突触权重来体现。冯·诺伊曼结构中，存储和处理是分离的，由存储器和运算器实现，二者之间存在巨大的差异。在TPU设计上，关于存储与运算也进行了深刻的论证。 ​ 现有的基于冯·诺伊曼结构的经典计算机（如X86处理器和英伟达GPU）来跑神经网络应用时，不可避免地受到存储和处理分离式结构的制约，影响效率。这也就是专门针对人工智能的专业芯片，能够对传统芯片有一定先天优势的原因之一，NPU实现了计算与存储的结合。。 7.6.3、出现​ 国内NPU典型代表有寒武纪芯片和国外IBM的TrueNorth芯片。以寒武纪为例，DianNaoYu指令直接面对大规模神经元和突触的处理，一条指令即完成一组神经元的处理，并对神经元和突触数据在芯片上的传输提供了一系列专门的支持。 ​ 指令编程不论对于人工智能，对于大数据处理、对于音视频和图形图像都有着重要的意义。 ​ CPU、GPU、NPU相比，有百倍以上性能或能耗比差距。寒武纪团队和Inria联合发表的DianNao论文为例——DianNao为单核处理器，主频为0.98GHz，峰值达每秒4520亿次神经网络基本运算，65nm工艺下功耗为0.485W，面积3.02平方毫米mm。这就是专业设计的优势所在。 ​ ​ mate10中的麒麟970芯片，集成了寒武纪的NPU，实现所谓的照片优化功能，保证手机用了很长时间后还能不卡。 ​ 华为从麒麟810芯片开始，使用自家研发的达芬奇架构集成NPU，大大提升了芯片的AI处理能力，至今采用了华为NPU的手机AI高性能计算仍是卖点之一。2018年10月，华为发布了最新的NPU芯片，包括用于云端训练的晟腾910和用于终端推理的晟腾310，晟腾系列NPU正式走入人们的视野。 ​ 华为手机使用NPU芯片，也是华为手机的成功要素之一。手机是终端，对视音频图形图像有着更多的应用，NPU的支持，保障应用的顺利进行。 ​ ​ 2019年9月25日，“云栖大会”上阿里正式对外发布了全新的含光800芯片。含光800是一款高性能的采用ASIC技术的用于云端推理的AI芯片NPU。 ​ 1颗含光800的算力相当于10颗GPU，含光800推理性能达到78563 IPS，能效比500 IPS/W。相比传统GPU算力，性价比提升100%。 ​ ​ 举国造芯激动人心的时刻到来了，财大气粗的阿里不再沉默，达摩院重要的使命之一，就是造芯，资本的投入推动芯片技术的发展。 ​ 嵌入式神经网络处理器（NPU）采用“数据驱动并行计算”架构，擅长处理视频、图像类的海量多媒体数据。 ​ NPU处理器专门为物联网人工智能而设计，用于加速神经网络的运算，解决传统芯片在神经网络运算时效率低下的问题。近些年，神经网络称为人工智能算法的重要支柱。 ​ NPU可以和CPU、GPU、MCU结合，成为其中的一部分，NPU这种组合的模式，已经广泛使用。NPU也可以进行定制，大大加强了NPU的范围应用。 ​ GX8010中，CPU和MCU各有一个NPU，MCU中的NPU相对较小，也被称为SNPU。NPU的应用已经步入家家户户，未来还有很大的发展空间。 ​ 7.6.4、组成​ NPU的结构充分考虑了神经网络运算的特点，专为神经网络运算而设计，各个模块通力结合，保障了神经网络算法的高效执行。 ​ NPU处理器有如下几部分组成：乘加、激活函数、二维数据运算、解压缩等模块。 ​ 乘加模块用于计算矩阵乘加、卷积、点乘等功能，NPU内部有64个MAC，SNPU有32。 ​ 激活函数模块采用最高12阶参数拟合的方式实现神经网络中的激活函数，NPU内部有6个MAC，SNPU有3个。 ​ 二维数据运算模块用于实现对一个平面运算，如降采样、平面数据拷贝等，NPU内部有1个MAC，SNPU有1个。 ​ ​ 解压缩模块用于对权重数据的解压。为解决物联网设备中内存带宽小的特点，在NPU编译器中会对神经网络中的权重进行压缩，在不影响精度的情况下，可以实现6-10倍的压缩效果。 ​ 专业的设计，考虑了运算的方方面面，简单直接，面向问题。对通用专业硬件设计有一定的借鉴作用。下图为高通的NPU芯片，高通一直是嵌入式领域的王者。 ​ 7.6.5、代码示例​ 华为NPU编程示例代码： ​ 7.6.6、总结​ NPU在现实中有着广泛应用，尤其在智能计算、图形AI识别领域。下面总结AI场景，对NPU应用进行整理。 ​ ​ 拍照时通过NPU实现AI场景识别，并利用NPU运算修图、.NPU判断光源和暗光细节合成超级夜景、通过NPU实现语音助手的运行、.使用NPU记录用户使用习惯杀后台。 ​ ​ NPU配合GPU Turbo预判下一帧实现提前渲染提高游戏流畅度、NPU预判触控提高跟手度和灵敏度、NPU判断前台后台网速需求差异配合实现Link Turbo、跑分。 ​ ​ NPU判断游戏渲染负载智能调整分辨率、NPU辅助清理系统18月不卡、把降低游戏时AI的运算负载交给NPU以省电、NPU实现CPU和GPU的动态调度。 ​ 利用NPU和人工智能算法定期更换壁纸的功能、NPU辅助大数据广告推送、NPU实现输入法AI智能联想词的功能。 ​ ​ 应用场景的支持下，NPU已经成为最重要的芯片。目前，NPU技术已经成熟，已经广泛应用愈交互领域。在手机、军工、嵌入式领域广泛应用。 ​ 美摄SDK，完美支持CPU、GPU、NPU运算。20年视音频技术积淀，在短视频领域，把人工智能应用做到极致。 ​ 时光变幻，岁月横流，计算机应用的深度与广度增大，对图形图像处理也提出了更高的要求。传统的硬件设计、计算框架、运算理论、软件接口都面临着极大的挑战。为了适应人工智能技术的发展，软硬件技术都在进行着巨变。 ​ 智能时代创造了很多机会，塑造了无数的科技巨头，公司有更大的科技自由度。智能时代技术百花齐放，硬件辈出、框架争鸣、平台显现、万马奔腾。 ​ 不同的硬件框架适应显示的需求。显示技术的后面，有着GPU架构和并行计算架构在支持。在相关专题。阐述主流的CPU、GPU架构，CPU、GPU并行计算模型。 ​ 计算显示硬件发展的历史，可以看出，专业计算显示硬件往往是民间计算显示硬件发展的前奏，专业硬件发展成熟时，民间消费应用的春天到来了。 ​ 专业性开发承担着更多的研发成本，各家公司道路不尽相同，成本相对高的项目，承担着巨大的风险。人工智能时代不仅仅是新的软件理论，计算框架，更是硬件技术的进步。 8 前置说明：​ 至此、整个主题全部结束，借鉴了一些资料，如有异议，请联系作者。下面主题，开始讲述处理器架构与指令。 ​ 材料与制造技术的进步推动了微电子技术的发展，微电子技术的进步推动集成电路的发展，集成电路的发展推动了显示芯片的发展。 ​ 显示技术发展过程中，遵从了双色芯片，2D芯片，3D芯片，再到智能芯片的发展过程，在芯片发展的背后，计算机图形学从早期的文本显示到后来2D、3D世界的呈现，再到今天机器视觉技术的发展。 ​ 硬件技术的提升，带来了显示标准的变化。显示标准从早期的MDA，EGA、VGA、V-Sync到今天的G-Sync和Freesync 2。标准的出现指导着硬件的发展，为图形图像API、引擎的出现做了铺垫。 ​ 从早期驱动编程，到API编程(GDI，GDI+，D2D，AGG，Cairo，Cocoa Drawing)，到专业图形引擎编程(Glide，OpenGL，D3D)，代表着图形图像技术的繁荣，图形图像引擎推动了音视频技术的发展。 ​ 不同的显示标准带来计算机图形学的发展变化。图形图像硬件变革上，AMD推出APU的概念，同时推出APP并行运算框架，并对OpenCI大力支持，推出VEGA架构的显卡。英伟达推出自己的CUDA并行计算技术。Intel推出了Xe图形架构的显卡，推出图形库TBB，pafor编程包。 ​ 硬件架构、运算平台、软件架构、编程框架是硬件厂商的问题，软件架构、编程框架面向终端市场。 ​ 国内大力激励半导体产业发展，寻求半导体技术的自主可控，芯片IP产业有望进入黄金时代。对于这个时代来说，选择从头做研发是很困难的事，将已有的IP放到芯片中则容易得多。 ​ 类似Imagination的这种总部在欧洲、具有中资背景，且具有几十年GPU IP积淀的半导体IP企业有望迎来新的契机。 ​ 人工智能发展大背景下，神经网络异军突起。为音视频发展注入了智能因素，把音视频深度应用推向一个新的高度。 ​ 美摄科技，以音视频技术为基础，以并行计算为依托，以人工智能技术、图形图像技术为双翼，推动融媒技术发展。 9 常用术语9.1、APU​ APU：Accelerated Processing Unit，加速处理器。AMD公司推出加速图像处理芯片产品。 9.2、BPU​ BPU： Brain Processing Unit，大脑处理器。地平线科技提出的嵌入式人工智能处理器架构。第一代是高斯架构，第二代是伯努利架构，第三代是贝叶斯架构。目前地平线已经设计出了第一代高斯架构，并与英特尔在2017年CES展会上联合推出了ADAS系统（高级驾驶辅助系统）。 9.3、CPU​ CPU：Central Processing Unit，中央处理器。目前PC 核心主流产品。 9.4、DPU​ DPU：Deep learning Processing Unit，深度学习处理器。最早国内深鉴科技提出，基于Xilinx可重构特性的FPGA芯片，设计专用的深度学习处理单元，可基于已有的逻辑单元，设计并行高效的乘法器及逻辑电路，属于IP范畴，抽象出定制化的指令集和编译器，而非使用OpenCL，从而实现快速的开发与产品迭代。事实上，深鉴提出的DPU属于半定制化的FPGA。 9.5、FPU​ FPU：Floating Processing Unit，浮点计算单元。通用处理器中的浮点运算模块。 9.6、GPU​ GPU：Graphics Processing Unit，图形处理器。采用多线程SIMD架构，为图形处理而生。 9.7、HPU​ HPU：Holographics Processing Unit，全息图像处理器。微软出品的全息计算芯片与设备。 9.8、IPU​ IPU：Intelligence Processing Unit或者Image Processing Unit。与相机，显示相关。Deep Mind投资的Graphcore公司，开发出的AI处理器。包括：Display、Camera、Image Rotation, Inversion, Color Space Conversion、Image quality enhancement、 Video/graphics combining。 9.9、MPU​ MPU/MCU：Microprocessor/Micro controller Unit，微处理器/微控制器。用于低计算应用的RISC计算机体系架构产品，如ARM-M系列处理器。 9.10、NPU​ NPU：Neural Network Processing Unit，神经网络处理器。基于神经网络算法与加速的新型处理器总称，如中科院计算所/寒武纪公司出品的diannao系列。 9.11、RPU​ RPU：Radio Processing Unit，无线电处理器。Imagination Technologies公司推出的集合集Wifi/蓝牙/FM/处理器为单片的处理器。 9.12、TPU​ TPU：Tensor Processing Unit，张量处理器。Google 公司推出的加速人工智能算法的专用处理器。目前一代TPU面向Inference，第二代面向训练。 9.13、VPU​ VPU：Vector Processing Unit，矢量处理器。Intel收购的Movidius公司推出的图像处理与人工智能的专用芯片的加速计算核心。 9.14、WPU​ WPU：Wearable Processing Unit，可穿戴处理器。Ineda Systems公司推出的可穿戴片上系统产品，包含GPU/MIPS CPU等IP。 9.15、XPU​ XPU：百度与Xilinx公司在2017年Hotchips大会上发布的FPGA智能云加速，含256核。 9.16、ZPU​ ZPU：Zylin Processing Unit。 由挪威Zylin 公司推出的一款32位开源处理器。 9.17、凸凹贴图​ 凹凸贴图：计算机图形学在三维场景中凸凹处理的一个技术。 9.18、像素填充率​ 像素填充率：每秒渲染的像素数量，早期10亿级别，现在100亿级别。 9.19、三角形生成速度​ 三角形生成速度：三角形是三维图形渲染的重要单元，当前从千万到亿级别不等。 9.20、硬件T&amp;L​ 硬件T&amp;L：显卡坐标转换和光源编程。 9.21、DDR 显存​ DDR 显存：显卡的高速颗粒，有更快的数据交互速度。 9.22、HyperZ 技术​ HyperZ 技术：显存优化管理单元，通过快速Z轴清除等手段优化显存的利用效率。 9.23、显卡流水线​ 显卡流水线：数量的多少决定显卡性能高低的一个很重要的指标，Nvidia和AMD-ATI也在不断地增加显卡的流处理器数量使显卡的性能达到跳跃式增长。这个和核心构建，显存带宽等因素配合，单一多，意义不大。 9.24、F-Buffer​ F-Buffer：片断流缓冲区技术，处理无限制指令长度的阴影着色程序。执行原理：把需要经过渲染引擎多次处理的像素临时存储起来，而不是把它们写到帧缓冲里面。只有那些需要单通道处理的数据被写到帧缓冲。这样节省显存的带宽，从而使VPU工作得更加有效率。缺点：F-Buffer只能对所有流程都是基于同一视点的多流程渲染有效，对于用于生成不同视点图像的多流程渲染没用，在日常3D应用中，不同视点的多流程渲染十分普遍。其次F-Buffer的执行过程有可能产生溢出，一旦产生溢出其处理过程十分复杂，会影响GPU的执行效率。 9.25、FPGAFPGA：可编程逻辑，计算效率高，更接近底层IO，通过冗余晶体管和连线实现逻辑可编辑。本质上是无指令、无需共享内存，计算效率比CPU、GPU高。主要应用于智能手机、便携式移动设备、汽车。","link":"/2023/11/19/9%20%E6%98%BE%E7%A4%BA%E7%A1%AC%E4%BB%B6%E5%8F%91%E5%B1%95%E4%B8%8E%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91%E7%9F%A5%E8%AF%86%E7%82%B9%E6%89%AB%E7%9B%B2/"},{"title":"音视频编解码相关知识学习","text":"前些天一直在研究关于GPUi相关的知识，在周六的时候终于是写好了相应的测试手册，周一法师检测出问题的话我再加，其实也没啥可以加的东西了，不管是OPENGL还是OPENCL，只要相应的mali库成功即可，其他的倒是没啥，然后呢我也该去搞一下mpp 音视频编解码相关的东西了，后面其实还有摄像头啥的，这些都是要搞的，至少软件里面是要适配的对吧，还有那个缠绕我好久的buildroot opencv的问题，问题太多了，但是总要一点一点来，问题是一个一个解决的，总不可能一蹴而就，慢慢来呗 音视频的基本概念一 视频1、码率√码率，又叫比特率，单位时间内传输的数据量，单位一般为kbps(千位每秒)。需要注意的是，这里b代表bit，而不是Byte，这里乘以8是Byte转成bit。计算公式：平均码率(kbps)=文件大小(kB)*8/时间(s)。动态码率(kbps)=每秒传输数据量(kB)*8。 “bps” 是 “bits per second” 的缩写，指的是数据传输速率或比特率，用于测量数据在通信或存储系统中的传输速度。它表示每秒传输的比特数，其中比特是计算机中最小的数据单位。比特率通常用于描述网络带宽、调制解调器速度、数字音频/视频流的传输速度等。 恒定码率：CBR，码率稳定可控，带宽要求不高，图像变化量比较大时方块效应比较明显。 动态码率：VBR，码率波动较大，带宽要求较高，图像变化量比较大时方块效应有所改善。发生网络抖动时，比较容易丢包，需要重传，或者FEC前向纠错，从而带来延时。 2、分辨率分辨率又称为解析度，分辨率越高，像素越多，图像越清晰。 视频分辨率：又称为图像分辨率，由视频的宽高组成，表示形式宽x高，常见的视频分辨率有480P、720P、1080P、2K(2048x1080/2160x1440)、4K(4096x2160/3840x2160)，具体如下表1所示。 屏幕分辨率：又称为显示分辨率，描述屏幕分辨率的单位是ppi(pixel per inch，每英寸的像素数)。 位分辨率：又称为位深(BitDepth)，每个像素点存储信息的位数。常见的有：8位、16位、24位、32位色彩。Android的Bitmap常见的有ALPHA_8、RGB_565、ARGB_4444、ARGB_8888。 显示模式 水平像素x垂直像素 宽高比 QCIF 176x144 11:9 QVGA 320x240 4:3 CIF 352x288 11:9 nHD 640x360 16:9 VGA 640x480 4:3 HD 1280x720 16:9 Full HD 1920x1080 16:9 2K(FHD+) 2048x1080 17:9 4K(UHD) 3840x2160 16:9 3、帧率视频帧率：测量显示帧数的量度，单位为每秒显示帧数(FPS，全称为Frame Per Second)。一般视频帧率为24fps，P制(PAL，德国提出，中国、印度、巴基斯坦等国家使用)为25fps，也就是每帧显示40ms，N制(NTSC，美国标准委员会提出，美国、日本、韩国等国家使用)为30fps。有些超高帧率的视频达到60fps。 显示帧率：以帧为单位的位图图像连续出现在显示器的频率，也称为刷新速率。Android设备刷新率一般为60Hz，也就是帧率为60fps，每帧为16ms，超过16ms能给人的肉眼带来延迟卡顿的感觉。做性能优化方面，也就是保证从测量、布局、绘制、上传指令、与GPU交换缓冲区等一系列动作在16ms完成。Android11支持120Hz的更高帧率，一般为对帧率要求极高的应用场景，比如互动游戏。 4、像素格式像素格式：像素色彩分量的排列，由每个像素使用的总位数以及各分量的位数决定。图像的像素格式一般是RGBA四个分量通道各占8bits，组成一个32位的像素。其中R代表Red、G代表Green、B代表Blue、A代表Alpha。但是，视频压缩存储的像素格式不是RGBA，而是YUV，其中Y代表亮度(Luma)，U代表色度(Chroma)，V代表对比度(Contrast)。 5、画质画质：画面质量，由清晰度、锐度、解析度、色彩纯度、色彩平衡等指标构成。 清晰度：指图像细节纹理及其边界的清晰程度。 锐度：反应图像平面清晰程度，以及图像边缘的锐利程度。 解析度：指像素点的数量，与分辨率对应，分辨率越高，解析度越高。 色彩纯度：指色彩的鲜艳程度。所有色彩都是三原色组成，其他颜色都是三原色混合而成，理论上可以混合出256种颜色。原色的纯度最高。色彩纯度是指原色在色彩中的百分比。 色彩平衡：用来控制图像的色彩分布，使得图像整体达到色彩平衡。 6、色域与HDR色域：指某种表色模式所能表达的颜色构成的范围区域，色域空间越大，所能表现的颜色越多。 HDR：High Danamic Range，高动态范围，比普通图像提供更多动态范围和图像细节，能够更好反应真实环境的视觉效果。颜色值经过归一化后，范围一般是[0,1]。而HDR可以表达超出1的颜色值，拥有更大的颜色范围。 7、旋转角度旋转角度：视频的YUV储存方向。一般的视频旋转角度是0°，对应的是横屏显示。后置摄像头竖屏拍的视频，旋转角度为90°，对应的是竖屏显示。Android中可以通过MediaMetaDataRetriever获取旋转角度。 8、时长视频所有图像播放所需要的时间称为视频时长。计算公式：时长(s)=帧数x每帧时长=帧数x(1/帧率)。假设一个视频帧数为1000，帧率为25fps，那么时长为40s。 9、封装格式封装格式（Container Format），也被称为容器格式、多媒体容器或封装协议，是用于将音频、视频、字幕等多种媒体数据进行封装和存储的文件格式。它将不同类型的媒体数据组合在一起，同时提供了文件结构、元数据、同步信息和索引等，以便播放器或解码器能够正确解析和播放媒体内容。 封装格式通常由以下几个主要组成部分构成： 特定格式头（Format Header）：封装格式的文件头部分包含了关于文件本身的重要信息，如文件类型、版本、总体文件大小等。这些信息在解析和处理文件时起到了关键作用。 媒体信息（Metadata）：封装格式可以包含有关媒体内容的附加信息，例如标题、作者、描述、时长、分辨率、采样率等。这些元数据提供了有关媒体文件的描述和标识，使其能够被正确地识别和分类。 音视频轨（Track）：封装格式可以容纳多个音频、视频或字幕轨道。每个轨道包含相应媒体数据的编码信息、时间戳和相关参数。例如，一个视频轨道可能包含视频帧的压缩编码数据，而一个音频轨道可能包含音频样本的编码数据。 索引（Index）：为了快速定位和访问媒体数据，封装格式通常包含一个索引表。索引表记录了文件中各个部分的位置、时间戳和长度等信息，以便播放器能够快速定位到需要的数据位置。通过索引，播放器可以跳转到特定时间点或轨道的特定位置。 其他数据：除了上述主要组成部分之外，封装格式还可以包含其他数据，如字幕轨道、章节信息、描述文本、封面图像等。这些附加数据提供了更丰富的媒体体验和交互功能。 不同的封装格式具有不同的特点和功能。一些封装格式具有更广泛的兼容性和流行度，例如MP4（MPEG-4 Part 14）和MKV（Matroska）。这些封装格式支持多种编码格式、多个轨道和广泛的元数据支持。其他封装格式如AVI、MOV、FLV等也有各自的特点和应用领域。 封装格式在数字媒体的存储、传输和播放中起到了重要的作用。它们提供了一种标准化的方式来组织和管理多媒体数据，使得不同类型的媒体可以在各种设备和平台上进行兼容性播放和交互。。 10、编码协议编码协议是指用于将原始视频数据进行压缩和编码的特定算法和规范。这些编码协议的目的是减小视频文件的大小并提高传输和存储效率，同时尽量保持较高的视频质量。以下是对几种常见的视频编码协议的详细介绍： H.264 / AVC：H.264（也称为高级视频编码，Advanced Video Coding）是一种广泛使用的视频编码协议。它采用了先进的压缩技术，能够提供较高的视频质量和更低的比特率。H.264广泛应用于各种领域，包括互联网视频流媒体、蓝光光盘、视频会议等。 H.265 / HEVC：H.265（High Efficiency Video Coding）是H.264的后继者，也是一种先进的视频编码协议。相比于H.264，H.265能够进一步减小视频文件大小，并提供更高的视频质量。它在保持相同视频质量的情况下，能够将比特率降低约50%。H.265常用于4K和8K高分辨率视频、流媒体服务等。 VP8 / VP9：VP8和VP9是由Google开发的开放源代码视频编码协议。它们提供了高效的视频压缩和较高的视频质量，并被广泛应用于WebRTC、WebM等互联网标准中。VP9相比VP8进一步提升了压缩性能，能够在更低的比特率下保持较高的视频质量。 MPEG-4：MPEG-4是一系列的视频编码协议，包括MPEG-4 Part 2和MPEG-4 Part 10（也称为H.264）。MPEG-4 Part 2常用于视频的存储和传输，而MPEG-4 Part 10（H.264）被广泛使用于各种应用，包括互联网视频、移动视频等。 MJPEG：MJPEG（Motion JPEG）是一种将视频中的每一帧都作为独立的JPEG图像进行压缩的编码协议。它适用于一些特定应用，如摄像头和视频监控系统。尽管MJPEG在压缩率和存储效率方面比较低，但解码过程相对简单，避免了帧间预测等复杂的算法。 WMV3：WMV3（Windows Media Video 3）是由微软开发的一种视频编码协议。它广泛用于Windows Media Player和其他微软产品中，提供了较好的视频质量和压缩效率。WMV3支持各种分辨率和比特率，并具有较好的兼容性。 这些编码协议在视频压缩方面采用了不同的算法和技术，以平衡视频质量、压缩比和解码复杂性。不同的应用场景和设备可能选择不同的编码协议，根据需求和限制来平衡视频质量和性能。 11、视频播放整体流程当您在电脑上打开一个视频文件时，涉及到了多个步骤和组件，以确保视频能够被正确解码和显示。以下是一个详细的视频文件在电脑上显示的典型流程： 文件读取：计算机首先会读取视频文件的数据。这涉及从硬盘或其他存储设备中读取文件的二进制数据，并将其加载到计算机的内存中以供后续处理。 封装格式解析：计算机会根据视频文件的封装格式（如MP4、MKV等）来解析文件的结构和元数据。这包括读取文件头部信息、索引表和媒体轨道的描述等。通过解析封装格式，计算机可以了解视频文件的整体结构和内容。 视频解码：视频解码器开始对视频轨道进行解码。它根据封装格式中存储的视频编码器信息，解码压缩的视频数据并将其转换为原始的像素数据。解码过程涉及对视频帧进行逐帧解压缩和重构，以还原出原始的图像数据。 音频解码：如果视频文件包含音频轨道，音频解码器将对音频轨道进行解码。类似于视频解码过程，音频解码器根据封装格式中的音频编码器信息，解码压缩的音频数据并将其转换为原始的音频样本数据。 同步和播放：视频解码器和音频解码器的输出需要进行同步，以确保视频和音频的播放保持一致。计算机使用时间戳、帧率和采样率等信息来确保视频和音频流的同步，并根据显示设备的刷新率来进行适当的帧率调整。 图像渲染：计算机使用图像渲染器将解码后的视频像素数据转换为适合显示的图像格式。这可能涉及色彩空间转换、调整图像大小、应用滤镜或效果等处理。 音频渲染：类似地，音频渲染器将解码后的音频样本数据转换为适合音频输出设备的音频格式。这可能包括音频混合、音量调整、空间效果等处理。 显示输出：最后，计算机将渲染后的视频图像和音频数据发送到显示设备和扬声器，以进行实际的播放。这可能涉及将视频图像传输到显示器，并通过显示器的硬件和软件进行显示。同时，音频数据也会被发送到扬声器或音频输出设备进行播放。 二 音频1、采样率采样率：对声音信号每秒的采样次数，采样率越高，声音的还原越真实。采样率单位为Hz，常见的采样率有：8000Hz、16000Hz、44100Hz、48000Hz。人类一般能够听到的声音范围：20Hz～20000Hz。根据奈奎斯特采样定理：当采样频率大于信号中最高频率的2倍时，采样后的数字信号能够完整保留原始信号的信息。 2、声道声道：指声音在录制或播放时，在不同空间位置采集或回放的相互独立音频信号。声道数指在录音时的音源数量，或者在播放时的扬声器数量。 3、声道布局不同声道数对应不同声道布局。常见的声道布局有单声道(mono)、立体声道(stereo)、四声环绕、5.1声道。 单声道：只有一个声道，优点数据量小，amr_nb和amr_wb默认为单声道，缺点是缺乏对声音位置定位。 立体声道：一般为两个声道，由左声道、右声道组成，改善对声音位置定位的状况。 四声环绕：由前左、前右、后左、后右组成，形成立体环绕。4.1声道是在四声环绕基础上，增加一个低音。 5.1声道：在4.1基础上，增加一个中场声道，杜比AC3就是采用5.1声道，也就是影院宣传的杜比音效。 4、音质音质：声音的质量，经过编码压缩后的音频信号保真度，由音量、音高和音色组成。 音量：音频的强度，数值范围0-100，静音时为0，最大值为100。Android中有提供音量增强LoudnessEnhancer，调节声音分贝值。 音高：声音的音调，即音频频率或每秒变化次数。 音色：音频泛音，又称为音品，不同声音表现在波形方面与众不同的特性。 5、封装格式音频的封装格式，与视频封装格式类似，由特定格式头+媒体信息+音频轨数据组成。常见的封装格式有：mp3、m4a、ogg、amr、wma、wav、flac、aac、ape等。 MP3（MPEG Audio Layer III）：MP3 是一种广泛使用的音频封装格式，具有较高的压缩比和音质，适用于音乐和语音的存储和传输。 M4A（MPEG-4 Audio）：M4A 是苹果公司使用的音频封装格式，它可以包含多种编码格式的音频数据，如 AAC（Advanced Audio Coding）和 ALAC（Apple Lossless Audio Codec）。M4A 格式通常与 iTunes 和 Apple 设备相关联。 OGG：OGG 是一种自由开放的音频封装格式，支持多种编码格式，如 Vorbis、Opus 等。它具有较好的音质和压缩比，常用于网络流媒体和游戏音效。 AMR（Adaptive Multi-Rate）：AMR 是一种用于语音编码和封装的格式，主要用于手机通话和语音录制。它具有较高的压缩比，适合在低比特率下传输语音数据。 WMA（Windows Media Audio）：WMA 是微软开发的音频封装格式，支持多种编码格式，如 WMA 标准、WMA Pro 和 WMA Lossless。它在 Windows 平台上得到广泛应用，常用于音乐和音频流媒体。 WAV（Waveform Audio File Format）：WAV 是一种无损音频封装格式，它存储原始音频数据，不进行压缩。WAV 格式具有较高的音质，常用于音乐制作和音频编辑。 FLAC（Free Lossless Audio Codec）：FLAC 是一种无损音频封装格式，它可以实现无损的音频压缩和解压缩，保留了原始音频数据的完整性。FLAC 格式适用于音乐存储和音频传输。 AAC（Advanced Audio Coding）：AAC 是一种高级音频编码格式，常用于音乐和视频的存储和传输。它具有较高的音质和压缩效率，是目前广泛支持的音频编码格式。 APE（Monkey’s Audio）：APE 是一种无损音频封装格式，类似于 FLAC，但压缩比略低。它常用于音乐存储和音频传输，提供了较高的音质和文件压缩率。 6、编码协议音频经过解封装得到的音频轨数据，也是经过编码的。常见的音频编码协议有：mp3、aac、amr_nb、amr_wb、ac3、vorbis、opus、flac、wmav2等。 MP3（MPEG Audio Layer III）：MP3 是一种常见的有损音频编码格式，它通过移除人耳听不到或对音质影响较小的音频信号，实现了较高的压缩比。MP3 格式广泛用于音乐存储和传输。 AAC（Advanced Audio Coding）：AAC 是一种先进的音频编码格式，它在音质和压缩效率上优于 MP3。AAC 常用于音乐、视频和流媒体的存储和传输，被广泛支持。 AMR-NB（Adaptive Multi-Rate Narrowband）：AMR-NB 是一种窄带自适应多速率编码格式，用于语音编码和传输。它在低比特率下实现了较高的语音质量，常用于手机通话。 AMR-WB（Adaptive Multi-Rate Wideband）：AMR-WB 是一种宽带自适应多速率编码格式，也用于语音编码和传输。相比于 AMR-NB，AMR-WB 在更宽的频率范围内提供了更好的语音质量。 AC3（Audio Coding 3）：AC3 是一种有损音频编码格式，常用于影片音轨和 DVD 视频中。AC3 格式支持多声道音频，提供了较高的音质和环绕声效果。 Vorbis：Vorbis 是一种开放的无损音频编码格式，采用了无损压缩算法，可以提供高音质和较小的文件大小。Vorbis 常用于音乐存储和网络流媒体。 Opus：Opus 是一种开放的音频编码格式，具有低延迟、高音质和较高的压缩效率。Opus 支持多种应用场景，包括音乐、语音通信和网络流媒体。 FLAC（Free Lossless Audio Codec）：FLAC 是一种开放的无损音频编码格式，可以实现无损的音频压缩和解压缩。FLAC 格式保留了原始音频数据的完整性，提供了较高的音质。 WMA（Windows Media Audio）：WMA 是微软开发的音频编码格式，支持多种编码配置，如 WMA 标准、WMA Pro 和 WMA Lossless。WMA 常用于 Windows 平台上的音乐和音频流媒体。 7、采样数采样数，即每帧采样的数量。在FFmpeg的AVFrame中，定义为nb_samples。 8、采样位数采样位数，即每个采样占用多少位。在RIFF(Resource Interchange File Format)资源交换文件格式有个字段bits_per_sample表示采样位数，在FFmpeg也是用这个字段表示采样位数。 9、存储空间音频的每秒存储空间由：采样率、声道数、每个采样位数。假设采样率为44.1k，声道数为2，采样位数为16。那么，每秒所占存储空间字节数=44100 * 2 * 16 / 8 10、帧时长音频的帧时长=采样数 / 采样率。假设采样率为44.1k，采样数为1024。那么每帧时长约等于23ms。 11、采样格式音频的采样格式分为大端存储和小端存储。按照符号划分有：有符号与无符号。按照类型划分有：整型与浮点型。按照存储位数划分有：8位、16位、32位、64位，都是8的倍数。在FFmpeg的AVSampleFormat枚举如下： 123456789101112131415161718enum AVSampleFormat { AV_SAMPLE_FMT_NONE = -1, AV_SAMPLE_FMT_U8, // unsigned 8 bits AV_SAMPLE_FMT_S16, // signed 16 bits AV_SAMPLE_FMT_S32, // signed 32 bits AV_SAMPLE_FMT_FLT, // float AV_SAMPLE_FMT_DBL, // double AV_SAMPLE_FMT_U8P, // unsigned 8 bits, planar AV_SAMPLE_FMT_S16P, // signed 16 bits, planar AV_SAMPLE_FMT_S32P, // signed 32 bits, planar AV_SAMPLE_FMT_FLTP, // float, planar AV_SAMPLE_FMT_DBLP, // double, planar AV_SAMPLE_FMT_S64, // signed 64 bits AV_SAMPLE_FMT_S64P, // signed 64 bits, planar AV_SAMPLE_FMT_NB // Number of sample formats}; 视频封装格式 音视频的时长怎么获取，音视频的封面怎么获取，音视频的格式怎么获取呢？这些信息都以特定格式存储在文件开头或者结尾，称为多媒体信息或者多媒体元数据。通用的封装格式由：文件标识头+多媒体信息+音视频(字幕)轨+视频帧索引块组成，如果是纯音频，后面可能还有歌词。音视频的封装格式就是通过解析文件标识头进行判断的，然后解析多媒体信息从而获取时长，再解析视频帧索引块，最后根据索引块去获取对应时间戳的视频帧。 音视频封装格式存储的字段包括：时长、码率、音视频编码器、分辨率(宽x高)、帧率、像素格式、旋转角度、采样率、声道数等等。其中视频专有的字段是分辨率、帧率、像素格式、旋转角度，而音频专有的字段是采样率、声道数。 常见的视频格式有：mp4、mov、3gp、mkv、webm、flv、avi、mpg、wmv、ts等等。其中mp4、mov、3gp同属一个协议簇，目前mp4最为流行，mp4全称为MPEG-4，由国际标准化组织和国际电工委员会下属的动态图像专家组(Moving Picture Experts Group)制定，具体协议可参考：ISO/IEC14496-14协议；mkv与webm公用封装格式：matroska，对于高清视频而言，mkv/webm最受欢迎；而avi是比较古老的格式，音视频流交错(Audio Video Interleave)，可以封装各种编码格式的音视频流；mpg属于ps的一种封装格式；wmv(Windows Media Video)是微软推出的视频编解码格式统称，采用ASF(Advance System Format)作为容器，基于Object对象进行封装；而ts的全称为MPEG2-TS，即为Transport Stream的缩写，具体可参考ISO/IEC13818-1协议，作用于传输层，主要用于实时传输的节目，HLS直播协议就是基于ts切片来传输视频流的，主要特点是从视频流任一片段都可独立解码播放；ps与ts类似，全称为MPEG-PS，即为Program Stream的缩写，用于存储固定时长的节目。视频格式如下图所示： 整个解封装流程：从读取文件头判断视频格式开始，然后选择对应的Extractor，解析多媒体信息，再解析视频帧的索引块，最后根据索引去定位并读取音视频数据。如下图所示： 读取文件头：读取文件头是为了获取文件的基本信息和标识。文件头通常是文件的前几个字节，它包含了文件的格式信息以及其他元数据。读取文件头可以通过打开文件并读取前几个字节的方式实现。 判断文件格式：通过读取文件头中的信息，可以判断文件的格式。在提供的文件格式中，常见的文件格式有： 视频格式：mp4、avi、mkv、flv、wmv 音频格式：mp3、m4a、flac、amr 选择对应的解析器（Extractor）：根据判断出的文件格式，选择对应的解析器（Extractor）。解析器是用于解析文件的工具或库，它能够提取出文件中的特定信息。不同的文件格式通常需要使用不同的解析器进行解析。 解析多媒体信息：使用选择的解析器，对文件进行解析以获取多媒体信息。多媒体信息包括视频的分辨率、帧率、编码格式等，音频的采样率、声道数、编码格式等。解析多媒体信息可以通过解析器提供的函数或方法来实现。 解析视频帧索引：如果文件是视频文件，可以进一步解析视频的帧索引。视频帧索引包含了视频中每一帧的位置和时间信息。解析视频帧索引可以帮助我们定位和提取特定的视频帧。 读取音视频数据：最后，通过解析器提供的函数或方法，读取音视频数据。音视频数据是文件中实际存储的音频和视频内容。可以根据需要，逐帧读取视频数据或逐样本读取音频数据。 mp4作为目前最流行的视频封装格式，也是本篇文章的男一号主角，下面将围绕mp4格式进行展开分析。mp4是由一系列的box组成(在quick time协议中，称为atom)，box又由Header和Data组成，box的结构如图2所示： 而Header由size、type、largeSize、extendType组成，其中size和type是必要字段，如表1所示： ​ full box的Header多两个字段：version、flag，一般是track box采用full box形式，如表2所示： box分为normal box、full box、large box、extend box。如果size为1，那么表明该box为large box，使用largeSize来存储box的大小；如果size为0，那么表明该box是文件的最后一个box；如果box的类型为uuid，那么表明该box是扩展box。如下面代码段所示： 12345678910111213aligned(8) class Box (unsigned int(32) boxtype, optional unsigned int(8)[16] extended_type) { unsigned int(32) size; unsigned int(32) type = boxtype; if (size==1) { unsigned int(64) largesize; } else if (size==0) { // box extends to end of file } if (boxtype==‘uuid’) { unsigned int(8)[16] usertype = extended_type; }} moov box作为mp4格式的重要组成部分，根据moov box与mdat box的相对位置，分为moov前置和moov后置。如下面图3、图4所示： 通常情况下，mp4的moov都是在mdat前面的；一般只有实时录制的mp4视频，moov才在mdat的后面。 ftyp box：mp4视频标识头，包含major brand、minor version、compatible brands。其中major brand一般为isom，而compatible brands包括isom、iso2、avc、mp41、mp42等。 moov box：存储多媒体信息，嵌套着movie box(mvhd)、track box(trak box)、usedata box(udat)；而track box分为视频轨、音频轨、字幕轨，如果有多语言，就会对应有多音轨；trak/mdia/minf/stbl/stsd存储的是音视频编码器信息，比如视频轨的是avc，音频轨是mp4a；trak/mdia/minf/stbl/stsz存储的是视频帧size；trak/mdia/minf/stbl/stco存储的是chunk offset。 mdat box：音视频数据，根据moov及其嵌套box解析出来的视频帧索引，去定位关键帧，然后根据帧类型读取音视频数据。 音频封装格式 音频封装格式一般由：多媒体信息+音频流+封面流+歌词流组成。有些音乐会包含封面和歌词，则对应有封面流、歌词流。多媒体信息包括：标题、艺术家、专辑、作曲、音乐风格、日期、码率、时长、声道布局、采样率、音频编码器等。而音频封装包括：mp3、m4a、ogg、amr、wma、aac、wav、flac、ape等。前面两篇文章介绍过相关概念：走进音视频的世界——音视频基本概念、走进音视频世界——视频封装格式。音频格式如下图所示： 以下面问题为出发点，揭开音频封装格式的面纱： ① 音乐封面如何获取？ ② 音乐歌词如何获取与显示？ ③ 有损格式与无损格式有什么区别？ ④ 不同封装格式有什么联系，又有什么区别？ 先从FFprobe检测到的音频metadata说起，如下图1所示： 从上图可以看出，前半部分是title标题、artist艺术家、album专辑、album_artist艺术家专辑、composer作曲者、genre音乐风格式；中间部分是lyrics歌词，每句歌词前面有对应的时间戳；后半部分是两个流，第0编号的流是音频轨，包含：音频编码器、采样率、声道布局、码率，第1编号的流是封面，其实是一帧图像，包含：图像编码器、像素格式、分辨率。接下来根据上面提出的问题进行展开分析。 1、获取音乐的封面音乐封面保存在视频图像流中，先解析出图像编码器、像素格式、分辨率等参数，然后根据编码器去寻找对应的解码器，并打开解码器，对图像编码压缩数据进行解码，最终解码出来的图像就是封面了。 2、音乐歌词的获取与显示上面有提及，每句歌词前面有显示的时间戳，以音频时钟为基准，歌词时间戳同步于音频时间戳。也就是根据音频时间戳来同步解析歌词，然后把歌词回调到应用层渲染显示。另外一个问题，当前歌词什么时候该消失呢？歌词没有具体的显示时长，等待下一个歌词的到来，把当前歌词覆盖。 3、有损格式与无损格式的区别(1) 无损音乐格式 无损音乐格式有ape、wav、flac三种，其中ape、flac都是基于wav进行压缩。而wav是微软专门为Windows开发的一种标准数字音频文件，文件扩展名wav，是WaveForm的缩写，文件大小计算公式：size=(采样率量化位数声道/8)/时间(秒)。一般采样率是44100Hz，量化位数为16位，声道数为2（即立体声道），1分钟的音频占用存储空间约为10M。 在Windows环境下，大多数媒体文件都是按照资源互换文件格式(Resource Interchange File Format)来储存信息的，简称为RIFF格式。构成RIFF的基本单位成为块(Chunk)，每个RIFF文件由若干块组成，wav基本结构如下表所示： 每个块由块标识、长度、数据组成，如下代码段： 12345struct chunk { u32 id; //块标识 u32 size; //块大小 u8 data[size]; //块内容}; 其中fmt块由声道数、采样率、码率、块对齐、量化位数五个参数组成，如下表所示： 12345Num Channels 2 Bytes 小端存储SampleRate 4 Bytes 小端存储ByteRate 4 Bytes 小端存储Block Align 2 Bytes 小端存储BitsPerSample 2 Bytes 小端存储 (2) 有损音乐格式 有损音乐格式包括：mp3、m4a、ogg、amr、wma、aac等。目前最为流行的是mp3(MPEG-1 audio layer3)，有着mp3的下一代之称的是aac(Advance Audio Coding)。有损格式压缩率比无损的高，文件占用存储空间小，但是声音还原度不如无损格式。我们下载音乐时，碰到高品质或者无损音质的音乐，通常要VIP会员或按需收费，因为越高品质越接近原声。而无损音乐从理论上能够100%保留声音细节，100%还原原声。无损音质英文简称为SQ(Super Quality，超音质)。关于无损格式与有损格式对比如下表所示： 4、不同封装格式的联系与区别封装格式共同点是基本结构是相同的，都是由多媒体信息+音频流+封面流+歌词流组成。区别是不同封装格式，采用编码方式不一样，压缩率不一样，音频流子结构不一样。下面是不同封装格式的多方位对比，如表4所示： 音视频编码音视频流是通过特定编码器压缩，由一系列的压缩图像/语音帧组成。当然可能存在多种语言多音轨，每个音轨之间的音频流相互独立。还可能存在内置字幕，常见的字幕格式有sub、smi、ssa、srt等。但是，本篇文章讨论的主角是音视频编码，常见的视频编码有h264、h265、vp9、mpeg4、mjpeg、wmv3、av1(Alliance for Open Media Video 1，由开放媒体联盟推出，对标h265，旨在成为下一代视频编码技术标准)，常见的音频编码有mp3、aac、amr_nb、amr_wb、ac3、vorbis、opus、flac、wmav2等等。音视频格式如下图所示： 一、视频编码视频编码是将原始视频信号进行压缩和编码的过程，以便在存储和传输中减少数据量。下面详细解释为什么需要对视频进行编码以及视频编码的原理和过程。 为什么需要进行视频编码？视频数据通常由连续的图像帧组成，每一帧都包含了大量的像素数据。原始的视频数据以YUV或RGB格式存储，其中Y表示亮度分量，U和V表示色度分量。这些原始数据非常大，特别是对于高分辨率和高帧率的视频来说，它们需要大量的存储空间和传输带宽。为了有效地存储和传输视频，需要对视频进行压缩，而视频编码就是实现视频压缩的一种方式。 1、变换与量化变换：把空间域的图像信号变换到频率域。常见的变换有离散余弦变换、傅里叶变换。其中，离散余弦变换又称为DCT变换，在视频压缩中得到广泛应用。 量化：人类对图像的低频特性的信息敏感(比如亮度)，对高频特性的信息不敏感(比如色度、对比度)，所以才编码过程中可以少用高频信息，全保留低频信息。量化过程是对低频区进行细量化，对高频区进行粗量化，减少人眼不太敏感的图像信息，从而减小数据量、提高压缩率。量化是有损的，量化参数(Quantization Parameter)越大，图像质量越低。 2、运动补偿与运动估计运动估计：把图像分割成互不重叠的子块，然后以一定大小的窗口，在前一图像或后一图像去移动搜索相似的图像块，这个搜索过程称为运动估计。 运动补偿：通过先前的局部图像来预测、补偿当前的局部图像； 3、熵编码熵编码是基于变长编码，出现概率大的符号采用短码，出现概率小的符号采用长码，最终的平均码长接近信源熵值。其他的变长编码还包括：哈夫曼编码、游程编码、算术编码等。 4、帧内压缩与帧间压缩帧内压缩：每帧图像内部存在数据冗余。比如一副图像中有一块颜色相同的画布，编码时按照nxn大小的宏块进行划分，那么宏块之间存在相似性，这就使得可以从空间层面进行压缩，即帧内压缩； 帧间压缩：连续图像之间存在许多相似细节。比如一辆运动中的汽车，从当前时刻到下一时刻发生相对位移，从另外一个角度来说，是周边环境发生相对位移而汽车本身没有变化，这就使得可以从时间层面进行压缩，即帧间压缩； 5、I帧、P帧、B帧I帧：内部编码帧，又称为关键帧，使用I帧编码可以完整还原一副图像，帧的数据量会比较大； P帧：前向预测帧，又称为前向参考帧，需要参考前一个I帧进行编码，数据量会比I帧小。同理，解码时也需要参考前一个I帧进行解码； B帧：双向内插帧，又称为双向参考帧，需要参考前后的I帧或P帧进行编码，压缩率会比P帧更高，数据量比P帧更小。但是，解码时需要下一个I帧或者P帧的到来，解码时序需要严格控制，解码复杂度也相对高。 6、GOP与关键帧间隔GOP(全称Group Of Pictures)，图像序列组，由一个关键帧和若干个非关键帧组成。在编码器参数设置中，有一个参数设置GOP大小。以Android的mediacodec为例，设置关键帧间隔时间Key_Frame_Interval，也就是设置多少秒来一个关键帧。另外有一个类似的参数，关键帧间隔：多少帧来一个关键帧。 7、码率控制码率控制，是指网络请求码流时，根据网络带宽状况来控制码率大小。分为五种控制方式：恒定码率、动态码率、平均码率、恒定质量因子、恒定量化参数。而Youtube请求网络流时，会根据网络拥挤程度来动态调整码率，得益于一种新的多媒体传输控制协议——DASH，全称为Danymic Adaptive Streaming over HTTP，即基于HTTP的动态自适应媒体流。接下来对码率控制方式进行展开分析。 恒定码率：CBR(Constant Bitrate)，以恒定的码率去编码，波动小，编码质量欠佳； 动态码率：VBR(Variable Bitrate)，以动态的码率去编码，波动大，编码质量比较稳定； 平均码率：ABR(Average Bitrate)，以平均的码率去编码，编码质量参差不齐； 恒定质量因子：CQF(Constant Quality Factor)，又称为CRF(Constant Rate Factor)，在x264和x265编码默认采用CRF，取值范围为[0,51]，数值越大表示视频压缩率越高，编码质量越低； 恒定量化参数：CQP(Constant Quantization Parameter)，瞬时码率会随场景复杂度有所波动，在H264定义的QP范围为[0,51]，数值越大表示量化步长越大，编码质量越低。当为QP=0时，表示无损编码； 8、SVC分级编码SVC(全称Scalable Video Coding)，可扩展的视频编码，也称为分级编码。具有三大特性：时间可分级、空间可分级、质量可分级。 时间可分级：分为T0、T1、T2、T3，用来设置帧率，丢弃棕、绿、蓝得到不同帧率。如下图所示： 质量可分级：可以从码流提取不同图像质量的子码流。 应用领域：视频监控、流媒体直播、视频会议。 优点：分级码流应用灵活，一次编码多次使用，可得到不同帧率、分辨率、质量； 缺点：分级码流的解码复杂度增加，比单层码流的压缩率低10%左右； 9、YUV视频压缩编码后，是以YUV格式进行存储的，Y代表亮度(Chroma)，U代表色度(Luma)，V代表对比度(Contrast)。常见的YUV排列格式有YUV444、YUV422、YUV420，区别如下表所示： YUV420分为YUV420P和YUV420SP。其中，YUV420P又称为I420，P代表Planar平面，按照Y、U、V顺序排列，存储结构如下图所示： 而YUV420SP，其中SP代表Semi Planar半独立平面，U和V是交错存储的，存储结构如下图所示： 能不能举个例子，经过编码和不应该编码的一部电影他们的大小能差多少？ 当涉及到视频编码的压缩效果时，实际的压缩比例会受到多个因素的影响，包括视频内容、编码参数和压缩算法等。因此，无法给出具体的数字来表示编码前后视频大小的差异，因为结果会因情况而异。然而，我可以通过一个简化的例子来说明视频编码对文件大小的影响。 假设我们有一部电影，持续时间为2小时，分辨率为1920x1080像素，帧率为24帧/秒。我们将比较原始未经编码的视频（Raw Video）和经过常见有损压缩算法（如H.264）编码后的视频的文件大小。 原始未经编码的视频（Raw Video）：对于每一帧，假设使用RGB颜色空间，每个像素需要3个字节（一个字节用于红色通道，一个字节用于绿色通道，一个字节用于蓝色通道）。因此，每一帧的数据大小为：1920 x 1080 x 3 = 6,220,800字节。考虑到24帧/秒，2小时长的视频将需要非常大的存储空间。 经过有损压缩编码的视频：使用常见的有损压缩算法（如H.264）对视频进行编码时，会应用变换、量化、运动估计、运动补偿和熵编码等技术。这些技术将减少冗余数据和舍弃视觉上较不重要的信息，从而显著减小文件大小。具体的压缩比例将取决于编码参数和视频内容。 每一帧的数据大小为：1920 x 1080 x 3 = 6,220,800 字节。 考虑到视频的帧率为 24 帧/秒，接下来我们计算每秒的数据大小：每秒的数据大小 = 每帧的数据大小 x 帧率 = 6,220,800 字节 x 24 = 149,299,200 字节= 0.1389636993408203 GB。 接下来，我们计算整个视频的数据大小。视频的长度为 2 小时，即 2 x 60 x 60 = 7,200 秒：视频的数据大小 = 每秒的数据大小 x 视频长度 = 149,299,200 字节 x 7,200 = 1,074,681,600,000 字节。 将字节转换为更常见的单位，我们可以得到：视频的数据大小约为 1.07 TB（1 TB = 1,099,511,627,776 字节）。 这意味着对于一部持续 2 小时的视频，如果每帧使用 RGB 颜色空间并且每个像素需要 3 个字节来表示，未经过任何编码压缩的视频将需要约 1.07 TB 的存储空间。 这个数字显示了为什么视频编码在存储和传输视频时非常重要，因为原始视频数据的大小是非常庞大的。视频编码可以显著减小视频文件的大小，从而降低存储成本和传输带宽需求。 二、音频编码人类的听觉范围为20Hz~20KHz，那么低于20Hz或者高于20KHz，这些低频或高频信号基本听不到，可以作为冗余数据，通过特定采样率进行采样、编码。 1、采样率采样率描述的是每秒对原始声音信号的采样次数，常见的采样率8000Hz、16000Hz、44100Hz、48000Hz，目前使用最广泛的是44100Hz，即44.1KHz。 2、波形编码直接把时域信号转换为数字编码，不利用任何参数，使得重构后的波形与原始信号的波形形状尽可能保持一致。基本原理是在时间轴对模拟语音信号按照一定速率采样，然后把幅度样本量化，并用代码表示。 3、参数编码从语音波形信号中提取生成语音的参数，使用这些参数通过语音生成模型重构出语音。音质比较低，但是保密性良好，广泛应用于军事技术中，典型的参数编码为LPC(Linear Predictive Coding)。 4、混合编码混合编码是指采用两种以上编码技术，比如波形编码与参数编码结合，形成优势互补。 5、PCMPCM(Pulse Code Modulation 脉冲编码调制)，是对连续变化的模型信号抽样、量化、编码的过程，最终转换为数字信号。 音视频解码音视频文件是经过编码、封装而成的。那么反过来，要播放音视频文件，首先得解封装、解码。上一篇博客讨论到音视频编码：走进音视频的世界——音视频编码，我们来个上下呼应，本文与大家探讨一下音视频解码。本质上，是按照既定的解码协议去解析编码内容，也就是编码的逆过程。常见的视频解码器有：H264、H265、VP8、VP9、MPEG4、MJPEG、WMV3、MSMPEG4V3，常见的音频解码器有：MP3、AAC、FLAC、AC3、OPUS、VORBIS、AMR、WMA。 一、视频解码1、pts与dtsdts：Decode Timestamp，解码时间戳，决定什么时候解码该帧数据。 pts：Presentation Timestamp，显示时间戳，决定什么时候显示该帧图像。以参考时钟为基准，超前参考时钟则等待，落后（在30ms与500ms之间）参考时钟则快速渲染，十分落后（超过500ms）参考时钟则丢弃该帧。参考时钟分为三种：系统时钟、音频时钟、视频时钟。一般以音频时钟作为参考时钟，因为人类对声音更加敏感，相对图像而言。 2、关键帧与非关键帧关键帧：I帧为关键帧，所以I帧可以直接解码还原出一个图像。 非关键帧：P帧与B帧为非关键帧，需要依赖关键帧才能解码。而B帧是双向预测帧，还要另外等待下一个I帧或P帧，才可以成功解码出来。B帧压缩率比较高，但是编解码复杂度也相对高。 3、组包与拼帧有些封装格式会把一帧数据拆成若干包，因为关键帧数据可能比较大；RTP封装数据时，也会把一帧拆成若干包，因为MTU规定网络层最大传输单元为1500bytes。因此，在解封装或者接收网络数据包时，需要根据序号排列，把若干个包组成一个完整包，然后再解码。例如FFmpeg读取一帧数据过程，源码在avformat/utils.c中，如下图所示(参考雷神博客)： 4、特定帧头在解析h264/h265编码的视频帧时，需要在帧头添加起始码，一般起始码为0x00 0x00 0x01或者0x00 0x00 0x00 0x01。比如mp4封装格式，一般是以h264为视频编码、aac为音频编码。 二、音频解码1、planar与packed存储planar：每个声道数据单独存储。以立体声道为例，L表示左声道，R表示右声道。那么存储格式为LLLLRRRR。在FFmpeg中，第i个声道数据存储在frame-&gt;data[i]。类似视频的像素格式YUV420P，Y、U、V三个分量单独存储，4个Y分量对应一个U分量与一个V分量。 packed：所有声道数据交错存储。同样地，以立体声道数据为例。那么存储格式为LRLRLRLR。在FFmpeg中，所有声道数据都存储在frame-&gt;data[0]。类似视频的YUV420SP，Y独立存储，UV交错存储，4个Y分量对应一组UV分量。 2、量化位数量化位数：量化位是对模拟音频信号的幅度轴数字化，它决定了模拟信号数字化的动态范围。量化位数越大，质量越好。bitsPerSample，占2bytes，一般为8bits、16bits、32bits、64bits。在WAVE的Format chunk有定义，如下表所示： 3、采样率音频采样率是指录音设备在1秒时间内对声音信号的采样次数，采样频率越高，那么声音的还原越真实自然。常见的采样率有8000Hz、16000Hz、32000Hz、44100Hz、48000Hz。其中44100Hz可达到CD音质标准，也是目前最为常用的采样率。 4、声道数与声道布局常见声道数有：单声道、立体声道、3声道、4声道、5声道、6声道、7声道、8声道。其中3声道以上，又称为立体环绕声道，其中杜比音效就是采用多声道同时输出，实现立体环绕效果。 声道布局的各个声道描述如下： 12345678FC: front centerBC: back centerFL/FR: front left/rightFCL/FCR: front center left/rightFTL/FTR: front top left/rightSL/SR: back surround left/rightBL/BR: back left/rightLFE: low frequency effects 声道数与声道布局关系，如下表所示： VPU","link":"/2023/11/19/8%20%E9%9F%B3%E8%A7%86%E9%A2%91%E7%BC%96%E8%A7%A3%E7%A0%81%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E5%AD%A6%E4%B9%A0/"},{"title":"rkdeb包的制作","text":"先说一下前情提要： 最近这一个月一直在制作debian和ubuntu文件系统，rk官方默认情况下只是构建了debian，好像是因为版权问题，然而呢，我肯定是要构建ubuntu镜像的，而我要做的，就是根据rk提供的debian系统的构建方法，来进行ubuntu的构建。 ​ 最大的问题出现在deb包的构建,也就是下面这些deb包： 很多很多的包，根本不知道从哪里来的~~，而现在呢大约知道了，首先呢先来分析一下各个dockerfile文件。 几个很重要的github链接： docker环境的大佬链接 1https://github.com/Caesar-github 各种库的大佬链接： 1https://github.com/JeffyCN?tab=repositories 香橙派的仓库链接 1https://github.com/orangepi-xunlong/rk-rootfs-build 1 dockerfile 文件1.1 debian101234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798FROM debian:busterMAINTAINER Caesar Wang &quot;wxt@rock-chips.com&quot;# 设置多架构环境RUN dpkg --add-architecture arm64# 设置 apt 配置以跳过 SSL 验证RUN touch /etc/apt/apt.conf.d/99verify-peer.conf &amp;&amp; echo &gt;&gt;/etc/apt/apt.conf.d/99verify-peer.conf &quot;Acquire { https::Verify-Peer false }&quot;# 添加源列表ADD sources.list /etc/apt/# 更新并安装交叉编译所需的基本软件包RUN apt-get update &amp;&amp; apt-get install -y crossbuild-essential-arm64 apt-transport-https# 添加 overlay 目录ADD ./overlay/ /# 安装构建依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get install -y sudo locales git fakeroot devscripts cmake vim qemu-user-static:arm64 binfmt-support \\ dh-make dh-exec pkg-kde-tools device-tree-compiler:arm64 bc cpio parted dosfstools mtools libssl-dev:arm64 \\ g++-aarch64-linux-gnu dpkg-dev meson debhelper pkgconf# 安装 arm64 架构下 libdrm 的构建依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get build-dep -y -a arm64 libdrm# 安装 arm64 架构下 xorg-server 的构建依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get build-dep -y -a arm64 xorg-server# 安装 arm64 架构下的 gstreamer 相关软件包RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get install -y gstreamer1.0-plugins-bad:arm64 gstreamer1.0-plugins-base:arm64 gstreamer1.0-tools:arm64 \\ gstreamer1.0-alsa:arm64 gstreamer1.0-plugins-base-apps:arm64 qtmultimedia5-examples:arm64# 安装 libdrm-dev:arm64RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libdrm-dev:arm64# 安装 gstreamer-rockchip 相关软件包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libx11-dev:arm64 libdrm-dev:arm64 libgstreamer1.0-dev:arm64 \\ libgstreamer-plugins-base1.0-dev:arm64# 安装 libmali 相关软件包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libstdc++6:arm64 libgbm-dev:arm64 libdrm-dev:arm64 libx11-xcb1:arm64 libxcb-dri2-0:arm64 libxdamage1:arm64 \\ libxext6:arm64 libwayland-client0:arm64# 安装 drm-cursor 相关软件包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libgbm-dev:arm64 libegl1-mesa-dev:arm64 libgles2-mesa-dev:arm64# 安装 glmark2 相关软件包RUN apt-get install -y debhelper-compat libjpeg-dev:arm64 libpng-dev:arm64 libudev-dev:arm64 libxcb1-dev:arm64 python3 wayland-protocols libwayland-dev libwayland-bin# 安装 rktoolkit 相关软件包#RUN apt install -y libmad-ocaml-dev libmad0-dev:arm64# 安装 lib4l2 相关软件包#RUN apt update -y#RUN apt build-dep -y libv4l-dev:arm64# 安装 blueman 的构建依赖项RUN apt-get build-dep -y blueman# 生成 en_US.UTF-8 本地化设置RUN locale-gen en_US.UTF-8ENV LANG en_US.UTF-8ENV LANGUAGE en_US:enENV LC_ALL en_US.UTF-8RUN sed -i -e 's/# en_US.UTF-8 UTF-8/en_US.UTF-8 UTF-8/' /etc/locale.gen &amp;&amp; \\ echo 'LANG=&quot;en_US.UTF-8&quot;'&gt;/etc/default/locale &amp;&amp; \\ dpkg-reconfigure --frontend=non交互式 locales &amp;&amp; \\ update-locale LANG=en_US.UTF-8RUN echo &quot;Update Headers!&quot;RUN dpkg -i /packages/arm64/rga/*.debRUN dpkg -i /packages/arm64/mpp/*.debRUN apt-get install -fy --allow-downgrades /packages/arm64/gst-rkmpp/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gstreamer/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-base1.0/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-bad1.0/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-good1.0/*.debRUN apt-get install -fy --allow-downgrades /packages/arm64/libv4l/*.deb#RUN dpkg -i /packages/arm64/gst-rkmpp/*.deb#RUN dpkg -i /packages/arm64/ffmpeg/*.deb#RUN dpkg -i /packages/arm64/libmali/libmali-midgard-t86x-r18p0-x11*.debRUN find /packages/arm64/libdrm -name '*.deb' | sudo xargs -I{} dpkg -x {} /RUN echo &quot;deb https://mirrors.ustc.edu.cn/debian/ bullseye main contrib non-free&quot; &gt;&gt; /etc/apt/sources.listRUN apt updateRUN apt install -y meson=0.56.2-1RUN apt-get update &amp;&amp; apt-get install -y -f# 切换到非 root 用户RUN useradd -c 'rk user' -m -d /home/rk -s /bin/bash rkRUN sed -i -e '/\\%sudo/ c \\%sudo ALL=(ALL) NOPASSWD: ALL' /etc/sudoersRUN usermod -a -G sudo rkUSER rk 1.2 debian111234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889FROM debian:bookwormMAINTAINER Caesar Wang &quot;wxt@rock-chips.com&quot;# 设置多架构环境RUN dpkg --add-architecture arm64#RUN echo &quot;deb-src http://deb.debian.org/debian bullseye main&quot; &gt;&gt; /etc/apt/sources.list#RUN echo &quot;deb-src http://deb.debian.org/debian bullseye-updates main&quot; &gt;&gt; /etc/apt/sources.list#RUN echo &quot;deb-src http://security.debian.org bullseye/updates main&quot; &gt;&gt; /etc/apt/sources.list# 运行apt-get update并安装ca-certificates#RUN apt-get update &amp;&amp; apt-get install -y ca-certificatesRUN touch /etc/apt/apt.conf.d/99verify-peer.conf &amp;&amp; echo &gt;&gt;/etc/apt/apt.conf.d/99verify-peer.conf &quot;Acquire { https::Verify-Peer false }&quot;# 添加sources.list文件到/etc/apt/目录ADD sources.list /etc/apt/RUN apt-get update &amp;&amp; apt-get install -y crossbuild-essential-arm64# 添加overlay目录到根目录ADD ./overlay/ /# 安装构建依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get install -y sudo locales git fakeroot devscripts cmake vim qemu-user-static:arm64 binfmt-support \\ dh-make dh-exec pkg-kde-tools device-tree-compiler:arm64 bc cpio parted dosfstools mtools libssl-dev:arm64 \\ g++-aarch64-linux-gnu dpkg-dev meson debhelper pkgconfRUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get build-dep -y -a arm64 libdrmRUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get build-dep -y -a arm64 xorg-serverRUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get install -y gstreamer1.0-plugins-bad:arm64 gstreamer1.0-plugins-base:arm64 gstreamer1.0-tools:arm64 \\ gstreamer1.0-alsa:arm64 gstreamer1.0-plugins-base-apps:arm64 qtmultimedia5-examples:arm64# 安装rga所需的依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libdrm-dev:arm64# 安装gstreamer-rockchip所需的依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libx11-dev:arm64 libdrm-dev:arm64 libgstreamer1.0-dev:arm64 \\ libgstreamer-plugins-base1.0-dev:arm64# 安装libmali所需的依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libstdc++6:arm64 libgbm-dev:arm64 libdrm-dev:arm64 libx11-xcb1:arm64 libxcb-dri2-0:arm64 libxdamage1:arm64 \\ libxext6:arm64 libwayland-client0:arm64# 安装drm-cursor所需的依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libgbm-dev:arm64 libegl1-mesa-dev:arm64 libgles2-mesa-dev:arm64# 安装glmark2所需的依赖项RUN apt-get install -y debhelper-compat libjpeg-dev:arm64 libpng-dev:arm64 libudev-dev:arm64 libxcb1-dev:arm64 python3 wayland-protocols libwayland-dev libwayland-bin# 安装rktoolkit所需的依赖项#RUN apt install -y libmad-ocaml-dev libmad0-dev:arm64# 安装lib4l2所需的依赖项#RUN apt update -y#RUN apt build-dep -y libv4l-dev:arm64# 生成en_US.UTF-8本地化RUN locale-gen en_US.UTF-8ENV LANG en_US.UTF-8ENV LANGUAGE en_US:enENV LC_ALL en_US.UTF-8RUN sed -i -e 's/# en_US.UTF-8 UTF-8/en_US.UTF-8 UTF-8/' /etc/locale.gen &amp;&amp; \\ echo 'LANG=&quot;en_US.UTF-8&quot;'&gt;/etc/default/locale &amp;&amp; \\ dpkg-reconfigure --frontend=noninteractive locales &amp;&amp; \\ update-locale LANG=en_US.UTF-8RUN echo &quot;Update Headers!&quot;RUN dpkg -i /packages/arm64/rga/*.debRUN dpkg -i /packages/arm64/mpp/*.debRUN apt-get install -fy --allow-downgrades /packages/arm64/gst-rkmpp/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gstreamer/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-base1.0/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-bad1.0/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-good1.0/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/libv4l/*.deb#RUN dpkg -i /packages/arm64/gst-rkmpp/*.deb#RUN dpkg -i /packages/arm64/ffmpeg/*.deb#RUN dpkg -i /packages/arm64/libmali/libmali-midgard-t86x-r18p0-x11*.debRUN find /packages/arm64/libdrm -name '*.deb' | sudo xargs -I{} dpkg -x {} /RUN apt-get update &amp;&amp; apt-get install -y -f# 切换到非root用户RUN useradd -c 'rk user' -m -d /home/rk -s /bin/bash rkRUN sed -i -e '/\\%sudo/ c \\%sudo ALL=(ALL) NOPASSWD: ALL' /etc/sudoersRUN usermod -a -G sudo rkUSER rk 1.3 debian12123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104# 使用Debian bookworm作为基础镜像FROM debian:bookworm# 设置镜像的维护者信息MAINTAINER Caesar Wang &quot;wxt@rock-chips.com&quot;# 添加arm64架构支持RUN dpkg --add-architecture arm64# 配置apt，禁用HTTPS的证书验证RUN touch /etc/apt/apt.conf.d/99verify-peer.conf &amp;&amp; echo &gt;&gt;/etc/apt/apt.conf.d/99verify-peer.conf &quot;Acquire { https::Verify-Peer false }&quot;# 添加自定义的sources.list文件到容器的/etc/apt/目录ADD sources.list /etc/apt/# 更新apt源并安装crossbuild-essential-arm64软件包RUN apt-get update &amp;&amp; apt-get install -y crossbuild-essential-arm64# 将当前目录下的overlay目录添加到镜像的根目录ADD ./overlay/ /# 安装构建过程中需要的依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt install -fy sudo locales git fakeroot devscripts cmake vim qemu-user-static:arm64 binfmt-support \\ dh-make dh-exec device-tree-compiler:arm64 bc:arm64 cpio:arm64 parted dosfstools:arm64 mtools:arm64 libssl-dev:arm64 \\ g++-aarch64-linux-gnu dpkg-dev:arm64 meson:arm64 debhelper:arm64 pkgconf:arm64# 安装构建libdrm库所需的依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get build-dep -y -a arm64 libdrm# 安装构建xorg-server所需的依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get build-dep -y -a arm64 xorg-server# 安装GStreamer相关的依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get install -y gstreamer1.0-plugins-bad:arm64 gstreamer1.0-plugins-base:arm64 gstreamer1.0-tools:arm64 \\ gstreamer1.0-alsa:arm64 gstreamer1.0-plugins-base-apps:arm64 qtmultimedia5-examples:arm64# 安装libdrm-dev依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libdrm-dev:arm64# 安装libx11-dev、libdrm-dev、libgstreamer1.0-dev、libgstreamer-plugins-base1.0-dev等依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libx11-dev:arm64 libdrm-dev:arm64 libgstreamer1.0-dev:arm64 libgstreamer-plugins-base1.0-dev:arm64 \\ libgstreamer-plugins-base1.0-dev:arm64# 安装libstdc++6、libgbm-dev、libdrm-dev、libx11-xcb1、libxcb-dri2-0、libxdamage1、libxext6、libwayland-client0等依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libstdc++6:arm64 libgbm-dev:arm64 libdrm-dev:arm64 libx11-xcb1:arm64 libxcb-dri2-0:arm64 libxdamage1:arm64 \\ libxext6:arm64 libwayland-client0:arm64# 安装libgbm-dev、libegl1-mesa-dev、libgles2-mesa-dev依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libgbm-dev:arm64 libegl1-mesa-dev:arm64 libgles2-mesa-dev:arm64# 安装debhelper-compat、libjpeg-dev、libpng-dev、libudev-dev、libxcb1-dev、python3、wayland-protocols、libwayland-dev、libwayland-bin等依赖包RUN apt-get install -y debhelper-compat libjpeg-dev:arm64 libpng-dev:arm64 libudev-dev:arm64 libxcb1-dev:arm64 python3 wayland-protocols libwayland-dev libwayland-bin# 安装构建weston所需的依赖包RUN apt-get update &amp;&amp; apt build-dep -y weston:arm64# 生成并设置系统的locale为en_US.UTF-8RUN locale-gen en_US.UTF-8ENV LANG en_US.UTF-8ENV LANGUAGE en_US:enENV LC_ALL en_US.UTF-8# 修改locale.gen文件并重新配置locales，更新locale设置RUN sed -i -e 's/# en_US.UTF-8 UTF-8/en_US.UTF-8 UTF-8/' /etc/locale.gen &amp;&amp; \\ echo 'LANG=&quot;en_US.UTF-8&quot;'&gt;/etc/default/locale &amp;&amp; \\ dpkg-reconfigure --frontend=noninteractive locales &amp;&amp; \\ update-locale LANG=en_US.UTF-8# 打印日志信息RUN echo &quot;Update Headers!&quot;# 安装rga2软件包RUN dpkg -i /packages/arm64/rga2/*.deb# 安装mpp软件包RUN dpkg -i /packages/arm64/mpp/*.deb# 安装gst-rkmpp软件包RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-rkmpp/*.deb# 安装gst-plugins-base1.0软件包RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-base1.0/*.deb# 安装libv4l软件包RUN apt-get install -fy --allow-downgrades /packages/arm64/libv4l/*.deb# 解压libdrm软件包RUN find /packages/arm64/libdrm -name '*.deb' | sudo xargs -I{} dpkg -x {} /# 更新apt源并安装依赖包RUN apt-get update &amp;&amp; apt-get install -y -f# 创建名为rk的用户RUN useradd -c 'rk user' -m -d /home/rk -s /bin/bash rk# 修改sudoers文件，允许rk用户使用sudo命令无需密码验证RUN sed -i -e '/\\%sudo/ c \\%sudo ALL=(ALL) NOPASSWD: ALL' /etc/sudoers# 将rk用户添加到sudo用户组中RUN usermod -a -G sudo rk# 切换到rk用户USER rk 2.问题探究默认情况下是不可以下载软件源码的，当取消一些特定的注释之后，是可以使用apt-get source命令进行软件包源码的下载的， 1apt-get source xorg-server 最后一句话忽略即可 xorg-server-1.20.13：这是一个目录，其中包含了xorg-server软件包的源代码文件和其他相关文件。 xorg-server_1.20.13-1ubuntu1~20.04.9.diff.gz：这是一个压缩文件，其中包含了对源代码进行修改的补丁文件（diff文件）。 xorg-server_1.20.13-1ubuntu1~20.04.9.dsc：这是一个文本文件，其中包含了软件包的元数据信息，例如软件包的名称、版本号、维护者等。 xorg-server_1.20.13.orig.tar.gz：这是一个压缩文件，其中包含了软件包的原始源代码文件，即未经过任何修改的原始文件。 xorg-server_1.20.13.orig.tar.gz.asc：这是一个数字签名文件，用于验证软件包的完整性和真实性。 由于我是虚拟机上进行测试的所以我应该安装电脑amd64的，这里先安装构建xorg-server的软件包，下面需要注意的是build-dep这个参数： 1DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get build-dep -y -a amd64 xorg-server 然后使用以下命令构建deb包 1DEB_BUILD_OPTIONS=nocheck dpkg-buildpackage -rfakeroot -b -d -uc -us -aamd64 DEB_BUILD_OPTIONS=nocheck：这个选项设置构建过程中不运行自动化的测试。 dpkg-buildpackage：这个命令用于构建 Debian 软件包。 -rfakeroot：这个选项在构建过程中模拟 root 权限，以便可以在非特权用户下进行构建。 -b：这个选项告诉 dpkg-buildpackage 构建二进制软件包（即生成 .deb 文件）。 -d：这个选项告诉 dpkg-buildpackage 忽略构建依赖关系，即不检查构建依赖关系是否满足。 -uc：这个选项告诉 dpkg-buildpackage 不使用软件包的维护者密钥进行签名。 -us：这个选项告诉 dpkg-buildpackage 不生成源码软件包（即不生成 .dsc 文件）。 -aamd64：这个选项指定了目标架构为 amd64，即构建适用于 amd64 架构的软件包。 构建完成之后如下图所示： 根据提供的软件包列表，可以将它们分为以下几类： xorg-server 相关： xorg-server-source_1.20.13-1ubuntu1~20.04.9_all.deb：xorg-server 的源代码包。 xorg-server_1.20.13-1ubuntu1~20.04.9_amd64.deb：xorg-server 的二进制软件包。 xorg-server-dbgsym_1.20.13-1ubuntu1~20.04.9_amd64.ddeb：xorg-server 的调试符号包。 xserver-xorg-core 相关： xserver-xorg-core_1.20.13-1ubuntu1~20.04.9_amd64.deb：xserver-xorg-core 的二进制软件包。 xserver-xorg-core-dbgsym_1.20.13-1ubuntu1~20.04.9_amd64.ddeb：xserver-xorg-core 的调试符号包。 xserver-xorg-core-udeb_1.20.13-1ubuntu1~20.04.9_amd64.udeb：xserver-xorg-core 的用于 Debian 安装程序的最小化二进制软件包。 xserver-xephyr 相关： xserver-xephyr_1.20.13-1ubuntu1~20.04.9_amd64.deb：xserver-xephyr 的二进制软件包。 xserver-xephyr-dbgsym_1.20.13-1ubuntu1~20.04.9_amd64.ddeb：xserver-xephyr 的调试符号包。 xserver-xorg-legacy 相关： xserver-xorg-legacy_1.20.13-1ubuntu1~20.04.9_amd64.deb：xserver-xorg-legacy 的二进制软件包。 xserver-xorg-legacy-dbgsym_1.20.13-1ubuntu1~20.04.9_amd64.ddeb：xserver-xorg-legacy 的调试符号包。 其他组件： xdmx_1.20.13-1ubuntu1~20.04.9_amd64.deb：xdmx 的二进制软件包。 xdmx-dbgsym_1.20.13-1ubuntu1~20.04.9_amd64.ddeb：xdmx 的调试符号包。 xdmx-tools_1.20.13-1ubuntu1~20.04.9_amd64.deb：xdmx-tools 的二进制软件包。 xdmx-tools-dbgsym_1.20.13-1ubuntu1~20.04.9_amd64.ddeb：xdmx-tools 的调试符号包。 xnest_1.20.13-1ubuntu1~20.04.9_amd64.deb：xnest 的二进制软件包。 xnest-dbgsym_1.20.13-1ubuntu1~20.04.9_amd64.ddeb：xnest 的调试符号包。 xwayland_1.20.13-1ubuntu1~20.04.9_amd64.deb：xwayland 的二进制软件包。 xwayland-dbgsym_1.20.13-1ubuntu1~20.04.9_amd64.ddeb：xwayland 的调试符号包。 xserver-common_1.20.13-1ubuntu1~20.04.9_all.deb：xserver 的公共文件包。 xserver-xorg-dev_1.20.13-1ubuntu1~20.04.9_amd64.deb：xserver-xorg-dev 的二进制软件包。 xvfb_1.20.13-1ubuntu1~20.04.9_amd64.deb：xvfb 的二进制软件包。 xvfb-dbgsym_1.20.13-1ubuntu1~20.04.9_amd64.ddeb：xvfb 的调试符号包。 ==为什么会有deb udeb ddeb呢有什么区别？== 在 Debian 系统中，软件包文件的扩展名可以有不同的形式，如 .deb、.udeb 和 .ddeb。这些扩展名代表了不同类型的软件包。 .deb：.deb 是最常见的 Debian 软件包扩展名，用于二进制软件包。这些软件包包含已经编译好的二进制文件，可以直接安装和使用。通常用于常规的应用程序、库和工具等。 .udeb：.udeb 是用于 Debian 安装程序的特殊类型的软件包扩展名，它表示微型二进制软件包（microdeb）。这些软件包通常非常小，并包含了在系统安装过程中所需的最小化组件。.udeb 文件主要用于 Debian 安装程序（如 Debian Installer）期间的系统安装和配置，它们通常包含一些核心组件和驱动程序。 .ddeb：.ddeb 是调试符号软件包的扩展名。调试符号包包含了编译后的二进制文件与调试信息的映射关系，它们用于在调试软件时进行符号解析和调试。通过将调试符号包与相应的二进制软件包结合使用，开发人员可以在调试过程中获取更详细和有用的调试信息。.ddeb 文件通常用于开发和调试目的。 也就是说这些才是最重要的： 那么现在我上面的那些docker镜像终于有作用了。 然后拉取大佬的xserver源码，拉取完成如下所示： 1git clone https://github.com/JeffyCN/xorg-xserver.git 然后切换分支到1.20.4 1git chechout remotes/origin/rockchip/debian/1.20.4 然后查看一下分支： 最后使用docker加载一下该源码 1docker run --privileged -it -v /home/topeet/Linux/xorg-xserver:/home/topeet/xorg-xserver debian10 然后使用以下命令构建deb包 1sudo DEB_BUILD_OPTIONS=nocheck dpkg-buildpackage -rfakeroot -b -d -uc -us -aarm64 ==我还以为这是aarch64，我说咋一直不对~~~==，构建完成如下图所示： 然后开始在上一节目录下生成了对应的deb包： 1.debian10 dockerfile123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100FROM debian:busterMAINTAINER Caesar Wang &quot;wxt@rock-chips.com&quot;# 设置多架构环境RUN dpkg --add-architecture arm64# 设置 apt 配置以跳过 SSL 验证RUN touch /etc/apt/apt.conf.d/99verify-peer.conf &amp;&amp; echo &gt;&gt;/etc/apt/apt.conf.d/99verify-peer.conf &quot;Acquire { https::Verify-Peer false }&quot;# 添加源列表ADD sources.list /etc/apt/# 更新并安装交叉编译所需的基本软件包RUN apt-get update &amp;&amp; apt-get install -y crossbuild-essential-arm64 apt-transport-https# 添加 overlay 目录ADD ./overlay/ /# 安装构建依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get install -y sudo locales git fakeroot devscripts cmake vim qemu-user-static:arm64 binfmt-support \\ dh-make dh-exec pkg-kde-tools device-tree-compiler:arm64 bc cpio parted dosfstools mtools libssl-dev:arm64 \\ g++-aarch64-linux-gnu dpkg-dev meson debhelper pkgconf# 安装 arm64 架构下 libdrm 的构建依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get build-dep -y -a arm64 libdrm# 安装 arm64 架构下 xorg-server 的构建依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get build-dep -y -a arm64 xorg-server# 安装 arm64 架构下的 gstreamer 相关软件包RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get install -y gstreamer1.0-plugins-bad:arm64 gstreamer1.0-plugins-base:arm64 gstreamer1.0-tools:arm64 \\ gstreamer1.0-alsa:arm64 gstreamer1.0-plugins-base-apps:arm64 qtmultimedia5-examples:arm64# 安装 libdrm-dev:arm64RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libdrm-dev:arm64# 安装 gstreamer-rockchip 相关软件包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libx11-dev:arm64 libdrm-dev:arm64 libgstreamer1.0-dev:arm64 \\ libgstreamer-plugins-base1.0-dev:arm64# 安装 libmali 相关软件包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libstdc++6:arm64 libgbm-dev:arm64 libdrm-dev:arm64 libx11-xcb1:arm64 libxcb-dri2-0:arm64 libxdamage1:arm64 \\ libxext6:arm64 libwayland-client0:arm64# 安装 drm-cursor 相关软件包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libgbm-dev:arm64 libegl1-mesa-dev:arm64 libgles2-mesa-dev:arm64# 安装 glmark2 相关软件包RUN apt-get install -y debhelper-compat libjpeg-dev:arm64 libpng-dev:arm64 libudev-dev:arm64 libxcb1-dev:arm64 python3 wayland-protocols libwayland-dev libwayland-bin# 安装 rktoolkit 相关软件包#RUN apt install -y libmad-ocaml-dev libmad0-dev:arm64# 安装 lib4l2 相关软件包#RUN apt update -y#RUN apt build-dep -y libv4l-dev:arm64# 安装 blueman 的构建依赖项RUN apt-get build-dep -y blueman# 生成 en_US.UTF-8 本地化设置RUN locale-gen en_US.UTF-8ENV LANG en_US.UTF-8ENV LANGUAGE en_US:enENV LC_ALL en_US.UTF-8RUN sed -i -e 's/# en_US.UTF-8 UTF-8/en_US.UTF-8 UTF-8/' /etc/locale.gen &amp;&amp; \\ echo 'LANG=&quot;en_US.UTF-8&quot;'&gt;/etc/default/locale &amp;&amp; \\ dpkg-reconfigure --frontend=non交互式 locales &amp;&amp; \\ update-locale LANG=en_US.UTF-8RUN echo &quot;Update Headers!&quot;RUN dpkg -i /packages/arm64/rga/*.debRUN dpkg -i /packages/arm64/mpp/*.debRUN apt-get install -fy --allow-downgrades /packages/arm64/gst-rkmpp/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gstreamer/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-base1.0/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-bad1.0/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-good1.0/*.debRUN apt-get install -fy --allow-downgrades /packages/arm64/libv4l/*.deb#RUN dpkg -i /packages/arm64/gst-rkmpp/*.deb#RUN dpkg -i /packages/arm64/ffmpeg/*.deb#RUN dpkg -i /packages/arm64/libmali/libmali-midgard-t86x-r18p0-x11*.debRUN find /packages/arm64/libdrm -name '*.deb' | sudo xargs -I{} dpkg -x {} /RUN echo &quot;deb https://mirrors.ustc.edu.cn/debian/ bullseye main contrib non-free&quot; &gt;&gt; /etc/apt/sources.listRUN apt updateRUN apt install -y meson=0.56.2-1RUN apt-get update &amp;&amp; apt-get install -y -f# 切换到非 root 用户RUN useradd -c 'topeet user' -m -d /home/topeet -s /bin/bash topeetRUN sed -i -e '/\\%sudo/ c \\%sudo ALL=(ALL) NOPASSWD: ALL' /etc/sudoersRUN usermod -a -G sudo topeetUSER topeetWORKDIR /home/topeetENTRYPOINT [ &quot;/bin/bash&quot;] 然后运行以下命令进行镜像的构建，之前都构建了一次了所以这次应该挺快的 1docker build -t debian10 . 发现问题，源不太对了，所以这里先改一下源，好像不改也可以，是我自己的电脑问题，重启就好了 12345678deb https://mirrors.huaweicloud.com/repository/debian/ buster main contrib non-freedeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster main contrib non-freedeb https://mirrors.huaweicloud.com/repository/debian/ buster-updates main contrib non-freedeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-updates main contrib non-freedeb https://mirrors.huaweicloud.com/repository/debian/ buster-backports main contrib non-freedeb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-backports main contrib non-freedeb https://mirrors.huaweicloud.com/repository/debian-security buster/updates main contrib non-freedeb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security buster/updates main contrib non-free 构建完成如上所示，然后打包该镜像 1docker save -o debian10.tar.gz debian10 最后整体打包一下： 1tar -zcvf docker-rockchip-debian-buster.tar.gz docker-rockchip-debian-buster/ 2.debian11 dockerfile12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091FROM debian:bookwormMAINTAINER Caesar Wang &quot;wxt@rock-chips.com&quot;# 设置多架构环境RUN dpkg --add-architecture arm64#RUN echo &quot;deb-src http://deb.debian.org/debian bullseye main&quot; &gt;&gt; /etc/apt/sources.list#RUN echo &quot;deb-src http://deb.debian.org/debian bullseye-updates main&quot; &gt;&gt; /etc/apt/sources.list#RUN echo &quot;deb-src http://security.debian.org bullseye/updates main&quot; &gt;&gt; /etc/apt/sources.list# 运行apt-get update并安装ca-certificates#RUN apt-get update &amp;&amp; apt-get install -y ca-certificatesRUN touch /etc/apt/apt.conf.d/99verify-peer.conf &amp;&amp; echo &gt;&gt;/etc/apt/apt.conf.d/99verify-peer.conf &quot;Acquire { https::Verify-Peer false }&quot;# 添加sources.list文件到/etc/apt/目录ADD sources.list /etc/apt/RUN apt-get update &amp;&amp; apt-get install -y crossbuild-essential-arm64# 添加overlay目录到根目录ADD ./overlay/ /# 安装构建依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get install -y sudo locales git fakeroot devscripts cmake vim qemu-user-static:arm64 binfmt-support \\ dh-make dh-exec pkg-kde-tools device-tree-compiler:arm64 bc cpio parted dosfstools mtools libssl-dev:arm64 \\ g++-aarch64-linux-gnu dpkg-dev meson debhelper pkgconfRUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get build-dep -y -a arm64 libdrmRUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get build-dep -y -a arm64 xorg-serverRUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get install -y gstreamer1.0-plugins-bad:arm64 gstreamer1.0-plugins-base:arm64 gstreamer1.0-tools:arm64 \\ gstreamer1.0-alsa:arm64 gstreamer1.0-plugins-base-apps:arm64 qtmultimedia5-examples:arm64# 安装rga所需的依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libdrm-dev:arm64# 安装gstreamer-rockchip所需的依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libx11-dev:arm64 libdrm-dev:arm64 libgstreamer1.0-dev:arm64 \\ libgstreamer-plugins-base1.0-dev:arm64# 安装libmali所需的依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libstdc++6:arm64 libgbm-dev:arm64 libdrm-dev:arm64 libx11-xcb1:arm64 libxcb-dri2-0:arm64 libxdamage1:arm64 \\ libxext6:arm64 libwayland-client0:arm64# 安装drm-cursor所需的依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libgbm-dev:arm64 libegl1-mesa-dev:arm64 libgles2-mesa-dev:arm64# 安装glmark2所需的依赖项RUN apt-get install -y debhelper-compat libjpeg-dev:arm64 libpng-dev:arm64 libudev-dev:arm64 libxcb1-dev:arm64 python3 wayland-protocols libwayland-dev libwayland-bin# 安装rktoolkit所需的依赖项#RUN apt install -y libmad-ocaml-dev libmad0-dev:arm64# 安装lib4l2所需的依赖项#RUN apt update -y#RUN apt build-dep -y libv4l-dev:arm64# 生成en_US.UTF-8本地化RUN locale-gen en_US.UTF-8ENV LANG en_US.UTF-8ENV LANGUAGE en_US:enENV LC_ALL en_US.UTF-8RUN sed -i -e 's/# en_US.UTF-8 UTF-8/en_US.UTF-8 UTF-8/' /etc/locale.gen &amp;&amp; \\ echo 'LANG=&quot;en_US.UTF-8&quot;'&gt;/etc/default/locale &amp;&amp; \\ dpkg-reconfigure --frontend=noninteractive locales &amp;&amp; \\ update-locale LANG=en_US.UTF-8RUN echo &quot;Update Headers!&quot;RUN dpkg -i /packages/arm64/rga/*.debRUN dpkg -i /packages/arm64/mpp/*.debRUN apt-get install -fy --allow-downgrades /packages/arm64/gst-rkmpp/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gstreamer/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-base1.0/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-bad1.0/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-good1.0/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/libv4l/*.deb#RUN dpkg -i /packages/arm64/gst-rkmpp/*.deb#RUN dpkg -i /packages/arm64/ffmpeg/*.deb#RUN dpkg -i /packages/arm64/libmali/libmali-midgard-t86x-r18p0-x11*.debRUN find /packages/arm64/libdrm -name '*.deb' | sudo xargs -I{} dpkg -x {} /RUN apt-get update &amp;&amp; apt-get install -y -f# 切换到非 root 用户RUN useradd -c 'topeet user' -m -d /home/topeet -s /bin/bash topeetRUN sed -i -e '/\\%sudo/ c \\%sudo ALL=(ALL) NOPASSWD: ALL' /etc/sudoersRUN usermod -a -G sudo topeetUSER topeetWORKDIR /home/topeetENTRYPOINT [ &quot;/bin/bash&quot;] 然后运行以下命令进行镜像的构建，之前都构建了一次了所以这次应该挺快的 1docker build -t debian11 . 构建完成如上所示，然后打包该镜像 1docker save -o debian11.tar.gz debian11 最后整体打包一下： 1tar -zcvf docker-rockchip-debian-bullseye.tar.gz docker-rockchip-debian-bullseye 3.debian12 dockerfile123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100# 使用Debian bookworm作为基础镜像FROM debian:bookworm# 设置镜像的维护者信息MAINTAINER Caesar Wang &quot;wxt@rock-chips.com&quot;# 添加arm64架构支持RUN dpkg --add-architecture arm64# 配置apt，禁用HTTPS的证书验证RUN touch /etc/apt/apt.conf.d/99verify-peer.conf &amp;&amp; echo &gt;&gt;/etc/apt/apt.conf.d/99verify-peer.conf &quot;Acquire { https::Verify-Peer false }&quot;# 添加自定义的sources.list文件到容器的/etc/apt/目录ADD sources.list /etc/apt/# 更新apt源并安装crossbuild-essential-arm64软件包RUN apt-get update &amp;&amp; apt-get install -y crossbuild-essential-arm64# 将当前目录下的overlay目录添加到镜像的根目录ADD ./overlay/ /# 安装构建过程中需要的依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt install -fy sudo locales git fakeroot devscripts cmake vim qemu-user-static:arm64 binfmt-support \\ dh-make dh-exec device-tree-compiler:arm64 bc:arm64 cpio:arm64 parted dosfstools:arm64 mtools:arm64 libssl-dev:arm64 \\ g++-aarch64-linux-gnu dpkg-dev:arm64 meson:arm64 debhelper:arm64 pkgconf:arm64# 安装构建libdrm库所需的依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get build-dep -y -a arm64 libdrm# 安装构建xorg-server所需的依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get build-dep -y -a arm64 xorg-server# 安装GStreamer相关的依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get install -y gstreamer1.0-plugins-bad:arm64 gstreamer1.0-plugins-base:arm64 gstreamer1.0-tools:arm64 \\ gstreamer1.0-alsa:arm64 gstreamer1.0-plugins-base-apps:arm64 qtmultimedia5-examples:arm64# 安装libdrm-dev依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libdrm-dev:arm64# 安装libx11-dev、libdrm-dev、libgstreamer1.0-dev、libgstreamer-plugins-base1.0-dev等依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libx11-dev:arm64 libdrm-dev:arm64 libgstreamer1.0-dev:arm64 libgstreamer-plugins-base1.0-dev:arm64 \\ libgstreamer-plugins-base1.0-dev:arm64# 安装libstdc++6、libgbm-dev、libdrm-dev、libx11-xcb1、libxcb-dri2-0、libxdamage1、libxext6、libwayland-client0等依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libstdc++6:arm64 libgbm-dev:arm64 libdrm-dev:arm64 libx11-xcb1:arm64 libxcb-dri2-0:arm64 libxdamage1:arm64 \\ libxext6:arm64 libwayland-client0:arm64# 安装libgbm-dev、libegl1-mesa-dev、libgles2-mesa-dev依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libgbm-dev:arm64 libegl1-mesa-dev:arm64 libgles2-mesa-dev:arm64# 安装debhelper-compat、libjpeg-dev、libpng-dev、libudev-dev、libxcb1-dev、python3、wayland-protocols、libwayland-dev、libwayland-bin等依赖包RUN apt-get install -y debhelper-compat libjpeg-dev:arm64 libpng-dev:arm64 libudev-dev:arm64 libxcb1-dev:arm64 python3 wayland-protocols libwayland-dev libwayland-bin# 安装构建weston所需的依赖包RUN apt-get update &amp;&amp; apt build-dep -y weston:arm64# 生成并设置系统的locale为en_US.UTF-8RUN locale-gen en_US.UTF-8ENV LANG en_US.UTF-8ENV LANGUAGE en_US:enENV LC_ALL en_US.UTF-8# 修改locale.gen文件并重新配置locales，更新locale设置RUN sed -i -e 's/# en_US.UTF-8 UTF-8/en_US.UTF-8 UTF-8/' /etc/locale.gen &amp;&amp; \\ echo 'LANG=&quot;en_US.UTF-8&quot;'&gt;/etc/default/locale &amp;&amp; \\ dpkg-reconfigure --frontend=noninteractive locales &amp;&amp; \\ update-locale LANG=en_US.UTF-8# 打印日志信息RUN echo &quot;Update Headers!&quot;# 安装rga2软件包RUN dpkg -i /packages/arm64/rga2/*.deb# 安装mpp软件包RUN dpkg -i /packages/arm64/mpp/*.deb# 安装gst-rkmpp软件包RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-rkmpp/*.deb# 安装gst-plugins-base1.0软件包RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-base1.0/*.deb# 安装libv4l软件包RUN apt-get install -fy --allow-downgrades /packages/arm64/libv4l/*.deb# 解压libdrm软件包RUN find /packages/arm64/libdrm -name '*.deb' | sudo xargs -I{} dpkg -x {} /# 更新apt源并安装依赖包RUN apt-get update &amp;&amp; apt-get install -y -f# 切换到非 root 用户RUN useradd -c 'topeet user' -m -d /home/topeet -s /bin/bash topeetRUN sed -i -e '/\\%sudo/ c \\%sudo ALL=(ALL) NOPASSWD: ALL' /etc/sudoersRUN usermod -a -G sudo topeetUSER topeetWORKDIR /home/topeetENTRYPOINT [ &quot;/bin/bash&quot;] 然后运行以下命令进行镜像的构建，之前都构建了一次了所以这次应该挺快的 1docker build -t debian12 . 构建完成如上所示，然后打包该镜像 1docker save -o debian12.tar.gz debian12 最后整体打包一下： 1tar -zcvf docker-rockchip-debian-bookworm.tar.gz docker-rockchip-debian-bookworm 4.ubuntu20 dockerfile1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586FROM arm64v8/ubuntu:20.04# 设置多架构环境RUN dpkg --add-architecture arm64# 运行apt-get update并安装ca-certificates#RUN apt-get update &amp;&amp; apt-get install -y ca-certificatesRUN touch /etc/apt/apt.conf.d/99verify-peer.conf &amp;&amp; echo &gt;&gt;/etc/apt/apt.conf.d/99verify-peer.conf &quot;Acquire { https::Verify-Peer false }&quot;# 添加sources.list文件到/etc/apt/目录ADD sources.list /etc/apt/RUN apt-get update &amp;&amp; apt-get install -y crossbuild-essential-arm64# 添加overlay目录到根目录ADD ./overlay/ /# 安装构建依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get install -y sudo locales git fakeroot devscripts cmake vim qemu-user-static:arm64 binfmt-support \\ dh-make dh-exec pkg-kde-tools device-tree-compiler:arm64 bc cpio parted dosfstools mtools libssl-dev:arm64 \\ g++-aarch64-linux-gnu dpkg-dev meson debhelper pkgconfRUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get build-dep -y -a arm64 libdrmRUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get build-dep -y -a arm64 xorg-serverRUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get install -y gstreamer1.0-plugins-bad:arm64 gstreamer1.0-plugins-base:arm64 gstreamer1.0-tools:arm64 \\ gstreamer1.0-alsa:arm64 gstreamer1.0-plugins-base-apps:arm64 qtmultimedia5-examples:arm64# 安装rga所需的依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libdrm-dev:arm64# 安装gstreamer-rockchip所需的依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libx11-dev:arm64 libdrm-dev:arm64 libgstreamer1.0-dev:arm64 \\ libgstreamer-plugins-base1.0-dev:arm64# 安装libmali所需的依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libstdc++6:arm64 libgbm-dev:arm64 libdrm-dev:arm64 libx11-xcb1:arm64 libxcb-dri2-0:arm64 libxdamage1:arm64 \\ libxext6:arm64 libwayland-client0:arm64# 安装drm-cursor所需的依赖项RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libgbm-dev:arm64 libegl1-mesa-dev:arm64 libgles2-mesa-dev:arm64# 安装glmark2所需的依赖项RUN apt-get install -y debhelper-compat libjpeg-dev:arm64 libpng-dev:arm64 libudev-dev:arm64 libxcb1-dev:arm64 python3 wayland-protocols libwayland-dev libwayland-bin# 安装rktoolkit所需的依赖项#RUN apt install -y libmad-ocaml-dev libmad0-dev:arm64# 安装lib4l2所需的依赖项#RUN apt update -y#RUN apt build-dep -y libv4l-dev:arm64# 生成en_US.UTF-8本地化RUN locale-gen en_US.UTF-8ENV LANG en_US.UTF-8ENV LANGUAGE en_US:enENV LC_ALL en_US.UTF-8RUN sed -i -e 's/# en_US.UTF-8 UTF-8/en_US.UTF-8 UTF-8/' /etc/locale.gen &amp;&amp; \\ echo 'LANG=&quot;en_US.UTF-8&quot;'&gt;/etc/default/locale &amp;&amp; \\ dpkg-reconfigure --frontend=noninteractive locales &amp;&amp; \\ update-locale LANG=en_US.UTF-8RUN echo &quot;Update Headers!&quot;RUN apt-get install -fy --allow-downgrades /packages/arm64/rga/*.debRUN apt-get install -fy --allow-downgrades /packages/arm64/mpp/*.debRUN apt-get install -fy --allow-downgrades /packages/arm64/gst-rkmpp/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gstreamer/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-base1.0/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-bad1.0/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-good1.0/*.deb#RUN apt-get install -fy --allow-downgrades /packages/arm64/libv4l/*.deb#RUN dpkg -i /packages/arm64/gst-rkmpp/*.deb#RUN dpkg -i /packages/arm64/ffmpeg/*.deb#RUN dpkg -i /packages/arm64/libmali/libmali-midgard-t86x-r18p0-x11*.deb#RUN find /packages/arm64/libdrm -name '*.deb' | sudo xargs -I{} dpkg -x {} /RUN apt-get update &amp;&amp; apt-get install -y -f# 切换到非 root 用户RUN useradd -c 'topeet user' -m -d /home/topeet -s /bin/bash topeetRUN sed -i -e '/\\%sudo/ c \\%sudo ALL=(ALL) NOPASSWD: ALL' /etc/sudoersRUN usermod -a -G sudo topeetUSER topeetWORKDIR /home/topeetENTRYPOINT [ &quot;/bin/bash&quot;] 然后运行以下命令进行镜像的构建，之前都构建了一次了所以这次应该挺快的 1docker build -t debian11 . 构建完成如上所示，然后打包该镜像 1docker save -o ubuntu20.tar.gz ubuntu20 5.ubuntu22 dockerfile123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596FROM arm64v8/ubuntu:22.04# 添加arm64架构支持RUN dpkg --add-architecture arm64# 配置apt，禁用HTTPS的证书验证RUN touch /etc/apt/apt.conf.d/99verify-peer.conf &amp;&amp; echo &gt;&gt;/etc/apt/apt.conf.d/99verify-peer.conf &quot;Acquire { https::Verify-Peer false }&quot;# 添加自定义的sources.list文件到容器的/etc/apt/目录ADD sources.list /etc/apt/# 更新apt源并安装crossbuild-essential-arm64软件包RUN apt-get update &amp;&amp; apt-get install -y crossbuild-essential-arm64# 将当前目录下的overlay目录添加到镜像的根目录ADD ./overlay/ /# 安装构建过程中需要的依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt install -fy sudo locales git fakeroot devscripts cmake vim qemu-user-static:arm64 binfmt-support \\ dh-make dh-exec device-tree-compiler:arm64 bc:arm64 cpio:arm64 parted dosfstools:arm64 mtools:arm64 libssl-dev:arm64 \\ g++-aarch64-linux-gnu dpkg-dev:arm64 meson:arm64 debhelper:arm64 pkgconf:arm64# 安装构建libdrm库所需的依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get build-dep -y -a arm64 libdrm# 安装构建xorg-server所需的依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get build-dep -y -a arm64 xorg-server# 安装GStreamer相关的依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;&amp; apt-get install -y gstreamer1.0-plugins-bad:arm64 gstreamer1.0-plugins-base:arm64 gstreamer1.0-tools:arm64 \\ gstreamer1.0-alsa:arm64 gstreamer1.0-plugins-base-apps:arm64 qtmultimedia5-examples:arm64# 安装libdrm-dev依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libdrm-dev:arm64# 安装libx11-dev、libdrm-dev、libgstreamer1.0-dev、libgstreamer-plugins-base1.0-dev等依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libx11-dev:arm64 libdrm-dev:arm64 libgstreamer1.0-dev:arm64 libgstreamer-plugins-base1.0-dev:arm64 \\ libgstreamer-plugins-base1.0-dev:arm64# 安装libstdc++6、libgbm-dev、libdrm-dev、libx11-xcb1、libxcb-dri2-0、libxdamage1、libxext6、libwayland-client0等依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libstdc++6:arm64 libgbm-dev:arm64 libdrm-dev:arm64 libx11-xcb1:arm64 libxcb-dri2-0:arm64 libxdamage1:arm64 \\ libxext6:arm64 libwayland-client0:arm64# 安装libgbm-dev、libegl1-mesa-dev、libgles2-mesa-dev依赖包RUN DEBIAN_FRONTEND=noninteractive apt-get install -y libgbm-dev:arm64 libegl1-mesa-dev:arm64 libgles2-mesa-dev:arm64# 安装debhelper-compat、libjpeg-dev、libpng-dev、libudev-dev、libxcb1-dev、python3、wayland-protocols、libwayland-dev、libwayland-bin等依赖包RUN apt-get install -y debhelper-compat libjpeg-dev:arm64 libpng-dev:arm64 libudev-dev:arm64 libxcb1-dev:arm64 python3 wayland-protocols libwayland-dev libwayland-bin# 安装构建weston所需的依赖包RUN apt-get update &amp;&amp; apt build-dep -y weston:arm64# 生成并设置系统的locale为en_US.UTF-8RUN locale-gen en_US.UTF-8ENV LANG en_US.UTF-8ENV LANGUAGE en_US:enENV LC_ALL en_US.UTF-8# 修改locale.gen文件并重新配置locales，更新locale设置RUN sed -i -e 's/# en_US.UTF-8 UTF-8/en_US.UTF-8 UTF-8/' /etc/locale.gen &amp;&amp; \\ echo 'LANG=&quot;en_US.UTF-8&quot;'&gt;/etc/default/locale &amp;&amp; \\ dpkg-reconfigure --frontend=noninteractive locales &amp;&amp; \\ update-locale LANG=en_US.UTF-8# 打印日志信息RUN echo &quot;Update Headers!&quot;# 安装rga2软件包RUN dpkg -i /packages/arm64/rga2/*.deb# 安装mpp软件包RUN dpkg -i /packages/arm64/mpp/*.deb# 安装gst-rkmpp软件包RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-rkmpp/*.deb# 安装gst-plugins-base1.0软件包# RUN apt-get install -fy --allow-downgrades /packages/arm64/gst-plugins-base1.0/*.deb# 安装libv4l软件包# RUN apt-get install -fy --allow-downgrades /packages/arm64/libv4l/*.deb# 解压libdrm软件包# RUN find /packages/arm64/libdrm -name '*.deb' | sudo xargs -I{} dpkg -x {} /# 更新apt源并安装依赖包RUN apt-get update &amp;&amp; apt-get install -y -f# 切换到非 root 用户RUN useradd -c 'topeet user' -m -d /home/topeet -s /bin/bash topeetRUN sed -i -e '/\\%sudo/ c \\%sudo ALL=(ALL) NOPASSWD: ALL' /etc/sudoersRUN usermod -a -G sudo topeetUSER topeetWORKDIR /home/topeetENTRYPOINT [ &quot;/bin/bash&quot;] 然后运行以下命令进行镜像的构建，之前都构建了一次了所以这次应该挺快的 1docker build -t debian12 . 构建完成如上所示，然后打包该镜像 1docker save -o ubuntu22.tar.gz ubuntu22 6.继续构建docker搞完了，然后继续搞deb包的构建。先使用debian10 构建xserver的， 1docker run --privileged -it -v /home/topeet/Linux/xorg-xserver:/home/topeet/ubuntu20_build debian10 然后使用以下命令构建deb包 1sudo DEB_BUILD_OPTIONS=nocheck dpkg-buildpackage -rfakeroot -b -d -uc -us -aarm64 构建成功了，但是我目前仍旧不知道具体的区别所在。 X server 是一种实现图形用户界面的服务器软件，它允许图形应用程序在计算机上运行并与显示设备交互。“glamor” 是 X server 中的一个加速架构，它提供了对OpenGL ES 2.0的支持，可以加速图形渲染。“rga” 是一种基于 Arm Mali GPU 的图形加速器，可以提高图形渲染性能。“exa” 是 X server 的一个图形加速架构，可以提高 2D 图形操作的性能。因此，“X server with glamor hacks for gles2 and rga based exa” 意味着某种针对 OpenGL ES 2.0、rga 图形加速和 exa 图形加速的 X server 的改进版本或配置。这可能是一种优化后的 X server，可以提供更好的图形渲染性能和功能。 7.测试xserver测试的灵感来自这个csdn https://blog.csdn.net/Neutionwei/article/details/111411023 我先来几个疑问？ 1.什么是glamor？ Glamor 是一个用于加速 2D 图形渲染的开源库和技术。它最初是为 X.Org 服务器开发的，旨在提供更高效的图形渲染方式。Glamor 的目标是通过利用现代图形硬件的能力，提供快速和高效的图形渲染，从而改善用户界面的性能和响应能力。 传统上，X.Org 服务器使用软件渲染来处理图形操作，这对于复杂的图形和动画效果可能效率较低。Glamor 的出现解决了这个问题，它利用了现代图形硬件中的 2D 加速功能，从而在支持硬件加速的系统上提供更快的图形渲染性能。 Glamor 的工作原理是将高级的 2D 图形操作转换为底层的图形加速接口调用，如 OpenGL 或 Vulkan。它通过将图形操作转发给底层硬件加速接口，利用 GPU 强大的并行处理能力来加速图形渲染。这种方式比传统的软件渲染更高效，可以显著提升图形渲染的性能和响应速度。 Glamor 提供了一个抽象层，使得开发者可以方便地在支持 Glamor 的系统上使用硬件加速的图形渲染。它可以与多种图形库和窗口系统集成，如 Xlib、Wayland 和 DirectFB。开发者可以使用 Glamor 提供的 API 来绘制图形，而无需直接操作底层的硬件加速接口。 2.上面提到了glamor是一个硬件加速技术，那在rk3568上我要如何实现glamor硬件加速呢？ 确认硬件支持：首先，确保 RK3568 平台的图形硬件支持硬件加速。RK3568 是一款搭载了 Mali-G52 GPU 的芯片，Mali-G52 是一款支持 OpenGL ES、Vulkan 和 OpenCL 等标准的图形处理器。你需要确保该芯片在 Linux 系统上的驱动程序正确安装和配置，并支持硬件加速功能。 安装相关软件：为了使用硬件加速，你需要安装支持 Glamor 的图形库和驱动程序。通常，这包括 Mesa 3D 图形库、X.Org 服务器和相应的 DRM/KMS 驱动程序。你可以根据具体的 Linux 发行版和系统配置，使用包管理器来安装这些软件包。 配置 X.Org 服务器：Glamor 是为 X.Org 服务器设计的，因此你需要配置 X.Org 服务器以启用 Glamor。你可以编辑 X.Org 服务器的配置文件（通常是 /etc/X11/xorg.conf 或 /etc/X11/xorg.conf.d/ 目录下的文件），添加或修改相关的配置选项来启用 Glamor。具体的配置选项可能会因不同的系统和驱动程序而有所差异，你可以参考相关文档或官方指南来了解如何正确配置 Glamor。 测试和验证：完成上述步骤后，你可以编写一个简单的测试程序来验证硬件加速是否正常工作。你可以使用 OpenGL 或 Vulkan 等图形库来进行绘图操作，并通过性能测试或其他指标来评估图形渲染性能的提升。你也可以尝试使用 Glamor 提供的 API 来进行图形绘制，以验证 Glamor 的功能和性能。 3.那我用默认的ubuntu软件包和 Mali-G52驱动能正常使用glamor吗？ 在使用默认的 Ubuntu 软件包和 Mali-G52 驱动时，使用 Glamor 应该是可行的。Ubuntu 是一个广泛使用的 Linux 发行版，它通常包含了 Mesa 3D 图形库和 X.Org 服务器等组件，这些组件对于使用 Glamor 是必要的。 Mali-G52 是 ARM 公司的图形处理器，它在 Linux 系统上有对应的 DRM/KMS 驱动程序，用于与 X.Org 服务器和图形库进行交互。这些驱动程序通常会随着操作系统的更新和发布而更新，以确保兼容性和性能优化。 在大多数情况下，当你使用默认的 Ubuntu 软件包和 Mali-G52 驱动时，Glamor 应该已经预先配置并启用了。这意味着你可以直接通过 X.Org 服务器和相关图形库（如 OpenGL）来进行图形渲染，而无需额外的配置步骤。 4.但我看瑞芯微已经对drm xserver等软件包进行了魔改，这是为啥呢？ 瑞芯微对 DRM（Direct Rendering Manager）和 X.Org 服务器等软件包进行魔改的主要目的是为了更好地适配和优化他们的芯片和硬件。这种魔改通常是为了解决特定的硬件功能、性能或兼容性问题，并确保在特定的瑞芯微平台上能够获得最佳的图形渲染性能和用户体验。 以下是一些可能的原因和动机： 硬件优化：瑞芯微可能会对 DRM 和 X.Org 服务器进行修改，以最大程度地利用他们的芯片中的硬件加速功能。通过直接访问硬件特性和功能，他们可以实现更高效的图形渲染和处理，提供更好的性能和响应能力。 兼容性和稳定性：瑞芯微可能会对软件包进行修改，以确保其与他们的芯片和硬件之间的兼容性。这可能涉及对驱动程序的修改、参数的调整或特定硬件功能的支持。通过这些修改，他们可以提供更稳定和可靠的图形渲染环境，减少与硬件相关的问题和兼容性冲突。 定制化需求：瑞芯微的客户可能有特定的需求，需要定制化的图形渲染解决方案。通过对软件包进行魔改，他们可以满足客户的定制需求，提供针对特定应用场景和硬件平台的优化和定制化功能。 测试程序如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108#include &lt;iostream&gt;#include &lt;chrono&gt;#include &lt;X11/Xlib.h&gt;void drawRectangleWithGlamor(int width, int height, int drawCount) { Display* display = XOpenDisplay(NULL); if (display == NULL) { std::cerr &lt;&lt; &quot;无法打开 X 服务器连接&quot; &lt;&lt; std::endl; return; } Window rootWindow = DefaultRootWindow(display); Window window = XCreateSimpleWindow(display, rootWindow, 0, 0, width, height, 0, 0, 0); XSelectInput(display, window, StructureNotifyMask); XMapWindow(display, window); XEvent event; do { XNextEvent(display, &amp;event); } while (event.type != MapNotify); GC gc = XCreateGC(display, window, 0, NULL); auto startTime = std::chrono::high_resolution_clock::now(); for (int i = 0; i &lt; drawCount; ++i) { XSetForeground(display, gc, WhitePixel(display, DefaultScreen(display))); XFillRectangle(display, window, gc, 0, 0, width, height); XFlush(display); } auto endTime = std::chrono::high_resolution_clock::now(); double drawTime = std::chrono::duration&lt;double, std::milli&gt;(endTime - startTime).count(); double drawRate = static_cast&lt;double&gt;(drawCount) / (drawTime / 1000); XFreeGC(display, gc); XDestroyWindow(display, window); XCloseDisplay(display); std::cout &lt;&lt; width &lt;&lt; &quot;x&quot; &lt;&lt; height &lt;&lt; &quot;大小的矩形（使用 glamor）：&quot; &lt;&lt; std::endl; std::cout &lt;&lt; drawCount &lt;&lt; &quot;次绘制，每次绘制耗时&quot; &lt;&lt; drawTime / drawCount &lt;&lt; &quot;毫秒，每秒绘制次数为&quot; &lt;&lt; drawRate &lt;&lt; &quot;次。&quot; &lt;&lt; std::endl;}void drawRectangleWithoutGlamor(int width, int height, int drawCount) { Display* display = XOpenDisplay(NULL); if (display == NULL) { std::cerr &lt;&lt; &quot;无法打开 X 服务器连接&quot; &lt;&lt; std::endl; return; } Window rootWindow = DefaultRootWindow(display); Window window = XCreateSimpleWindow(display, rootWindow, 0, 0, width, height, 0, 0, 0); XSelectInput(display, window, StructureNotifyMask); XMapWindow(display, window); XEvent event; do { XNextEvent(display, &amp;event); } while (event.type != MapNotify); GC gc = XCreateGC(display, window, 0, NULL); auto startTime = std::chrono::high_resolution_clock::now(); for (int i = 0; i &lt; drawCount; ++i) { XSetForeground(display, gc, WhitePixel(display, DefaultScreen(display))); XDrawRectangle(display, window, gc, 0, 0, width - 1, height - 1); XFillRectangle(display, window, gc, 0, 0, width, height); XFlush(display); } auto endTime = std::chrono::high_resolution_clock::now(); double drawTime = std::chrono::duration&lt;double, std::milli&gt;(endTime - startTime).count(); double drawRate = static_cast&lt;double&gt;(drawCount) / (drawTime / 1000); XFreeGC(display, gc); XDestroyWindow(display, window); XCloseDisplay(display); std::cout &lt;&lt; width &lt;&lt; &quot;x&quot; &lt;&lt; height &lt;&lt; &quot;大小的矩形（不使用 glamor）：&quot; &lt;&lt; std::endl; std::cout &lt;&lt; drawCount &lt;&lt; &quot;次绘制，每次绘制耗时&quot; &lt;&lt; drawTime / drawCount &lt;&lt; &quot;毫秒，每秒绘制次数为&quot; &lt;&lt; drawRate &lt;&lt; &quot;次。&quot; &lt;&lt; std::endl;}void drawRectangle(int width, int height, int drawCount, bool useGlamor) { if (useGlamor) { drawRectangleWithGlamor(width, height, drawCount); } else { drawRectangleWithoutGlamor(width, height, drawCount); }}int main() { // 不使用 glamor 的测试 drawRectangle(1, 1, 50000, false); drawRectangle(10, 10, 50000, false); drawRectangle(100, 100, 50000, false); drawRectangle(500, 500, 50000, false); std::cout &lt;&lt; std::endl; // 使用 glamor 的测试 drawRectangle(1, 1, 50000, true); drawRectangle(10, 10, 50000, true); drawRectangle(100, 100, 50000, true); drawRectangle(500, 500, 50000, true); return 0;} 然后使用以下命令进行编译： 1g++ test.cpp -o test -lX11 然后运行测试，测试结果如下所示： 得出的结论如下所示：使用加速（glamor）： 对于1x1、10x10、100x100和500x500大小的矩形，每次绘制的耗时都在0.0057毫秒到0.0061毫秒之间。 每秒绘制次数在162242到175190之间。 不使用加速： 对于1x1、10x10、100x100和500x500大小的矩形，每次绘制的耗时在0.0028毫秒到0.0087毫秒之间。 每秒绘制次数在114430到357260之间。 从这些数据中可以看出，使用加速（glamor）相对于不使用加速，绘制矩形的耗时更稳定且更快。而不使用加速的情况下，绘制耗时有较大的波动，并且随着矩形大小的增加，绘制次数呈现不同程度的下降。 总体而言，使用加速（glamor）可以提供更稳定和高效的绘制性能，特别是在处理较大尺寸的矩形时。然而，要注意这些结论仅基于你提供的数据，具体的性能差异可能会因不同的环境和配置而有所变化。 上面是通过程序测试的，也有一个专门的命令行进行查看 1cat /var/log/Xorg.0.log | grep glamor 显示“glamor initialized”，则表示已启用加速。 8.测试opencl打印基础信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#define CL_TARGET_OPENCL_VERSION 220#include &lt;CL/cl.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt; // 使用标准库函数需包含该头文件int main() { cl_platform_id *platform; cl_uint num_platform; cl_int err; // 获取平台数量 err = clGetPlatformIDs(0, NULL, &amp;num_platform); if (err != CL_SUCCESS) { printf(&quot;无法获取平台数量\\n&quot;); return err; } platform = (cl_platform_id *)malloc(sizeof(cl_platform_id) * num_platform); // 获取平台ID err = clGetPlatformIDs(num_platform, platform, NULL); if (err != CL_SUCCESS) { printf(&quot;无法获取平台ID\\n&quot;); free(platform); return err; } for (int i = 0; i &lt; num_platform; i++) { size_t size; char *name, *vendor, *version, *profile, *extensions; // 获取平台名称 err = clGetPlatformInfo(platform[i], CL_PLATFORM_NAME, 0, NULL, &amp;size); name = (char *)malloc(size); err = clGetPlatformInfo(platform[i], CL_PLATFORM_NAME, size, name, NULL); printf(&quot;CL_PLATFORM_NAME: %s\\n&quot;, name); free(name); // 获取平台供应商 err = clGetPlatformInfo(platform[i], CL_PLATFORM_VENDOR, 0, NULL, &amp;size); vendor = (char *)malloc(size); err = clGetPlatformInfo(platform[i], CL_PLATFORM_VENDOR, size, vendor, NULL); printf(&quot;CL_PLATFORM_VENDOR: %s\\n&quot;, vendor); free(vendor); // 获取平台版本 err = clGetPlatformInfo(platform[i], CL_PLATFORM_VERSION, 0, NULL, &amp;size); version = (char *)malloc(size); err = clGetPlatformInfo(platform[i], CL_PLATFORM_VERSION, size, version, NULL); printf(&quot;CL_PLATFORM_VERSION: %s\\n&quot;, version); free(version); // 获取平台配置文件 err = clGetPlatformInfo(platform[i], CL_PLATFORM_PROFILE, 0, NULL, &amp;size); profile = (char *)malloc(size); err = clGetPlatformInfo(platform[i], CL_PLATFORM_PROFILE, size, profile, NULL); printf(&quot;CL_PLATFORM_PROFILE: %s\\n&quot;, profile); free(profile); // 获取平台扩展 err = clGetPlatformInfo(platform[i], CL_PLATFORM_EXTENSIONS, 0, NULL, &amp;size); extensions = (char *)malloc(size); err = clGetPlatformInfo(platform[i], CL_PLATFORM_EXTENSIONS, size, extensions, NULL); printf(&quot;CL_PLATFORM_EXTENSIONS: %s\\n&quot;, extensions); free(extensions); printf(&quot;\\n\\n&quot;); } free(platform); return 0;} 编译： 1gcc opencl.cpp -o opencl_test -lmali -L/usr/lib/aarch64-linux-gnu/ -I/usr/include/CL/ 运行“ 然后使用clinfo命令也可以打印opencl的信息 123456789101112131415161718192021222324252627282930313233343536373839404142root@topeet:/home/topeet$ clinfoNumber of platforms 1 Platform Name ARM Platform Platform Vendor ARM Platform Version OpenCL 2.1 v1.g6p0-01eac0.efb75e2978d783a80fe78be1bfb0efc1 Platform Profile FULL_PROFILE Platform Extensions cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_byte_addressable_store cl_khr_3d_image_writes cl_khr_int64_base_atomics cl_khr_int64_extended_atomics cl_khr_fp16 cl_khr_icd cl_khr_egl_image cl_khr_image2d_from_buffer cl_khr_depth_images cl_khr_subgroups cl_khr_subgroup_extended_types cl_khr_subgroup_non_uniform_vote cl_khr_subgroup_ballot cl_khr_il_program cl_khr_priority_hints cl_khr_create_command_queue cl_khr_spirv_no_integer_wrap_decoration cl_khr_extended_versioning cl_khr_device_uuid cl_arm_core_id cl_arm_printf cl_arm_non_uniform_work_group_size cl_arm_import_memory cl_arm_import_memory_dma_buf cl_arm_import_memory_host cl_arm_integer_dot_product_int8 cl_arm_integer_dot_product_accumulate_int8 cl_arm_integer_dot_product_accumulate_saturate_int8 cl_arm_scheduling_controls cl_arm_controlled_kernel_termination cl_ext_cxx_for_opencl Platform Extensions function suffix ARM Platform Host timer resolution 1ns Platform Name ARM PlatformNumber of devices 1arm_release_ver of this libmali is 'g6p0-01eac0', rk_so_ver is '5'. Device Name Mali-LODX r0p0 Device Vendor ARM Device Vendor ID 0xa8670000 Device Version OpenCL 2.1 v1.g6p0-01eac0.efb75e2978d783a80fe78be1bfb0efc1 Device UUID 000067a8-0100-0000-0000-000000000000 Driver UUID d9495bef-ea91-7c52-8a43-8a3c2f7b49cc Valid Device LUID No Device LUID 0000-000000000000 Device Node Mask 0 Device Numeric Version 0x801000 (2.1.0) Driver Version 2.1 Device OpenCL C Version OpenCL C 2.0 v1.g6p0-01eac0.efb75e2978d783a80fe78be1bfb0efc1 Device C++ for OpenCL Numeric Version 0x400000 (1.0.0) Device Type GPU Device Profile FULL_PROFILE Device Available Yes Compiler Available Yes Linker Available Yes Max compute units 4 Available core IDs 0, 2, 16, 18 Max clock frequency 1000MHz Device Partition (core) Max number of sub-devices 0 Supported partition types None Supported affinity domains (n/a) Max work item dimensions 3 Max work item sizes 1024x1024x1024 Max work group size 1024 Preferred work group size multiple (kernel) 16 clpeak测试，这个源里面是没有的，所以需要先git 123456git clone https://github.com/krrishnarraj/clpeakmkdir clpeak/buildcd clpeak/buildcmake ..make -j$(nproc)./clpeak 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859oot@topeet:/home/topeet/clpeak/build$ ./clpeakPlatform: ARM Platformarm_release_ver of this libmali is 'g6p0-01eac0', rk_so_ver is '5'. Device: Mali-LODX r0p0 Driver version : 2.1 (Linux ARM64) Compute units : 4 Clock frequency : 1000 MHz Global memory bandwidth (GBPS) float : 23.15 float2 : 24.43 float4 : 25.12 float8 : 12.74 float16 : 12.29 Single-precision compute (GFLOPS) float : 439.08 float2 : 467.79 float4 : 463.03 float8 : 432.98 float16 : 408.58 Half-precision compute (GFLOPS) half : 439.79 half2 : 867.20 half4 : 898.12 half8 : 875.33 half16 : 835.56 No double precision support! Skipped Integer compute (GIOPS) int : 124.79 int2 : 125.28 int4 : 124.83 int8 : 123.36 int16 : 123.81 Integer compute Fast 24bit (GIOPS) int : 124.67 int2 : 125.32 int4 : 124.79 int8 : 123.36 int16 : 123.82 Transfer bandwidth (GBPS) enqueueWriteBuffer : 2.73 enqueueReadBuffer : 7.82 enqueueWriteBuffer non-blocking : 7.26 enqueueReadBuffer non-blocking : 8.16 enqueueMapBuffer(for read) : 60.05 memcpy from mapped ptr : 9.09 enqueueUnmap(after write) : 56.96 memcpy to mapped ptr : 8.79 Kernel launch latency : 40.79 usroot@topeet:/home/topeet/clpeak/build$ 这个输出显示了在 ARM 平台上的 OpenCL 性能测试结果。具体来说，它提供了以下信息： 平台信息：ARM 平台。 设备信息：Mali-LODX r0p0 设备，具有以下特性： 驱动版本：2.1 (Linux ARM64)。 计算单元数量：4。 时钟频率：1000 MHz。 然后，它提供了一系列性能指标，包括： 全局内存带宽（单位：GBPS）：浮点数运算的带宽。 float：23.15 GBPS float2：24.43 GBPS float4：25.12 GBPS float8：12.74 GBPS float16：12.29 GBPS 单精度浮点数计算性能（单位：GFLOPS）： float：439.08 GFLOPS float2：467.79 GFLOPS float4：463.03 GFLOPS float8：432.98 GFLOPS float16：408.58 GFLOPS 半精度浮点数计算性能（单位：GFLOPS）： half：439.79 GFLOPS half2：867.20 GFLOPS half4：898.12 GFLOPS half8：875.33 GFLOPS half16：835.56 GFLOPS 不支持双精度浮点数计算。 整数计算性能（单位：GIOPS）： int：124.79 GIOPS int2：125.28 GIOPS int4：124.83 GIOPS int8：123.36 GIOPS int16：123.81 GIOPS 快速 24 位整数计算性能（单位：GIOPS）： int：124.67 GIOPS int2：125.32 GIOPS int4：124.79 GIOPS int8：123.36 GIOPS int16：123.82 GIOPS 传输带宽（单位：GBPS）：不同类型的内存传输操作的带宽。 enqueueWriteBuffer：2.73 GBPS enqueueReadBuffer：7.82 GBPS enqueueWriteBuffer non-blocking：7.26 GBPS enqueueReadBuffer non-blocking：8.16 GBPS enqueueMapBuffer(for read)：60.05 GBPS memcpy from mapped ptr：9.09 GBPS enqueueUnmap(after write)：56.96 GBPS memcpy to mapped ptr：8.79 GBPS 内核启动延迟：40.79 微秒。 9.对比测试（编译一个什么都没有的ubuntu）1 10 opengl学习学习网址：https://blog.csdn.net/XscKernel/article/details/50158329?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169996845316800211564994%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=169996845316800211564994&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-50158329-null-null.142 ==什么是opengl？== OpenGL（Open Graphics Library）是一个用于渲染2D和3D图形的跨平台图形编程接口。它提供了一套函数和命令，用于管理图形数据、执行基本绘图操作和实现高级的图形效果。 下面是一些关于OpenGL的详细说明： 跨平台性: OpenGL是跨平台的，可以在不同的操作系统（如Windows、MacOS、Linux）上运行。这使得开发者可以编写与特定操作系统无关的图形应用程序。 硬件加速: OpenGL可以利用计算机中的图形硬件（如显卡）进行硬件加速，以提高图形渲染的性能。这使得OpenGL在处理复杂的3D图形时具有出色的性能。 图形渲染管线: OpenGL使用图形渲染管线来处理图形数据。图形渲染管线是一系列的处理阶段，将输入的3D图形数据转换为最终在屏幕上显示的2D图像。它包括几何处理、光栅化、着色和输出等阶段。 基本几何图元: OpenGL支持绘制基本几何图元，如点、线和三角形。这些图元构成了绘制复杂3D对象的基础。 着色器编程: OpenGL使用着色器来处理图形的顶点和像素。顶点着色器负责对每个顶点进行变换和处理，而像素着色器则在光栅化阶段对每个像素进行处理。这使得开发者可以根据需要自定义图形的外观和效果。 纹理映射: OpenGL支持将纹理映射到3D模型的表面，以实现更加真实和详细的图形效果。纹理可以包含图像、颜色或其他数据，可以用于模拟材质、添加细节和实现纹理映射效果。 光照和阴影: OpenGL提供了灯光模型和阴影技术，可以模拟光的交互和对象之间的阴影关系。这使得图形更加逼真和真实。 扩展和版本: OpenGL不断发展和更新，引入新的功能和扩展，以适应不断增长的图形需求。每个OpenGL版本都有其特定的功能和支持的硬件级别。 10.1 环境搭建安装OpenGL Library 1sudo apt-get install libgl1-mesa-dev 安装OpenGL Utilities 1sudo apt-get install libglu1-mesa-dev OpenGL Utilities 是一组建构于 OpenGL Library 之上的工具组，提供许多很方便的函式，使 OpenGL 更强大且更容易使用。 安装OpenGL Utility Toolkit 1sudo apt-get install freeglut3-dev OpenGL Utility Toolkit 是建立在 OpenGL Utilities 上面的工具箱，除了强化了 OpenGL Utilities 的不足之外，也增加了 OpenGL 对于视窗介面支援。 测试程序 123456789101112131415161718192021#include &lt;GL/glut.h&gt;void myDisplay(void){ glClear(GL_COLOR_BUFFER_BIT); glRectf(-0.5f, -0.5f, 0.5f, 0.5f); glFlush();}int main(int argc, char *argv[]){ glutInit(&amp;argc, argv); glutInitDisplayMode(GLUT_RGB | GLUT_SINGLE); glutInitWindowPosition(100, 100); glutInitWindowSize(400, 400); glutCreateWindow(&quot;the first opengL test&quot;); glutDisplayFunc(&amp;myDisplay); glutMainLoop(); return 0;} 1gcc -o test test.c -lGL -lGLU -lglut 演示效果如下所示： 10.2：画一个圆1234567891011121314151617181920212223242526272829303132333435363738#include &lt;GL/glut.h&gt; // 引入OpenGL库#include &lt;math.h&gt;const int n = 20; // 定义多边形的边数const GLfloat R = 0.5f; // 多边形的半径const GLfloat Pi = 3.1415926536f; // 圆周率Pivoid myDisplay(void){ glClear(GL_COLOR_BUFFER_BIT); // 清空颜色缓冲区 glBegin(GL_POLYGON); // 开始绘制多边形 for (int i = 0; i &lt; n; ++i) { // 计算多边形每个顶点的坐标 GLfloat x = R * cos(2 * Pi / n * i); GLfloat y = R * sin(2 * Pi / n * i); glVertex2f(x, y); // 添加顶点 } glEnd(); // 结束绘制多边形 glFlush(); // 清空OpenGL命令缓冲区，强制执行绘图命令}int main(int argc, char* argv[]){ glutInit(&amp;argc, argv); // 初始化GLUT库 glutInitDisplayMode(GLUT_RGB); // 设置显示模式为RGB颜色模式 glutInitWindowSize(400, 400); // 设置窗口大小 glutCreateWindow(&quot;OpenGL Polygon&quot;); // 创建窗口，并设置标题为 &quot;OpenGL Polygon&quot; glutDisplayFunc(myDisplay); // 注册显示回调函数 glutMainLoop(); // 进入主循环，开始事件处理 return 0;} 1gcc -o test test.c -lGL -lGLU -lglut 10.3 画一个五角星1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;GL/glut.h&gt;#include &lt;math.h&gt;const GLfloat Pi = 3.1415926536f;void myDisplay(void){ // 计算五角星的相关坐标 GLfloat a = 1 / (2 - 2 * cos(72 * Pi / 180)); GLfloat bx = a * cos(18 * Pi / 180); GLfloat by = a * sin(18 * Pi / 180); GLfloat cy = -a * cos(18 * Pi / 180); // 定义五个顶点的坐标 GLfloat PointA[2] = {0, a}; GLfloat PointB[2] = {bx, by}; GLfloat PointC[2] = {0.5, cy}; GLfloat PointD[2] = {-0.5, cy}; GLfloat PointE[2] = {-bx, by}; glClear(GL_COLOR_BUFFER_BIT); // 按照A-&gt;C-&gt;E-&gt;B-&gt;D-&gt;A的顺序，绘制五角星 glBegin(GL_LINE_LOOP); glVertex2fv(PointA); glVertex2fv(PointC); glVertex2fv(PointE); glVertex2fv(PointB); glVertex2fv(PointD); glEnd(); glFlush();}int main(int argc, char* argv[]){ glutInit(&amp;argc, argv); glutInitDisplayMode(GLUT_RGB); glutInitWindowSize(400, 400); glutCreateWindow(&quot;OpenGL Star&quot;); glutDisplayFunc(myDisplay); glutMainLoop(); return 0;} 1gcc -o test test.c -lm -lGL -lGLU -lglut 10.4 画一个正弦12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;GL/glut.h&gt;#include &lt;math.h&gt;const GLfloat factor = 0.1f;void myDisplay(void){ GLfloat x; glClear(GL_COLOR_BUFFER_BIT); // 绘制坐标轴 glBegin(GL_LINES); glVertex2f(-1.0f, 0.0f); // x轴起点 glVertex2f(1.0f, 0.0f); // x轴终点 glVertex2f(0.0f, -1.0f); // y轴起点 glVertex2f(0.0f, 1.0f); // y轴终点 glEnd(); // 绘制正弦曲线 glBegin(GL_LINE_STRIP); for (x = -1.0f / factor; x &lt; 1.0f / factor; x += 0.01f) { glVertex2f(x * factor, sin(x) * factor); } glEnd(); glFlush();}int main(int argc, char* argv[]){ glutInit(&amp;argc, argv); glutInitDisplayMode(GLUT_RGB); glutInitWindowSize(400, 400); glutCreateWindow(&quot;OpenGL Sine Curve&quot;); glutDisplayFunc(myDisplay); glutMainLoop(); return 0;} 1gcc -o test test.c -lm -lGL -lGLU -lglut 10.5 指定着色模型12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;GL/glut.h&gt;#include &lt;math.h&gt;const GLdouble Pi = 3.1415926536;void myDisplay(void){ int i; glClear(GL_COLOR_BUFFER_BIT); glBegin(GL_TRIANGLE_FAN); glColor3f(1.0f, 1.0f, 1.0f); glVertex2f(0.0f, 0.0f); for (i = 0; i &lt;= 8; ++i) { glColor3f((i &amp; 0x04) ? 1.0f : 0.0f, (i &amp; 0x02) ? 1.0f : 0.0f, (i &amp; 0x01) ? 1.0f : 0.0f); glVertex2f(cos(i * Pi / 4), sin(i * Pi / 4)); } glEnd(); glFlush();}int main(int argc, char *argv[]){ glutInit(&amp;argc, argv); glutInitDisplayMode(GLUT_RGB); glutInitWindowSize(400, 400); glutCreateWindow(&quot;OpenGL Colorful Triangle&quot;); glutDisplayFunc(myDisplay); glutMainLoop(); return 0;} 1gcc -o test test.c -lm -lGL -lGLU -lglut 这个图形渲染出来就很慢，这可能就是GPU的作用了 10.6 三维变换模型变换和视图变换 投影变换 视口变换 操作矩阵堆栈 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;GL/glut.h&gt;static int day = 200;void myDisplay(void){ glEnable(GL_DEPTH_TEST); glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); glMatrixMode(GL_PROJECTION); glLoadIdentity(); gluPerspective(75, 1, 1, 400000000); glMatrixMode(GL_MODELVIEW); glLoadIdentity(); gluLookAt(0, -200000000, 200000000, 0, 0, 0, 0, 0, 1); glColor3f(1.0f, 0.0f, 0.0f); glutSolidSphere(69600000, 20, 20); glColor3f(0.0f, 0.0f, 1.0f); glRotatef(day / 360.0f * 360.0f, 0.0f, 0.0f, -1.0f); glTranslatef(150000000, 0.0f, 0.0f); glutSolidSphere(15945000, 20, 20); glColor3f(1.0f, 1.0f, 0.0f); glRotatef(day / 30.0f * 360.0f - day / 360.0f * 360.0f, 0.0f, 0.0f, -1.0f); glTranslatef(38000000, 0.0f, 0.0f); glutSolidSphere(4345000, 20, 20); glFlush();}int main(int argc, char* argv[]){ glutInit(&amp;argc, argv); glutInitDisplayMode(GLUT_RGB | GLUT_DEPTH); glutInitWindowSize(800, 800); glutCreateWindow(&quot;Solar System&quot;); glutDisplayFunc(myDisplay); // 添加深度测试函数 glEnable(GL_DEPTH_TEST); glDepthFunc(GL_EQUAL); glutMainLoop(); return 0;} 1gcc -o test test.c -lm -lGL -lGLU -lglut 10.7 动起来12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;GL/glut.h&gt;// 太阳、地球和月亮// 假设每个月都是30天// 一年12个月，共是360天static int day = 200; // day的变化：从0到359void myDisplay(void){ glEnable(GL_DEPTH_TEST); glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); glMatrixMode(GL_PROJECTION); glLoadIdentity(); gluPerspective(75, 1, 1, 400000000); glMatrixMode(GL_MODELVIEW); glLoadIdentity(); gluLookAt(0, -200000000, 200000000, 0, 0, 0, 0, 0, 1); // 绘制红色的“太阳” glColor3f(1.0f, 0.0f, 0.0f); glutSolidSphere(69600000, 20, 20); // 绘制蓝色的“地球” glColor3f(0.0f, 0.0f, 1.0f); glRotatef(day / 360.0f * 360.0f, 0.0f, 0.0f, -1.0f); glTranslatef(150000000, 0.0f, 0.0f); glutSolidSphere(15945000, 20, 20); // 绘制黄色的“月亮” glColor3f(1.0f, 1.0f, 0.0f); glRotatef(day / 30.0f * 360.0f - day / 360.0f * 360.0f, 0.0f, 0.0f, -1.0f); glTranslatef(38000000, 0.0f, 0.0f); glutSolidSphere(4345000, 20, 20); glFlush(); glutSwapBuffers();}void myIdle(void){ /* 新的函数，在空闲时调用，作用是把日期往后移动一天并重新绘制，达到动画效果 */ ++day; if (day &gt;= 360) day = 0; glutPostRedisplay(); // 通知系统重新绘制窗口，触发显示回调函数 myDisplay()}int main(int argc, char *argv[]){ glutInit(&amp;argc, argv); glutInitDisplayMode(GLUT_RGB | GLUT_DOUBLE); glutInitWindowPosition(100, 100); glutInitWindowSize(400, 400); glutCreateWindow(&quot;太阳，地球和月亮&quot;); glutDisplayFunc(myDisplay); glutIdleFunc(myIdle); glutMainLoop(); return 0;} 1gcc -o test test.c -lm -lGL -lGLU -lglut 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192#include &lt;GL/glut.h&gt;void setLight(void){ static const GLfloat light_position[] = {1.0f, 1.0f, -1.0f, 1.0f}; static const GLfloat light_ambient[] = {0.2f, 0.2f, 0.2f, 1.0f}; static const GLfloat light_diffuse[] = {1.0f, 1.0f, 1.0f, 1.0f}; static const GLfloat light_specular[] = {1.0f, 1.0f, 1.0f, 1.0f}; glLightfv(GL_LIGHT0, GL_POSITION, light_position); glLightfv(GL_LIGHT0, GL_AMBIENT, light_ambient); glLightfv(GL_LIGHT0, GL_DIFFUSE, light_diffuse); glLightfv(GL_LIGHT0, GL_SPECULAR, light_specular); glEnable(GL_LIGHT0); glEnable(GL_LIGHTING); glEnable(GL_DEPTH_TEST);}void setMaterial(const GLfloat mat_diffuse[4], GLfloat mat_shininess){ static const GLfloat mat_specular[] = {0.0f, 0.0f, 0.0f, 1.0f}; static const GLfloat mat_emission[] = {0.0f, 0.0f, 0.0f, 1.0f}; glMaterialfv(GL_FRONT, GL_AMBIENT_AND_DIFFUSE, mat_diffuse); glMaterialfv(GL_FRONT, GL_SPECULAR, mat_specular); glMaterialfv(GL_FRONT, GL_EMISSION, mat_emission); glMaterialf(GL_FRONT, GL_SHININESS, mat_shininess);}void myDisplay(void){ // 定义一些材质颜色 const static GLfloat red_color[] = {1.0f, 0.0f, 0.0f, 1.0f}; const static GLfloat green_color[] = {0.0f, 1.0f, 0.0f, 0.3333f}; const static GLfloat blue_color[] = {0.0f, 0.0f, 1.0f, 0.5f}; // 清除屏幕 glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); // 启动混合并设置混合因子 glEnable(GL_BLEND); glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA); // 设置光源 setLight(); // 以(0, 0, 0.5)为中心，绘制一个半径为0.3的不透明红色球体（离观察者最远） setMaterial(red_color, 30.0); glPushMatrix(); glTranslatef(0.0f, 0.0f, 0.5f); glutSolidSphere(0.3, 30, 30); glPopMatrix(); // 下面将绘制半透明物体了，因此将深度缓冲设置为只读 glDepthMask(GL_FALSE); // 以(0.2, 0, -0.5)为中心，绘制一个半径为0.2的半透明蓝色球体（离观察者最近） setMaterial(blue_color, 30.0); glPushMatrix(); glTranslatef(0.2f, 0.0f, -0.5f); glutSolidSphere(0.2, 30, 30); glPopMatrix(); // 以(0.1, 0, 0)为中心，绘制一个半径为0.15的半透明绿色球体（在前两个球体之间） setMaterial(green_color, 30.0); glPushMatrix(); glTranslatef(0.1, 0, 0); glutSolidSphere(0.15, 30, 30); glPopMatrix(); // 完成半透明物体的绘制，将深度缓冲区恢复为可读可写的形式 glDepthMask(GL_TRUE); glutSwapBuffers();}int main(int argc, char** argv) { glutInit(&amp;argc, argv); glutInitDisplayMode(GLUT_RGB | GLUT_DOUBLE | GLUT_DEPTH); glutInitWindowPosition(100, 100); glutInitWindowSize(800, 600); glutCreateWindow(&quot;Transparent Objects&quot;); glClearColor(0.0f, 0.0f, 0.0f, 1.0f); glutDisplayFunc(myDisplay); glutMainLoop(); return 0;} 1gcc -o test test.c -lm -lGL -lGLU -lglut 11.opencl学习==什么是opencl？== OpenCL（Open Computing Language）是一个开放的跨平台编程框架，用于实现并行计算和通用计算任务的加速。它允许开发者利用多核 CPU、GPU、FPGA和其他加速器等异构计算资源，以高效地执行并行计算任务。 下面是对OpenCL的详细解释： 跨平台性: OpenCL是一个跨平台的编程框架，可在各种操作系统（如Windows、MacOS、Linux）和硬件平台上运行。这使得开发者可以编写与特定平台和硬件无关的并行计算代码。 异构计算: OpenCL支持异构计算，利用多种计算设备（如CPU、GPU、FPGA等）的并行计算能力。这些设备以不同的方式处理数据和执行计算任务，使得开发者能够充分利用各种硬件资源。 并行计算模型: OpenCL采用基于任务和数据并行的计算模型。开发者可以将计算任务分解为多个独立的子任务，然后并行执行这些子任务。这种并行计算模型可以在不同的设备上同时执行任务，实现高效的并行计算。 内核函数: OpenCL使用内核函数来描述并行计算任务。内核函数是程序员编写的并行计算代码，运行在OpenCL设备上的并行处理单元上。开发者可以通过编写内核函数来定义要执行的计算任务。 内存模型: OpenCL提供了全局内存、局部内存和私有内存等不同类型的内存来管理数据。全局内存对所有内核函数可见，局部内存用于共享数据和协同工作，而私有内存用于每个工作项的私有数据。开发者可以根据计算需求来选择合适的内存类型。 任务调度和并行执行: OpenCL使用工作组（work-group）和工作项（work-item）的概念来管理任务的调度和并行执行。工作组是一组相关的工作项，它们可以协同工作和共享数据。工作项是最小的并行执行单元，每个工作项独立执行内核函数。 运行时系统: OpenCL通过运行时系统来管理和调度并行计算任务。运行时系统负责加载和初始化设备驱动程序，分配和管理内存，调度并行任务的执行，以及在设备之间进行数据传输。 扩展和版本: OpenCL不断发展和更新，引入新的功能和扩展，以适应不断增长的并行计算需求。每个OpenCL版本都有其特定的功能和支持的硬件级别。 12.rga编译RGA（Raster Graphic Acceleration Unit）光栅图形加速单元是一个独立的硬件加速器，专门用于加速2D图形操作。它提供了高效的点/线绘制、图像缩放、旋转、位块传输（bitBlt）、Alpha混合等常见的2D图形操作功能。 RGA 的设计目标是通过硬件加速来提高2D图形处理的性能和效率，减轻CPU的负担。它具有独立的硬件模块，可以通过用户空间驱动程序进行访问和控制。 以下是 RGA 的主要特性和功能： 点/线绘制加速：RGA 提供了硬件加速的点和线绘制功能，可以快速绘制图形中的点和线条，提供更高的绘制性能。 图像缩放和旋转：RGA 支持硬件加速的图像缩放和旋转，可以快速执行图像的放大、缩小和旋转操作，适用于图像处理和显示应用。 位块传输（bitBlt）：RGA 提供了硬件加速的位块传输功能，可以高效地在内存之间传输图像数据，包括复制、填充和裁剪等操作。 Alpha混合：RGA 支持硬件加速的Alpha混合操作，可以实现图像的透明度混合，以实现图像叠加和特效效果。 用户空间驱动程序：RGA 提供了用户空间驱动程序，允许应用程序通过API访问和控制RGA硬件加速器。这样，开发者可以方便地利用RGA的功能来加速2D图形操作。 RGA 的优势在于它提供了高效的硬件加速，能够加速常见的2D图形操作，从而提高图形处理和显示的性能。应用程序可以通过使用RGA的用户空间驱动程序来利用这些功能，实现更快速、流畅的图形处理和显示效果。 RGA（Raster Graphic Acceleration Unit）并不是一个独立的硬件加速器。实际上，RGA是一种软件技术，也可以指代一组相关的软件库和驱动程序。 RGA是Rockchip（瑞芯微电子）公司开发的图像处理技术，主要应用于他们的系统芯片中。RGA技术在Rockchip的芯片中集成了一个专门的硬件模块，用于加速2D图形操作。这个硬件模块通常被称为RGA硬件加速器。 然而，RGA并不是像GPU（图形处理单元）这样的独立硬件设备。它是与Rockchip系统芯片集成的一部分，用于提供2D图形处理的加速功能。RGA的驱动程序和软件库允许开发者通过API来访问和利用这个硬件加速器。 因此，RGA实际上是Rockchip芯片中的一个特定功能模块，用于加速2D图形操作，并通过软件驱动程序提供对该模块的访问和控制。 rockchip 的github https://github.com/orgs/rockchip-linux/repositories?type=all rga的github https://github.com/JeffyCN/mirrors/tree/linux-rga-multi 1git clone https://github.com/Caesar-github/linux-rga.git 1docker run --privileged -it -v /home/topeet/:/home/topeet/ ubuntu20 使用以下命令构建deb包 1sudo DEB_BUILD_OPTIONS=nocheck dpkg-buildpackage -b -d -uc -us -aarm64 DEB_BUILD_OPTIONS=nocheck: 这是一个环境变量设置，指定在构建软件包时不运行自动化测试。nocheck 选项告诉构建系统跳过自动化测试阶段，以加快构建过程。 dpkg-buildpackage: 这是用于构建 Debian 软件包的工具。它会根据当前目录中的源代码和相关文件构建一个 .deb 文件。 -b: 这是一个选项，指定只构建二进制软件包，不包括源代码。 -d: 这是一个选项，告诉 dpkg-buildpackage 在构建过程中处理依赖关系。 -uc -us: 这是两个选项，用于指定在构建过程中不签名软件包。-uc 表示不对源代码包进行签名，-us 表示不对二进制软件包进行签名。 -aarm64: 这是一个选项，指定要构建的目标架构为 arm64（ARM 64位架构）。 这就编译成功了，得到了三个包。 13.mpp编译MPP（Media Processing Platform）是一种多媒体处理平台，用于实现音频和视频数据的处理、编解码和处理。MPP 提供了一组丰富的功能和算法，用于处理各种多媒体数据，并且能够在硬件加速的环境下提供高效的处理性能。 以下是 MPP 的主要作用： 视频编解码：MPP 提供了各种视频编解码器，如 H.264、H.265、MPEG-2 等。这些编解码器能够将视频数据进行压缩（编码）和解压缩（解码），以满足不同应用场景对视频数据的存储和传输需求。通过硬件加速，MPP 可以提供高效的视频编解码性能，减轻 CPU 的负担。 图像处理：MPP 包含了一系列图像处理算法，如图像缩放、旋转、裁剪、色彩空间转换等。这些算法可以对图像进行各种操作和转换，以满足不同应用场景对图像处理的需求。MPP 的硬件加速能力可以加快图像处理的速度，并提供更高的效率。 音频编解码：除了视频编解码，MPP 还提供了音频编解码的功能。它支持常见的音频编码格式，如 AAC、MP3、AC3 等。通过 MPP，可以对音频数据进行高效的压缩和解压缩，实现音频的存储、传输和处理。 多媒体处理流程管理：MPP 提供了一个统一的框架和接口，用于管理和控制多媒体处理流程。它可以对多个媒体处理单元进行调度和协调，实现复杂的多媒体处理任务。MPP 还提供了丰富的配置选项和参数设置，以满足不同应用场景的需求。 总之，MPP 是一个强大的多媒体处理平台，提供了视频编解码、图像处理、音频编解码等功能。它通过硬件加速，能够实现高效的多媒体数据处理和处理性能，满足各种应用场景对多媒体处理的需求。 https://github.com/rockchip-linux/mpp 1git clone https://github.com/rockchip-linux/mpp 1docker run --privileged -it -v /home/topeet/:/home/topeet/ ubuntu20 使用以下命令构建deb包 1sudo DEB_BUILD_OPTIONS=nocheck dpkg-buildpackage -b -d -uc -us -aarm64 14.drm-cursor编译drm-cursor 模块的作用是在 Linux 内核中管理和控制硬件光标的显示和操作。它提供了对硬件光标平面（cursor plane）的支持，允许用户在图形界面中显示和操作硬件加速的光标。 具体而言，drm-cursor 模块负责以下功能： 硬件光标位置控制：它允许用户在屏幕上drm-cursor 模块的作用是在 Linux 内核中管理和控制硬件光标的显示和操作。它提供了对硬件光标平面（cursor plane）的支持，允许用户在图形界面中显示和操作硬件加速的光标。 具体而言，drm-cursor 模块负责以下功能： 硬件光标位置控制：它允许用户在屏幕上设置光标的位置，使光标能够随着鼠标移动而移动。 硬件光标外观设置：它允许用户定义光标的外观，包括光标的形状、大小、颜色等。 硬件光标的显示和更新：它负责将光标的图像数据传递给显示硬件，以便在屏幕上显示光标。它还负责在光标位置发生变化时更新光标的显示。 硬件光标的交互响应：它监听用户的鼠标输入，并将相应的事件传递给应用程序，以实现光标的交互操作，如点击、拖动等。 通过硬件加速的光标显示和操作，drm-cursor 模块提供了更高效、更平滑和更响应的光标体验，从而提升了图形界面的用户体验。 https://github.com/JeffyCN/drm-cursor.git 1git clone https://github.com/JeffyCN/drm-cursor.git 1docker run --privileged -it -v /home/topeet/:/home/topeet/ ubuntu20 使用以下命令构建deb包 1sudo DEB_BUILD_OPTIONS=nocheck dpkg-buildpackage -b -d -uc -us -aarm64 15.mali编译https://github.com/JeffyCN/mirrors/tree/libmali 1git clone https://github.com/JeffyCN/mirrors/tree/libmali 1docker run --privileged -it -v /home/topeet/:/home/topeet/ ubuntu20 使用以下命令构建deb包 1sudo DEB_BUILD_OPTIONS=nocheck dpkg-buildpackage -b -d -uc -us -aarm64 12apt-get install pippip3 install meson==0.54.0 -i https://pypi.mirrors.ustc.edu.cn/simple/ 16.libv4l-mpp编译(目前没这个，还不需要)1git clone https://github.com/JeffyCN/libv4l-rkmpp.git 1docker run --privileged -it -v /home/topeet/:/home/topeet/ ubuntu20 1sudo DEB_BUILD_OPTIONS=nocheck dpkg-buildpackage -b -d -uc -us -aarm64 17.gst-rk编译(目前没这个，还不需要)https://github.com/JeffyCN/mirrors/tree/gstreamer-rockchip 1git clone https://github.com/JeffyCN/mirrors/tree/gstreamer-rockchip 1docker run --privileged -it -v /home/topeet/:/home/topeet/ ubuntu20 使用以下命令构建deb包 1sudo DEB_BUILD_OPTIONS=nocheck dpkg-buildpackage -b -d -uc -us -aarm64 18.xserver编译xserver这个我看瑞芯微并没有提供ubuntu20 和ubuntu22的，所以这里就使用它提供好的xserver来代替。现在就先这样了，也没有其他好办法。首先拉取提供好的源码： 1git clone https://github.com/JeffyCN/xorg-xserver.git 1 ==上面的不对，看了看瑞芯微的直播课找到了方法== 获取ubuntu的xserver源码 1apt-get source xorg-server 获取rk的xserver源码： 1git clone https://github.com/JeffyCN/xorg-xserver.git 切换版本，这里切换到1.20.11： 1git checkout remotes/origin/rockchip/debian/1.20.11 获取补丁包 1git format-patch e4f4521ca 打补丁的脚本 1234567891011121314151617181920212223242526272829303132#!/bin/bashPATCHES_DIR=&quot;$1&quot; # 补丁文件所在目录SOURCE_DIR=&quot;$2&quot; # 源码目录# 检查补丁文件目录是否存在if [ ! -d &quot;$PATCHES_DIR&quot; ]; then echo &quot;补丁文件目录不存在: $PATCHES_DIR&quot; exit 1fi# 检查源码目录是否存在if [ ! -d &quot;$SOURCE_DIR&quot; ]; then echo &quot;源码目录不存在: $SOURCE_DIR&quot; exit 1fi# 获取补丁文件列表，并按文件名排序PATCH_FILES=$(find &quot;$PATCHES_DIR&quot; -type f -name &quot;*.patch&quot; | sort)# 应用每个补丁文件到源码中for PATCH_FILE in $PATCH_FILES; do echo &quot;应用补丁文件: $PATCH_FILE&quot; patch -d &quot;$SOURCE_DIR&quot; -p1 --no-backup-if-mismatch -f &lt; &quot;$PATCH_FILE&quot; # 检查应用补丁是否成功 if [ $? -eq 0 ]; then echo &quot;补丁文件已成功应用&quot; else echo &quot;应用补丁文件时出错&quot; fidone 脚本运行如下所示： 到这里就修改完成了，然后加载docker镜像，挂载相应的目录 1docker run --privileged -it -v /home/topeet/tmp/xorg:/home/topeet/ ubuntu20 接下来修改一些版本号，首先是configure.ac，将原来的1.20.8修改为1.20.13 1sudo vim configure.ac 然后修改meson.build文件，通样修改版本号，修改完成如下图所示： 最后修改构建deb包的debain文件，其中的debian/changelog用来控制构建的名称，然后添加上下面这个，这样最后生成的就是对应名称的的包了。 123456789101112xorg-server (2:1.20.13-1ubuntu1~20.04.9) focal-security; urgency=medium * SECURITY UPDATE: OOB write in XIChangeDeviceProperty and RRChangeOutputProperty - debian/patches/CVE-2023-5367.patch: fix handling of PropModeAppend and PropModePrepend in Xi/xiproperty.c, randr/rrproperty.c. - CVE-2023-5367 * SECURITY UPDATE: Use-after-free bug in DestroyWindow - debian/patches/CVE-2023-5380.patch: reset the PointerWindows reference on screen switch in dix/enterleave.h, include/eventstr.h, mi/mipointer.c. - CVE-2023-5380 到这里就修改完成了，然后加载docker镜像，挂载相应的目录 1docker run --privileged -it -v /home/topeet/:/home/topeet/ ubuntu20 然后进行构建即可，构建完成如下所示 123sudo quilt refresh -fsudo quilt pop -a -fsudo debian/rules clean 1sudo DEB_BUILD_OPTIONS=nocheck dpkg-buildpackage -b -d -uc -us -aarm64 无论是ubuntu20还是ubutnu22应该都能以同样的方式进行构建xserver的包，安装gpu驱动之后会黑屏，这时候上面构建的deb包就需要安装了。 1sudo DEB_BUILD_OPTIONS=nocheck dpkg-buildpackage -b -d -uc -us -aarm64 自己做的deb包：1.20.13 123链接：https://pan.baidu.com/s/1237Qxwq0u7s6cJwTDF5oyQ 提取码：gh2p --来自百度网盘超级会员V6的分享 明天再做ubuntu22的 19.firefly 网址https://wiki.t-firefly.com/zh_CN/Firefly-Linux-Guide/manual_ubuntu.html#shi-pin-ying-jian-bian-jie-ma-zhi-chi 20.Rockchip Graphics介绍https://bbs.elecfans.com/jishu_2275817_1_1.html 21.ubuntu20 qt的编译docker加载镜像和源码： 1docker run --privileged -it -v /home/topeet/Linux/qt/:/home/topeet/ ubuntu20 22.开发调试流程简介 Rockchip_Developer_Guide_Third_Party_System_Adaptation_CN.pdf这个pdf文件很重要。","link":"/2023/11/14/7%20rk%20deb%E5%8C%85%E7%9A%84%E5%88%B6%E4%BD%9C/"},{"title":"PCB学习","text":"从今天开始学习一下PCB的学习，我当然也是想画一些高速PCB板子，那些8层的、10层的，但是路还很远，很长，所以慢慢的加油吧。 11月12 日，今天来学习第一部分，软件的安装，由于使用的是两层板，版本是AD19,所以这里要先进行软件的安装和设置，后续的内容，下一个星期日再见。 1 AD 19软件安装和配置123链接：https://pan.baidu.com/s/1gznZRe00REAmoUThExJrCQ 提取码：gtqh --来自百度网盘超级会员V6的分享 下载之后如下图所示： 先来安装： 这里的安装倒是没啥，换个中文然后下一步即可，等待安装完成： 然后来到License文件 将两个用于破解和验证的文件放到安装的AD目录， 然后打开AD软件，找到add licence 然后找到拷贝过去的alf文件，点击确定，破解完成如下图所示： 然后进行中文的切换，点击右上角的小齿轮，进入设置界面，如下图所示： 点击使用本地资源，如下图所示： 设置完成之后，重启ad软件即可，可以看到已经是中文了。 navigation 导航，这里可以通过原理图去寻找PCB，需要注意的是右面只是保存了元件，其他两个可能并不好用 然后是design insight，将这些全部取消勾选 然后是data 的自动保存，这里设置十分钟自动保存： 原理图中的\\代表负信号，进行勾选 PCB中的设置，这里的光标类型选择Large 90，然后文件报告忽略都打开 显示抬头颜色这里取消： 颜色选择实心覆盖： 过孔大小设置为12 和 24，并且i勾选盖油 铜皮操作，设置大小为4和5，移除死铜 保存好的ad配置网盘链接如下所示：链接：https://pan.baidu.com/s/1EKzwbSOtfkkl_NPCFTDGCw提取码：sd8a–来自百度网盘超级会员V6的分享 可以直接进行导入即可，省去了这一系列的设置，还是挺方便的。 ==11月12日 21：48学习完成，下一次学习就是下个周日了，希望不会忘记==","link":"/2023/11/12/6%20ad%E5%AD%A6%E4%B9%A0/"},{"title":"docker学习","text":"这是我学习docker的一个前提条件，在之前的一些时间，我也是简单的看了一下docker，当时我是想用docker来进行deb包的构建的，为什么想到用docker了呢，这是因为我看大佬的github和瑞芯微的指导手册里都使用的docker，其实这个就跟开发板直接编译的效果是一样的，只是docker是在本机上，所以操作更流畅一些，而且开发板的编译速度以及方便程度，是有些区别的，所以docker就出现了，再然后我发现源码的编译里也是可以用到docker的，毕竟也就仅仅是一些环境而已，所以我又萌发了用docker编译源码的想法，所以docker的学习正式开始。 弱小和无知不是生存的障碍，傲慢才是 唯有出现需求，你的目标和需求相匹配，才是学习最快速的路径。 Docker为什么出现在我看来，我不是运维人员，我是嵌入式软件工程师，现在编译一个系统，换一个开发板，他们的环境都是不一样的，这就很烦，然而docker呢就很方便的解决了依赖这些相关的问题，而且还很小，这也是我学习docker的原因。 Docker的思想来自于集装箱，集装箱解决了什么问题？在一艘大船上，可以把货物规整的摆放起来。并且各种各样的货物被集装箱标准化了，集装箱和集装箱之间不会互相影响。那么我就不需要专门运送水果的船和专门运送化学品的船了。只要这些货物在集装箱里封装的好好的，那我就可以用一艘大船把他们都运走。 Docker是基于Go语言实现的云开源项目。 Docker的主要目标是“Build，Ship and Run Any App , Anywhere”，也就是通过对应用组件的封装、分发、部署、运行等生命周期的管理，使用户的APP（可以是一个WEB应用或数据库应用等等）及其运行环境能够做到“一次封装，到处运行”。Linux 容器技术的出现就解决了这样一个问题，而 Docker 就是在它的基础上发展过来的。将应用运行在Docker 容器上面，而 Docker 容器在任何操作系统上都是一致的，这就实现了跨平台、跨服务器。只需要一次配置好环境，换到别的机子上就可以一键部署好，大大简化了操作。 虚拟机的缺点： 1、资源占用多 2、冗余步骤多 3 、启动慢 容器虚拟化技术 由于前面虚拟机存在这些缺点，Linux 发展出了另一种虚拟化技术：Linux 容器（Linux Containers，缩写为 LXC）。 Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。有了容器，就可以将软件运行所需的所有资源打包到一个隔离的容器中。容器与虚拟机不同，不需要捆绑一整套操作系统，只需要软件工作所需的库资源和设置。系统因此而变得高效轻量并保证部署在任何环境中的软件都能始终如一地运行。 比较了 Docker 和传统虚拟化方式的不同之处： 传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程； 而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。 每个容器之间互相隔离，每个容器有自己的文件系统 ，容器之间进程不会相互影响，能区分计算资源。 学习途径 Docker官网：http://www.docker.com Docker中文网站：https://www.docker-cn.com Docker Hub官网：https://hub.docker.com （仓库） 还是我那句话，只要学不死，就往死里学！ Docker安装我这里就直接使用ubuntu20 ，也就是3588的虚拟机了，我要虚拟一个ubuntu20的docker容器，这是我的第一个目的。 1.安装gcc g++相关环境 1apt-get -y install gcc g++ 确保之前的docker删除掉： 1for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done 然后设置镜像仓库 12345678910111213# Add Docker's official GPG key:sudo apt-get updatesudo apt-get install ca-certificates curl gnupgsudo install -m 0755 -d /etc/apt/keyringscurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpgsudo chmod a+r /etc/apt/keyrings/docker.gpg# Add the repository to Apt sources:echo \\ &quot;deb [arch=&quot;$(dpkg --print-architecture)&quot; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ &quot;$(. /etc/os-release &amp;&amp; echo &quot;$VERSION_CODENAME&quot;)&quot; stable&quot; | \\ sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/nullsudo apt-get update 接下来安装docker 1sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin 测试docker helloworld 1docker run hello-world 首先本地是没有docker的helloworld镜像的，所以他会首先从dockerhub拉取helloworld镜像，然后开始运行，到这里docker就安装完成了。 然后可以使用以下命令可以查看目前系统中有哪些docker镜像。 1docker ps -a 阿里云镜像加速由于国外的dockerhub太慢了。拉取一些镜像非常慢，所以就需要更换国内的源来进行加速 1、介绍：https://www.aliyun.com/product/acr 2、注册一个属于自己的阿里云账户(可复用淘宝账号) 3、进入管理控制台设置密码，开通 4、查看镜像加速器自己的 https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors 针对Docker客户端版本大于 1.10.0 的用户 您可以通过修改daemon配置文件/etc/docker/daemon.json来使用加速器 12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'{ &quot;registry-mirrors&quot;: [&quot;https://4cmfmhps.mirror.aliyuncs.com&quot;]}EOFsudo systemctl daemon-reloadsudo systemctl restart docker Docker常用命令帮助命令docker version # 显示 Docker 版本信息。 docker info # 显示 Docker 系统信息，包括镜像和容器数。 docker –help # 帮助 镜像命令docker images列出本地主机上的镜像 1docker images 123456789101112# 解释REPOSITORY 镜像的仓库源TAG 镜像的标签IMAGE ID 镜像的IDCREATED 镜像创建时间SIZE 镜像大小# 同一个仓库源可以有多个 TAG，代表这个仓库源的不同版本，我们使用REPOSITORY：TAG 定义不同的镜像，如果你不定义镜像的标签版本，docker将默认使用 lastest 镜像！# 可选项-a： 列出本地所有镜像-q： 只显示镜像id--digests： 显示镜像的摘要信息 docker search搜索镜像 1docker search mysql 123# docker search 某个镜像的名称 对应DockerHub仓库中的镜像# 可选项--filter=stars=50 ： 列出收藏数不小于指定值的镜像。 docker pull下载镜像 1docker pull mysql 1234567 # 不写tag，默认是latest sha256:61a2a33f4b8b4bc93b7b6b9e65e64044aaec594809f818aeffbff69a893d1944 #签名Status: Downloaded newer image for mysql:latestdocker.io/library/mysql:latest # 真实位置# 指定版本下载docker pull mysql:5.7 docker rmi删除镜像 1234# 删除镜像docker rmi -f 镜像id # 删除单个docker rmi -f 镜像名:tag 镜像名:tag # 删除多个docker rmi -f $(docker images -qa) # 删除全部 容器命令有镜像才能创建容器，狂神的是cenos，我这里肯定用ubuntu，线搜索一下ubuntu 然后我这里拉取ubuntu20.04的镜像： 1docker pull ubuntu:20.04 docker run新建容器并启动 12345678910111213# 命令docker run [OPTIONS] IMAGE [COMMAND][ARG...]# 常用参数说明--name=&quot;Name&quot; # 给容器指定一个名字-d # 后台方式运行容器，并返回容器的id！-i # 以交互模式运行容器，通过和 -t 一起使用-t # 给容器重新分配一个终端，通常和 -i 一起使用-P # 随机端口映射（大写）-p # 指定端口映射（小结），一般可以有四种写法ip:hostPort:containerPortip::containerPorthostPort:containerPort (常用)containerPort 先使用 docker images命令查看一下拉取的镜像 1docker images 使用ubuntu进行用交互模式启动容器，在容器内执行/bin/bash命令！ 1docker run -it ubuntu:20.04 /bin/bash ==注意，这里要添加tag标签，不然无法成功== 最后使用exit退出镜像即可。 docker ps列出所有容器 1234567# 命令docker ps [OPTIONS]# 常用参数说明-a # 列出当前所有正在运行的容器 + 历史运行过的容器-l # 显示最近创建的容器-n=? # 显示最近n个创建的容器-q # 静默模式，只显示容器编号。 exit退出容器 docker start启动容器 需要注意：==docker run用于创建和启动新的容器，并可以指定要在容器内执行的命令，而docker start仅用于启动已经存在但目前停止的容器。== docker restart 重启容器 docker stop停止容器 docker kill 强制停止容器 docker rm删除容器 其他常用命令docker run -d后台启动容器 docker logs -f -t –tail查看日志 docker top查看容器中运行的进程信息 docker inspect查看容器/镜像的元数据 docker exec -it进入正在运行的容器 docker cp从容器内拷贝文件到主机上 ==一般用的不多吧，一般都是直接卷的挂载== docker commit从容器创建一个新的镜像，类似于虚拟机的快照相关的东西，但是后面的dockerfile实现的是一个形同的目的，所以这里直接去到dockerfile 挂载卷这个方法很重要，以后的挂载构建镜像以及构系统源码进行编译都要用这个，但是后面的挂载我还不是很懂，这里后面要在看看。 DockerFiledockerfile是用来构建Docker镜像的构建文件，是由一系列命令和参数构成的脚本。 构建步骤： 1、编写DockerFile文件 2、docker build 构建镜像 3、docker run DockerFile****构建过程 基础知识： 1、每条保留字指令都必须为大写字母且后面要跟随至少一个参数 2、指令按照从上到下，顺序执行 3、# 表示注释 4、每条指令都会创建一个新的镜像层，并对镜像进行提交 流程： 1、docker从基础镜像运行一个容器 2、执行一条指令并对容器做出修改 3、执行类似 docker commit 的操作提交一个新的镜像层 4、Docker再基于刚提交的镜像运行一个新容器 5、执行dockerfile中的下一条指令直到所有指令都执行完成！ 说明： 从应用软件的角度来看，DockerFile，docker镜像与docker容器分别代表软件的三个不同阶段。 DockerFile 是软件的原材料 （代码） Docker 镜像则是软件的交付品 （.apk） Docker 容器则是软件的运行状态 （客户下载安装执行） DockerFile 面向开发，Docker镜像成为交付标准，Docker容器则涉及部署与运维，三者缺一不可！ 1234567891011121314FROM # 基础镜像，当前新镜像是基于哪个镜像的MAINTAINER # 镜像维护者的姓名混合邮箱地址RUN # 容器构建时需要运行的命令EXPOSE # 当前容器对外保留出的端口WORKDIR # 指定在创建容器后，终端默认登录的进来工作目录，一个落脚点ENV # 用来在构建镜像过程中设置环境变量ADD # 将宿主机目录下的文件拷贝进镜像且ADD命令会自动处理URL和解压tar压缩包COPY # 类似ADD，拷贝文件和目录到镜像中！VOLUME # 容器数据卷，用于数据保存和持久化工作CMD # 指定一个容器启动时要运行的命令，dockerFile中可以有多个CMD指令，但只有最后一个生效！ENTRYPOINT # 指定一个容器启动时要运行的命令！和CMD一样ONBUILD # 当构建一个被继承的DockerFile时运行命令，父镜像在被子镜像继承后，父镜像的ONBUILD被触发 编写完一个完整的dockerfile文件如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206FROM ubuntu:20.04ARG DEBIAN_FRONTEND=noninteractiveRUN apt-get update \\ &amp;&amp; apt-get install -y --no-install-recommends \\ gnupg \\ gnupg1 \\ gpgv1 \\ &amp;&amp; rm -rf /var/lib/apt/lists/*RUN dpkg --add-architecture i386RUN apt-get update \\ &amp;&amp; apt-get -y upgrade \\ &amp;&amp; apt-get install -y --no-install-recommends \\ acl \\ aptly \\ aria2 \\ bc \\ binfmt-support \\ binutils \\ bison \\ btrfs-progs \\ build-essential \\ ca-certificates \\ ccache \\ cpio \\ cryptsetup \\ cryptsetup-bin \\ curl \\ debian-archive-keyring \\ debian-keyring \\ debootstrap \\ device-tree-compiler \\ dialog \\ dosfstools \\ f2fs-tools \\ fakeroot \\ flex \\ gawk \\ git \\ imagemagick \\ kmod \\ lib32ncurses6 \\ lib32stdc++6 \\ lib32tinfo6 \\ libbison-dev \\ libc6-dev-armhf-cross \\ libc6-i386 \\ libfile-fcntllock-perl \\ libfl-dev \\ liblz4-tool \\ libncurses5-dev \\ libpython2.7-dev \\ libpython3-dev \\ libssl-dev \\ libusb-1.0-0-dev \\ linux-base \\ locales \\ lsb-release \\ lzop \\ ncurses-base \\ ncurses-term \\ nfs-kernel-server \\ ntpdate \\ p7zip-full \\ parted \\ patchutils \\ pigz \\ pixz \\ pkg-config \\ psmisc \\ pv \\ python2 \\ python3 \\ python3-dev \\ python3-distutils \\ qemu-user-static \\ rsync \\ swig \\ systemd-container \\ tzdata \\ u-boot-tools \\ udev \\ unzip \\ uuid-dev \\ wget \\ whiptail \\ xxd \\ zip \\ zlib1g-dev \\ zlib1g:i386 \\ sudo \\ vim \\ uuid \\ uuid-dev \\ zlib1g-dev \\ liblz-dev \\ liblzo2-2 \\ liblzo2-dev \\ lzop \\ git \\ curl \\ u-boot-tools \\ mtd-utils \\ openjdk-8-jdk \\ device-tree-compiler \\ gdisk \\ m4 \\ zlib1g-dev \\ git \\ gnupg \\ flex \\ bison \\ gperf \\ libsdl1.2-dev \\ libesd-java \\ squashfs-tools \\ build-essential \\ zip \\ curl \\ libncurses5-dev \\ zlib1g-dev \\ pngcrush \\ schedtool \\ libxml2 \\ libxml2-utils \\ xsltproc \\ lzop \\ libc6-dev \\ schedtool \\ g++-multilib \\ lib32z1-dev \\ lib32ncurses-dev \\ lib32readline-dev \\ gcc-multilib \\ libswitch-perl \\ libssl-dev \\ unzip \\ zip \\ liblz4-tool \\ git \\ ssh \\ make \\ gcc \\ libssl-dev \\ liblz4-tool \\ vim \\ expect \\ g++ \\ patchelf \\ chrpath \\ gawk \\ texinfo \\ chrpath \\ diffstat \\ binfmt-support \\ qemu-user-static \\ live-build \\ bison \\ flex \\ fakeroot \\ cmake \\ gcc-multilib \\ g++-multilib \\ unzip \\ device-tree-compiler \\ python3-pip \\ libncurses5-dev \\ rsync \\ subversion \\ sed \\ make \\ binutils \\ build-essential \\ gcc \\ g++ \\ wget \\ python-is-python2 \\ libncurses5 \\ bzr \\ cvs \\ git \\ mercurial \\ patch \\ gzip \\ bzip2 \\ perl \\ tar \\ cpio \\ unzip \\ rsync \\ file \\ bc \\ wget \\ qemu-user-static \\ live-build \\ android-sdk-libsparse-utils \\ android-sdk-ext4-utils \\ time \\ &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; rm -rf /usr/bin/python \\ &amp;&amp; sudo ln -s /usr/bin/python3 /usr/bin/pythonRUN locale-gen en_US.UTF-8ENV LANG='en_US.UTF-8' LANGUAGE='en_US:en' LC_ALL='en_US.UTF-8' TERM=screenWORKDIR /home/topeetENTRYPOINT [ &quot;/bin/bash&quot;] 运行构建docker的命令如下所示： 1docker build -f Dockerfile -t ubuntu20:1 . ==注意最后有个.表示当前目录~~我说呢== 然后运行： 1docker run -it ubuntu20:1 运行成功证明构建的没问题，然后打包ubuntu20： 1docker save -o image.tar.gz ubuntu20:1 r然后在其他电脑上只需要使用下面的命令加载镜像即可 1docker load -i image.tar.gz 最后测试挂载然后编译： 1docker run --privileged -it -v /home/topeet/Linux/ubuntu20_build:/home/topeet/ubuntu20_build ubuntu20:1 其中 –privileged是必须要加的，否则构建系统的时候会有权限问题。构建ubuntu20文件系统通过，没有任何问题： 然后测试编译Linux源码 1docker run --privileged -it -v /home/topeet/Linux/3588-linux:/home/topeet/3588-linux ubuntu20:1 测试没有什么问题，编译的时间太长了，晚上再测。 1docker run --privileged -it -v /home/topeet/Android/3588-android12:/home/topeet/3588-android12 ubuntu20:1","link":"/2023/11/09/5%20docker%E5%AD%A6%E4%B9%A0/"},{"title":"音视频测试","text":"1.gst-play-1.0测试1gst-play-1.0 --videosink=xvimagesink /usr/local/test.mp4 GStreamer 的 gst-play-1.0 工具会加载指定的视频文件，并使用 xvimagesink 插件将视频渲染到 X Window 系统上的显示设备上，以实现视频的播放效果。 2.mpv测试1mpv --hwdec=rkmpp --vd-lavc-software-fallback=no --vo=xv /usr/local/test.mp4 mpv 媒体播放器将使用 Rockchip MPP 硬件解码器进行硬件解码，禁用软件回退以确保只使用硬件解码，并使用 xv 视频输出插件渲染视频，以实现高性能的视频播放效果。 1mpv --hwdec=rkmpp --vo=opengl --gpu-hwdec-interop=drmprime-drm --gpu-context=x11egl /usr/local/test.mp4 mpv 媒体播放器将使用 Rockchip MPP 硬件解码器进行硬件解码，使用 OpenGL 作为视频输出，同时启用 DRM Prime 与 DRM 之间的 GPU 硬件解码器互操作性，并使用 X11 EGL 上下文进行 GPU 加速，以实现高性能的视频播放效果。 3. gst-launch-1.0 测试1GST_DEBUG=fps*:7 gst-launch-1.0 uridecodebin uri=file:///usr/local/test.mp4 ! fpsdisplaysink video-sink=xvimagesink text-overlay=false signal-fps-measurements=true GStreamer 的 gst-launch-1.0 工具将创建一个简单的流水线，其中包含 uridecodebin 元素用于解码指定的视频文件，并通过 fpsdisplaysink 元素显示视频和帧率信息。帧率信息将以调试输出的形式显示在终端上。 测试最大的帧率 1GST_DEBUG=fps*:7 gst-launch-1.0 uridecodebin uri=file:///usr/local/test.mp4 ! fpsdisplaysink video-sink=fakesink text-overlay=false signal-fps-measurements=true sync=false 1gst-launch-1.0 uridecodebin uri=file:///usr/local/test.mp4 ! xvimagesink 4.谷歌浏览器测试12echo 0x100 &gt; /sys/module/rk_vcodec/parameters/mpp_dev_debugchromium --no-sandbox file:///usr/local/test.mp4 Chromium 浏览器将在没有沙盒的情况下启动，并加载指定路径的 test.mp4 视频文件。这样，您可以在浏览器中直接播放本地视频文件。 播放视频的时候查看GPU的利用率发现明显的上升，所以判断谷歌浏览器为硬件解码。 5.摄像头测试123export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/aarch64-linux-gnu/gstreamer-1.0gst-launch-1.0 v4l2src device=/dev/video0 ! video/x-raw,format=NV12,width=1920,height=1080, framerate=30/1 ! xvimagesinkgst-launch-1.0 v4l2src device=/dev/video1 ! video/x-raw,format=NV12,width=1920,height=1080, framerate=30/1 ! xvimagesink 我发现不加上第一句的库的导入会出现发绿的情况，而且是0发绿，1没事，不加第一句的话1的颜色不太对 gst-launch-1.0 v4l2src device=/dev/video9 ! image/jpeg, width=640, height=480, framerate=30/1 ! jpegparse ! mppjpegdec ! xvimagesink sync=false 6.mpp测试首先要监控输出： 1tail -f /var/log/syslog 调用mpi_dec_test，解码视频，将h264转为yuv 1mpi_dec_test -i /oem/200frames_count.h264 -t 7 -n 250 -o /home/topeet/test.yuv -w 640 -h 480 调用mpi_enc_test，编码视频，将yuv转为h264 1mpi_enc_test -i /home/topeet/test.yuv -t 7 -n 250 -o /home/topeet/test.h264 -w 640 -h 480 -fps 25","link":"/2023/10/26/4%20%E9%9F%B3%E8%A7%86%E9%A2%91%E6%B5%8B%E8%AF%95/"},{"title":"如何构建deb包","text":"1.三个核心概念三个最核心的概念为： 上游原始代码包（upstream tarball）: 通常，人们为上游开发者（通常为第三方）编写的软件打包。 上游开发者会使用源代码归档软件或原始代码包的方式发放他们的软件。 原始代码包一般是上游制作的 .tar.gz 或 .tgz 文件，它也可能被压缩成 .tar.bz2，.tb2 或 .tar.xz 格式。原始代码包就是 Debian 构建包时使用的原材料。 源码包： 当您拥有了上游制作的原始代码包，下一步就可以制作 Debian 源码包了。 二进制包： 从源码包您可以构建 Debian 二进制包，它才是是实际上会被安装的包。 最简单的源码包由3个文件组成： 上游原始代码包，需要被重命名来符合一个特定的模式。 一个 debian 目录，带有所有上游源代码的更改记录，外加所有为 Debian 打包系统生成的所有文件。这种包拥有 .debian.tar.gz 的文件名。 一个描述文件（以 .dsc 结尾），罗列了其他两个文件。 听起来有些过于复杂，人们的第一印象是：所有东西都放在一个文件里会更简单。然而，保持上游代码包与 Debian 特定更改分离可以节省大量磁盘空间和带宽。对 Debian 来说，追踪必要的修改也更加简单。 2. deb包制作流程首先创建一个debian目录 1mkdir debian 我们需要提供不少文件，让我们按顺序来看。 2.1 debian/changelog第一个文件是 debian/changelog，这个是记录 Debian 包变化的日志文件。它无需罗列出上游代码的每一个改变，只要它能帮助用户总结这些变化即可。我们在制作第一个版本，所以这里应当什么都没有。然而，我们仍需制作一个变化日志的入口，因为打包工具会从日志里读取特定信息。最重要的是它会读取包的版本。 debian/changelog 拥有一个十分特殊的格式。最简单的创建方式就是使用 dch 工具。 12apt install devscriptsdch --create -v 1.0-1 --package hithere 会在文件中产生以下内容： 这里有很多注意点： hithere 部分必须与源代码包的名字相同。1.0-1 是版本号，1.0 部分是上游版本号。-1 部分是 Debian 的版本：它是第一个上游版本为 1.0 的 Debian 包。如果这个 Debian 包有错误，并且被修复了，那么上游版本号仍保持相同，下一个版本应当被叫做 1.0-2，接下来是 1.0-3，依此类推。 UNRELEASED 被称作上传目标。它会告诉上传工具这个二进制包应当被上传到哪里。UNRELEASED 意味着这个包还没有做好上传的准备。保持 UNRELEASED 是一个好主意，以避免您错误上传它。 目前请先忽略 urgency=medium。 (Closes：#XXXXXX) 作用在于上传包时关闭错误。这是在 Debian 中关闭错误的常用方法：当上传修复错误的包时，错误跟踪器会注意到这一点，并将错误标记为已关闭。我们可以删除 (Closes...) 位 2.2 debian/control控制文件描述代码和二进制包，并给出他们的详细信息，比如名称、包的维护者是谁，等等。下面是一个示例： 123456789101112Source: hithereMaintainer: Lars Wirzenius &lt;liw@liw.fi&gt;Section: miscPriority: optionalStandards-Version: 3.9.2Build-Depends: debhelper (&gt;= 9)Package: hithereArchitecture: anyDepends: ${shlibs:Depends}, ${misc:Depends}Description: greet user hithere greets the user, or the world. 在这个文件里有许多需求的字段，但是现在您可以像对待魔法一样对待它。那么，在 debian/control 中有两段文字。 第一段文字描述了源代码包，使用以下字段： 2.2.1 Source源代码包名。 2.2.2 Maintainer维护者的姓名和电子邮箱。 2.2.3 Priority包的重要性（’required 可选的’, ‘important 重要的’, ‘standard 标准’ 或 ‘optional’ 其中之一）。通常，包是“可选”的，除非它对于标准系统功能是“必不可少的”，即启动或网络功能。 如果包与另一个“可选”包冲突，或者它不打算用于标准桌面安装，则应该是“额外”的而不是“可选”的。 “额外”包的显着例子是调试包。 （由Sebastian Tennant添加）。 2.2.4 Build-Depends需要安装以构建程序包的程序包列表。实际使用包时有可能需要它们。 第一个之后的所有段落都描述了从此源构建的二进制包。 可以有许多从同一来源构建的二进制包; 但对于我们的例子只有一个。 我们使用这些字段： 2.2.5 Package二进制包的名称。 名称可能与源包名称不同。 2.2.6 Architecture指定二进制包预期使用的计算机体系结构：用于32位Intel CPU的i386，用于64位的amd64，用于ARM处理器的armel等等。 Debian总共可以处理大约十几种计算机体系结构，因此这种体系结构支持至关重要。 “Architecture”字段可以包含特定体系结构的名称，但通常它包含两个特殊值中的一个。 any （我们在示例中看到）意味着可以为任何体系结构构建包。 换句话说，代码是可移植的，因此它不会对硬件做太多假设。 但是，仍然需要为每个体系结构单独构建二进制包。 all 意味着相同的二进制包将适用于所有体系结构，而无需为每个体系结构单独构建。 例如，仅包含shell脚本的包将是“all”。 Shell脚本在任何地方都可以工作，不需要编译。 2.2.7 Depends为了让二进制包中程序能够正常运行，需要安装的包列表。手动列出这些依赖项是繁琐且容易出错的工作。为了能够让其工作，我们需要一个神奇的小东西 ${shlibs:Depends}。另一个神奇的东西是给 debhelper 的，它是 ${misc:Depends}。shlibs 是为了动态链接库，而 misc 是为了 debherlper 的一些工作。对于别的依赖，您可以将其手动加入到 Depends 或 Build-Depends 中。但请注意，${...} 仅在 Depends 中有效。 2.2.8 Description二进制包的完整描述。它希望对用户有所帮助。第一行用作简要概要（摘要）描述，其余部分是包的更长的描述。 命令 cme edit dpkg 提供了一个GUI能够用来编辑大多数打包文件，包括 debian/control。 请参阅使用 cme 页面管理 Debian 软件包。cme命令在 Debian 中的 cme 包中提供。您也可以使用 cme edit dpkg-control 命令仅编辑 debian/control 文件。 12345Source: linux-rockchip-5.10.110Section: kernelPriority: optionalStandards-Version: 4.6.0Build-Depends: bc, rsync, kmod, cpio, build-essential, u-boot-tools, bison, python3 | python, python-is-python3 | python-is-python2, flex | flex:native , , libssl-dev:native 2.3 debian/copyright这是一个非常重要的文件，但是现在我们将先使用一个空文件。 对于 Debian ，此文件用于跟踪有关包的合法性、版权相关信息。但是，从技术角度来看，这并不重要。目前，我们将专注于技术方面。如果有兴趣，我们可以稍后再回到 debian/copyright。 2.4 debian/rules123#!/usr/bin/make -f%: dh $@ 注意： 最后一行应当使用一个 Tab 字符进行缩进，而不使用空格。这个文件是一个 Makefile，因此 Tab 字符是 make 所期望的。 事实上 debian/rules 可能是一个相当复杂的文件。然而，在 debhelper 7 中的 dh 命令让它可以在大多数情况下变得更简单。 2.5 debian/source/format最后一个我们需要的文件是 debian/source/format，它应当包含源代码包的版本号，这里为 3.0 (quilt)。 13.0 (quilt) 3.实例制作一个包 changelog: 文件记录了deb包的作者、版本以及最后一次更新日期等信息； control: 文件记录了包名、版本号、架构、维护者及描述等信息； copyright: 文件记录了一些版权信息； postinst: 软件在进行正常目录文件拷贝到系统后需要执行的脚本。 postrm文件: 软件卸载后需要执行的脚本。 这里以昨天编译的opencv静态库和动态库为例进行deb的打包 为了不影响两个包，我这里就单独创建一个deb目录了，然后拷贝动态opencv库，拷贝完成如下所示： 然后创建DEBIAN目录，在DEBIAN目录下创建三个文件，命令如下所示： 123mkdir DEBIAN touch DEBIAN/control 但是我感觉我可以不用这些~~，我能安装上就行了，为啥还要有这些说明呢，现在还不需要呢，就先这样. 但是control这个是必须要添加的,向DEBIAN/control文件中写入以下内容 123456789Package: opencv-debVersion: 1.0.0Section: freePriority: optionalEssential: noArchitecture: arm64Maintainer: topeet &lt;topeet@topeet&gt;Provides: opencv_debDescription: opencv 4.8.0 然后使用以下命令构建deb包： 1dpkg-deb -b ../deb ../opencv_4_8.0_arm64.deb 在上一级的目录下就创建了该目录 可以使用以下命令查看deb包的内容 1dpkg -c opencv_4_8.0_arm64.deb 使用以下命令查看deb包的信息： 1dpkg --info opencv_4_8.0_arm64.deb 可以看到该包的信息就被打印了出来，也就是我们在上面填写的DEBIAN/control的内容 我现在这个包是arm64架构的，但是我想在虚拟机ubuntu上用，那我要怎么办呢，实际上是可以强制安装的，在-i参数前面加入一个–force-depends 参数： 1dpkg --force-depends -i opencv_4_8.0_arm64.deb 然鹅发现还是不行，看来这个架构问题是永远改不了的呀，伤心了 还是解包吧 1dpkg --unpack opencv_4_8.0_arm64.deb 因为体系不行解包都不行，因为这个也类似于安装 只是解压应该用这个命令 1dpkg -x opencv_4_8.0_arm64.deb opencv 这就好了，搞到这个地方应该就可以了，我认为。ok，那就先这样。","link":"/2023/10/19/14%20%E6%9E%84%E5%BB%BAdeb%E5%8C%85.md/"},{"title":"buildroot的学习","text":"buildroot官网地址：https://buildroot.org/ github链接：https://github.com/buildroot/buildroot 两个指导文档 1.拉取buildroot拉取下载buildroot 1git clone https://github.com/buildroot/buildroot 建议以普通用户来进行操作，buildroot管饭极力推荐普通用户 2.help帮助菜单所有的交互都是通过在主构建根源目录中调用make来实现的，可以通过make help来获取帮助，具体内容如下所示： 清理： clean - 删除构建生成的所有文件 distclean - 删除所有非源代码文件（包括.config文件） 构建： all - 构建整个系统 toolchain - 构建工具链 sdk - 构建可移植的SDK 配置： menuconfig - 交互式基于curses的配置工具 nconfig - 交互式基于ncurses的配置工具 xconfig - 交互式基于Qt的配置工具 gconfig - 交互式基于GTK的配置工具 oldconfig - 解决.config文件中的未解决符号 syncconfig - 与oldconfig相同，但静默执行，并更新依赖关系 olddefconfig - 与syncconfig相同，但将新符号设置为默认值 randconfig - 随机回答所有选项的新配置 defconfig - 所有选项都使用默认答案的新配置；如果在命令行上设置了BR2_DEFCONFIG，则使用其作为输入 savedefconfig - 将当前配置保存到BR2_DEFCONFIG（最小配置） ​ 上面的这两个应该是在配置里面最有用的那一个，默认情况下这个BR2_DEFCONFIG并不会被设置，所以只能是配置完成之后，第一次是一定要设置的。特殊记忆一下。 ​ update-defconfig - 与savedefconfig相同​ allyesconfig - 所有选项都接受yes答案的新配置​ allnoconfig - 所有选项都使用no答案的新配置​ alldefconfig - 所有选项都设置为默认值的新配置​ randpackageconfig - 随机回答包选项的新配置​ allyespackageconfig - 所有包选项都接受yes答案的新配置​ allnopackageconfig - 所有包选项都使用no答案的新配置 针对特定软件包： - 构建并安装及其所有依赖项 -source - 仅下载的源代码文件 1make opencv4-source ​ -extract - 提取的源代码 1make opencv4-extract ​ -patch - 对应用补丁 1make opencv4-patch -depends - 构建的依赖项 1make opencv4-depends ​ -configure - 构建到配置阶段 1make opencv4-configure ​ -build - 构建到编译阶段 1make opencv4-build ​ -show-info - 生成关于的信息，以JSON格式呈现​ -show-depends - 列出依赖的软件包​ -show-rdepends - 列出以为依赖的软件包​ -show-recursive-depends 递归列出依赖的软件包​ -show-recursive-rdepends 递归列出以为依赖的软件包​ -graph-depends - 生成依赖关系的图形​ -graph-rdepends - 生成反向依赖关系的图形​ -dirclean - 删除的构建目录​ -reconfigure - 从配置阶段重新开始构建​ -rebuild - 从编译阶段重新开始构建​ -reinstall - 从安装阶段重新开始构建 文档： manual - 构建所有格式的手册 manual-html - 构建HTML格式的手册 manual-split-html - 构建拆分的HTML格式的手册 manual-pdf - 构建PDF格式的手册 manual-text - 构建文本格式的手册 manual-epub - 构建ePub格式的手册 graph-build - 生成构建时间的图表 graph-depends - 生成依赖树的图表 graph-size - 生成文件系统大小的统计信息 list-defconfigs - 列出所有预配置的最小系统 杂项：source - 下载离线构建所需的所有源代码external-deps - 列出使用的外部软件包legal-info - 生成有关许可证合规性的信息show-info - 生成关于软件包的信息，以JSON格式呈现pkg-stats - 以JSON和HTML格式生成有关软件包的信息printvars - 导出通过VARS=…选择的内部变量show-vars - 以JSON格式呈现所有内部变量；使用VARS=…限制列表以匹配该模式 make V=0|1 - 0 =&gt; 静默构建（默认），1 =&gt; 详细构建make O=dir - 将所有输出文件定位在”dir”中，包括.config文件 有关更多详细信息，请参阅README，生成Buildroot手册或在线查阅它，网址为http://buildroot.org/docs.html","link":"/2023/10/16/2%20buildroot%E7%9A%84%E5%AD%A6%E4%B9%A0/"},{"title":"挂载镜像文件","text":"编译完成之后的镜像为ubuntu-22.04.3-preinstalled-desktop-arm64.img，这里面包括spl tpl uboot boot分区和文件系统分区，其中spl tpl uboot是通过dd命令写入的，而另外两个是创建的分区，现在我想的是挂载上这个img镜像，然后查看里面的系统，在CSDN上找到了这样一个博客 挂载img分区 首先使用fdisk命令查看img镜像分区 1fdisk ubuntu-22.04.3-preinstalled-desktop-arm64.img 分区是从32768和1081344开始的，然后，就可以挂载分区了，这里要用到offset参数： 1mount -o loop,offset=$((32768*512)) ubuntu-22.04.3-preinstalled-desktop-arm64.img 1 1mount -o loop,offset=$((61440*512)) ubuntu-22.04.3-preinstalled-desktop-arm64.img 1 1mount -o loop,offset=$((1081344*512)) ubuntu-22.04.3-preinstalled-desktop-arm64.img 2 1234567/usr/bin/make -f ./Makefile intdeb-pkg \\ KERNELRELEASE=5.10.160-rockchip \\ KDEB_PKGVERSION=5.10.160-14 \\ CROSS_COMPILE=aarch64-linux-gnu- \\ ARCH=arm64 \\ -j 32 1gzip -dc ../initrd.img | cpio -idm 1lz4 -dc ../initrd.img | cpio -idm","link":"/2023/10/08/18%20%E6%8C%82%E8%BD%BD%E9%95%9C%E5%83%8F%E6%96%87%E4%BB%B6/"},{"title":"适配瑞芯微官方SDK","text":"瑞芯微的分区表如上图所示，虽然在瑞芯微的wiki中提供了一些简单的开源介绍，但是我是没有见过的。，，很坑，所以还是以瑞芯微的开放SDK进行移植 1. miniloader瑞芯微官方miniloader路径为https://github.com/rockchip-linux/rkbin.git 首先克隆官方的rkbin，瑞芯微提供了闭源的的二进制文件 1git clone https://github.com/rockchip-linux/rkbin.git 拉取完成如下图所示： 瑞芯微的README如下所示： 123456789101112131415161718192021222324252627282930313233343536Rockchip loader binaries naming rule总则：不管单个模块，还是合并后的loader，命名都采用[chip]_[module]_[feature]_[version].[postfix]chip: 芯片或芯片系列名称, 必选项, 与所有kernel/uboot driver中的名称保持一致, 具体命名方式不在此讨论, 小写module: 模块名称, 必选项, 如loader, ddr, miniloader，usbplug,bl3x,tee,tee_ta，小写feature: 模块特征, 可选项, 可多个, 如ddr使用的频率, 或者只支持某个特定的ddr, miniloader的特别选项等, 小写version: 版本信息, 必选项, 格式采用[v1.00,], 正式发布之前为0.xx, 正式发布后为1.00以后，小写postfix: 后缀名, 必选项, 代码编译出来的默认为.bin, 也有可能为.elf, 合并后为.img，小写连接符号采用下划线“_”例如：ddr模块提供的文件rk3228_ddr3_800MHz_v1.06.bin特殊规则：1. 合并后的loader命名: loader: 由ddrbin, usbplug, miniloader合并而成可用于Windows RK升级工具使用的loader; ubootloader: 由ddrbin, usbplug, U-Boot合并而成可用于Windows RK升级工具使用的loader; idbloader: 由ddrbin, 一级loader(miniloader或uboot)按IDB格式合并直接用于烧写到IDB区的binary; 注: miniloader的命名, 仅表示miniloader工程编译输出的bin, 不再延续到合并后的loader中使用;2. 合并后的loader的version定义: vx.yy.zzzv: version的意思，一直采用这个字符，小写x.yy: ddr所提供文件的版本号，小写zzz: [1]是miniloader所提供文件的版本号，去掉点号的，小写 [2]uboot提供的版本号3. 命名小写会引起歧义的，就用大写如ddr的GB，不能写成gb举例：合并好的loader命名：rk3328_loader_v1.03.106.bin其中的1.03是ddr的版本号v1.03106是miniloader的版本号v1.06去掉点号的 接下来对这些目录的内容进行介绍 **bin/**：通常用于存放可执行文件（二进制文件） 进入该目录之后又有一系列的子目录，我们要适配的是3588，所以要进入rk35的目录，具体内容如下所示： 根据名称来看总共是有两种类型的二进制文件，分别为rkddr*的tpl 和 rk“”spl的spl，第一个用来进行初始化内存，然后加载spl，spl用来初始化时钟等其他外设，这里我们用到的应该是rk3588_ddr_lp4_2112MHz_lp5_2736MHz_v1.12.bin和rk3588_spl_v1.12.bin两二进制文件， 2.**doc/**目录，通常用于存放文档文件。在这个目录下，有着更新时候的一些说明，如下图所示： 3.img目录根3588无关不用理会。 4.LICENSE：通常用于存放软件或项目的许可证信息 5.README**：是一个简要的说明文件 6.**RKBOOT/**：它可能包含与引导（Boot）相关的文件、脚本或配置。具体内容如下所示： 这个其实是后面讲到uboot make.sh时候的说明，用来将spl和tpl整合成一个完整的miniloader的，我们要用到的是RK3588MINIALL.ini，具体内容如下所示：、 Path1=bin/rk35/rk3588_ddr_lp4_2112MHz_lp5_2736MHz_v1.12.bin FlashData=bin/rk35/rk3588_ddr_lp4_2112MHz_lp5_2736MHz_v1.12.bin FlashBoot=bin/rk35/rk3588_spl_v1.12.bin PATH=rk3588_spl_loader_v1.12.112.bin 7.RKBOOT.ini：不用管 8.**RKTRUST/**：这是一个目录，可能与 Rockchip 平台安全性（Trust）相关。根据目录名称，它可能包含与安全启动、安全引导或安全认证相关的文件、脚本或配置。 ​ 这也是一些ini文件，这是基于开源的bl31和bl32来的，上面的两个流程呀，属于第二条，闭源的miniloader属于第一条。 **scripts/**：checkpatch.sh只有这一个脚本，看了一下应该没啥用，应该是瑞芯微用于检查时候的一个脚本， 这些脚本可以用于自动化任务、配置设置、编译构建等。 **tools/**：这是一个目录，通常用于存放工具文件。工具文件可以是用于特定任务或目的的实用程序、应用程序或脚本。这些工具可以帮助你完成各种操作，如调试、分析、转换等。 ddrbin_tool_user_guide.txt 是ddrbin_tool的使用说明，倒是还挺详细，我们要改的是ddr相关的tpl，重要内容整理如下 功能 1：从 ddrbin_param.txt 修改 ddr.bin 文件。 修改 ‘ddrbin_param.txt’ 文件，设置你想要的 DDR 频率、UART 信息等。如果想保持默认值，请将这些项目留空。 运行 ‘ddrbin_tool’，并使用以下参数：参数 1 为 ddrbin_param.txt，参数 2 为 ddr.bin 文件。例如：./ddrbin_tool ddrbin_param.txt px30_ddr_333MHz_v1.13.bin 功能 2：将 ddr.bin 文件的配置保存到 gen_param.txt 文件中。如果想要获取 ddr.bin 文件的配置，请执行以下操作：./ddrbin_tool -g gen_param.txt px30_ddr_333MHz_v1.15.bin配置信息将显示在 gen_param.txt 文件中。 而我要修改的是rk3588_ddr_lp4_2112MHz_lp5_2736MHz_v1.12.bin，想用功能2 保存到 gen_param.txt 1./ddrbin_tool -g gen_param.txt rk3588_ddr_lp4_2112MHz_lp5_2736MHz_v1.12.bin 修改之后还需要重新生成bin文件 1./ddrbin_tool gen_param.txt rk3588_ddr_lp4_2112MHz_lp5_2736MHz_v1.12.bin 修改的地方只有这里的115200，其他倒是没关，然后就是看看如何整合spl和tpl了，整合成一个完整的loader.bin 这里我就不用uboot的的make.sh了，而是找到他的命令和makefile具体内容如下所示： 123456789101112131415function pack_loader_image(){ rm -f *loader*.bin *download*.bin *idblock*.img cd ${RKBIN} DEF_PATH=${RKBIN}/`filt_val &quot;^PATH&quot; ${INI_LOADER}` IDB_PATH=${RKBIN}/`filt_val &quot;IDB_PATH&quot; ${INI_LOADER}` ${SCRIPT_LOADER} --ini ${INI_LOADER} cd - if [ -f ${DEF_PATH} ]; then mv ${DEF_PATH} ./ fi if [ -f ${IDB_PATH} ]; then mv ${IDB_PATH} ./ fi} 1234567891011121314151617181920212223242526272829303132333435363738394041#!/bin/bash## Copyright (c) 2020 Rockchip Electronics Co., Ltd## SPDX-License-Identifier: GPL-2.0#set -eif [ $# -eq 0 ]; then echo &quot;ERROR: No args of $0&quot; exit 1fiwhile [ $# -gt 0 ]; do case $1 in --ini) INI=$2 shift 2 ;; *) echo &quot;ERROR: Unknown arg: $1&quot; exit 1 ;; esacdoneif [ ! -f ${INI} ]; then echo &quot;pack loader failed! Can't find: ${INI}&quot; exit 0fiCOUNT=`cat ${INI} | wc -l`if [ ${COUNT} -eq 1 ]; then IMG=`sed -n &quot;/PATH=/p&quot; ${INI} | tr -d '\\r' | cut -d '=' -f 2` cp ${IMG} ./else ./tools/boot_merger ${INI}fiecho &quot;pack loader okay! Input: ${INI}&quot; 最后用的还是boot_merger这个工具。 1./tools/boot_merger RKBOOT/RK3588MINIALL.ini 关于spl和tpl就这样了，然后是uboot 2.uboot克隆源码 1git clone https://github.com/rockchip-linux/u-boot.git 修改make menuconfig，rk3588的默认配置文件为./configs/rk3588_defconfig 123export arch=arm64make rk3588_defconfigmake menuconfig 目前只需要将这里的uboot修改为115200即可，然后重新保存configs/rk3588_defconfig，重新编译 1234export arch=arm64make rk3588_defconfigmake CROSS_COMPILE=&quot;aarch64-linux-gnu-&quot; -j32modules_install 编译完这里的uboot.img就是我们需要的镜像，不对，后来发现事情并不是想的那样，理论上应该是uboot.img这里的选择不对。所以接下来去寻找uboot.img的生成流程 实际应该是 1./make.sh rk3588 CROSS_COMPILE=aarch64-linux-gnu- 12# 编译uboot.itbmake CROSS_COMPILE=&quot;aarch64-linux-gnu-&quot; -j32 u-boot.itb 但是并没有找到源头，然后找一下make.sh的内容具体内容如下所示： 1234567891011121314151617# 打包生成uboot镜像function pack_uboot_image(){ rm u-boot.img u-boot-dtb.img -f LOAD_ADDR=`sed -n &quot;/CONFIG_SYS_TEXT_BASE=/s/CONFIG_SYS_TEXT_BASE=//p&quot; include/autoconf.mk|tr -d '\\r'` if [ -z &quot;${LOAD_ADDR}&quot; ]; then # upstream U-Boot LOAD_ADDR=`grep CONFIG_SYS_TEXT_BASE include/generated/autoconf.h | awk '{ print $3 }' | tr -d '\\r'` fi if [ -z &quot;${LOAD_ADDR}&quot; ]; then echo &quot;ERROR: No CONFIG_SYS_TEXT_BASE for u-boot&quot;; exit 1 fi ${SCRIPT_UBOOT} --load ${LOAD_ADDR} ${PLAT_UBOOT_SIZE}} SCRIPT_UBOOT=”${SRCTREE}/scripts/uboot.sh” LOAD_ADDR=0x00200000 –size 2048 1 configs/rk3588-ramboot.config:4:CONFIG_UBOOT_SIZE_KB=2048 configs/rk3588-ramboot.config:5:CONFIG_UBOOT_NUM=1 可行的代码为 1./scripts/uboot.sh --load 0x00200000 --size 2048 1 uboot.sh内容如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#!/bin/bash## Copyright (c) 2020 Rockchip Electronics Co., Ltd## SPDX-License-Identifier: GPL-2.0#set -eif [ $# -eq 0 ]; then echo &quot;ERROR: No args of $0&quot; exit 1fiwhile [ $# -gt 0 ]; do case $1 in --load) LOAD_ADDR=$2 shift 2 ;; --size) SIZE=&quot;$1 $2 $3&quot; shift 3 ;; *) echo &quot;ERROR: Unknown arg: $1&quot; exit 1 ;; esacdonerm uboot.img -fif [ -z &quot;${LOAD_ADDR}&quot; ]; then echo &quot;ERROR: No load address&quot; exit 1fiHEAD_KB=2BIN_KB=`ls -l u-boot.bin | awk '{ print $5 }'`if [ -z &quot;${SIZE}&quot; ]; then MAX_KB=1046528else MAX_KB=`echo ${SIZE} | awk '{print strtonum($2)}'` MAX_KB=$(((MAX_KB-HEAD_KB)*1024))fiif [ ${BIN_KB} -gt ${MAX_KB} ]; then echo &quot;ERROR: pack uboot failed! u-boot.bin actual: ${BIN_KB} bytes, max limit: ${MAX_KB} bytes&quot; exit 1fi../rkbin/tools/loaderimage --pack --uboot u-boot.bin uboot.img ${LOAD_ADDR} ${SIZE}echo &quot;pack uboot okay! Input: u-boot.bin&quot;echo 而实际上使用的命令是 1../rkbin/tools/loaderimage --pack --uboot u-boot.bin uboot.img 0x00200000 --size 2048 1 不知道他的源码呀~~~~，这就没意思了。。。先这样吧。 3.kernelgit拉取源码 1git clone https://github.com/rockchip-linux/kernel.git 查看全部分支，如下所示： 我直接一步到位，直接到5.10就行 1git checkout develop-5.10 然后寻找kernel的编译过程， 12345678910111213141516171819202122232425262728293031323334353637383940# 构建 Kernelbuild_kernel(){ # 检查 RK_KERNEL_DTS 和 RK_KERNEL_DEFCONFIG 配置是否存在，若不存在则返回 check_config RK_KERNEL_DTS RK_KERNEL_DEFCONFIG || return 0 echo &quot;============Start building kernel============&quot; echo &quot;TARGET_KERNEL_ARCH =$RK_KERNEL_ARCH&quot; echo &quot;TARGET_KERNEL_CONFIG =$RK_KERNEL_DEFCONFIG&quot; echo &quot;TARGET_KERNEL_DTS =$RK_KERNEL_DTS&quot; echo &quot;TARGET_KERNEL_CONFIG_FRAGMENT =$RK_KERNEL_DEFCONFIG_FRAGMENT&quot; echo &quot;==========================================&quot; # 设置交叉编译工具链 setup_cross_compile # 使用 KMAKE 构建 Kernel $KMAKE $RK_KERNEL_DEFCONFIG $RK_KERNEL_DEFCONFIG_FRAGMENT $KMAKE $RK_KERNEL_DTS.img # 检查是否存在 Kernel FIT 文件并使用 mk-fitimage.sh 创建镜像 ITS=&quot;$CHIP_DIR/$RK_KERNEL_FIT_ITS&quot; if [ -f &quot;$ITS&quot; ]; then $COMMON_DIR/mk-fitimage.sh kernel/$RK_BOOT_IMG \\ &quot;$ITS&quot; $RK_KERNEL_IMG fi # 创建链接到 rockdev 目录的 boot.img ln -rsf kernel/$RK_BOOT_IMG rockdev/boot.img # 将 boot.img 复制到 u-boot 目录下，用于安全性考虑 cp rockdev/boot.img u-boot/ # 构建检查电源域 build_check_power_domain # 完成构建流程 finish_build} 12KMAKE=&quot;make ARCH=arm64 -j32&quot; CROSS_COMPILE=aarch64-linux-gnu- make ARCH=arm64 -j32 CROSS_COMPILE=aarch64-linux-gnu- rockchip_linux_defconfig rk3588_linux.config make ARCH=arm64 -j32 CROSS_COMPILE=aarch64-linux-gnu- rk3588-evb7-lp4-v10-linux.img 编译成功，但是还需要修改波特率，要修改的设备树为rk3588-linux.dtsi 然后修改rk3588-evb7-lp4.dtsi文件，里面有PCIE相关的内容，需要disabled不然会卡在内核 反正现在的dhmi屏幕问题不大，就先这样了。 4.image首先git大佬的源码 1git clone https://github.com/Joshua-Riek/ubuntu-rockchip.git 我这里先以香橙派为例进行编译 export VENDOR=orangepi export BOARD=orangepi-5b build-u-boot.sh内容如下所示： 1234567891011121314151617181920212223242526272829303132#!/bin/bashset -eE trap 'echo Error: in $0 on line $LINENO' ERRif [ &quot;$(id -u)&quot; -ne 0 ]; then echo &quot;Please run as root&quot; exit 1ficd &quot;$(dirname -- &quot;$(readlink -f -- &quot;$0&quot;)&quot;)&quot; &amp;&amp; cd ..mkdir -p build &amp;&amp; cd buildif [[ -z ${VENDOR} ]]; then echo &quot;Error: VENDOR is not set&quot; exit 1fiif [ ! -d u-boot-&quot;${VENDOR}&quot; ]; then # shellcheck source=/dev/null source ../packages/u-boot-&quot;${VENDOR}&quot;-rk3588/debian/upstream git clone --single-branch --progress -b &quot;${BRANCH}&quot; &quot;${GIT}&quot; u-boot-&quot;${VENDOR}&quot; git -C u-boot-&quot;${VENDOR}&quot; checkout &quot;${COMMIT}&quot; cp -r ../packages/u-boot-&quot;${VENDOR}&quot;-rk3588/debian u-boot-&quot;${VENDOR}&quot;ficd u-boot-&quot;${VENDOR}&quot;# Compile u-boot into a deb packagedpkg-buildpackage -a &quot;$(cat debian/arch)&quot; -d -b -nc -ucrm -f ../*.buildinfo ../*.changes build.sh内容如下所示： 12345678910111213141516171819202122232425262728293031mkdir -p build/logsexec &gt; &gt;(tee &quot;build/logs/build-$(date +&quot;%Y%m%d%H%M%S&quot;).log&quot;) 2&gt;&amp;1if [[ ${KERNEL_ONLY} == &quot;Y&quot; ]]; then eval &quot;${DOCKER}&quot; ./scripts/build-kernel.sh exit 0fiif [[ ${UBOOT_ONLY} == &quot;Y&quot; ]]; then eval &quot;${DOCKER}&quot; ./scripts/build-u-boot.sh exit 0fiif [[ ${LAUNCHPAD} != &quot;Y&quot; ]]; then if [[ ! -e &quot;$(find build/linux-image-*.deb | sort | tail -n1)&quot; || ! -e &quot;$(find build/linux-headers-*.deb | sort | tail -n1)&quot; ]]; then eval &quot;${DOCKER}&quot; ./scripts/build-kernel.sh fifiif [[ ${LAUNCHPAD} != &quot;Y&quot; ]]; then if [[ ! -e &quot;$(find build/u-boot-&quot;${BOARD}&quot;_*.deb | sort | tail -n1)&quot; ]]; then eval &quot;${DOCKER}&quot; ./scripts/build-u-boot.sh fifieval &quot;${DOCKER}&quot; ./scripts/build-rootfs.sheval &quot;${DOCKER}&quot; ./scripts/config-image.shexit 0 boot.cmd 123456setenv bootargs &quot;console=ttyS2,115200 earlycon=uart8250,mmio32,0xff130000 root=/dev/mmcblk1p2 rw rootwait&quot;load mmc 1:1 ${fdt_addr_r} rk3588-evb7-lp4-v10-linux.dtbsetenv kernel_comp_addr_r 0x0a000000load mmc 1:1 ${kernel_addr_r} Image.gzsetenv kernel_comp_size ${filesize}booti ${kernel_addr_r} - ${fdt_addr_r} mkimage -A arm -O linux -T script -C none -a 0 -e 0 -d boot.cmd boot.scr 安装内核模块 1make ARCH=arm64 CROSS_COMPILE=&quot;aarch64-linux-gnu-&quot; INSTALL_MOD_STRIP=1 INSTALL_MOD_PATH=&quot;/home/topeet/rockchip/image/lib&quot; modules_install -j32 12find -name &quot;*ko&quot; -exec cp {} /home/topeet/rockchip/image/rootfs/lib/modules/5.10.110 \\;find -name &quot;*ko&quot; | xargs -I {} cp {} /home/topeet/rockchip/image/rootfs/lib/modules/5.10.110 制作完整的镜像 1./gen_image_generic.sh &lt;file&gt; &lt;kernel size&gt; &lt;kernel directory&gt; &lt;rootfs size&gt; &lt;rootfs image&gt; [&lt;align&gt;] 其中，&lt;file&gt;是要生成的镜像文件的名称，&lt;kernel size&gt;是内核文件系统的大小，&lt;kernel directory&gt;是包含内核文件系统内容的目录，&lt;rootfs size&gt;是根文件系统的大小，&lt;rootfs image&gt;是根文件系统的镜像文件，&lt;align&gt;是可选的对齐参数。 1./gen_image_generic.sh system.img 100 boot 7144 rootfs.img 32768 写入uboot 1sudo dd if=uboot.img of=system.img seek=64 conv=notrunc 1sudo dd if=system.img of=/dev/sdc status=progress 5.打包12345678910111213141516171819202122232425262728293031323334build_updateimg(){ IMAGE_PATH=$TOP_DIR/rockdev # 设置IMAGE_PATH变量为$TOP_DIR/rockdev，用于存储生成的镜像文件路径 PACK_TOOL_DIR=$TOP_DIR/tools/linux/Linux_Pack_Firmware # 设置PACK_TOOL_DIR变量为$TOP_DIR/tools/linux/Linux_Pack_Firmware，用于存储打包工具的路径 cd $PACK_TOOL_DIR/rockdev # 进入$PACK_TOOL_DIR/rockdev目录 if [ -f &quot;$RK_PACKAGE_FILE_AB&quot; ]; then # 如果存在$RK_PACKAGE_FILE_AB文件 build_sdcard_package # 调用build_sdcard_package函数，构建SD卡包 build_otapackage # 调用build_otapackage函数，构建OTA包 cd $PACK_TOOL_DIR/rockdev # 返回$PACK_TOOL_DIR/rockdev目录 echo &quot;Make Linux a/b update_ab.img.&quot; source_package_file_name=`ls -lh package-file | awk -F ' ' '{print $NF}'` # 获取package-file的文件名 ln -fs &quot;$RK_PACKAGE_FILE_AB&quot; package-file # 创建软链接，将$RK_PACKAGE_FILE_AB链接到package-file ./mkupdate.sh # 运行mkupdate.sh脚本，生成update.img mv update.img $IMAGE_PATH/update_ab.img # 将生成的update.img移动到$IMAGE_PATH/update_ab.img ln -fs $source_package_file_name package-file # 创建软链接，将source_package_file_name链接到package-file else echo &quot;Make update.img&quot; if [ -f &quot;$RK_PACKAGE_FILE&quot; ]; then # 如果存在$RK_PACKAGE_FILE文件 source_package_file_name=`ls -lh package-file | awk -F ' ' '{print $NF}'` # 获取package-file的文件名 ln -fs &quot;$RK_PACKAGE_FILE&quot; package-file # 创建软链接，将$RK_PACKAGE_FILE链接到package-file ./mkupdate.sh # 运行mkupdate.sh脚本，生成update.img ln -fs $source_package_file_name package-file # 创建软链接，将source_package_file_name链接到package-file else ./mkupdate.sh # 运行mkupdate.sh脚本，生成update.img fi mv update.img $IMAGE_PATH # 将生成的update.img移动到$IMAGE_PATH fi finish_build # 调用finish_build函数，进行后续的清理和处理操作} 研究了一下这个玩意，这个打包完成确实是问题不大，现在我只想知道boot.img是怎样编译出来的 boot.img kernel.img resource.img zboot.img 最后找到发现是在scripts/mkimg脚本里，里面有一个repack_boot_img的函数 12345678910111213141516171819202122232425make_boot_img(){ RAMDISK_IMG_PATH=${objtree}/ramdisk.img [ -f ${RAMDISK_IMG_PATH} ] &amp;&amp; RAMDISK_IMG=ramdisk.img &amp;&amp; RAMDISK_ARG=&quot;--ramdisk ${RAMDISK_IMG_PATH}&quot; ${srctree}/scripts/mkbootimg \\ ${KERNEL_IMAGE_ARG} \\ ${RAMDISK_ARG} \\ --second resource.img \\ -o boot.img &amp;&amp; \\ echo &quot; Image: boot.img (with Image ${RAMDISK_IMG} resource.img) is ready&quot;; echo ${KERNEL_IMAGE_ARG} \\ ${RAMDISK_ARG} \\ --second resource.img \\ -o boot.img &amp;&amp; \\ ${srctree}/scripts/mkbootimg \\ ${KERNEL_ZIMAGE_ARG} \\ ${RAMDISK_ARG} \\ --second resource.img \\ -o zboot.img &amp;&amp; \\ echo &quot; Image: zboot.img (with ${ZIMAGE} ${RAMDISK_IMG} resource.img) is ready&quot;} resource.img的由来 LOGO=logo.bmp LOGO_KERNEL=logo_kernel.bmp DTB_PATH=${objtree}/arch/arm/boot/dts/rk3588-evb7-lp4-v10-linux.dtb 12scripts/resource_tool ${DTB_PATH} ${LOGO} ${LOGO_KERNEL}scripts/resource_tool arch/arm64/boot/dts/rockchip/rk3588-evb7-lp4-v10-linux.dtb logo.bmp logo_kernel.bmp 然后可以用下面的命令解包 1scripts/resource_tool --verbose --unpack --image=resource.img 而是实际的打包其实是repack-bootimg这个脚本 12345${srctree}/scripts/mkbootimg \\ ${KERNEL_IMAGE_ARG} \\ ${RAMDISK_ARG} \\ --second resource.img \\ -o boot.img &amp;&amp; \\ 打包 1scripts/mkbootimg --kernel ./arch/arm64/boot/Image --second resource.img -o boot.img 再一绕发现是mkbootimg这个脚本，，，真的6 123456789101112$srctree/scripts/mkbootimg \\--kernel $kernel \\$SECOND \\--ramdisk $ramdisk \\$DTB \\$RECOVERY_DTBO \\--cmdline &quot;${cmdline}${extra_cmdline}&quot; \\--header_version $version \\--os_version $os_version \\--os_patch_level $os_patch_level \\--output $output 一些相关内容如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243mkbootimg命令的帮助信息，它用于创建Android引导镜像。命令的用法如下：shellCopymkbootimg [-h] [--kernel KERNEL] [--ramdisk RAMDISK] [--second SECOND] [--dtb DTB] [--recovery_dtbo RECOVERY_DTBO | --recovery_acpio RECOVERY_ACPIO] [--cmdline CMDLINE] [--vendor_cmdline VENDOR_CMDLINE] [--base BASE] [--kernel_offset KERNEL_OFFSET] [--ramdisk_offset RAMDISK_OFFSET] [--second_offset SECOND_OFFSET] [--dtb_offset DTB_OFFSET] [--os_version OS_VERSION] [--os_patch_level OS_PATCH_LEVEL] [--tags_offset TAGS_OFFSET] [--board BOARD] [--pagesize {2048,4096,8192,16384}] [--id] [--header_version HEADER_VERSION] [-o OUTPUT] [--vendor_boot VENDOR_BOOT] [--vendor_ramdisk VENDOR_RAMDISK]以下是参数的说明：-h, --help：显示帮助信息并退出。--kernel KERNEL：指定内核文件的路径。--ramdisk RAMDISK：指定ramdisk文件的路径。--second SECOND：指定第二级引导加载程序文件的路径。--dtb DTB：指定设备树二进制文件的路径。--recovery_dtbo RECOVERY_DTBO：指定恢复DTBO文件的路径。--recovery_acpio RECOVERY_ACPIO：指定恢复ACPIO文件的路径。--cmdline CMDLINE：指定传递给内核命令行的额外参数。--vendor_cmdline VENDOR_CMDLINE：包含在供应商引导中的内核命令行参数。--base BASE：指定基地址。--kernel_offset KERNEL_OFFSET：指定内核偏移量。--ramdisk_offset RAMDISK_OFFSET：指定ramdisk偏移量。--second_offset SECOND_OFFSET：指定第二级引导加载程序偏移量。--dtb_offset DTB_OFFSET：指定设备树偏移量。--os_version OS_VERSION：操作系统版本。--os_patch_level OS_PATCH_LEVEL：操作系统补丁级别。--tags_offset TAGS_OFFSET：标签偏移量。--board BOARD：板级名称。--pagesize {2048,4096,8192,16384}：页面大小。--id：在标准输出中打印图像ID。--header_version HEADER_VERSION：引导镜像头版本。-o OUTPUT, --output OUTPUT：输出文件名。--vendor_boot VENDOR_BOOT：供应商引导输出文件名。--vendor_ramdisk VENDOR_RAMDISK：指定供应商ramdisk文件的路径。","link":"/2023/09/27/17%20%E9%80%82%E9%85%8D%E7%91%9E%E8%8A%AF%E5%BE%AE%E5%AE%98%E6%96%B9SDK/"},{"title":"U-Boot编译过程浅析","text":"一、U-Boot源代码获取可以参考我之前输出的这篇文章： [RK356x] [Firefly-Linux] 10min带你获取、了解与编译U-Boot源代码 切换成linux_release_v1.2.3a版本： 12git remote updategit checkout -b rk356x/linux_release_v1.2.3a rk356x/linux_release_v1.2.3a 二、编译RK3568RK356x 配置文件查看：清除历史编译状态： 1make clean 使用 make.sh 配置 configs/rk3568_defconfig 并编译： 1./make.sh rk3568 三、编译日志分析常用编译变量说明： 命令 描述 HOSTCC PC 机 gcc 编译命令 HOSTCXX PC 机 g++ 编译命令 HOSTLD PC 机 ld 链接命令 CC 交叉工具链 gcc 编译命令 CPP 交叉工具链 gcc -E 编译命令 LD 交叉工具链 ld 链接命令 OBJCOPY 交叉工具链 objcopy 命令 OBJDUMP 交叉工具链 objdump 链接命令 DTC 设备树编译命令 dtc CHECK 执行静态检查 sparse 摘自顶层Makefile： 注意：上图中的cc与gcc是同一个东西！ 编译日志主要分成以下几部分： 配置文件生成 工具目录编译 U-Boot核心代码交叉编译 U-Boot目标文件生成 设备树编译并追加到U-Boot目标文件 TPL与SPL代码编译 TPL与SPL目标文件生成 最终固件打包 3.1 配置文件生成执行make rk3568_defconfig -j8命令，生成.config：执行scripts/kconfig/conf --silentoldconfig Kconfig，这个话主要是检查是否有新的配置项，这里是清除历史输出文件后进行编译，因此所有配置项都认为是新的！ 在这个过程根据config.h文件配置u-boot.cfg、spl/u-boot.cfg、 /u-boot.cfg等文件，然后产生了各自的autoconf.mk文件。编译sam-offsets.s产生u-boot.lds链接脚本。 另外include/generated/version_autogenerated.h是描述版本信息的头文件。 3.2 工具目录编译对tools下的工具进行一系列编译： 3.3 U-Boot核心代码交叉编译编译完成tools目录后，开始交叉编译核心代码，我们会看到有非常多build-in.o，这个输出文件很有意思，它是该文件所处目录所有*.o文件的集合体，例如arch/arm/cpu/built-in.o，那它就是arch/arm/cpu/目录所有*.o文件的集合体！ 核心代码的编译过程主要涉及arch架构代码目录、common通用目录、cmd命令目录与driver驱动目录，当然还有lib公共库目录与examles例程目录，注意这个编译过程不是按照顺序编译打印的，这个因为前面使用-j8编译选项，这个选项的意思是打开8个线程并发编译： 3.4 U-Boot目标文件生成核心代码交叉编译完毕后链接之前所有的built-in.o文件，通过objcopy命令生成u-boot-nodtb.bin文件与u-boot.sym符号表，并且使用relocate-rela工具对u-boot-nodtb.bin静态reloc（静态rela.dyn修复）： 3.5 设备树编译并追加到U-Boot目标文件接下来是编译设备树dts，并且产生dt.dtb（u-boot设备树dtb文件）、dt-spl.dtb（spl设备树dtb文件）、dt-tpl.dtb（tpl设备树dtb文件），并且把dtb文件追加到u-boot文件生成u-boot.bin文件： 3.6 TPL与SPL代码编译spl是初始化DDR内存使用的，而spl相当于一个精简版u-boot，，只不过它的目的是加载u-boot固件，它们编译套路与U-Boot核心代码类似，注意的是它会把编译生成的*.o搬到tpl、spl目录，tpl、spl目录树的排布与U-Boot目录树一样： 3.7 TPL与SPL目标文件生成u-boot-spl.lds是spl的链接脚本，u-boot-spl.dtb是spl的设备树dtb文件： u-boot-spl-nodtb.bin是spl目标文件，同样地把设备树dtb文件追加进去并产生u-boot-spl.bin文件：u-boot-tpl-nodtb.bin是tpl目标文件，注意这里直接复制成u-boot-tpl.bin（没有追加设备树dtb文件）： 还有一点需要注意的是，u-boot-tpl.bin是不能烧录进RK356x的，这是因为tpl相关代码，RK官方并没有开源！我们需要使用rkbin的ddr.bin文件替换！ 3.8 最终固件打包首先通过rkbin/RKTRUST/RK3568TRUST.ini文件描述的内容把u-boot.bin打包成u-boot.itb，紧接着根据 FIT 描述文件的内容把 ATF、OP-TEE、U-Boot、MCU 打包到一起（当然也包括设备树 DTB）： 最后生成的固件为uboot.img，并且根据rkbin/RKBOOT/RK3568MINIALL.ini文件生成rk356x_spl_loader_v1.12.112.bin（注意这里并没有打包我们编译产生的u-boot-spl.bin文件，而是打包存放于rkbin目录下的spl.bin文件）","link":"/2023/09/10/15%20U-Boot%E7%BC%96%E8%AF%91%E8%BF%87%E7%A8%8B%E6%B5%85%E6%9E%90/"},{"title":"bootloader引导流程","text":"一、RK芯片通用引导流程对于RK芯片的引导流程，我们可以参考以下这张图： 根据两种Boot Flow，我们可以一次梳理两种不同的引导流程： 12Boot Code -&gt; idbloader.img(miniloader) -&gt; uboot.img -&gt; boot.img -&gt; rootfs.imgBoot Code -&gt; idbloader.img(TPL/SPL) -&gt; uboot.itb -&gt; boot.img -&gt; rootfs.img 对于idbloader.img，我们会发现有相似的地方： 12ddr.bin &lt;-&gt; u-boot-tpl.binrkxx_miniloader_vx.xx.bin &lt;-&gt; u-boot-spl.bin 此时我们会问，为什么会有两套引导流程？ 事实上idbloader.img(miniloader)这套引导方案是RK定制的，它们并没有开源的，RK发布的是二进制文件，它们都存放于rkbin目录下，例如RK356x： 注意上图中红方框处：rk3588_spl_v1.11.bin实际上指的是rkxx_miniloader_vx.xx.bin`！ 二、RK356x引导流程下面通过RK356x的启动日志进行简要分析！ 2.1 ddr.bin运行RK3588上电后，我们看到的第一阶段日志是关于DDR的，这主要是对DDR进行初始化，我们看到使用的是LPDDR4，频率逐步从528MHz 切换到2112MHz，并且进行一些读写训练操作 12345678910111213141516DDR Version V1.08 20220617LPDDR4X, 2112MHzchannel[0] BW=16 Col=10 Bk=8 CS0 Row=16 CS=1 Die BW=16 Size=1024MBchannel[1] BW=16 Col=10 Bk=8 CS0 Row=16 CS=1 Die BW=16 Size=1024MBchannel[2] BW=16 Col=10 Bk=8 CS0 Row=16 CS=1 Die BW=16 Size=1024MBchannel[3] BW=16 Col=10 Bk=8 CS0 Row=16 CS=1 Die BW=16 Size=1024MBManufacturer ID:0x1 SamsungCH0 RX Vref:33.7%, TX Vref:21.8%,0.0%CH1 RX Vref:32.7%, TX Vref:18.8%,0.0%CH2 RX Vref:30.7%, TX Vref:17.8%,0.0%CH3 RX Vref:34.7%, TX Vref:18.8%,0.0%change to F1: 528MHzchange to F2: 1068MHzchange to F3: 1560MHzchange to F0: 2112MHzout 2.2 spl.bin运行​ 接下来我们会看到SPL的板级初始化，紧接着逐步从MMC2（SD卡）、MMC1（eMMC）寻找U-boot.img（包括atf-1、uboot、fdt、atf-2、atf-3、atf-4、atf-5、optee），通过atf-1来运行uboot： 12345678910111213U-Boot SPL board initU-Boot SPL 2017.09-orangepi (Apr 21 2023 - 10:35:39)Trying to boot from MMC1Trying fit image at 0x4000 sector## Verified-boot: 0## Checking atf-1 0x00040000 ... sha256(806278dba1...) + OK## Checking uboot 0x00200000 ... sha256(a14cd96f5d...) + OK## Checking fdt 0x00349350 ... sha256(cf0060a3cf...) + OK## Checking atf-2 0x000f0000 ... sha256(c00c7fd75b...) + OK## Checking atf-3 0xff100000 ... sha256(71c3a5841b...) + OK## Checking atf-4 0xff001000 ... sha256(2301cf73be...) + OKJumping to U-Boot(0x00200000) via ARM Trusted Firmware(0x00040000)Total: 209.584 ms 注意atf-*与optee这些是 ARM trust 固件，属于另外一个领域，有兴趣可以参考以下文章： https://blog.csdn.net/Neutionwei/article/details/111395775https://blog.csdn.net/Neutionwei/article/det 2.3 atf运行运行BL31，初始化与运行BL32： 123456789101112131415161718192021INFO: Preloader serial: 2NOTICE: BL31: v2.3():v2.3-405-gb52c2eadd:derrick.huangNOTICE: BL31: Built : 11:23:47, Aug 15 2022INFO: spec: 0x13INFO: ext 32k is validINFO: GICv3 without legacy support detected.INFO: ARM GICv3 driver initialized in EL3INFO: system boots from cpu-hwid-0INFO: idle_st=0x21fff, pd_st=0x11fff9, repair_st=0xfff70001INFO: dfs DDR fsp_params[0].freq_mhz= 2112MHzINFO: dfs DDR fsp_params[1].freq_mhz= 528MHzINFO: dfs DDR fsp_params[2].freq_mhz= 1068MHzINFO: dfs DDR fsp_params[3].freq_mhz= 1560MHzINFO: BL31: Initialising Exception Handling FrameworkINFO: BL31: Initializing runtime servicesWARNING: No OPTEE provided by BL2 boot loader, Booting device without OPTEE initialization. SMC`s destined for OPTEE will return SMC_UNKERROR: Error initializing runtime service opteed_fastINFO: BL31: Preparing for EL3 exit to normal worldINFO: Entry point address = 0x200000INFO: SPSR = 0x3c9 2.4 uboot运行2.4.1 设备环境初始化从atf切换到uboot之后，uboot依次执行以下操作： 打印一些必要的信息：板型、串口、内存、系统内存初始化、代码重定位情况； 获取MMC存储器信息，打印当前启动的存储器（atags）； 获取存储器分区情况并加载内核设备树； 初始化I2C0、初始化PMIC电源芯片、相关芯片供电电压与IO电源域； 初始化DRM框架以及显示器接口（HDMI）; 初始化时钟树。 12345678910111213141516171819202122232425262728293031323334353637U-Boot 2017.09-orangepi (Apr 21 2023 - 10:35:39 +0800)Model: Orange Pi 5BPreSerial: 2, raw, 0xfeb50000DRAM: 3.7 GiBSysmem: initRelocation Offset: eda2d000Relocation fdt: eb9f9008 - eb9fecb8CR: M/C/IUsing default environmentmmc@fe2c0000: 0, mmc@fe2e0000: 1Bootdev(atags): mmc 0MMC0: Legacy, 52MhzPartType: EFIDM: v2boot mode: NoneModel: Orange Pi 5BCLK: (sync kernel. arm: enter 1008000 KHz, init 1008000 KHz, kernel 0N/A) b0pll 24000 KHz b1pll 24000 KHz lpll 24000 KHz v0pll 24000 KHz aupll 24000 KHz cpll 1500000 KHz gpll 1188000 KHz npll 24000 KHz ppll 1100000 KHz aclk_center_root 702000 KHz pclk_center_root 100000 KHz hclk_center_root 396000 KHz aclk_center_low_root 500000 KHz aclk_top_root 750000 KHz pclk_top_root 100000 KHz aclk_low_top_root 396000 KHzNet: No ethernet found. 2.4.2 内核的加载1234567891011121314151617181920212223242526272829303132333435363738394041switch to partitions #0, OKmmc0 is current devicemmc@fe2c0000: 0 (SD)mmc@fe2e0000: 1switch to partitions #0, OKmmc0 is current deviceScanning mmc 0:1...Found U-Boot script /boot.scrreading /boot.scr3411 bytes read in 4 ms (832 KiB/s)## Executing script at 00500000Boot script loaded from mmc 0reading /orangepiEnv.txt222 bytes read in 3 ms (72.3 KiB/s)reading /uInitrd18641659 bytes read in 1844 ms (9.6 MiB/s)reading /Image34736640 bytes read in 3049 ms (10.9 MiB/s)reading /dtb/rockchip/rk3588s-orangepi-5b.dtb233728 bytes read in 24 ms (9.3 MiB/s)reading /dtb/rockchip/overlay/rk3588-fixup.scr2756 bytes read in 6 ms (448.2 KiB/s)Applying kernel provided DT fixup script (rk3588-fixup.scr)## Executing script at 09000000Fdt Ramdisk skip relocation## Loading init Ramdisk from Legacy Image at 0a200000 ... Image Name: uInitrd Image Type: AArch64 Linux RAMDisk Image (gzip compressed) Data Size: 18641595 Bytes = 17.8 MiB Load Address: 00000000 Entry Point: 00000000 Verifying Checksum ... OK## Flattened Device Tree blob at 0x0a100000 Booting using the fdt blob at 0x0a100000 reserving fdt memory region: addr=a100000 size=9f000 'reserved-memory' ramoops@110000: addr=110000 size=f0000 Using Device Tree in place at 000000000a100000, end 000000000a1a1fffAdding bank: 0x00200000 - 0xf0000000 (size: 0xefe00000)Total: 5283.754 msStarting kernel ... 从Starting kernel ...开始，uboot的生命周期结束，之后产生的打印是由内核产生的！ 值得注意的是，加载Flat Device Tree设备树之后，日志还打印了相关映像加载情况，这部分非常有用，我们以后再深入分析！ 三、BootRom阶段做了什么？BootRom固件是Rockchip原厂芯片出厂时烧录到内部存储器的，目的是从各个外部存储媒介中加载miniloader(tpl + spl)！ 以下是摘自《Rockchip RK3568 TRM Part1 V1.1-20210301》，它很清晰地说明了BootRom阶段做了什么事情： 我们按照正常引导走一遍： 从0x0000FFFF地址读取第一条指令运行； 逐一检查与校验Nor Flash、Nand Flash、eMMC、SD/MMC中的ID BLOCK（RK 固件定义在第 64 扇区）； 假如我们的固件存放于eMMC，那么校验ID BLOCK成功后就读取DDR初始化代码到SYSTEM_SRAM； 紧接着运行刚刚读取的代码来初始化DDR； 初始化DDR后DDR就可以工作了，把引导代码加载到DDR并调到DDR继续运行。 如果各个存储器都没有找到ID BLOCK，那么会执行以下操作： 等待请求DDR程序（即在RKDevTool工具可以看到处于Maskrom模式）： 四、RK固件在存储器中是如何分布的？如下图，其中 RK356x和rk3588 是没有使用 trust分区，这个要注意： 另外要注意的是从loader2分区开始所有的分区大小与起始地址是由parameter.txt文件进行描述，具体参考： https://blog.csdn.net/Neutionwei/article/details/122911086","link":"/2023/09/10/13%20bootloader%E5%BC%95%E5%AF%BC%E6%B5%81%E7%A8%8B/"},{"title":"瑞芯微build-sh脚本分析","text":"build.sh脚本内容如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210310410510610710810911011111211311411511611711811912012112212312412512612712812913013113213313413513613713813914014114214314414514614714814915015115215315415515615715815916016116216316416516616716816917017117217317417517617717817918018118218318418518618718818919019119219319419519619719819920020120220320420520620720820921021121221321421521621721821922022122222322422522622722822923023123223323423523623723823924024124224324424524624724824925025125225325425525625725825926026126226326426526626726826927027127227327427527627727827928028128228328428528628728828929029129229329429529629729829930030130230330430530630730830931031131231331431531631731831932032132232332432532632732832933033133233333433533633733833934034134234334434534634734834935035135235335435535635735835936036136236336436536636736836937037137237337437537637737837938038138238338438538638738838939039139239339439539639739839940040140240340440540640740840941041141241341441541641741841942042142242342442542642742842943043143243343443543643743843944044144244344444544644744844945045145245345445545645745845946046146246346446546646746846947047147247347447547647747847948048148248348448548648748848949049149249349449549649749849950050150250350450550650750850951051151251351451551651751851952052152252352452552652752852953053153253353453553653753853954054154254354454554654754854955055155255355455555655755855956056156256356456556656756856957057157257357457557657757857958058158258358458558658758858959059159259359459559659759859960060160260360460560660760860961061161261361461561661761861962062162262362462562662762862963063163263363463563663763863964064164264364464564664764864965065165265365465565665765865966066166266366466566666766866967067167267367467567667767867968068168268368468568668768868969069169269369469569669769869970070170270370470570670770870971071171271371471571671771871972072172272372472572672772872973073173273373473573673773873974074174274374474574674774874975075175275375475575675775875976076176276376476576676776876977077177277377477577677777877978078178278378478578678778878979079179279379479579679779879980080180280380480580680780880981081181281381481581681781881982082182282382482582682782882983083183283383483583683783883984084184284384484584684784884985085185285385485585685785885986086186286386486586686786886987087187287387487587687787887988088188288388488588688788888989089189289389489589689789889990090190290390490590690790890991091191291391491591691791891992092192292392492592692792892993093193293393493593693793893994094194294394494594694794894995095195295395495595695795895996096196296396496596696796896997097197297397497597697797897998098198298398498598698798898999099199299399499599699799899910001001100210031004100510061007100810091010101110121013101410151016101710181019102010211022102310241025102610271028102910301031103210331034103510361037103810391040104110421043104410451046104710481049105010511052105310541055105610571058105910601061106210631064106510661067106810691070107110721073107410751076107710781079108010811082108310841085108610871088108910901091109210931094109510961097109810991100110111021103110411051106110711081109111011111112111311141115111611171118111911201121112211231124112511261127112811291130113111321133113411351136113711381139114011411142114311441145114611471148114911501151115211531154115511561157115811591160116111621163116411651166116711681169117011711172117311741175117611771178117911801181118211831184118511861187118811891190119111921193119411951196119711981199120012011202120312041205120612071208120912101211121212131214121512161217121812191220122112221223122412251226122712281229123012311232123312341235123612371238123912401241124212431244124512461247124812491250125112521253125412551256125712581259126012611262126312641265126612671268126912701271127212731274127512761277127812791280128112821283128412851286128712881289129012911292129312941295129612971298129913001301130213031304130513061307130813091310131113121313131413151316131713181319132013211322132313241325132613271328132913301331133213331334133513361337133813391340134113421343134413451346134713481349135013511352135313541355135613571358135913601361136213631364136513661367136813691370137113721373137413751376137713781379138013811382138313841385138613871388138913901391139213931394139513961397139813991400140114021403140414051406140714081409141014111412141314141415141614171418141914201421142214231424142514261427142814291430143114321433143414351436143714381439144014411442144314441445144614471448144914501451145214531454145514561457145814591460146114621463146414651466146714681469147014711472147314741475147614771478147914801481148214831484148514861487148814891490149114921493149414951496149714981499150015011502150315041505150615071508150915101511151215131514151515161517151815191520152115221523152415251526152715281529153015311532153315341535153615371538153915401541154215431544154515461547154815491550155115521553155415551556155715581559156015611562156315641565156615671568156915701571157215731574157515761577157815791580158115821583158415851586158715881589159015911592159315941595159615971598159916001601160216031604160516061607160816091610161116121613161416151616161716181619162016211622162316241625162616271628162916301631163216331634163516361637163816391640164116421643164416451646164716481649165016511652165316541655165616571658165916601661166216631664166516661667166816691670167116721673167416751676167716781679168016811682168316841685168616871688168916901691169216931694169516961697169816991700170117021703170417051706170717081709171017111712171317141715171617171718171917201721172217231724172517261727172817291730173117321733173417351736173717381739174017411742174317441745174617471748174917501751175217531754175517561757175817591760176117621763176417651766176717681769177017711772177317741775#!/bin/bash# 设置环境变量 LC_ALL，用于定义程序的本地化设置# 将 LC_ALL 设置为 C，表示使用标准的C语言环境，忽略本地化设置export LC_ALL=C# 设置环境变量 LD_LIBRARY_PATH，用于指定动态链接库的搜索路径# 将 LD_LIBRARY_PATH 设置为空，表示清空动态链接库搜索路径export LD_LIBRARY_PATH=# 错误处理函数err_handler(){ ret=$? [ &quot;$ret&quot; -eq 0 ] &amp;&amp; return # 打印错误信息 echo &quot;ERROR: Running ${FUNCNAME[1]} failed!&quot; echo &quot;ERROR: exit code $ret from line ${BASH_LINENO[0]}:&quot; echo &quot; $BASH_COMMAND&quot; # 退出脚本 exit $ret}# 设置错误处理函数为 trap 的处理程序，当发生错误时调用 err_handler() 函数trap 'err_handler' ERR# 设置 shell 的错误处理行为set -eE# 完成构建操作finish_build(){ echo &quot;Running ${FUNCNAME[1]} succeeded.&quot; # 切换到顶级目录 cd $TOP_DIR}# 检查配置函数check_config(){ # 清除变量 missing unset missing # 遍历传入的参数列表 for var in $@; do # 使用 eval 检查变量是否存在值，如果存在则跳过 eval [ \\$$var ] &amp;&amp; continue # 将缺失的配置变量记录到 missing 变量中 missing=&quot;$missing $var&quot; done # 如果所有配置变量均存在值，则返回0表示检查通过 [ -z &quot;$missing&quot; ] &amp;&amp; return 0 # 如果存在缺失的配置变量，则输出错误信息并返回1 echo &quot;Skipping ${FUNCNAME[1]} for missing configs: $missing.&quot; return 1}# 选择板卡函数choose_board(){ # 获取板卡配置文件列表到 BOARD_ARRAY 数组 BOARD_ARRAY=( $(cd ${CHIP_DIR}/; ls BoardConfig*.mk | sort) ) # 获取板卡数组的长度 RK_TARGET_BOARD_ARRAY_LEN=${#BOARD_ARRAY[@]} # 如果板卡数组长度为0，则表示没有可用的板卡配置文件，输出错误信息并返回-1 if [ $RK_TARGET_BOARD_ARRAY_LEN -eq 0 ]; then echo &quot;No available Board Config&quot; return -1 fi echo echo &quot;You're building on Linux&quot; echo &quot;Lunch menu...pick a combo:&quot; echo &quot;&quot; # 输出可用的板卡配置文件列表 echo &quot;0. default BoardConfig.mk&quot; echo ${BOARD_ARRAY[@]} | xargs -n 1 | sed &quot;=&quot; | sed &quot;N;s/\\n/. /&quot; local INDEX read -p &quot;Which would you like? [0]: &quot; INDEX INDEX=$((${INDEX:-0} - 1)) # 根据用户选择的索引确定所选的板卡配置文件 if echo $INDEX | grep -vq [^0-9]; then BOARD=&quot;${BOARD_ARRAY[$INDEX]}&quot; else echo &quot;Lunching for Default BoardConfig.mk boards...&quot; BOARD=BoardConfig.mk fi # 创建符号链接，将所选的板卡配置文件链接到 BOARD_CONFIG 变量指定的路径 ln -rsf &quot;$CHIP_DIR/$BOARD&quot; &quot;$BOARD_CONFIG&quot; echo &quot;switching to board: $(realpath $BOARD_CONFIG)&quot;}# 获取当前脚本所在目录的绝对路径，并赋值给 COMMON_DIR 变量COMMON_DIR=&quot;$(dirname &quot;$(realpath &quot;$0&quot;)&quot;)&quot;# 根据 COMMON_DIR 计算出顶级目录的绝对路径，并赋值给 TOP_DIR 变量TOP_DIR=&quot;$(realpath &quot;$COMMON_DIR/../../..&quot;)&quot;# 切换到顶级目录cd &quot;$TOP_DIR&quot;# 创建 rockdev 目录（如果不存在）mkdir -p rockdev# 设置 BOARD_CONFIG 变量为顶级目录下的 device/rockchip/.BoardConfig.mk 文件的绝对路径BOARD_CONFIG=&quot;$TOP_DIR/device/rockchip/.BoardConfig.mk&quot;# 获取 CHIP_DIR 变量的绝对路径，该变量指向顶级目录下的 device/rockchip/.target_product 目录CHIP_DIR=&quot;$(realpath $TOP_DIR/device/rockchip/.target_product)&quot;# 预构建 U-Boot 函数prebuild_uboot(){ # 构建 U-Boot 的编译命令字符串 UBOOT_COMPILE_COMMANDS=&quot;\\ ${RK_TRUST_INI_CONFIG:+../rkbin/RKTRUST/$RK_TRUST_INI_CONFIG} \\ ${RK_SPL_INI_CONFIG:+../rkbin/RKBOOT/$RK_SPL_INI_CONFIG} \\ ${RK_UBOOT_SIZE_CONFIG:+--sz-uboot $RK_UBOOT_SIZE_CONFIG} \\ ${RK_TRUST_SIZE_CONFIG:+--sz-trust $RK_TRUST_SIZE_CONFIG}&quot; UBOOT_COMPILE_COMMANDS=&quot;$(echo $UBOOT_COMPILE_COMMANDS)&quot; # 如果启用 RAMDISK 安全启动，则添加相关的编译命令选项 if [ &quot;$RK_RAMDISK_SECURITY_BOOTUP&quot; = &quot;true&quot; ];then UBOOT_COMPILE_COMMANDS=&quot; \\ $UBOOT_COMPILE_COMMANDS \\ ${RK_ROLLBACK_INDEX_BOOT:+--rollback-index-boot $RK_ROLLBACK_INDEX_BOOT} \\ ${RK_ROLLBACK_INDEX_UBOOT:+--rollback-index-uboot $RK_ROLLBACK_INDEX_UBOOT} &quot; fi}# 预构建安全启动的 U-Boot 函数prebuild_security_uboot(){ # 获取传入的模式参数 local mode=$1 # 如果启用 RAMDISK 安全启动，则添加相关的编译命令选项 if [ &quot;$RK_RAMDISK_SECURITY_BOOTUP&quot; = &quot;true&quot; ];then # 如果 RK_SECURITY_OTP_DEBUG 不等于 &quot;true&quot;，则添加 --burn-key-hash 选项 if [ &quot;$RK_SECURITY_OTP_DEBUG&quot; != &quot;true&quot; ]; then UBOOT_COMPILE_COMMANDS=&quot;$UBOOT_COMPILE_COMMANDS --burn-key-hash&quot; fi # 根据传入的模式参数进行不同的处理 case &quot;${mode:-normal}&quot; in # 对于 uboot 模式，不需要额外的处理 uboot) ;; # 对于 boot 模式，添加 --boot_img 选项，并设置值为 $TOP_DIR/u-boot/boot.img boot) UBOOT_COMPILE_COMMANDS=&quot; \\ --boot_img $TOP_DIR/u-boot/boot.img \\ $UBOOT_COMPILE_COMMANDS &quot; ;; # 对于 recovery 模式，添加 --recovery_img 选项，并设置值为 $TOP_DIR/u-boot/recovery.img recovery) UBOOT_COMPILE_COMMANDS=&quot; \\ --recovery_img $TOP_DIR/u-boot/recovery.img $UBOOT_COMPILE_COMMANDS &quot; ;; *) # 对于其他模式，默认添加 --boot_img 选项，并设置值为 $TOP_DIR/u-boot/boot.img UBOOT_COMPILE_COMMANDS=&quot; \\ --boot_img $TOP_DIR/u-boot/boot.img \\ $UBOOT_COMPILE_COMMANDS &quot; # 如果 RK_PACKAGE_FILE_AB 为空，则添加 --recovery_img 选项，并设置值为 $TOP_DIR/u-boot/recovery.img test -z &quot;${RK_PACKAGE_FILE_AB}&quot; &amp;&amp; \\ UBOOT_COMPILE_COMMANDS=&quot;$UBOOT_COMPILE_COMMANDS --recovery_img $TOP_DIR/u-boot/recovery.img&quot; ;; esac # 使用 echo 命令重新赋值 UBOOT_COMPILE_COMMANDS 变量，去除多余空格 UBOOT_COMPILE_COMMANDS=&quot;$(echo $UBOOT_COMPILE_COMMANDS)&quot; fi}# 用法函数，打印脚本的使用说明usage(){ # 打印使用说明 echo &quot;Usage: build.sh [OPTIONS]&quot; echo &quot;Available options:&quot; echo &quot;BoardConfig*.mk -switch to specified board config&quot; echo &quot;lunch -list current SDK boards and switch to specified board config&quot; echo &quot;wifibt -build wifibt&quot; echo &quot;uboot -build uboot&quot; echo &quot;uefi -build uefi&quot; echo &quot;spl -build spl&quot; echo &quot;loader -build loader&quot; echo &quot;kernel-4.4 -build kernel 4.4&quot; echo &quot;kernel-4.19 -build kernel 4.19&quot; echo &quot;kernel-5.10 -build kernel 5.10&quot; echo &quot;kernel -build kernel&quot; echo &quot;modules -build kernel modules&quot; echo &quot;rootfs -build rootfs (default is buildroot)&quot; echo &quot;buildroot -build buildroot rootfs&quot; echo &quot;yocto -build yocto rootfs&quot; echo &quot;debian -build debian rootfs&quot; echo &quot;pcba -build pcba&quot; echo &quot;recovery -build recovery&quot; echo &quot;all -build uboot, kernel, rootfs, recovery image&quot; echo &quot;cleanall -clean uboot, kernel, rootfs, recovery&quot; echo &quot;firmware -pack all the image we need to boot up system&quot; echo &quot;updateimg -pack update image&quot; echo &quot;otapackage -pack ab update otapackage image (update_ota.img)&quot; echo &quot;sdpackage -pack update sdcard package image (update_sdcard.img)&quot; echo &quot;save -save images, patches, commands used to debug&quot; echo &quot;allsave -build all &amp; firmware &amp; updateimg &amp; save&quot; echo &quot;info -see the current board building information&quot; echo &quot;&quot; echo &quot;createkeys -create secureboot root keys&quot; echo &quot;security_rootfs -build rootfs and some relevant images with security paramter (just for dm-v)&quot; echo &quot;security_boot -build boot with security paramter&quot; echo &quot;security_uboot -build uboot with security paramter&quot; echo &quot;security_recovery -build recovery with security paramter&quot; echo &quot;security_check -check security paramter if it's good&quot; echo &quot;&quot; echo &quot;Default option is 'allsave'.&quot;}# 构建信息函数，打印当前构建的相关信息build_info(){ # 如果 CHIP_DIR 路径不存在，则打印错误信息，表示未找到目标芯片 if [ ! -L $CHIP_DIR ];then echo &quot;No found target chip!!!&quot; fi # 如果 BOARD_CONFIG 路径不存在，则打印错误信息，表示未找到目标板级配置 if [ ! -L $BOARD_CONFIG ];then echo &quot;No found target board config!!!&quot; fi # 如果存在 .repo/manifest.xml 文件，则获取 SDK 版本号，并打印构建的 SDK 版本 if [ -f .repo/manifest.xml ]; then local sdk_ver=&quot;&quot; sdk_ver=`grep &quot;include name&quot; .repo/manifest.xml | awk -F\\&quot; '{print $2}'` sdk_ver=`realpath .repo/manifests/${sdk_ver}` echo &quot;Build SDK version: `basename ${sdk_ver}`&quot; else echo &quot;Not found .repo/manifest.xml [ignore] !!!&quot; fi # 打印当前构建的信息，包括目标芯片、目标板级配置和一些目标的其他配置参数 echo &quot;Current Building Information:&quot; echo &quot;Target Chip: $CHIP_DIR&quot; echo &quot;Target BoardConfig: `realpath $BOARD_CONFIG`&quot; echo &quot;Target Misc config:&quot; echo &quot;`env |grep &quot;^RK_&quot; | grep -v &quot;=$&quot; | sort`&quot; # 根据 RK_KERNEL_ARCH 变量的值确定设备树（dtb）的路径，并删除已存在的 dtb 文件 if [ &quot;$RK_KERNEL_ARCH&quot; == &quot;arm&quot; ]; then dtb=&quot;kernel/arch/arm/boot/dts/${RK_KERNEL_DTS}.dtb&quot; else dtb=&quot;kernel/arch/arm64/boot/dts/rockchip/${RK_KERNEL_DTS}.dtb&quot; fi rm -f $dtb # 使用 $KMAKE dtbs 命令生成设备树（dtb）文件 $KMAKE dtbs # 调用 build_check_power_domain 函数检查电源域 build_check_power_domain}# 构建检查电源域函数，用于检查电源域配置是否正确build_check_power_domain(){ # 定义临时文件和变量 local dump_kernel_dtb_file local tmp_phandle_file local tmp_io_domain_file local tmp_regulator_microvolt_file local tmp_final_target local tmp_none_item # 根据 RK_KERNEL_ARCH 变量的值确定设备树（dts）文件的路径 if [ &quot;$RK_KERNEL_ARCH&quot; == &quot;arm&quot; ]; then dts=&quot;kernel/arch/arm/boot/dts/$RK_KERNEL_DTS&quot; else dts=&quot;kernel/arch/arm64/boot/dts/rockchip/$RK_KERNEL_DTS&quot; fi # 定义临时文件的路径 dump_kernel_dtb_file=${dts}.dump.dts tmp_phandle_file=`mktemp` tmp_io_domain_file=`mktemp` tmp_regulator_microvolt_file=`mktemp` tmp_final_target=`mktemp` tmp_grep_file=`mktemp` # 将设备树二进制文件转换为文本格式，并保存为 dump_kernel_dtb_file dtc -I dtb -O dts -o ${dump_kernel_dtb_file} ${dts}.dtb 2&gt;/dev/null # 如果 RK_SYSTEM_CHECK_METHOD 变量的值为 &quot;DM-E&quot;，则检查是否在设备树中添加了 optee-tz 的兼容性 if [ &quot;$RK_SYSTEM_CHECK_METHOD&quot; = &quot;DM-E&quot; ] ; then if ! grep &quot;compatible = \\&quot;linaro,optee-tz\\&quot;;&quot; $dump_kernel_dtb_file &gt; /dev/null 2&gt;&amp;1 ; then echo &quot;Please add: &quot; echo &quot; optee: optee {&quot; echo &quot; compatible = \\&quot;linaro,optee-tz\\&quot;;&quot; echo &quot; method = \\&quot;smc\\&quot;;&quot; echo &quot; status = \\&quot;okay\\&quot;;&quot; echo &quot; }&quot; echo &quot;To your dts file&quot; return -1; fi fi # 使用正则表达式从设备树中提取 io-domains 配置，并保存到临时文件 tmp_io_domain_file 和 tmp_grep_file if ! grep -Pzo &quot;io-domains\\s*{(\\n|\\w|-|;|=|&lt;|&gt;|\\&quot;|_|\\s|,)*};&quot; $dump_kernel_dtb_file 1&gt;$tmp_grep_file 2&gt;/dev/null; then #echo &quot;Not Found io-domains in ${dts}.dts&quot; rm -f $tmp_grep_file return 0 fi # 从临时文件 tmp_grep_file 中提取供电（supply）信息，并保存到临时文件 tmp_io_domain_file grep -a supply $tmp_grep_file &gt; $tmp_io_domain_file rm -f $tmp_grep_file awk '{print &quot;phandle = &quot; $3}' $tmp_io_domain_file &gt; $tmp_phandle_file # 逐行读取临时文件 tmp_phandle_file 和 tmp_io_domain_file，并进行处理 while IFS= read -r item_phandle &amp;&amp; IFS= read -u 3 -r item_domain do echo &quot;${item_domain% *}&quot; &gt;&gt; $tmp_regulator_microvolt_file tmp_none_item=${item_domain% *} cmds=&quot;grep -Pzo \\&quot;{(\\\\n|\\w|-|;|=|&lt;|&gt;|\\\\\\&quot;|_|\\s)*&quot;$item_phandle\\&quot; # 使用 eval 执行命令，从设备树中提取相应的 regulator-m..-microvolt 配置，并将结果保存到临时文件 tmp_regulator_microvolt_file eval &quot;$cmds $dump_kernel_dtb_file | strings | grep &quot;regulator-m..-microvolt&quot; &gt;&gt; $tmp_regulator_microvolt_file&quot; || \\ eval &quot;sed -i \\&quot;/${tmp_none_item}/d\\&quot; $tmp_regulator_microvolt_file&quot; &amp;&amp; continue echo &gt;&gt; $tmp_regulator_microvolt_file done &lt; $tmp_phandle_file 3&lt;$tmp_io_domain_file # 逐行读取临时文件 tmp_regulator_microvolt_file，生成最终的目标文件 tmp_final_target while read -r regulator_val do if echo ${regulator_val} | grep supply &amp;&gt;/dev/null; then echo -e &quot;\\n\\n\\e[1;33m${regulator_val%*=}\\e[0m&quot; &gt;&gt; $tmp_final_target else tmp_none_item=${regulator_val##*&lt;} tmp_none_item=${tmp_none_item%%&gt;*} echo -e &quot;${regulator_val%%&lt;*} \\e[1;31m$(( $tmp_none_item / 1000 ))mV\\e[0m&quot; &gt;&gt; $tmp_final_target fi done &lt; $tmp_regulator_microvolt_file echo -e &quot;\\e[41;1;30m PLEASE CHECK BOARD GPIO POWER DOMAIN CONFIGURATION !!!!!\\e[0m&quot; echo -e &quot;\\e[41;1;30m &lt;&lt;&lt; ESPECIALLY Wi-Fi/Flash/Ethernet IO power domain &gt;&gt;&gt; !!!!!\\e[0m&quot; echo -e &quot;\\e[41;1;30m Check Node [pmu_io_domains] in the file: ${dts}.dts \\e[0m&quot; echo echo -e &quot;\\e[41;1;30m 请再次确认板级的电源域配置！！！！！！\\e[0m&quot; echo -e &quot;\\e[41;1;30m &lt;&lt;&lt; 特别是Wi-Fi，FLASH，以太网这几路IO电源的配置 &gt;&gt;&gt; ！！！！！\\e[0m&quot; echo -e &quot;\\e[41;1;30m 检查内核文件 ${dts}.dts 的节点 [pmu_io_domains] \\e[0m&quot; cat $tmp_final_target rm -f $tmp_phandle_file rm -f $tmp_regulator_microvolt_file rm -f $tmp_io_domain_file rm -f $tmp_final_target rm -f $dump_kernel_dtb_file}# 设置交叉编译工具链和相关参数setup_cross_compile(){ if [ &quot;$RK_CHIP&quot; = &quot;rv1126_rv1109&quot; ]; then TOOLCHAIN_OS=rockchip else TOOLCHAIN_OS=none fi # 将 RK_KERNEL_ARCH 中的 arm64 替换为 aarch64 TOOLCHAIN_ARCH=${RK_KERNEL_ARCH/arm64/aarch64} # 查找匹配的 GCC 工具链路径 TOOLCHAIN_DIR=&quot;$(realpath prebuilts/gcc/*/$TOOLCHAIN_ARCH/gcc-arm-*)&quot; GCC=&quot;$(find &quot;$TOOLCHAIN_DIR&quot; -name &quot;*$TOOLCHAIN_OS*-gcc&quot;)&quot; # 检查是否存在可执行的 GCC 工具链 if [ ! -x &quot;$GCC&quot; ]; then echo &quot;No prebuilt GCC toolchain!&quot; return 1 fi # 设置交叉编译前缀 export CROSS_COMPILE=&quot;${GCC%gcc}&quot; echo &quot;Using prebuilt GCC toolchain: $CROSS_COMPILE&quot; # 获取可用的处理器核心数量 NUM_CPUS=$(getconf _NPROCESSORS_ONLN 2&gt;/dev/null || echo 1) # 设置并发编译任务数，默认为处理器核心数量加一 JLEVEL=${RK_JOBS:-$(( $NUM_CPUS + 1 ))} # 定义内核编译命令 KMAKE=&quot;make -C kernel/ ARCH=$RK_KERNEL_ARCH -j$JLEVEL&quot;}# 构建 UEFIbuild_uefi(){ # 设置交叉编译工具链和相关参数 setup_cross_compile # 根据 RK_KERNEL_ARCH 的值确定 dtb 文件路径 if [ &quot;$RK_KERNEL_ARCH&quot; == &quot;arm&quot; ]; then dtb=&quot;kernel/arch/arm/boot/dts/${RK_KERNEL_DTS}.dtb&quot; else dtb=&quot;kernel/arch/arm64/boot/dts/rockchip/${RK_KERNEL_DTS}.dtb&quot; fi echo &quot;============Start building uefi============&quot; echo &quot;Copy kernel dtb $dtb to uefi/edk2-platforms/Platform/Rockchip/DeviceTree/rk3588.dtb&quot; echo &quot;=========================================&quot; # 检查 dtb 文件是否存在 if [ ! -f $dtb ]; then echo &quot;Please compile the kernel before&quot; return -1 fi # 将 dtb 文件复制到 uefi 目录 cp $dtb uefi/edk2-platforms/Platform/Rockchip/DeviceTree/rk3588.dtb # 进入 uefi 目录并执行构建脚本 cd uefi ./make.sh $RK_UBOOT_DEFCONFIG # 完成构建流程 finish_build}# 构建 U-Bootbuild_uboot(){ # 检查 RK_UBOOT_DEFCONFIG 配置是否存在，若不存在则返回 check_config RK_UBOOT_DEFCONFIG || return 0 # 设置交叉编译工具链和相关参数 setup_cross_compile # 准备 U-Boot 构建所需的文件 prebuild_uboot prebuild_security_uboot $@ echo &quot;============Start building uboot============&quot; echo &quot;TARGET_UBOOT_CONFIG=$RK_UBOOT_DEFCONFIG&quot; echo &quot;=========================================&quot; # 进入 u-boot 目录并删除旧的 *_loader_*.bin 文件 cd u-boot rm -f *_loader_*.bin # 构建 U-Boot if [ -n &quot;$RK_UBOOT_DEFCONFIG_FRAGMENT&quot; ]; then if [ -f &quot;configs/${RK_UBOOT_DEFCONFIG}_defconfig&quot; ]; then UBOOT_CONFIGS=&quot;${RK_UBOOT_DEFCONFIG}_defconfig&quot; else UBOOT_CONFIGS=&quot;${RK_UBOOT_DEFCONFIG}.config&quot; fi UBOOT_CONFIGS=&quot;$UBOOT_CONFIGS $RK_UBOOT_DEFCONFIG_FRAGMENT&quot; else UBOOT_CONFIGS=&quot;$RK_UBOOT_DEFCONFIG&quot; fi ./make.sh $UBOOT_CONFIGS $UBOOT_COMPILE_COMMANDS \\ CROSS_COMPILE=$CROSS_COMPILE # 如果需要更新 RK_IDBLOCK_SPL，则执行带有 --idblock 和 --spl 参数的 make.sh if [ &quot;$RK_IDBLOCK_UPDATE_SPL&quot; = &quot;true&quot; ]; then ./make.sh --idblock --spl fi cd .. # 如果需要进行 RAMDISK 安全启动，则创建链接到 rockdev 目录的 boot.img 和 recovery.img if [ &quot;$RK_RAMDISK_SECURITY_BOOTUP&quot; = &quot;true&quot; ];then ln -rsf u-boot/boot.img rockdev/ test -z &quot;${RK_PACKAGE_FILE_AB}&quot; &amp;&amp; \\ ln -rsf u-boot/recovery.img rockdev/ || true fi # 创建链接到 rockdev 目录的 MiniLoaderAll.bin、uboot.img 和 trust.img（如果存在） LOADER=&quot;$(echo u-boot/*_loader_*v*.bin | head -1)&quot; SPL=&quot;$(echo u-boot/*_loader_spl.bin | head -1)&quot; ln -rsf &quot;${LOADER:-$SPL}&quot; rockdev/MiniLoaderAll.bin ln -rsf u-boot/uboot.img rockdev/ [ ! -e u-boot/trust.img ] || \\ ln -rsf u-boot/trust.img rockdev/ # 完成构建流程 finish_build}# 构建 SPLbuild_spl(){ # 检查 RK_SPL_DEFCONFIG 配置是否存在，若不存在则返回 check_config RK_SPL_DEFCONFIG || return 0 echo &quot;============Start building spl============&quot; echo &quot;TARGET_SPL_CONFIG=$RK_SPL_DEFCONFIG&quot; echo &quot;=========================================&quot; # 进入 u-boot 目录并删除旧的 spl.bin 文件 cd u-boot rm -f *spl.bin # 构建 SPL ./make.sh $RK_SPL_DEFCONFIG ./make.sh --spl cd .. # 创建链接到 rockdev 目录的 MiniLoaderAll.bin SPL=&quot;$(echo u-boot/*_loader_spl.bin | head -1)&quot; ln -rsf &quot;$SPL&quot; rockdev/MiniLoaderAll.bin # 完成构建流程 finish_build}# 构建 Loaderbuild_loader(){ # 检查 RK_LOADER_BUILD_TARGET 配置是否存在，若不存在则返回 check_config RK_LOADER_BUILD_TARGET || return 0 echo &quot;============Start building loader============&quot; echo &quot;RK_LOADER_BUILD_TARGET=$RK_LOADER_BUILD_TARGET&quot; echo &quot;==========================================&quot; # 进入 loader 目录并执行 build.sh 构建 Loader cd loader ./build.sh $RK_LOADER_BUILD_TARGET # 完成构建流程 finish_build}# 构建 Kernelbuild_kernel(){ # 检查 RK_KERNEL_DTS 和 RK_KERNEL_DEFCONFIG 配置是否存在，若不存在则返回 check_config RK_KERNEL_DTS RK_KERNEL_DEFCONFIG || return 0 echo &quot;============Start building kernel============&quot; echo &quot;TARGET_KERNEL_ARCH =$RK_KERNEL_ARCH&quot; echo &quot;TARGET_KERNEL_CONFIG =$RK_KERNEL_DEFCONFIG&quot; echo &quot;TARGET_KERNEL_DTS =$RK_KERNEL_DTS&quot; echo &quot;TARGET_KERNEL_CONFIG_FRAGMENT =$RK_KERNEL_DEFCONFIG_FRAGMENT&quot; echo &quot;==========================================&quot; # 设置交叉编译工具链 setup_cross_compile # 使用 KMAKE 构建 Kernel $KMAKE $RK_KERNEL_DEFCONFIG $RK_KERNEL_DEFCONFIG_FRAGMENT $KMAKE $RK_KERNEL_DTS.img # 检查是否存在 Kernel FIT 文件并使用 mk-fitimage.sh 创建镜像 ITS=&quot;$CHIP_DIR/$RK_KERNEL_FIT_ITS&quot; if [ -f &quot;$ITS&quot; ]; then $COMMON_DIR/mk-fitimage.sh kernel/$RK_BOOT_IMG \\ &quot;$ITS&quot; $RK_KERNEL_IMG fi # 创建链接到 rockdev 目录的 boot.img ln -rsf kernel/$RK_BOOT_IMG rockdev/boot.img # 将 boot.img 复制到 u-boot 目录下，用于安全性考虑 cp rockdev/boot.img u-boot/ # 构建检查电源域 build_check_power_domain # 完成构建流程 finish_build}# 构建 Wi-Fi 和蓝牙build_wifibt(){ # 设置交叉编译工具链 setup_cross_compile # 设置 Buildroot 相关路径 BUILDROOT_OUTDIR=$TOP_DIR/buildroot/output/$RK_CFG_BUILDROOT/ BUILDROOT_HOST_DIR=$BUILDROOT_OUTDIR/host/ # 检查 Buildroot 架构 if grep -wq aarch64 &quot;$BUILDROOT_OUTDIR/.config&quot; 2&gt;/dev/null; then BUILDROOT_ARCH=arm64 else BUILDROOT_ARCH=arm fi # 获取 Buildroot GCC 和 SYSROOT 路径 BUILDROOT_GCC=&quot;$(echo $BUILDROOT_HOST_DIR/bin/*buildroot*-gcc)&quot; BUILDROOT_SYSROOT=&quot;$(echo $BUILDROOT_HOST_DIR/*/sysroot/)&quot; if [ ! -x &quot;$BUILDROOT_GCC&quot; -o ! -d &quot;$BUILDROOT_SYSROOT&quot; ]; then echo &quot;ERROR: Buildroot not ready!&quot; exit -1 fi # 设置 Wi-Fi 和蓝牙芯片类型和 TTY 设备 if [ -n &quot;$1&quot; ]; then WIFI_CHIP=$1 elif [ -n &quot;$RK_WIFIBT_CHIP&quot; ]; then WIFI_CHIP=$RK_WIFIBT_CHIP else # 默认为 ALL_AP echo &quot;=== WARNNING WIFI_CHIP is NULL so default to ALL_AP ===&quot; WIFI_CHIP=ALL_AP fi if [ -n &quot;$2&quot; ]; then BT_TTY_DEV=$2 elif [ -n &quot;$RK_WIFIBT_TTY&quot; ]; then BT_TTY_DEV=$RK_WIFIBT_TTY else echo &quot;=== WARNNING BT_TTY is NULL so default to ttyS0 ===&quot; BT_TTY_DEV=ttyS0 fi # 检查内核 .config 配置 WIFI_USB=$(grep &quot;CONFIG_USB=y&quot; $TOP_DIR/kernel/.config || true) WIFI_SDIO=$(grep &quot;CONFIG_MMC=y&quot; $TOP_DIR/kernel/.config || true) WIFI_PCIE=$(grep &quot;CONFIG_PCIE_DW_ROCKCHIP=y&quot; $TOP_DIR/kernel/.config || true) WIFI_RFKILL=$(grep &quot;CONFIG_RFKILL=y&quot; $TOP_DIR/kernel/.config || true) if [ -z &quot;$WIFI_SDIO&quot; ]; then echo &quot;=== WARNNING CONFIG_MMC not set !!! ===&quot; fi if [ -z &quot;$WIFI_RFKILL&quot; ]; then echo &quot;=== WARNNING CONFIG_USB not set !!! ===&quot; fi if [[ &quot;$WIFI_CHIP&quot; =~ &quot;U&quot; ]]; then if [ -z &quot;$WIFI_USB&quot; ]; then echo &quot;=== WARNNING CONFIG_USB not set so ABORT!!! ===&quot; exit 0 fi fi echo &quot;kernel config: $WIFI_USB $WIFI_SDIO $WIFI_RFKILL&quot; TARGET_CC=${CROSS_COMPILE}gcc RKWIFIBT=$TOP_DIR/external/rkwifibt RKWIFIBT_APP=$TOP_DIR/external/rkwifibt-app TARGET_ROOTFS_DIR=$TOP_DIR/buildroot/output/$RK_CFG_BUILDROOT/target echo &quot;========build wifibt info=======&quot; echo CROSS_COMPILE=$CROSS_COMPILE echo WIFI_CHIP=$WIFI_CHIP echo BT_TTY_DEV=$BT_TTY_DEV echo TARGET_ROOTFS_DIR=$TARGET_ROOTFS_DIR echo BUILDROOT_GCC=$BUILDROOT_GCC echo BUILDROOT_SYSROOT=$BUILDROOT_SYSROOT if [[ &quot;$WIFI_CHIP&quot; =~ &quot;ALL_AP&quot; ]];then echo &quot;building bcmdhd sdio&quot; $KMAKE M=$RKWIFIBT/drivers/bcmdhd CONFIG_BCMDHD=m CONFIG_BCMDHD_SDIO=y CONFIG_BCMDHD_PCIE= if [ -n &quot;$WIFI_PCIE&quot; ]; then echo &quot;building bcmdhd pcie&quot; $KMAKE M=$RKWIFIBT/drivers/bcmdhd CONFIG_BCMDHD=m CONFIG_BCMDHD_PCIE=y CONFIG_BCMDHD_SDIO= fi if [ -n &quot;$WIFI_USB&quot; ]; then echo &quot;building rtl8188fu usb&quot; $KMAKE M=$RKWIFIBT/drivers/rtl8188fu modules fi echo &quot;building rtl8189fs sdio&quot; $KMAKE M=$RKWIFIBT/drivers/rtl8189fs modules echo &quot;building rtl8723ds sdio&quot; $KMAKE M=$RKWIFIBT/drivers/rtl8723ds modules echo &quot;building rtl8821cs sdio&quot; $KMAKE M=$RKWIFIBT/drivers/rtl8821cs modules echo &quot;building rtl8822cs sdio&quot; $KMAKE M=$RKWIFIBT/drivers/rtl8822cs modules echo &quot;building rtl8852bs sdio&quot; $KMAKE M=$RKWIFIBT/drivers/rtl8852bs modules DRV_PATH=$RKWIFIBT/drivers/rtl8852bs if [ -n &quot;$WIFI_PCIE&quot; ]; then echo &quot;building rtl8852be pcie&quot; $KMAKE M=$RKWIFIBT/drivers/rtl8852be modules DRV_PATH=$RKWIFIBT/drivers/rtl8852be fi fi if [[ &quot;$WIFI_CHIP&quot; =~ &quot;ALL_CY&quot; ]];then echo &quot;building CYW4354&quot; cp $RKWIFIBT/drivers/infineon/chips/CYW4354_Makefile $RKWIFIBT/drivers/infineon/Makefile -r $KMAKE M=$RKWIFIBT/drivers/infineon echo &quot;building CYW4373&quot; cp $RKWIFIBT/drivers/infineon/chips/CYW4373_Makefile $RKWIFIBT/drivers/infineon/Makefile -r $KMAKE M=$RKWIFIBT/drivers/infineon echo &quot;building CYW43438&quot; cp $RKWIFIBT/drivers/infineon/chips/CYW43438_Makefile $RKWIFIBT/drivers/infineon/Makefile -r $KMAKE M=$RKWIFIBT/drivers/infineon echo &quot;building CYW43455&quot; cp $RKWIFIBT/drivers/infineon/chips/CYW43455_Makefile $RKWIFIBT/drivers/infineon/Makefile -r $KMAKE M=$RKWIFIBT/drivers/infineon echo &quot;building CYW5557X&quot; cp $RKWIFIBT/drivers/infineon/chips/CYW5557X_Makefile $RKWIFIBT/drivers/infineon/Makefile -r $KMAKE M=$RKWIFIBT/drivers/infineon if [ -n &quot;$WIFI_PCIE&quot; ]; then echo &quot;building CYW5557X_PCIE&quot; cp $RKWIFIBT/drivers/infineon/chips/CYW5557X_PCIE_Makefile $RKWIFIBT/drivers/infineon/Makefile -r $KMAKE M=$RKWIFIBT/drivers/infineon echo &quot;building CYW54591_PCIE&quot; cp $RKWIFIBT/drivers/infineon/chips/CYW54591_PCIE_Makefile $RKWIFIBT/drivers/infineon/Makefile -r $KMAKE M=$RKWIFIBT/drivers/infineon fi echo &quot;building CYW54591&quot; cp $RKWIFIBT/drivers/infineon/chips/CYW54591_Makefile $RKWIFIBT/drivers/infineon/Makefile -r $ KMAKE M=$RKWIFIBT/drivers/infineon if [ -n &quot;$WIFI_USB&quot; ]; then echo &quot;building rtl8188fu usb&quot; $KMAKE M=$RKWIFIBT/drivers/rtl8188fu modules fi echo &quot;building rtl8189fs sdio&quot; $KMAKE M=$RKWIFIBT/drivers/rtl8189fs modules echo &quot;building rtl8723ds sdio&quot; $KMAKE M=$RKWIFIBT/drivers/rtl8723ds modules echo &quot;building rtl8821cs sdio&quot; $KMAKE M=$RKWIFIBT/drivers/rtl8821cs modules echo &quot;building rtl8822cs sdio&quot; $KMAKE M=$RKWIFIBT/drivers/rtl8822cs modules echo &quot;building rtl8852bs sdio&quot; $KMAKE M=$RKWIFIBT/drivers/rtl8852bs modules DRV_PATH=$RKWIFIBT/drivers/rtl8852bs if [ -n &quot;$WIFI_PCIE&quot; ]; then echo &quot;building rtl8852be pcie&quot; $KMAKE M=$RKWIFIBT/drivers/rtl8852be modules DRV_PATH=$RKWIFIBT/drivers/rtl8852be fi fi if [[ &quot;$WIFI_CHIP&quot; =~ &quot;AP6&quot; ]];then if [[ &quot;$WIFI_CHIP&quot; = &quot;AP6275_PCIE&quot; ]];then echo &quot;building bcmdhd pcie driver&quot; $KMAKE M=$RKWIFIBT/drivers/bcmdhd CONFIG_BCMDHD=m CONFIG_BCMDHD_PCIE=y CONFIG_BCMDHD_SDIO= else echo &quot;building bcmdhd sdio driver&quot; $KMAKE M=$RKWIFIBT/drivers/bcmdhd CONFIG_BCMDHD=m CONFIG_BCMDHD_SDIO=y CONFIG_BCMDHD_PCIE= fi fi if [[ &quot;$WIFI_CHIP&quot; = &quot;CYW4354&quot; ]];then echo &quot;building CYW4354&quot; cp $RKWIFIBT/drivers/infineon/chips/CYW4354_Makefile $RKWIFIBT/drivers/infineon/Makefile -r $KMAKE M=$RKWIFIBT/drivers/infineon fi if [[ &quot;$WIFI_CHIP&quot; = &quot;CYW4373&quot; ]];then echo &quot;building CYW4373&quot; cp $RKWIFIBT/drivers/infineon/chips/CYW4373_Makefile $RKWIFIBT/drivers/infineon/Makefile -r $KMAKE M=$RKWIFIBT/drivers/infineon fi if [[ &quot;$WIFI_CHIP&quot; = &quot;CYW43438&quot; ]];then echo &quot;building CYW43438&quot; cp $RKWIFIBT/drivers/infineon/chips/CYW43438_Makefile $RKWIFIBT/drivers/infineon/Makefile -r $KMAKE M=$RKWIFIBT/drivers/infineon fi if [[ &quot;$WIFI_CHIP&quot; = &quot;CYW43455&quot; ]];then echo &quot;building CYW43455&quot; cp $RKWIFIBT/drivers/infineon/chips/CYW43455_Makefile $RKWIFIBT/drivers/infineon/Makefile -r $KMAKE M=$RKWIFIBT/drivers/infineon fi if [[ &quot;$WIFI_CHIP&quot; = &quot;CYW5557X&quot; ]];then echo &quot;building CYW5557X&quot; cp $RKWIFIBT/drivers/infineon/chips/CYW5557X_Makefile $RKWIFIBT/drivers/infineon/Makefile -r $KMAKE M=$RKWIFIBT/drivers/infineon fi if [[ &quot;$WIFI_CHIP&quot; = &quot;CYW5557X_PCIE&quot; ]];then echo &quot;building CYW5557X_PCIE&quot; cp $RKWIFIBT/drivers/infineon/chips/CYW5557X_PCIE_Makefile $RKWIFIBT/drivers/infineon/Makefile -r $KMAKE M=$RKWIFIBT/drivers/infineon fi if [[ &quot;$WIFI_CHIP&quot; = &quot;CYW54591&quot; ]];then echo &quot;building CYW54591&quot; cp $RKWIFIBT/drivers/infineon/chips/CYW54591_Makefile $RKWIFIBT/drivers/infineon/Makefile -r $KMAKE M=$RKWIFIBT/drivers/infineon fi if [[ &quot;$WIFI_CHIP&quot; = &quot;CYW54591_PCIE&quot; ]];then echo &quot;building CYW54591_PCIE&quot; cp $RKWIFIBT/drivers/infineon/chips/CYW54591_PCIE_Makefile $RKWIFIBT/drivers/infineon/Makefile -r $KMAKE M=$RKWIFIBT/drivers/infineon fi if [[ &quot;$WIFI_CHIP&quot; = &quot;RTL8188FU&quot; ]];then echo &quot;building rtl8188fu driver&quot; $KMAKE M=$RKWIFIBT/drivers/rtl8188fu modules fi if [[ &quot;$WIFI_CHIP&quot; = &quot;RTL8189FS&quot; ]];then echo &quot;building rtl8189fs driver&quot; $KMAKE M=$RKWIFIBT/drivers/rtl8189fs modules fi if [[ &quot;$WIFI_CHIP&quot; = &quot;RTL8723DS&quot; ]];then $KMAKE M=$RKWIFIBT/drivers/rtl8723ds modules fi if [[ &quot;$WIFI_CHIP&quot; = &quot;RTL8821CS&quot; ]];then $KMAKE M=$RKWIFIBT/drivers/rtl8821cs modules fi if [[ &quot;$WIFI_CHIP&quot; = &quot;RTL8822CS&quot; ]];then $KMAKE M=$RKWIFIBT/drivers/rtl8822cs modules fi if [[ &quot;$WIFI_CHIP&quot; = &quot;RTL8852BS&quot; ]];then $KMAKE M=$RKWIFIBT/drivers/rtl8852bs modules fi if [[ &quot;$WIFI_CHIP&quot; = &quot;RTL8852BE&quot; ]];then $KMAKE M=$RKWIFIBT/drivers/rtl8852be modules fi echo &quot;building brcm_tools&quot; $TARGET_CC -o $RKWIFIBT/tools/brcm_tools/brcm_patchram_plus1 $RKWIFIBT/tools/brcm_tools/brcm_patchram_plus1.c $TARGET_CC -o $RKWIFIBT/tools/brcm_tools/dhd_priv $RKWIFIBT/tools/brcm_tools/dhd_priv.c echo &quot;building rk_wifibt_init&quot; $TARGET_CC -o $RKWIFIBT/src/rk_wifibt_init $RKWIFIBT/src/rk_wifi_init.c echo &quot;building realtek_tools&quot; make -C $RKWIFIBT/tools/rtk_hciattach/ CC=$TARGET_CC echo &quot;building realtek bt drivers&quot; $KMAKE M=$RKWIFIBT/drivers/bluetooth_uart_driver if [ -n &quot;$WIFI_USB&quot; ]; then $KMAKE M=$RKWIFIBT/drivers/bluetooth_usb_driver fi if [ &quot;$RK_CHIP&quot; = &quot;rv1126_rv1109&quot; ];then echo &quot;target is rv1126_rv1109, skip $RKWIFIBT_APP&quot; else echo &quot;building rkwifibt-app&quot; make -C $RKWIFIBT_APP CC=$BUILDROOT_GCC \\ SYSROOT=$BUILDROOT_SYSROOT ARCH=$BUILDROOT_ARCH || true fi echo &quot;chmod +x tools&quot; chmod 755 $RKWIFIBT/tools/brcm_tools/brcm_patchram_plus1 chmod 755 $RKWIFIBT/tools/brcm_tools/dhd_priv chmod 755 $RKWIFIBT/src/rk_wifibt_init chmod 755 $RKWIFIBT/tools/rtk_hciattach/rtk_hciattach echo &quot;mkdir rootfs dir&quot; $TARGET_ROOTFS_DIR rm -rf $TARGET_ROOTFS_DIR/system/lib/modules/ rm -rf $TARGET_ROOTFS_DIR/system/etc/firmware/ rm -rf $TARGET_ROOTFS_DIR/vendor/ rm -rf $TARGET_ROOTFS_DIR/usr/lib/modules/ mkdir -p $TARGET_ROOTFS_DIR/usr/lib/modules/ mkdir -p $TARGET_ROOTFS_DIR/system/lib/modules/ mkdir -p $TARGET_ROOTFS_DIR/system/etc/firmware/ mkdir -p $TARGET_ROOTFS_DIR/lib/firmware/rtlbt/ echo &quot;create link system-&gt;vendor&quot; cd $TARGET_ROOTFS_DIR/ rm -rf $TARGET_ROOTFS_DIR/vendor ln -rsf system $TARGET_ROOTFS_DIR/vendor cd - echo &quot;copy tools/sh to rootfs&quot; cp $RKWIFIBT/bin/$BUILDROOT_ARCH/* $TARGET_ROOTFS_DIR/usr/bin/ cp $RKWIFIBT/sh/wifi_start.sh $TARGET_ROOTFS_DIR/usr/bin/ cp $RKWIFIBT/sh/wifi_ap6xxx_rftest.sh $TARGET_ROOTFS_DIR/usr/bin/ cp $RKWIFIBT/conf/wpa_supplicant.conf $TARGET_ROOTFS_DIR/etc/ cp $RKWIFIBT/conf/dnsmasq.conf $TARGET_ROOTFS_DIR/etc/ cp $RKWIFIBT/tools/brcm_tools/dhd_priv $TARGET_ROOTFS_DIR/usr/bin/ cp $RKWIFIBT/tools/brcm_tools/brcm_patchram_plus1 $TARGET_ROOTFS_DIR/usr/bin/ cp $RKWIFIBT/src/rk_wifibt_init $TARGET_ROOTFS_DIR/usr/bin/ if [[ &quot;$WIFI_CHIP&quot; = &quot;ALL_CY&quot; ]];then echo &quot;copy infineon/realtek firmware/nvram to rootfs&quot; cp $RKWIFIBT/drivers/infineon/*.ko $TARGET_ROOTFS_DIR/system/lib/modules/ || true cp $RKWIFIBT/firmware/infineon/*/* $TARGET_ROOTFS_DIR/system/etc/firmware/ || true #todo rockchip #cp $RKWIFIBT/firmware/rockchip/* $TARGET_ROOTFS_DIR/system/etc/firmware/ cp $RKWIFIBT/sh/bt_load_broadcom_firmware $TARGET_ROOTFS_DIR/usr/bin/ cp $TARGET_ROOTFS_DIR/usr/bin/bt_load_broadcom_firmware $TARGET_ROOTFS_DIR/usr/bin/bt_init.sh cp $TARGET_ROOTFS_DIR/usr/bin/bt_load_broadcom_firmware $TARGET_ROOTFS_DIR/usr/bin/bt_pcba_test #reatek cp $RKWIFIBT/firmware/realtek/*/* $TARGET_ROOTFS_DIR/lib/firmware/ cp $RKWIFIBT/firmware/realtek/*/* $TARGET_ROOTFS_DIR/lib/firmware/rtlbt/ cp $RKWIFIBT/tools/rtk_hciattach/rtk_hciattach $TARGET_ROOTFS_DIR/usr/bin/ cp $RKWIFIBT/drivers/bluetooth_uart_driver/hci_uart.ko $TARGET_ROOTFS_DIR/usr/lib/modules/ if [ -n &quot;$WIFI_USB&quot; ]; then cp $RKWIFIBT/drivers/bluetooth_usb_driver/rtk_btusb.ko $TARGET_ROOTFS_DIR/usr/lib/modules/ fi rm -rf $TARGET_ROOTFS_DIR/etc/init.d/S36load_wifi_modules cp $RKWIFIBT/S36load_all_wifi_modules $TARGET_ROOTFS_DIR/etc/init.d/ sed -i &quot;s/BT_TTY_DEV/\\/dev\\/${BT_TTY_DEV}/g&quot; $TARGET_ROOTFS_DIR/etc/init.d/S36load_all_wifi_modules fi if [[ &quot;$WIFI_CHIP&quot; = &quot;ALL_AP&quot; ]];then echo &quot;copy ap6xxx/realtek firmware/nvram to rootfs&quot; cp $RKWIFIBT/drivers/bcmdhd/*.ko $TARGET_ROOTFS_DIR/system/lib/modules/ cp $RKWIFIBT/firmware/broadcom/*/wifi/* $TARGET_ROOTFS_DIR/system/etc/firmware/ || true cp $RKWIFIBT/firmware/broadcom/*/bt/* $TARGET_ROOTFS_DIR/system/etc/firmware/ || true #todo rockchip #cp $RKWIFIBT/firmware/rockchip/* $TARGET_ROOTFS_DIR/system/etc/firmware/ cp $RKWIFIBT/sh/bt_load_broadcom_firmware $TARGET_ROOTFS_DIR/usr/bin/ cp $TARGET_ROOTFS_DIR/usr/bin/bt_load_broadcom_firmware $TARGET_ROOTFS_DIR/usr/bin/bt_init.sh cp $TARGET_ROOTFS_DIR/usr/bin/bt_load_broadcom_firmware $TARGET_ROOTFS_DIR/usr/bin/bt_pcba_test #reatek cp -rf $RKWIFIBT/firmware/realtek/*/* $TARGET_ROOTFS_DIR/lib/firmware/ cp -rf $RKWIFIBT/firmware/realtek/*/* $TARGET_ROOTFS_DIR/lib/firmware/rtlbt/ cp $RKWIFIBT/tools/rtk_hciattach/rtk_hciattach $TARGET_ROOTFS_DIR/usr/bin/ cp $RKWIFIBT/drivers/bluetooth_uart_driver/hci_uart.ko $TARGET_ROOTFS_DIR/usr/lib/modules/ if [ -n &quot;$WIFI_USB&quot; ]; then cp $RKWIFIBT/drivers/bluetooth_usb_driver/rtk_btusb.ko $TARGET_ROOTFS_DIR/usr/lib/modules/ fi rm -rf $TARGET_ROOTFS_DIR/etc/init.d/S36load_wifi_modules cp $RKWIFIBT/S36load_all_wifi_modules $TARGET_ROOTFS_DIR/etc/init.d/ sed -i &quot;s/BT_TTY_DEV/\\/dev\\/${BT_TTY_DEV}/g&quot; $TARGET_ROOTFS_DIR/etc/init.d/S36load_all_wifi_modules fi if [[ &quot;$WIFI_CHIP&quot; =~ &quot;RTL&quot; ]];then echo &quot;Copy RTL file to rootfs&quot; if [ -d &quot;$RKWIFIBT/firmware/realtek/$WIFI_CHIP&quot; ]; then cp $RKWIFIBT/firmware/realtek/$WIFI_CHIP/* $TARGET_ROOTFS_DIR/lib/firmware/rtlbt/ cp $RKWIFIBT/firmware/realtek/$WIFI_CHIP/* $TARGET_ROOTFS_DIR/lib/firmware/ else echo &quot;INFO: $WIFI_CHIP isn't bluetooth?&quot; fi WIFI_KO_DIR=$(echo $WIFI_CHIP | tr '[A-Z]' '[a-z]') cp $RKWIFIBT/drivers/$WIFI_KO_DIR/*.ko $TARGET_ROOTFS_DIR/system/lib/modules/ cp $RKWIFIBT/sh/bt_load_rtk_firmware $TARGET_ROOTFS_DIR/usr/bin/ sed -i &quot;s/BT_TTY_DEV/\\/dev\\/${BT_TTY_DEV}/g&quot; $TARGET_ROOTFS_DIR/usr/bin/bt_load_rtk_firmware if [ -n &quot;$WIFI_USB&quot; ]; then cp $RKWIFIBT/drivers/bluetooth_usb_driver/rtk_btusb.ko $TARGET_ROOTFS_DIR/usr/lib/modules/ sed -i &quot;s/BT_DRV/rtk_btusb/g&quot; $TARGET_ROOTFS_DIR/usr/bin/bt_load_rtk_firmware else cp $RKWIFIBT/drivers/bluetooth_uart_driver/hci_uart.ko $TARGET_ROOTFS_DIR/usr/lib/modules/ sed -i &quot;s/BT_DRV/hci_uart/g&quot; $TARGET_ROOTFS_DIR/usr/bin/bt_load_rtk_firmware fi cp $TARGET_ROOTFS_DIR/usr/bin/bt_load_rtk_firmware $TARGET_ROOTFS_DIR/usr/bin/bt_init.sh cp $TARGET_ROOTFS_DIR/usr/bin/bt_load_rtk_firmware $TARGET_ROOTFS_DIR/usr/bin/bt_pcba_test cp $RKWIFIBT/tools/rtk_hciattach/rtk_hciattach $TARGET_ROOTFS_DIR/usr/bin/ rm -rf $TARGET_ROOTFS_DIR/etc/init.d/S36load_all_wifi_modules cp $RKWIFIBT/S36load_wifi_modules $TARGET_ROOTFS_DIR/etc/init.d/ sed -i &quot;s/WIFI_KO/\\/system\\/lib\\/modules\\/$WIFI_CHIP.ko/g&quot; $TARGET_ROOTFS_DIR/etc/init.d/S36load_wifi_modules fi if [[ &quot;$WIFI_CHIP&quot; =~ &quot;CYW&quot; ]];then echo &quot;Copy CYW file to rootfs&quot; #tools cp $RKWIFIBT/tools/brcm_tools/dhd_priv $TARGET_ROOTFS_DIR/usr/bin/ cp $RKWIFIBT/tools/brcm_tools/brcm_patchram_plus1 $TARGET_ROOTFS_DIR/usr/bin/ #firmware cp $RKWIFIBT/firmware/infineon/$WIFI_CHIP/* $TARGET_ROOTFS_DIR/system/etc/firmware/ cp $RKWIFIBT/drivers/infineon/*.ko $TARGET_ROOTFS_DIR/system/lib/modules/ #bt cp $RKWIFIBT/sh/bt_load_broadcom_firmware $TARGET_ROOTFS_DIR/usr/bin/ sed -i &quot;s/BT_TTY_DEV/\\/dev\\/${BT_TTY_DEV}/g&quot; $TARGET_ROOTFS_DIR/usr/bin/bt_load_broadcom_firmware sed -i &quot;s/BTFIRMWARE_PATH/\\/system\\/etc\\/firmware\\//g&quot; $TARGET_ROOTFS_DIR/usr/bin/bt_load_broadcom_firmware cp $TARGET_ROOTFS_DIR/usr/bin/bt_load_broadcom_firmware $TARGET_ROOTFS_DIR/usr/bin/bt_init.sh cp $TARGET_ROOTFS_DIR/usr/bin/bt_load_broadcom_firmware $TARGET_ROOTFS_DIR/usr/bin/bt_pcba_test #wifi rm -rf $TARGET_ROOTFS_DIR/etc/init.d/S36load_all_wifi_modules cp $RKWIFIBT/S36load_wifi_modules $TARGET_ROOTFS_DIR/etc/init.d/ sed -i &quot;s/WIFI_KO/\\/system\\/lib\\/modules\\/$WIFI_CHIP.ko/g&quot; $TARGET_ROOTFS_DIR/etc/init.d/S36load_wifi_modules fi if [[ &quot;$WIFI_CHIP&quot; =~ &quot;AP6&quot; ]];then echo &quot;Copy AP file to rootfs&quot; #tools cp $RKWIFIBT/tools/brcm_tools/dhd_priv $TARGET_ROOTFS_DIR/usr/bin/ cp $RKWIFIBT/tools/brcm_tools/brcm_patchram_plus1 $TARGET_ROOTFS_DIR/usr/bin/ #firmware cp $RKWIFIBT/firmware/broadcom/$WIFI_CHIP/wifi/* $TARGET_ROOTFS_DIR/system/etc/firmware/ cp $RKWIFIBT/firmware/broadcom/$WIFI_CHIP/bt/* $TARGET_ROOTFS_DIR/system/etc/firmware/ cp $RKWIFIBT/drivers/bcmdhd/*.ko $TARGET_ROOTFS_DIR/system/lib/modules/ #bt cp $RKWIFIBT/sh/bt_load_broadcom_firmware $TARGET_ROOTFS_DIR/usr/bin/ sed -i &quot;s/BT_TTY_DEV/\\/dev\\/${BT_TTY_DEV}/g&quot; $TARGET_ROOTFS_DIR/usr/bin/bt_load_broadcom_firmware sed -i &quot;s/BTFIRMWARE_PATH/\\/system\\/etc\\/firmware\\//g&quot; $TARGET_ROOTFS_DIR/usr/bin/bt_load_broadcom_firmware cp $TARGET_ROOTFS_DIR/usr/bin/bt_load_broadcom_firmware $TARGET_ROOTFS_DIR/usr/bin/bt_init.sh cp $TARGET_ROOTFS_DIR/usr/bin/bt_load_broadcom_firmware $TARGET_ROOTFS_DIR/usr/bin/bt_pcba_test #wifi rm -rf $TARGET_ROOTFS_DIR/etc/init.d/S36load_all_wifi_modules cp $RKWIFIBT/S36load_wifi_modules $TARGET_ROOTFS_DIR/etc/init.d/ if [[ &quot;$WIFI_CHIP&quot; =~ &quot;AP&quot; ]];then sed -i &quot;s/WIFI_KO/\\/system\\/lib\\/modules\\/bcmdhd.ko/g&quot; $TARGET_ROOTFS_DIR/etc/init.d/S36load_wifi_modules else sed -i &quot;s/WIFI_KO/\\/system\\/lib\\/modules\\/bcmdhd_pcie.ko/g&quot; $TARGET_ROOTFS_DIR/etc/init.d/S36load_wifi_modules fi fi finish_build #exit 0}# 构建内核模块build_modules(){ check_config RK_KERNEL_DEFCONFIG || return 0 echo &quot;============Start building kernel modules============&quot; echo &quot;TARGET_KERNEL_ARCH =$RK_KERNEL_ARCH&quot; echo &quot;TARGET_KERNEL_CONFIG =$RK_KERNEL_DEFCONFIG&quot; echo &quot;TARGET_KERNEL_CONFIG_FRAGMENT =$RK_KERNEL_DEFCONFIG_FRAGMENT&quot; echo &quot;==================================================&quot; # 设置交叉编译工具链 setup_cross_compile # 使用指定的内核配置和片段进行构建 $KMAKE $RK_KERNEL_DEFCONFIG $RK_KERNEL_DEFCONFIG_FRAGMENT $KMAKE modules # 完成构建 finish_build}# 构建 Buildroot 根文件系统build_buildroot(){ check_config RK_CFG_BUILDROOT || return 0 ROOTFS_DIR=$1 echo &quot;==========Start building buildroot rootfs ==========&quot; echo &quot;TARGET_BUILDROOT_CONFIG=$RK_CFG_BUILDROOT&quot; echo &quot;=========================================&quot; DST_DIR=.buildroot # 使用 mk-buildroot.sh 脚本构建 Buildroot 根文件系统 /usr/bin/time -f &quot;you take %E to build buildroot&quot; \\ $COMMON_DIR/mk-buildroot.sh $RK_CFG_BUILDROOT $DST_DIR # 删除旧的根文件系统目录并创建新的符号链接 rm -rf $ROOTFS_DIR ln -rsf $DST_DIR $ROOTFS_DIR # 完成构建 finish_build}kernel_version(){ [ -d &quot;$1&quot; ] || return 0 # 定义内核版本号的关键字 VERSION_KEYS=&quot;VERSION PATCHLEVEL&quot; VERSION=&quot;&quot; # 遍历关键字，获取内核版本号的各个部分 for k in $VERSION_KEYS; do v=$(grep &quot;^$k = &quot; $1/Makefile | cut -d' ' -f3) VERSION=${VERSION:+${VERSION}.}$v done echo $VERSION}# 构建 Yocto rootfsbuild_yocto(){ check_config RK_YOCTO_MACHINE || return 0 # 开始构建 Yocto rootfs echo &quot;=========开始构建 Yocto rootfs=========&quot; echo &quot;目标机器：$RK_YOCTO_MACHINE&quot; echo &quot;=====================================&quot; KERNEL_VERSION=$(kernel_version kernel/) cd yocto ln -rsf $RK_YOCTO_MACHINE.conf build/conf/local.conf source oe-init-build-env LANG=en_US.UTF-8 LANGUAGE=en_US.en LC_ALL=en_US.UTF-8 \\ bitbake core-image-minimal -r conf/include/rksdk.conf \\ -r conf/include/kernel-$KERNEL_VERSION.conf finish_build}# 构建 debian rootfsbuild_debian(){ ARCH=${RK_DEBIAN_ARCH:-${RK_KERNEL_ARCH}} case $ARCH in arm|armhf) ARCH=armhf ;; *) ARCH=arm64 ;; esac echo &quot;=========开始构建 Debian ($ARCH) 根文件系统=========&quot; cd debian # 检查是否存在 linaro 版本的 Debian 根文件系统压缩包，如果不存在则执行 mk-base-debian.sh 脚本构建 if [ ! -f linaro-$RK_DEBIAN_VERSION-alip-*.tar.gz ]; then RELEASE=$RK_DEBIAN_VERSION TARGET=desktop ARCH=$ARCH ./mk-base-debian.sh ln -rsf linaro-$RK_DEBIAN_VERSION-alip-*.tar.gz linaro-$RK_DEBIAN_VERSION-$ARCH.tar.gz fi VERSION=debug ARCH=$ARCH ./mk-rootfs-$RK_DEBIAN_VERSION.sh ./mk-image.sh # 完成构建 finish_build}# 编译文件系统build_rootfs(){ check_config RK_ROOTFS_TYPE || return 0 ROOTFS=${1:-${RK_ROOTFS_SYSTEM:-buildroot}} ROOTFS_IMG=rootfs.${RK_ROOTFS_TYPE} ROOTFS_DIR=.rootfs echo &quot;==========开始构建根文件系统($ROOTFS)，输出到$ROOTFS_DIR==========&quot; # 删除旧的根文件系统目录并创建新的目录 rm -rf $ROOTFS_DIR mkdir -p $ROOTFS_DIR case &quot;$ROOTFS&quot; in yocto) build_yocto ln -rsf yocto/build/latest/rootfs.img \\ $ROOTFS_DIR/rootfs.ext4 ;; debian) build_debian ln -rsf debian/linaro-rootfs.img \\ $ROOTFS_DIR/rootfs.ext4 ;; buildroot) build_buildroot $ROOTFS_DIR build_wifibt # 为 wifibt 重新编译 build_buildroot $ROOTFS_DIR ;; *) echo &quot;$ROOTFS 不支持！&quot; exit 1 ;; esac if [ ! -f &quot;$ROOTFS_DIR/$ROOTFS_IMG&quot; ]; then echo &quot;未生成 $ROOTFS_IMG...&quot; exit 1 fi ln -rsf $ROOTFS_DIR/$ROOTFS_IMG rockdev/rootfs.img [ ! -f $ROOTFS_DIR/oem.img ] || ln -rsf $ROOTFS_DIR/oem.img rockdev/ if [ &quot;$RK_RAMBOOT&quot; ]; then /usr/bin/time -f &quot;you take %E to pack ramboot image&quot; \\ $COMMON_DIR/mk-ramdisk.sh rockdev/rootfs.img \\ $ROOTFS_DIR/ramboot.img ln -rsf $ROOTFS_DIR/ramboot.img rockdev/boot.img # 用于安全性 cp rockdev/boot.img u-boot/ fi if [ &quot;$RK_RAMDISK_SECURITY_BOOTUP&quot; = &quot;true&quot; ]; then echo &quot;尝试为 $RK_SYSTEM_CHECK_METHOD 构建 init&quot; if [ &quot;$RK_SYSTEM_CHECK_METHOD&quot; = &quot;DM-V&quot; ]; then SYSTEM_IMG=rootfs.squashfs else SYSTEM_IMG=$ROOTFS_IMG fi if [ ! -f &quot;$ROOTFS_DIR/$SYSTEM_IMG&quot; ]; then echo &quot;未生成 $SYSTEM_IMG...&quot; exit -1 fi $COMMON_DIR/mk-dm.sh $RK_SYSTEM_CHECK_METHOD \\ $ROOTFS_DIR/$SYSTEM_IMG ln -rsf $ROOTFS_DIR/security-system.img rockdev/rootfs.img fi # 完成构建 finish_build}build_recovery(){ # 检查是否启用了主备份(A/B)模式的SD卡更新 if [ &quot;$RK_UPDATE_SDCARD_ENABLE_FOR_AB&quot; = &quot;true&quot; ] ;then # 如果是启用了主备份(A/B)模式的SD卡更新，则使用相应的恢复配置 RK_CFG_RECOVERY=$RK_UPDATE_SDCARD_CFG_RECOVERY fi # 检查是否存在主备份(A/B)模式的包文件 if [ ! -z &quot;$RK_PACKAGE_FILE_AB&quot; ]; then # 如果存在主备份(A/B)模式的包文件，则直接返回，不进行构建 return 0 fi # 检查恢复配置是否已配置 check_config RK_CFG_RECOVERY || return 0 # 打印构建恢复镜像的提示信息 echo &quot;==========开始构建恢复镜像(buildroot)==========&quot; echo &quot;TARGET_RECOVERY_CONFIG=$RK_CFG_RECOVERY&quot; echo &quot;========================================&quot; # 设置目标目录 DST_DIR=.recovery # 构建恢复镜像(buildroot) /usr/bin/time -f &quot;用时 %E 构建恢复镜像(buildroot)&quot; \\ $COMMON_DIR/mk-buildroot.sh $RK_CFG_RECOVERY $DST_DIR # 打包恢复镜像 /usr/bin/time -f &quot;用时 %E 打包恢复镜像&quot; \\ $COMMON_DIR/mk-ramdisk.sh $DST_DIR/rootfs.cpio.gz \\ $DST_DIR/recovery.img \\ &quot;$CHIP_DIR/$RK_RECOVERY_FIT_ITS&quot; ln -rsf $DST_DIR/recovery.img rockdev/ # 为了安全起见，将恢复镜像复制到u-boot目录 cp rockdev/recovery.img u-boot/ # 完成构建 finish_build}# 构建PCBAbuild_pcba(){ # 检查PCBA配置是否已配置 check_config RK_CFG_PCBA || return 0 # 打印构建PCBA镜像的提示信息 echo &quot;==========开始构建PCBA镜像(buildroot)==========&quot; echo &quot;TARGET_PCBA_CONFIG=$RK_CFG_PCBA&quot; echo &quot;====================================&quot; # 设置目标目录 DST_DIR=.pcba # 构建PCBA镜像(buildroot) /usr/bin/time -f &quot;用时 %E 构建PCBA镜像(buildroot)&quot; \\ $COMMON_DIR/mk-buildroot.sh $RK_CFG_PCBA $DST_DIR # 打包PCBA镜像 /usr/bin/time -f &quot;用时 %E 打包PCBA镜像&quot; \\ $COMMON_DIR/mk-ramdisk.sh $DST_DIR/rootfs.cpio.gz \\ $DST_DIR/pcba.img ln -rsf $DST_DIR/pcba.img rockdev/ # 完成构建 finish_build}BOOT_FIXED_CONFIGS=&quot; CONFIG_BLK_DEV_DM # 启用设备映射（Device Mapper） CONFIG_DM_CRYPT # 启用设备映射加密模块 CONFIG_BLK_DEV_CRYPTOLOOP # 启用块设备加密循环设备 CONFIG_DM_VERITY # 启用设备映射完整性校验模块&quot;BOOT_OPTEE_FIXED_CONFIGS=&quot; CONFIG_TEE # 启用可信执行环境（Trusted Execution Environment） CONFIG_OPTEE # 启用OP-TEE（Open Portable Trusted Execution Environment）&quot;UBOOT_FIXED_CONFIGS=&quot; CONFIG_FIT_SIGNATURE # 启用FIT（Flattened Image Tree）签名支持 CONFIG_SPL_FIT_SIGNATURE # 启用SPL（Secondary Program Loader）FIT签名支持&quot;UBOOT_AB_FIXED_CONFIGS=&quot; CONFIG_ANDROID_AB # 启用Android A/B分区支持&quot;ROOTFS_UPDATE_ENGINEBIN_CONFIGS=&quot; BR2_PACKAGE_RECOVERY # 启用恢复系统包 BR2_PACKAGE_RECOVERY_UPDATEENGINEBIN&quot; # 启用恢复系统更新引擎二进制文件ROOTFS_AB_FIXED_CONFIGS=&quot; $ROOTFS_UPDATE_ENGINEBIN_CONFIGS # 包括ROOTFS_UPDATE_ENGINEBIN_CONFIGS中的配置 BR2_PACKAGE_RECOVERY_BOOTCONTROL&quot; # 启用恢复系统引导控制# 检查默认配置defconfig_check(){ # 1. defconfig 2. fixed config echo debug-$1 # 调试输出，显示传入的参数1 for i in $2 # 遍历参数2中的每个配置选项 do echo &quot;查找 $i&quot; # 输出正在查找的配置选项 result=$(cat $1 | grep &quot;${i}=y&quot; -w || echo &quot;未找到&quot;) # 在配置文件中查找配置选项，将结果存储在变量result中 if [ &quot;$result&quot; = &quot;未找到&quot; ]; then # 如果未找到配置选项 echo -e &quot;\\e[41;1;37m错误：在 $1 中未找到配置项 ${i} \\e[0m&quot; # 输出错误信息，配置项未找到 echo &quot;请确保您的配置文件包含以下列表中的选项&quot; echo &quot;---------------------------------------&quot; echo &quot;$2&quot; # 输出参数2中的配置选项列表 echo &quot;---------------------------------------&quot; return -1; # 返回-1表示检查失败 fi done return 0 # 返回0表示检查通过}# 从默认配置文件中查找字符串find_string_in_config(){ result=$(cat &quot;$2&quot; | grep &quot;$1&quot; || echo &quot;No found&quot;) # 在文件$2中查找字符串$1，将结果存储在变量result中 if [ &quot;$result&quot; = &quot;No found&quot; ]; then # 如果未找到字符串 echo &quot;Security: No found string $1 in $2&quot; # 输出错误信息，未找到字符串 return -1; # 返回-1表示未找到 fi return 0; # 返回0表示找到了字符串}check_security_condition(){ # check security enabled test -z &quot;$RK_SYSTEM_CHECK_METHOD&quot; &amp;&amp; return 0 if [ ! -d u-boot/keys ]; then echo &quot;ERROR: No root keys(u-boot/keys) found in u-boot&quot; echo &quot; Create it by ./build.sh createkeys or move your key to it&quot; return -1 fi if [ &quot;$RK_SYSTEM_CHECK_METHOD&quot; = &quot;DM-E&quot; ]; then if [ ! -f u-boot/keys/root_passwd ]; then echo &quot;ERROR: No root passwd(u-boot/keys/root_passwd) found in u-boot&quot; echo &quot; echo your root key for sudo to u-boot/keys/root_passwd&quot; echo &quot; some operations need supper user permission when create encrypt image&quot; return -1 fi if [ ! -f u-boot/keys/system_enc_key ]; then echo &quot;ERROR: No enc key(u-boot/keys/system_enc_key) found in u-boot&quot; echo &quot; Create it by ./build.sh createkeys or move your key to it&quot; return -1 fi BOOT_FIXED_CONFIGS=&quot;${BOOT_FIXED_CONFIGS} ${BOOT_OPTEE_FIXED_CONFIGS}&quot; fi echo &quot;check kernel defconfig&quot; defconfig_check \\ kernel/arch/$RK_KERNEL_ARCH/configs/$RK_KERNEL_DEFCONFIG \\ &quot;$BOOT_FIXED_CONFIGS&quot; if [ ! -z &quot;${RK_PACKAGE_FILE_AB}&quot; ]; then UBOOT_FIXED_CONFIGS=&quot;${UBOOT_FIXED_CONFIGS} ${UBOOT_AB_FIXED_CONFIGS}&quot; defconfig_check buildroot/configs/${RK_CFG_BUILDROOT}_defconfig &quot;$ROOTFS_AB_FIXED_CONFIGS&quot; fi echo &quot;check uboot defconfig&quot; defconfig_check u-boot/configs/${RK_UBOOT_DEFCONFIG}_defconfig &quot;$UBOOT_FIXED_CONFIGS&quot; if [ &quot;$RK_SYSTEM_CHECK_METHOD&quot; = &quot;DM-E&quot; ]; then echo &quot;check ramdisk defconfig&quot; defconfig_check buildroot/configs/${RK_CFG_BUILDROOT}_defconfig &quot;$ROOTFS_UPDATE_ENGINEBIN_CONFIGS&quot; fi echo &quot;check rootfs defconfig&quot; find_string_in_config &quot;BR2_ROOTFS_OVERLAY=\\&quot;.*board/rockchip/common/security-system-overlay.*&quot; &quot;buildroot/configs/${RK_CFG_BUILDROOT}_defconfig&quot; echo &quot;Security: finish check&quot;}# check_security_condition函数用于检查安全条件check_security_condition(){ # 检查是否启用了安全选项，如果未启用则直接返回0 test -z &quot;$RK_SYSTEM_CHECK_METHOD&quot; &amp;&amp; return 0 # 检查是否存在u-boot/keys目录，如果不存在则输出错误信息并返回-1 if [ ! -d u-boot/keys ]; then echo &quot;错误：在u-boot中未找到根密钥（u-boot/keys）&quot; echo &quot; 请通过./build.sh createkeys创建或将您的密钥移动到该目录中&quot; return -1 fi # 如果RK_SYSTEM_CHECK_METHOD的值为DM-E，则继续进行下一步检查 if [ &quot;$RK_SYSTEM_CHECK_METHOD&quot; = &quot;DM-E&quot; ]; then # 检查是否存在u-boot/keys/root_passwd文件，如果不存在则输出错误信息并返回-1 if [ ! -f u-boot/keys/root_passwd ]; then echo &quot;错误：在u-boot中未找到根口令（u-boot/keys/root_passwd）&quot; echo &quot; 请将您的根密钥（用于sudo）echo到u-boot/keys/root_passwd中&quot; echo &quot; 创建加密镜像时某些操作需要超级用户权限&quot; return -1 fi # 检查是否存在u-boot/keys/system_enc_key文件，如果不存在则输出错误信息并返回-1 if [ ! -f u-boot/keys/system_enc_key ]; then echo &quot;错误：在u-boot中未找到加密密钥（u-boot/keys/system_enc_key）&quot; echo &quot; 请通过./build.sh createkeys创建或将您的密钥移动到该目录中&quot; return -1 fi # 将BOOT_OPTEE_FIXED_CONFIGS添加到BOOT_FIXED_CONFIGS变量中 BOOT_FIXED_CONFIGS=&quot;${BOOT_FIXED_CONFIGS} ${BOOT_OPTEE_FIXED_CONFIGS}&quot; fi echo &quot;检查内核配置&quot; defconfig_check \\ kernel/arch/$RK_KERNEL_ARCH/configs/$RK_KERNEL_DEFCONFIG \\ &quot;$BOOT_FIXED_CONFIGS&quot; # 如果RK_PACKAGE_FILE_AB不为空，则进行下一步检查 if [ ! -z &quot;${RK_PACKAGE_FILE_AB}&quot; ]; then # 将UBOOT_AB_FIXED_CONFIGS添加到UBOOT_FIXED_CONFIGS变量中 UBOOT_FIXED_CONFIGS=&quot;${UBOOT_FIXED_CONFIGS} ${UBOOT_AB_FIXED_CONFIGS}&quot; # 检查buildroot/configs/${RK_CFG_BUILDROOT}_defconfig文件是否存在 defconfig_check buildroot/configs/${RK_CFG_BUILDROOT}_defconfig &quot;$ROOTFS_AB_FIXED_CONFIGS&quot; fi echo &quot;检查uboot配置&quot; defconfig_check u-boot/configs/${RK_UBOOT_DEFCONFIG}_defconfig &quot;$UBOOT_FIXED_CONFIGS&quot; # 如果RK_SYSTEM_CHECK_METHOD的值为DM-E，则继续进行下一步检查 if [ &quot;$RK_SYSTEM_CHECK_METHOD&quot; = &quot;DM-E&quot; ]; then echo &quot;检查ramdisk配置&quot; defconfig_check buildroot/configs/${RK_CFG_BUILDROOT}_defconfig &quot;$ROOTFS_UPDATE_ENGINEBIN_CONFIGS&quot; fi echo &quot;检查rootfs配置&quot; # 在buildroot/configs/${RK_CFG_BUILDROOT}_defconfig文件中查找字符串&quot;BR2_ROOTFS_OVERLAY=\\&quot;.*board/rockchip/common/security-system-overlay.*&quot; find_string_in_config &quot;BR2_ROOTFS_OVERLAY=\\&quot;.*board/rockchip/common/security-system-overlay.*&quot; &quot;buildroot/configs/${RK_CFG_BUILDROOT}_defconfig&quot; echo &quot;安全检查完成&quot;}# 清理build_cleanall(){ echo &quot;clean uboot, kernel, rootfs, recovery&quot; # 执行清理操作，清理u-boot、kernel、rootfs和recovery相关的内容 make -C u-boot distclean # 在u-boot目录中执行distclean命令，清理构建过程产生的临时文件和目标文件 make -C kernel distclean # 在kernel目录中执行distclean命令，清理构建过程产生的临时文件和目标文件 rm -rf buildroot/output # 删除buildroot/output目录，清理构建rootfs过程中生成的文件 rm -rf yocto/build/tmp yocto/build/*cache # 删除yocto/build/tmp目录和所有yocto/build/*cache目录，清理构建yocto过程中生成的临时文件和缓存文件 rm -rf debian/binary # 删除debian/binary目录，清理构建debian包时生成的二进制文件 finish_build # 调用finish_build函数，进行后续的清理和处理操作}build_firmware(){ ./mkfirmware.sh $BOARD_CONFIG # 运行mkfirmware.sh脚本，传递$BOARD_CONFIG参数，用于构建固件 finish_build # 调用finish_build函数，进行后续的清理和处理操作}build_updateimg(){ IMAGE_PATH=$TOP_DIR/rockdev # 设置IMAGE_PATH变量为$TOP_DIR/rockdev，用于存储生成的镜像文件路径 PACK_TOOL_DIR=$TOP_DIR/tools/linux/Linux_Pack_Firmware # 设置PACK_TOOL_DIR变量为$TOP_DIR/tools/linux/Linux_Pack_Firmware，用于存储打包工具的路径 cd $PACK_TOOL_DIR/rockdev # 进入$PACK_TOOL_DIR/rockdev目录 if [ -f &quot;$RK_PACKAGE_FILE_AB&quot; ]; then # 如果存在$RK_PACKAGE_FILE_AB文件 build_sdcard_package # 调用build_sdcard_package函数，构建SD卡包 build_otapackage # 调用build_otapackage函数，构建OTA包 cd $PACK_TOOL_DIR/rockdev # 返回$PACK_TOOL_DIR/rockdev目录 echo &quot;Make Linux a/b update_ab.img.&quot; source_package_file_name=`ls -lh package-file | awk -F ' ' '{print $NF}'` # 获取package-file的文件名 ln -fs &quot;$RK_PACKAGE_FILE_AB&quot; package-file # 创建软链接，将$RK_PACKAGE_FILE_AB链接到package-file ./mkupdate.sh # 运行mkupdate.sh脚本，生成update.img mv update.img $IMAGE_PATH/update_ab.img # 将生成的update.img移动到$IMAGE_PATH/update_ab.img ln -fs $source_package_file_name package-file # 创建软链接，将source_package_file_name链接到package-file else echo &quot;Make update.img&quot; if [ -f &quot;$RK_PACKAGE_FILE&quot; ]; then # 如果存在$RK_PACKAGE_FILE文件 source_package_file_name=`ls -lh package-file | awk -F ' ' '{print $NF}'` # 获取package-file的文件名 ln -fs &quot;$RK_PACKAGE_FILE&quot; package-file # 创建软链接，将$RK_PACKAGE_FILE链接到package-file ./mkupdate.sh # 运行mkupdate.sh脚本，生成update.img ln -fs $source_package_file_name package-file # 创建软链接，将source_package_file_name链接到package-file else ./mkupdate.sh # 运行mkupdate.sh脚本，生成update.img fi mv update.img $IMAGE_PATH # 将生成的update.img移动到$IMAGE_PATH fi finish_build # 调用finish_build函数，进行后续的清理和处理操作}# 编译ota的包build_otapackage(){ IMAGE_PATH=$TOP_DIR/rockdev # 设置IMAGE_PATH变量为$TOP_DIR/rockdev，用于存储生成的镜像文件路径 PACK_TOOL_DIR=$TOP_DIR/tools/linux/Linux_Pack_Firmware # 设置PACK_TOOL_DIR变量为$TOP_DIR/tools/linux/Linux_Pack_Firmware，用于存储打包工具的路径 echo &quot;Make ota ab update_ota.img&quot; cd $PACK_TOOL_DIR/rockdev # 进入$PACK_TOOL_DIR/rockdev目录 if [ -f &quot;$RK_PACKAGE_FILE_OTA&quot; ]; then # 如果存在$RK_PACKAGE_FILE_OTA文件 source_package_file_name=`ls -lh $PACK_TOOL_DIR/rockdev/package-file | awk -F ' ' '{print $NF}'` # 获取package-file的文件名 ln -fs &quot;$RK_PACKAGE_FILE_OTA&quot; package-file # 创建软链接，将$RK_PACKAGE_FILE_OTA链接到package-file ./mkupdate.sh # 运行mkupdate.sh脚本，生成update.img mv update.img $IMAGE_PATH/update_ota.img # 将生成的update.img移动到$IMAGE_PATH/update_ota.img ln -fs $source_package_file_name package-file # 创建软链接，将source_package_file_name链接到package-file fi finish_build # 调用finish_build函数，进行后续的清理和处理操作}# 编译sd卡镜像build_sdcard_package(){ check_config RK_UPDATE_SDCARD_ENABLE_FOR_AB || return 0 # 检查配置项 RK_UPDATE_SDCARD_ENABLE_FOR_AB，如果没有启用则返回0 local image_path=$TOP_DIR/rockdev # 设置image_path变量为$TOP_DIR/rockdev，用于存储生成的镜像文件路径 local pack_tool_dir=$TOP_DIR/tools/linux/Linux_Pack_Firmware # 设置pack_tool_dir变量为$TOP_DIR/tools/linux/Linux_Pack_Firmware，用于存储打包工具的路径 local rk_sdupdate_ab_misc=${RK_SDUPDATE_AB_MISC:=sdupdate-ab-misc.img} # 设置rk_sdupdate_ab_misc变量为RK_SDUPDATE_AB_MISC的值（默认为sdupdate-ab-misc.img） local rk_parameter_sdupdate=${RK_PARAMETER_SDUPDATE:=parameter-sdupdate.txt} # 设置rk_parameter_sdupdate变量为RK_PARAMETER_SDUPDATE的值（默认为parameter-sdupdate.txt） local rk_package_file_sdcard_update=${RK_PACKAGE_FILE_SDCARD_UPDATE:=sdcard-update-package-file} # 设置rk_package_file_sdcard_update变量为RK_PACKAGE_FILE_SDCARD_UPDATE的值（默认为sdcard-update-package-file） local sdupdate_ab_misc_img=$TOP_DIR/device/rockchip/common/images/$rk_sdupdate_ab_misc # 设置sdupdate_ab_misc_img变量为$TOP_DIR/device/rockchip/common/images/加上rk_sdupdate_ab_misc的值 local parameter_sdupdate=$TOP_DIR/device/rockchip/common/images/$rk_parameter_sdupdate # 设置parameter_sdupdate变量为$TOP_DIR/device/rockchip/common/images/加上rk_parameter_sdupdate的值 local recovery_img=$TOP_DIR/buildroot/output/$RK_UPDATE_SDCARD_CFG_RECOVERY/images/recovery.img # 设置recovery_img变量为$TOP_DIR/buildroot/output/加上RK_UPDATE_SDCARD_CFG_RECOVERY/images/recovery.img的值 if [ $RK_UPDATE_SDCARD_CFG_RECOVERY ]; then # 如果存在RK_UPDATE_SDCARD_CFG_RECOVERY配置项 if [ -f $recovery_img ]; then # 如果存在recovery_img文件 echo -n &quot;create recovery.img...&quot; # 输出提示信息 ln -rsf $recovery_img $image_path/recovery.img # 创建软链接，将recovery_img链接到$image_path/recovery.img else echo &quot;error: $recovery_img not found!&quot; # 输出错误信息 return 1 # 返回1表示出错 fi fi echo &quot;Make sdcard update update_sdcard.img&quot; # 输出提示信息 cd $pack_tool_dir/rockdev # 进入$pack_tool_dir/rockdev目录 if [ -f &quot;$rk_package_file_sdcard_update&quot; ]; then # 如果存在$rk_package_file_sdcard_update文件 if [ $rk_parameter_sdupdate ]; then # 如果存在$rk_parameter_sdupdate变量 if [ -f $parameter_sdupdate ]; then # 如果存在$parameter_sdupdate文件 echo -n &quot;create sdcard update image parameter...&quot; # 输出提示信息 ln -rsf $parameter_sdupdate $image_path/ # 创建软链接，将$parameter_sdupdate链接到$image_path/ fi fi if [ $rk_sdupdate_ab_misc ]; then # 如果存在$rk_sdupdate_ab_misc变量 if [ -f $sdupdate_ab_misc_img ]; then # 如果存在$sdupdate_ab_misc_img文件 echo -n &quot;create sdupdate ab misc.img...&quot; # 输出提示信息 ln -rsf $sdupdate_ab_misc_img $image_path/ # 创建软链接，将$sdupdate_ab_misc_img链接到$image_path/ fi fi source_package_file_name=`ls -lh $pack_tool_dir/rockdev/package-file | awk -F ' ' '{print $NF}'` # 获取$pack_tool_dir/rockdev/package-file的文件名 ln -fs &quot;$rk_package_file_sdcard_update&quot; package-file # 创建软链接，将$rk_package_file_sdcard_update链接到package-file ./mkupdate.sh # 运行mkupdate.sh脚本，生成update.img mv update.img $image_path/update_sdcard.img # 将生成的update.img移动到$image_path/update_sdcard.img ln -fs $source_package_file_name package-file # 创建软链接，将$source_package_file_name链接到package-file rm -f $image_path/$rk_sdupdate_abmisc $image_path/$rk_parameter_sdupdate $image_path/recovery.img # 删除$image_path/$rk_sdupdate_ab_misc、$image_path/$rk_parameter_sdupdate和$image_path/recovery.img文件 fi finish_build # 调用finish_build函数}build_save(){ IMAGE_PATH=$TOP_DIR/rockdev # 设置IMAGE_PATH变量为$TOP_DIR/rockdev，用于存储生成的镜像文件路径 DATE=$(date +%Y%m%d.%H%M) # 获取当前日期和时间，格式为YYYYMMDD.HHMM STUB_PATH=Image/&quot;$RK_KERNEL_DTS&quot;_&quot;$DATE&quot;_RELEASE_TEST # 设置STUB_PATH变量为Image/加上$RK_KERNEL_DTS、日期和_RELEASE_TEST STUB_PATH=&quot;$(echo $STUB_PATH | tr '[:lower:]' '[:upper:]')&quot; # 将STUB_PATH转换为大写字母 export STUB_PATH=$TOP_DIR/$STUB_PATH # 导出STUB_PATH变量为$TOP_DIR/加上$STUB_PATH export STUB_PATCH_PATH=$STUB_PATH/PATCHES # 导出STUB_PATCH_PATH变量为$STUB_PATH/PATCHES mkdir -p $STUB_PATH # 创建$STUB_PATH目录 # 生成补丁文件# .repo/repo/repo forall -c \\# &quot;$TOP_DIR/device/rockchip/common/gen_patches_body.sh&quot; # 复制补丁文件# yes | .repo/repo/repo manifest -r -o $STUB_PATH/manifest_${DATE}.xml mkdir -p $STUB_PATCH_PATH/kernel # 创建$STUB_PATCH_PATH/kernel目录 cp kernel/.config $STUB_PATCH_PATH/kernel # 复制kernel目录下的.config文件到$STUB_PATCH_PATH/kernel目录 cp kernel/vmlinux $STUB_PATCH_PATH/kernel # 复制kernel目录下的vmlinux文件到$STUB_PATCH_PATH/kernel目录 mkdir -p $STUB_PATH/IMAGES/ # 创建$STUB_PATH/IMAGES/目录 cp $IMAGE_PATH/* $STUB_PATH/IMAGES/ # 复制$IMAGE_PATH目录下的所有文件到$STUB_PATH/IMAGES/目录 # 保存构建命令信息 echo &quot;UBOOT: defconfig: $RK_UBOOT_DEFCONFIG&quot; &gt;&gt; $STUB_PATH/build_cmd_info # 将UBOOT的配置信息写入build_cmd_info文件 echo &quot;KERNEL: defconfig: $RK_KERNEL_DEFCONFIG, dts: $RK_KERNEL_DTS&quot; &gt;&gt; $STUB_PATH/build_cmd_info # 将KERNEL的配置信息写入build_cmd_info文件 echo &quot;BUILDROOT: $RK_CFG_BUILDROOT&quot; &gt;&gt; $STUB_PATH/build_cmd_info # 将BUILDROOT的配置信息写入build_cmd_info文件 finish_build # 调用finish_build函数}build_allsave(){ rm -fr $TOP_DIR/rockdev # 删除$TOP_DIR/rockdev目录及其内容 mkdir -p $TOP_DIR/rockdev # 创建$TOP_DIR/rockdev目录 build_all # 调用build_all函数，执行全部构建过程 build_firmware # 调用build_firmware函数，构建固件 build_updateimg # 调用build_updateimg函数，构建更新镜像 build_save # 调用build_save函数，保存构建过程中的相关文件 build_check_power_domain # 调用build_check_power_domain函数，检查电源域配置 finish_build # 调用finish_build函数}create_keys(){ test -d u-boot/keys &amp;&amp; echo &quot;ERROR: u-boot/keys has existed&quot; &amp;&amp; return -1 # 检查u-boot/keys目录是否已存在，如果存在则输出错误信息并返回-1 mkdir u-boot/keys -p # 创建u-boot/keys目录 ./rkbin/tools/rk_sign_tool kk --bits 2048 --out u-boot/keys # 使用rk_sign_tool工具生成密钥对，密钥长度为2048位，并存储在u-boot/keys目录下 ln -s private_key.pem u-boot/keys/dev.key # 创建符号链接将private_key.pem命名为u-boot/keys/dev.key ln -s public_key.pem u-boot/keys/dev.pubkey # 创建符号链接将public_key.pem命名为u-boot/keys/dev.pubkey openssl req -batch -new -x509 -key u-boot/keys/dev.key -out u-boot/keys/dev.crt # 使用openssl生成自签名证书，使用u-boot/keys/dev.key作为私钥，生成的证书存储在u-boot/keys/dev.crt中 openssl rand -out u-boot/keys/system_enc_key -hex 32 # 使用openssl生成32字节的随机数，并以十六进制格式存储在u-boot/keys/system_enc_key文件中}security_is_enabled(){ if [ &quot;$RK_RAMDISK_SECURITY_BOOTUP&quot; != &quot;true&quot; ]; then # 如果环境变量$RK_RAMDISK_SECURITY_BOOTUP不等于&quot;true&quot; echo &quot;No security paramter found in $BOARD_CONFIG&quot; # 输出错误信息，表示在$BOARD_CONFIG中未找到安全参数 exit -1 # 退出脚本，返回-1 fi}#=========================# build targets#=========================# OPTIONS=&quot;${@:-allsave}&quot;if [ -z &quot;$1&quot; ]; then titlestr=&quot;请选择一个选项&quot; # 菜单标题 backtitle=&quot;iTOP-RK3568构建脚本，http://www.topeet.com&quot; # 返回标题 menustr=&quot;编译镜像 | u-boot| 内核| recovery| buildroot | debian | yocto | all&quot; # 菜单选项 TTY_X=$(($(stty size | awk '{print $2}')-6)) # 确定终端宽度 TTY_Y=$(($(stty size | awk '{print $1}')-6)) # 确定终端高度 choose+=(&quot;uboot&quot; &quot;build_uboot&quot;) # 选项1: u-boot编译 choose+=(&quot;kernel&quot; &quot;build_kernel&quot;) # 选项2: 内核编译 choose+=(&quot;recovery&quot; &quot;build_recovery&quot;) # 选项3: recovery编译 choose+=(&quot;buildroot&quot; &quot;build_rootfs buildroot&quot;) # 选项4: 编译buildroot根文件系统 choose+=(&quot;debian&quot; &quot;build_rootfs debian&quot;) # 选项5: 编译Debian根文件系统 choose+=(&quot;yocto&quot; &quot;build_rootfs yocto&quot;) # 选项6: 编译Yocto根文件系统 choose+=(&quot;save&quot; &quot;build_save&quot;) # 选项7: 保存构建结果 choose+=(&quot;all&quot; &quot;build_all&quot;) # 选项8: 编译所有 OPTIONS=$(whiptail --title &quot;${titlestr}&quot; --backtitle &quot;${backtitle}&quot; --notags \\ --menu &quot;${menustr}&quot; &quot;${TTY_Y}&quot; &quot;${TTY_X}&quot; $((TTY_Y - 8)) \\ --cancel-button 退出 --ok-button 选择 &quot;${choose[@]}&quot; \\ 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3) # 使用whiptail创建菜单，并获取用户选择的选项else OPTIONS=&quot;${1}&quot;fi# 预处理选项unset POST_OPTIONSfor option in $OPTIONS; do case $option in BoardConfig*.mk) option=&quot;$CHIP_DIR/$option&quot; ;&amp; *.mk) CONF=$(realpath $option) echo &quot;切换到配置文件: $CONF&quot; if [ ! -f $CONF ]; then echo &quot;文件不存在!&quot; exit 1 fi ln -rsf $CONF $BOARD_CONFIG ;; lunch) choose_board ;; kernel-4.4|kernel-4.19|kernel-5.10) RK_KERNEL_VERSION=${option#kernel-} ;; *) POST_OPTIONS=&quot;$POST_OPTIONS $option&quot;;; esacdoneif [ -r &quot;$BOARD_CONFIG&quot; ]; then # 如果配置文件存在且可读 source $BOARD_CONFIG # 导入配置文件else choose_board # 否则，调用选择板型函数fiif [ -d &quot;$CHIP_DIR/build-hooks/&quot; ]; then # 如果存在构建钩子目录 for hook in $(find &quot;$CHIP_DIR/build-hooks&quot; -name &quot;*.sh&quot;); do # 遍历所有以.sh结尾的文件 source &quot;$hook&quot; # 导入每个构建钩子脚本 donefi# 回退到当前内核版本RK_KERNEL_VERSION=${RK_KERNEL_VERSION:-$(kernel_version kernel/)}# 回退到5.10内核版本RK_KERNEL_VERSION=${RK_KERNEL_VERSION:-5.10}# 更新内核if [ &quot;$(kernel_version kernel/)&quot; != &quot;$RK_KERNEL_VERSION&quot; ]; then # 如果当前内核版本与指定版本不一致 KERNEL_DIR=kernel-$RK_KERNEL_VERSION # 设置新的内核目录名称 echo &quot;切换到 $KERNEL_DIR&quot; if [ ! -d &quot;$KERNEL_DIR&quot; ]; then # 如果新的内核目录不存在 echo &quot;不存在！&quot; exit 1 fi rm -rf kernel # 删除旧的内核软链接 ln -rsf $KERNEL_DIR kernel # 创建新的内核软链接fi# 后续选项处理for option in $POST_OPTIONS; do echo &quot;处理选项: $option&quot; case $option in all) build_all ;; # 执行编译所有选项 save) build_save ;; # 执行保存构建结果选项 allsave) build_allsave ;; # 执行编译所有并保存结果选项 cleanall) build_cleanall ;; # 执行清理所有构建结果选项 firmware) build_firmware ;; # 执行编译固件选项 updateimg) build_updateimg ;; # 执行编译更新镜像选项 otapackage) build_otapackage ;; # 执行编译OTA包选项 sdpackage) build_sdcard_package ;; # 执行编译SD卡镜像选项 spl) build_spl ;; # 执行编译SPL选项 uboot) build_uboot ;; # 执行编译u-boot选项 uefi) build_uefi ;; # 执行编译UEFI选项 loader) build_loader ;; # 执行编译loader选项 kernel) build_kernel ;; # 执行编译内核选项 wifibt) # 执行编译Wi-Fi和蓝牙固件选项 build_wifibt $2 $3 # 调用编译Wi-Fi和蓝牙固件的函数，并传递参数$2和$3 exit 1 ;; # 退出脚本 modules) build_modules ;; # 执行编译内核模块选项 rootfs) build_rootfs ;; # 执行编译根文件系统选项 buildroot|debian|yocto) build_rootfs $option ;; # 执行编译指定根文件系统选项 pcba) build_pcba ;; # 执行编译PCBA选项 recovery) build_recovery ;; # 执行编译recovery选项 info) build_info ;; # 执行显示构建信息选项 createkeys) create_keys ;; # 执行生成密钥选项 security_boot) # 执行启用安全引导的选项 security_is_enabled # 检查安全引导是否已启用 build_rootfs # 编译根文件系统 build_uboot boot # 编译启动引导程序 ;; security_uboot) # 执行启用安全引导的u-boot选项 security_is_enabled # 检查安全引导是否已启用 build_uboot uboot # 编译u-boot引导程序 ;; security_recovery) # 执行启用安全引导的recovery选项 security_is_enabled # 检查安全引导是否已启用 build_recovery # 编译recovery build_uboot recovery # 编译recovery引导程序 ;; security_check) check_security_condition ;; # 执行检查安全条件选项 security_rootfs) # 执行启用安全引导的根文件系统选项 security_is_enabled # 检查安全引导是否已启用 build_rootfs # 编译根文件系统 build_uboot # 编译u-boot引导程序 echo &quot;请更新 rootfs.img / boot.img&quot; ;; *) usage ;; # 显示用法 esacdone","link":"/2023/09/10/12%20%E7%91%9E%E8%8A%AF%E5%BE%AEbuild-sh%E8%84%9A%E6%9C%AC%E5%88%86%E6%9E%90/"},{"title":"cmake 基础课","text":"一、准备知识1.1 C++的编译过程 -E 仅预处理；不编译、汇编或链接。 -S 仅编译；不汇编或链接。 -c 编译和汇编，但不链接。 -o 将输出放入中。 C++源代码的编译过程 预处理：在预处理阶段，C++源代码中的预处理指令会被处理，包括宏展开和条件编译等。在此阶段，需要添加所有头文件的引用路径。 123# 将xx.cpp源文件预处理为xx.i文件（文本文件）g++ -E main.cpp -o main.i``` 编译：编译阶段会对预处理后的代码进行语法检查和编译，将代码翻译为汇编语言文件。 123# 将xx.i文件编译为xx.s的汇编文件（文本文件）g++ -S main.i -o main.s``` 汇编：汇编阶段将汇编语言文件转换为二进制格式的目标文件。 123# 将xx.s文件汇编为xx.o的二进制目标文件g++ -c main.s -o main.o``` 链接：链接阶段将目标文件与所依赖的库文件进行关联或组装，生成可执行文件。 123# 将目标文件进行链接，生成可执行程序g++ main.o -o main``` 1.2 静态链接库和动态链接库静态链接库和动态链接库的区别在于链接的阶段不同。 静态链接库的名称通常以.a结尾（表示archive library），它在编译阶段进行链接。如果一个工程依赖于静态链接库，那么生成的可执行文件或库会将静态链接库.a打包到输出文件中，因此生成的文件比较大。在运行时，不再需要单独的库文件。 动态链接库的链接发生在程序的执行过程中，它在编译阶段仅进行链接检查，而不进行真正的链接过程。动态链接库的后缀名通常为.so（表示shared object，在Linux上）或.dylib（在macOS上）。动态链接库在加载后，在内存中只保存一份拷贝。多个程序依赖于它时，不会重复加载和拷贝，节省了内存空间。 1.3 为什么需要CMake1.3.1 g++命令行编译当编译hello_world.cpp`文件时，可以使用以下命令进行编译和运行： 1g++ main.cpp -o main 如果需要引入外部库可以使用以下方法进行编译： 方法一：使用-lgflags参数进行链接** 首先，需要安装gflags库： 12345678sudo apt-get install libgflags-dev libgflags2.2```然后，使用以下命令进行编译：````bashg++ main.cpp -lgflags -o main``` 方法二：使用pkg-config进行库文件和头文件路径查找** 首先，需要安装pkg-config工具： 12345678910sudo apt-get install pkg-config```然后，使用以下命令进行编译：````bashg++ main.cpp `pkg-config --cflags --libs gflags` -o main```这里，`pkg-config --cflags --libs gflags`命令用于查找`gflags`库的头文件和库文件路径。 编译完成后，可以使用以下命令运行可执行文件： 1./main --age 31 --name alice 有时候，在编译时不需要手动添加头文件或链接库路径，因为g++可以在默认的查询路径中找到这些库。然而，当项目文件和引入的外部库变得较多时，使用命令行编译会变得冗长且不便于调试和编辑。通常，在测试单个文件时可以使用命令行编译，但不推荐在实际项目中使用命令行编译方式。 1.3.2 CMake简介在实际工作中，推荐使用CMake来构建C++项目。CMake是一个开源的跨平台工具，用于构建、测试和软件打包。 CMake具有以下特性： 自动搜索依赖项：CMake具有自动搜索可能需要的程序、库和头文件的能力，可以简化依赖项的配置过程。 独立的构建目录：CMake支持使用独立的构建目录（例如build目录），这样可以安全地清理构建产生的中间文件和输出文件，不会污染源代码目录。 自定义命令：CMake支持定义复杂的自定义命令，例如下载文件、生成各种文件等，可以满足项目构建过程中的特定需求。 自定义配置：CMake支持根据需求进行自定义配置，可以选择性地启用或禁用特定的组件或功能。 文本文件生成工作区和项目：CMake使用简单的文本文件（CMakeLists.txt）来描述项目的配置和构建规则，可以根据这些文件自动生成工作区和项目。 文件依赖项自动生成和并行构建：CMake可以在主流平台上自动生成文件之间的依赖关系，从而使构建过程更高效。同时，CMake支持并行构建，可以加快构建速度。 支持多种IDE：CMake几乎支持所有主流的集成开发环境（IDE），包括Visual Studio、Xcode、Eclipse等，可以方便地在不同的开发环境中进行项目开发和调试。 二、CMake基础知识2.1 安装在Ubuntu上安装CMake可以使用以下命令： 1sudo apt install cmake -y 这将使用apt包管理器自动安装CMake。 如果你想编译安装特定版本的CMake，可以按照以下步骤操作： 克隆CMake的源代码库： 1234git clone -b v3.25.1 https://github.com/Kitware/CMake.gitcd CMake这里以安装版本3.25.1为例，你可以将`v3.25.1`替换为你想要安装的特定版本。 配置和编译CMake： 1234./bootstrap --prefix=&lt;安装路径&gt;make你可以使用`--prefix`选项来指定安装路径，或者省略`--prefix`以安装到默认路径。 安装CMake： 123sudo make install这将以管理员权限安装CMake到系统中。 安装完成后，你可以验证CMake的安装版本： 1cmake --version 该命令将显示CMake的版本信息，确认安装成功与否。 2.2 第一个CMake例子配置： 使用cmake命令进行配置，其中-S选项指定源码目录，-B选项指定构建目录。在终端中执行以下命令： 123cmake -S . -B build这将在当前目录下执行CMake配置，并将生成的构建系统文件放在名为`build`的目录中。 生成： 使用cmake --build命令进行生成，其中--build选项指定构建目录。在终端中执行以下命令： 123cmake --build build这将在`build`目录中执行构建步骤，生成可执行文件。 运行： 使用以下命令运行生成的可执行文件： 123./build/first_cmake这将执行生成的可执行文件。 2.3 语法基础2.3.1 指定版本在CMake中，可以使用cmake_minimum_required命令指定当前项目所需的最低CMake版本。它的语法如下： 1cmake_minimum_required(VERSION &lt;version_number&gt;) 其中，&lt;version_number&gt;是所需的最低CMake版本号。在这个命令之后，CMake将会检查系统中安装的CMake版本是否满足这个要求，如果不满足则会产生错误。 例如，如果要指定最低的CMake版本为3.10，可以在CMakeLists.txt文件中添加以下命令： 1cmake_minimum_required(VERSION 3.10) 这样，CMake将会检查系统中的CMake版本是否大于等于3.10。 除了cmake_minimum_required命令，CMake中还有其他类似的命令，它们不区分大小写，并且有许多关键字来引导命令的参数输入，类似于函数的参数传递。这些命令使用的关键字在CMake中是不区分大小写的。 2.3.2 设置项目在CMakeLists.txt文件的开头，通常会使用project命令来指定项目的名称、版本、描述和所使用的语言。project命令的语法如下： 12345project(ProjectName [VERSION &lt;version_number&gt;] [DESCRIPTION &quot;project_description&quot;] [LANGUAGES &lt;language&gt;]) 其中，ProjectName是项目的名称，在例子中使用的是”first_cmake”。VERSION关键字后面是项目的版本号，可以是任意格式的版本号，例如”1.0.0”。DESCRIPTION关键字后面是项目的描述，可以是一个字符串。LANGUAGES关键字后面是项目所使用的语言，这里使用的是”Cxx”，表示C++。 示例中的project命令： 12345project(first_cmake VERSION 1.0.0 DESCRIPTION &quot;项目描述&quot; LANGUAGES Cxx) 这样，通过project命令，可以在CMakeLists.txt中指定项目的基本信息，方便管理和描述项目。 2.3.3 添加可执行文件目标使用了add_executable命令来定义一个可执行文件。该命令的语法如下： 1add_executable(&lt;target_name&gt; &lt;source_files&gt;) 其中，&lt;target_name&gt;是最终生成的可执行文件名，也是在CMake中定义的目标（Target）名。&lt;source_files&gt;是编译目标所使用的源文件。 在你提供的例子中，使用了add_executable命令来定义一个名为first_cmake的目标，并指定了一个源文件main.cpp。这意味着在编译时，会将main.cpp编译为一个可执行文件，该文件的名称将是first_cmake。 示例中的add_executable命令： 1add_executable(first_cmake main.cpp) 通过add_executable命令，可以在CMakeLists.txt中定义编译目标，并指定相应的源文件。这样，CMake将会根据这些定义生成相应的构建规则和编译指令。 2.3.4 生成静态库并链接A. 生成静态库： 在account_dir/CMakeLists.txt中，使用add_library命令来生成静态库。该命令的语法如下： 1add_library(&lt;library_name&gt; &lt;library_type&gt; &lt;source_files&gt;) 其中，&lt;library_name&gt;是最终生成的库文件名，例如在Linux下会生成libAccount.a。 &lt;library_type&gt;用于指定链接库的类型，可以是动态链接库（SHARED）或静态链接库（STATIC）。 &lt;source_files&gt;是需要用到的源文件。 例如，在account_dir/CMakeLists.txt中，使用add_library命令生成一个名为Account的静态库，其包含了Account.cpp和Account.h两个源文件。示例命令如下： 1add_library(Account STATIC Account.cpp Account.h) 这将生成一个静态库文件libAccount.a。 B. 链接： 在test_account/CMakeLists.txt中，可以通过target_link_libraries命令将生成的静态库链接到目标可执行文件中。该命令的语法如下： 1target_link_libraries(&lt;target_name&gt; &lt;library_name&gt;) 其中，&lt;target_name&gt;是目标可执行文件的名称，&lt;library_name&gt;是要链接的库文件名。 例如，在test_account/CMakeLists.txt中，假设有一个目标可执行文件名为test_account，需要链接生成的静态库Account。示例命令如下： 1target_link_libraries(test_account Account) 这样，生成的可执行文件test_account将会链接静态库Account。 2.3.5 生成动态库并连接A. 生成动态库： 在account_dir/CMakeLists.txt中，使用add_library命令来生成动态库。与生成静态库不同的是，需要将&lt;library_type&gt;参数设置为SHARED，表示生成动态链接库。 示例命令如下： 1add_library(Account SHARED Account.cpp Account.h) 这将生成一个动态库文件libAccount.so。 B. 链接： 链接过程与生成静态库时的操作相同，使用target_link_libraries命令将动态库链接到目标可执行文件中。 示例命令如下： 1target_link_libraries(test_account Account) 这样，生成的可执行文件test_account将会链接动态库Account。 2.3.6 CMake中的PUBLIC、PRIVATE、INTERFACE在CMake中，可以使用target_...()系列命令来操作目标（Target）。这些命令通常支持通过PUBLIC、PRIVATE、INTERFACE关键字来控制属性的传播。 以target_link_libraries(A B)为例，下面是对这些关键字的理解： PRIVATE：依赖项B仅链接到目标A。如果有目标C链接了目标A，目标C不会链接目标B。 INTERFACE：依赖项B并不链接到目标A。如果有目标C链接了目标A，目标C会链接目标B。 PUBLIC：依赖项B链接到目标A。如果有目标C链接了目标A，目标C也会链接目标B。 可以将其类比为一个散烟的比方： PRIVATE：就是自己抽烟，不给别人抽。 INTERFACE：就是自己不抽烟，给别人抽。 PUBLIC：就是自己抽烟，也给别人抽。 从使用的角度来看，假设有目标C链接了目标A： 如果目标B仅用于目标A的实现，并且不在头文件中提供给目标C使用，可以使用PRIVATE。 如果目标B不用于目标A的实现，仅在头文件中作为接口给目标C使用，可以使用INTERFACE。 如果目标B既用于目标A的实现，也在头文件中提供给目标C使用，可以使用PUBLIC。 以下是一个示例： 123456789# 创建库add_library(c c.cpp)add_library(D d.cpp)add_library(B b.cpp)# 使用target_link_libraries命令进行链接target_link_libraries(A PRIVATE B)target_link_libraries(A INTERFACE C)target_link_libraries(A PUBLIC D) 在上述示例中，目标A通过target_link_libraries命令链接了目标B、C和D，使用了不同的传播属性。具体属性的选择取决于目标之间的关系和使用需求。 2.3.7 变量在CMake中，你可以使用message命令输出消息并进行变量的操作和设置。 以下是一些常见的用法： 1.输出消息：使用message命令可以输出消息到CMake的输出。 1message(&quot;输出消息&quot;) 2.消息拼接：使用message命令可以将多个消息进行拼接输出。 1message(&quot;输出1&quot; &quot;输出2&quot; &quot;输出3&quot;) # 会进行拼接输出 3.设置变量：使用set命令可以设置变量的值。 1234set(VAR1 &quot;变量1&quot;)message(&quot;VAR1=&quot; ${VAR1}) # 外部访问message(&quot;输出变量VAR1:${VAR1}&quot;) # 内部拼接message(&quot;\\${VAR1}=${VAR1}&quot;) # 使用\\转义 4.删除变量：使用unset命令可以删除变量。 12unset(VAR1) # 删除变量message(&quot;\\${VAR1}=${VAR1}&quot;) # 删除变量后，输出为空 5.设置变量缓存：使用set命令的CACHE选项可以设置一个变量的缓存，可以通过命令行的-D参数来修改该变量的值。 12set(CACHE_VARIABLE_TEST &quot;原始值&quot; CACHE STRING &quot;变量缓存的描述&quot;)message(&quot;变量缓存的值:${CACHE_VARIABLE_TEST}&quot;) 6.常见的内置变量：CMake提供了一些内置的变量，用于获取构建系统的信息和配置 第一类: 提供信息的变量 PROJECT_NAME：项目名称，表示当前CMake项目的名称。 1message(&quot;${PROJECT_NAME}&quot;) CMAKE_SOURCE_DIR：源码目录，表示当前CMake项目的根源码目录。 1message(&quot;${CMAKE_SOURCE_DIR}&quot;) CMAKE_BINARY_DIR：编译目录，表示当前CMake项目的编译输出目录。 1message(&quot;${CMAKE_BINARY_DIR}&quot;) CMAKE_CURRENT_LIST_FILE：当前CMakeLists.txt文件路径，表示当前正在处理的CMakeLists.txt文件的完整路径。 1message(&quot;${CMAKE_CURRENT_LIST_FILE}&quot;) 这些变量提供了与项目、目录结构和文件相关的信息。 第二类: 控制CMake运行的变量 CMake中的变量通常是根据构建选项进行命名的，例如BUILD_SHARED_LIBS。这些变量用于控制CMake的运行和构建过程。 第三类: 描述系统的变量 WIN32：表示当前操作系统是否为Windows。 1message(&quot;是否是Windows系统: ${WIN32}&quot;) UNIX：表示当前操作系统是否为类Unix（包括Linux、macOS等）。 1message(&quot;是否是Unix系统: ${UNIX}&quot;) CMAKE_SYSTEM_NAME：系统名称，表示当前操作系统的名称。 1message(&quot;系统名称: ${CMAKE_SYSTEM_NAME}&quot;) 这些变量用于描述当前操作系统的一些信息，以便在构建过程中进行条件判断和配置。 2.3.8 include引入其他代码2.3.9 条件控制CMake提供了条件控制的语法和关键词，使得你可以根据条件来控制构建过程中的行为。以下是一些常用的条件控制关键词和语法： if (variable)：当变量的值为真时，执行相应的代码块。 123if (MY_VARIABLE) # 当MY_VARIABLE为真时执行的代码块endif() else()：在if条件为假时执行的代码块。 12345if (MY_VARIABLE) # 当MY_VARIABLE为真时执行的代码块else() # 当MY_VARIABLE为假时执行的代码块endif() 真值常量：ON、YES、TRUE、Y、1、非零数字等。 123if (MY_VARIABLE STREQUAL &quot;ON&quot;) # 当MY_VARIABLE的值为真时执行的代码块endif() 假值常量：OFF、NO、FALSE、N、0、空字符串、NOTFOUND等。 123if (MY_VARIABLE STREQUAL &quot;OFF&quot;) # 当MY_VARIABLE的值为假时执行的代码块endif() 关键词：NOT、TARGET、EXISTS (file)、DEFINED等，可以与条件一起使用。 123if (NOT TARGET MyTarget) # 当MyTarget不存在时执行的代码块endif() 逻辑运算符：AND、OR用于组合多个条件。 1234567if (CONDITION1 AND CONDITION2) # 当CONDITION1和CONDITION2同时为真时执行的代码块endif()if (CONDITION1 OR CONDITION2) # 当CONDITION1或CONDITION2至少一个为真时执行的代码块endif() MATCHES (regular expression)：使用正则表达式进行匹配。 123if (MY_VARIABLE MATCHES &quot;^prefix.*&quot;) # 当MY_VARIABLE以&quot;prefix&quot;开头时执行的代码块endif() VERSION LESS、VERSION LESS_EQUAL：用于比较版本号。 123if (MY_VERSION VERSION LESS 2.0) # 当MY_VERSION小于2.0时执行的代码块endif() 通过这些条件控制关键词和语法，你可以根据不同的条件来执行不同的代码块，从而实现更灵活和可配置的构建过程。你可以根据具体的需求选择适当的条件控制方式，并结合变量、关键词和运算符来编写CMake脚本。 2.3.10 CMake分步编译首先，你使用以下命令查看所有的目标： 1cmake --build . --target help 这将列出项目中可用的目标列表，包括默认目标”all”、”clean”、”depend”、”rebuild_cache”、”edit_cache”以及其他一些目标。 接下来，你执行以下命令进行预处理： 1cmake --build . --target main.i 这将对”main.cpp”源文件进行预处理，并将预处理结果保存在”CMakeFiles/steps_demo.dir/main.cpp.i”文件中。 然后，你执行以下命令进行编译： 1cmake --build . --target main.sI 这将将”main.cpp”源文件编译为汇编代码，并将汇编代码保存在”CMakeFiles/steps_demo.dir/main.cpp.s”文件中。 接着，你执行以下命令进行汇编： 1cmake --build . --target main.o 这将将汇编代码编译为目标文件，并将目标文件保存为”CMakeFiles/steps_demo.dir/main.cpp.o”。 最后，你执行以下命令进行链接： 1cmake --build . 这将扫描依赖项并链接生成最终的可执行文件”steps_demo”。 最后，你执行以下命令运行可执行文件： 1./steps_demo 这将运行生成的可执行文件。 2.3.11 生成器表达式生成器表达式是CMake中一种用于在生成构建系统时根据不同配置动态生成特定内容的表达式。它可以让代码更加精简和灵活。下面是几种常用的生成器表达式类型： 条件表达式：$&lt;condition:true_string&gt;。当条件为真时，返回true_string，否则返回空字符串。 123$&lt;0:TEST&gt; # 返回空字符串$&lt;1:TEST&gt; # 返回&quot;TEST&quot;$&lt;$&lt;BOOL:TRUE&gt;:TEST&gt; # 返回&quot;TEST&quot; 变量查询（Variable-Query）：通过查询变量来获取动态的值。 12$&lt;TARGET_EXISTS:target&gt; # 判断目标是否存在$&lt;CONFIG:Debug&gt; # 判断当前构建类型是否为Debug 目标查询（Target-Query）：通过查询目标来获取相关的信息。 12$&lt;TARGET_FILE:target&gt; # 获取目标的文件路径$&lt;TARGET_FILE_NAME:target&gt; # 获取目标的文件名 输出相关表达式：用于在不同的构建环节使用不同的参数。比如，在install和build阶段使用不同的参数。 123456add_library(Foo ...)target_include_directories(Foo PUBLIC $&lt;$&lt;CONFIG:Debug&gt;:${DEBUG_INCLUDES}&gt; $&lt;$&lt;CONFIG:Release&gt;:${RELEASE_INCLUDES}&gt;) 在上述示例中，根据不同的构建配置（Debug或Release），生成器表达式选择性地包含不同的头文件路径。 需要注意的是，生成器表达式在生成构建系统时被展开，因此无法通过message命令直接打印。你可以使用类似file(GENERATE OUTPUT &quot;./generator_test.txt&quot; CONTENT &quot;$&lt;$&lt;BOOL:TRUE&gt;:TEST&gt;&quot;)的方式将生成器表达式的结果写入文件，以间接测试生成器表达式的值。 2.3.12 函数和宏12345678910# 定义一个宏macro(my_macro) message(&quot;宏内部的信息&quot;) set(macro_var &quot;宏内部变量test&quot;)endmacro()# 定义一个函数function(second_func arg1 arg2) message(&quot;第一个参数: ${arg1}，第二个参数: ${arg2}&quot;)endfunction() 在这个示例中，my_macro是一个没有参数的宏，它在宏内部输出一条信息，并设置了一个变量macro_var的值。 second_func是一个函数，它有两个参数arg1和arg2。在函数内部，它输出了两个参数的值。 你可以在CMakeLists.txt文件中使用这些宏和函数，例如： 12345# 调用宏my_macro()# 调用函数second_func(&quot;Hello&quot; &quot;World&quot;) 当你运行CMake生成构建系统时，你将看到宏内部的信息输出，并且可以访问在宏或函数内部定义的变量。函数将输出参数的值。 请注意，宏和函数的定义需要在CMakeLists.txt文件的适当位置进行，并且在调用它们之前必须先定义它们。 2.3.13 设置安装install命令用于设置安装规则，将目标文件和文件夹安装到指定的位置。下面是你提供的代码的解释： 123456install(TARGETS instal_demo slib dlib RUNTIME DESTINATION bin # 可执行文件安装路径 LIBRARY DESTINATION lib # 动态库安装路径 ARCHIVE DESTINATION lib # 静态库安装路径 PUBLIC_HEADER DESTINATION include # 公共头文件安装路径) 在上述代码中，install命令指定了要安装的目标文件列表，其中包括instal_demo、slib和dlib。 接下来，通过指定不同的DESTINATION参数，定义了目标文件在安装过程中的安装路径： RUNTIME DESTINATION bin：指定可执行文件的安装路径为bin目录。 LIBRARY DESTINATION lib：指定动态库的安装路径为lib目录。 ARCHIVE DESTINATION lib：指定静态库的安装路径为lib目录。 PUBLIC_HEADER DESTINATION include：指定公共头文件的安装路径为include目录。 根据你的需求，这些目标文件将被安装到指定的目录中。 请注意，安装路径是相对于安装目录的，因此你需要确保安装目录在运行make install时正确设置。 要解决在安装后无法找到动态库的问题，可以使用set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE)和set(CMAKE_INSTALL_RPATH &quot;${CMAKE_INSTALL_PREFIX}/lib&quot;)来设置RPATH。 下面是相应的代码： 12set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE)set(CMAKE_INSTALL_RPATH &quot;${CMAKE_INSTALL_PREFIX}/lib&quot;) set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE)指示在构建过程中使用与安装RPATH相同的RPATH。这样，在构建时就可以正确地查找和链接动态库。 set(CMAKE_INSTALL_RPATH &quot;${CMAKE_INSTALL_PREFIX}/lib&quot;)将安装RPATH设置为${CMAKE_INSTALL_PREFIX}/lib，其中${CMAKE_INSTALL_PREFIX}是安装目录的路径。这将导致在安装时设置RPATH，使得安装后的可执行文件可以在${CMAKE_INSTALL_PREFIX}/lib目录中正确地查找和加载动态库。 通过使用这两个设置，你可以解决在安装后无法找到动态库的问题。确保将其放置在CMakeLists.txt文件中的合适位置，并根据实际情况调整${CMAKE_INSTALL_PREFIX}/lib路径，以匹配你的安装目录结构。 2.3.14 寻找依赖find_package对于大多数支持CMake的项目来说，可以使用find_package命令来查找对应的依赖库。通常情况下，如果找到了库，会设置以下变量（这些变量由库的作者设置）： &lt;LibaryName&gt;_FOUND：表示是否找到库。 &lt;LibaryName&gt;_INCLUDE_DIR：表示库的头文件目录。 &lt;LibaryName&gt;_LIBRARIES：表示库的库文件目录。 如果你编写了一个新的函数库，并希望其他项目可以通过find_package引用它，你可以使用以下两种方法： 编写一个Find&lt;LibraryName&gt;.cmake文件：适用于导入非CMake安装的项目。 你可以编写一个名为Find&lt;LibraryName&gt;.cmake的文件，并将其放置在CMake的Modules目录或项目的特定目录中。该文件应包含查找和设置相关变量的逻辑。其他项目可以通过find_package命令来引用这个自定义的查找文件，从而找到并使用你的库。 附件: 15.custom_find 使用install安装并生成&lt;LibraryName&gt;Config.cmake文件：适用于导入你自己开发的CMake项目。 在你的库项目中，可以使用install命令将库文件安装到指定位置，并生成&lt;LibraryName&gt;Config.cmake文件。该文件应包含设置变量和导出目标的逻辑。其他项目可以通过find_package命令找到并使用你的库。 ==现在只是简单的写了一下学习的内容，但是对于很多内容还并不是很熟悉，一切都要等到最后实战的时候==","link":"/2023/09/03/21%20cmake-%E5%9F%BA%E7%A1%80%E8%AF%BE/"},{"title":"windows搭建hexo","text":"Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 [Markdown]Daring Fireball: Markdown )（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 Hexo 官方中文网站: Hexo 第一章 前期准备1.1 安装前所需环境介绍安装 Hexo 之前，需要确保您的 PC 中已经安装以下工具: Node.js https://nodejs.org/en Git https://git-scm.com/如果您的电脑已经具备所需工具，那么您可以直接进入第二章开始安装 Hexo 了。 如果您还未安装这两款工具，那么请按照以下步骤进行安装。 1.2 安装 Git官方下载地址: https://git-scm.com/注意事项: 建议选择 64-bit Git for Windows Setup，并且安装时要勾选 Add to PATH 选项 win + R 在命令行输入cmd进入终端模式，输入下面指令，当显示版本则安装成功git -v 1.3 安装 Node.js官方下载地址: https://nodejs.org/en注意事项: 使用 Node.js 官方安装程序时，请确保勾选 Add to PATH 选项（默认已勾选） win + R 在命令行输入cmd进入终端模式，输入下面指令，当显示版本则安装成功node –version 至此，您已经完成了安装 Hexo 所需的所有额外环境，接下来就可以安装 Hexo 了。 第二章 安装 Hexo2.1 安装 cnpm当您安装 Node.js 之后，便可以在命令行中通过 node install 命令安装您想要的程序了。但本文推荐使用 cnpm 安装 Hexo，所以需要先通过 npm install 安装 cnpm。 命令: 1npm install -g cnpm --registry==https://registry.npm.taobao.org 说明: -g 表示进行全局安装，–registry==https://registry.npm.taobao.org 表示使用淘宝镜像安装 cnpm 安装后验证: 在 cmd 中输入命令 cnpm -v, 可查看 cnpm 版本 2.2 安装 Hexo命令: 1cnpm install -g hexo-cli 说明: -g 表示全局安装，hexo-cli 为所安装的包安装后验证: 在 cmd 中输入命令 hexo -v, 可查看 hexo 版本 2.3 注意事项建议永远安装最新版本的 Hexo，以及 [推荐的 Node.js 版本](文档 | Hexo )。至此，您已成成功安装了 Hexo，接下来进入 Github 的配置吧! 第三章 配置 Github如果您还没有 Gihub 账户，请注册一个 Github 账户吧! 3.1 在 Github 上创建仓库新建一个名为: http://username.github.io 的仓库(username 为您的 Github 用户名)比如，如果您的 github 用户名是 test，那么您就新建名为 http://test.github.io 的仓库（必须是您的用户名，其它名称无效），将来你的网站访问地址就是 https://test.github.io 了。由此可见，每一个 github 账户最多只能创建一个这样可以直接使用域名访问的仓库。 3.2 配置 SSH 免密登录为什么要配置这个呢？因为您提交代码肯定要拥有您的 github 权限才可以，但是直接使用用户名和密码太不安全了，所以我们使用 ssh key 来解决本地和服务器的连接问题。 注: 如果您已经配置过 SSH，可跳过此步骤 步骤: 1、首先打开电脑文件夹，找到 C:\\Users\\您的用户名\\ .ssh文件夹并删除(如果没有，则直接进入第二步) 2、在 C:\\Users\\您的用户名 文件夹下右键打开 Git Bash Here 输入命令: ssh-keygen -t rsa -C “你的github登录邮箱” 生成.ssh秘钥，输入后连敲三次回车，出现下图情况代表成功 3、生成了一个新的 C:\\Users\\您的用户名\\ .ssh文件夹，打开这个文件夹，找到 .ssh\\id_rsa.pub 文件，记事本打开并复制里面的内容 4、打开您的 github 主页，进入个人设置 -&gt; SSH and GPG keys -&gt; New SSH key，把复制的内容粘贴进去，title 随便填，保存即可，我们的公钥就添加成功了，设置好如下图: 5、检测是否设置成功: 输入命令: ssh -T git@github.com 看到以上信息说明 SSH 已配置成功! 如果出现提示则选择yes知道成功； 6、此外您还需要如下配置: 命令: git config –global user.name “chai0705 “ 命令: git config –global user.email 1361382269@qq.com 至此，您已经成功配置好了 Github，接下来开始搭建个人博客吧! 第四章 使用 Hexo 搭建博客Hexo 的一些命令生成静态文件：hexo g；清空静态文件：hexo cl；在本地运行：hexo s；部署到网站：hexo d；生成静态文件并部署到网站：hexo d -g 或 hexo g -d；创建新文章：hexo new 。 4.1 初始化1、在电脑的某个磁盘或路径新建一个名为 hexo 的文件夹(名字可以随便取)，比如我的是 D:\\hexo，由于这个文件夹将来就作为您存放代码的地方，所以最好不要随便放 2、在 D:\\hexo 文件夹下右键打开 Git Bash Here，输入命令: hexo init 进行初始化 hexo 会自动下载一些文件到这个目录，包括 node_modules，目录结构如下图: 3、执行命令: hexo g 会在 public 文件夹下生成相关的 html 文件，这些文件将来需要提交到 Github 上 4、执行命令: hexo s 可以开启本地预览服务，打开浏览器访问 http://localhost:4000 即可看到博客内容 4.2 将博客部署到 Github1、在 D:\\hexo 目录下安装 hexo-deployer-git 插件 命令: npm install hexo-deployer-git –save2、编辑 D:\\hexo 目录下的 _config.yml 文件，在文件末尾添加如下内容: 注意: 其中 repository 中的内容即为 github 个人主页链接地址 3、在 D:\\hexo 目录下，输入命令: hexo d 将本地 blog 推送到 github 远程仓库，也可能需要输入 username &amp; pwd 推送成功后，即可通过https://baizhouhaoyue.github.io/访问个人博客了 ! CLASH 1 文章的分类和标签 第5章 hexo进阶5.1 分类和标签分类的话就是在最上方的状态栏中加入 categories: 属性即可 标签的话就是在最上方的状态栏中加入 tags: 属性即可 5.2图床搭建教程根据这个教程来即可 图床 踩坑 picgo这个软件双击并不是直接打开，而是到了右下角的小菜单。。。 然后在typora软件中进行简单的设置即可。如下所示： 至此就搞完了，其他目前也没啥需求，继续学习C++","link":"/2023/09/03/0%20windows%E6%90%AD%E5%BB%BAhexo/"},{"title":"markdown语法学习","text":"MarkDown是什么Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档。 Markdown 语言在 2004 由约翰·格鲁伯（英语：John Gruber）创建。 Markdown 编写的文档可以导出 HTML 、Word、图像、PDF、Epub 等多种格式的文档。 Markdown 编写的文档后缀为 .md, .markdown。 1.如何自动生成目录点击【视图】——【大纲】 说明：但是此步骤生成的目录，并不是折叠的目录，折叠起来会更美观一些 设置折叠目录 点击【文件】——【偏好设置】——【外观】——侧边栏选择打钩，此时已经折叠成功 2.快捷键 Ctrl+1 ——设置一级标题 Ctrl+2 ——设置二级标题 Ctrl+3 ——设置三级标题 Ctrl+4 ——设置四级标题 Ctrl+5 ——设置五级标题 Ctrl+6 ——设置六级标题 空格 ——引用 回车、shift + tab ——退出引用 Ctrl + Shift + ] ——无序列表 Ctrl + Shift + [ ——有序列 Ctrl + Shift + ] 、tab——子列表 Shift + tab ——返回上一级列表、 Ctrl + B —— 加粗 Ctrl + T —— 表格 ~ ~ 要删除的内容 ~ ~ ——删除线 3.创建链接格式为[] ()，其中[]内为要展示的内容，()为链接。 4.图片路径管理Typora默认将所有文档的图片都放在一起，但是我们更想每一个文档都有属于自己的一个文件夹，文档中的图片也最好可以自动保存在该文件夹内。解决方法如下： 点击【文件】——【偏好设置】——【图像】——将该界面内容设置如下: 此时，该文档所在文件夹中会自动生成一个img文件，该路径为本文档中的图片路径。 5.划重点–高亮高亮 点击【文件】——【偏好设置】——【Markdown】——高亮处打钩 编辑高亮内容格式如下： == 内容== —— 高亮 == chai== ==cccc== == key== ==内容== cha 重启Typora，此时内容处会变成高亮的效果. 6.导入代码块~~~ ——代码块，点击代码框可选择语言 7.不使用自动拼写检查点击右下角[【Spell Check】勾选【不使用拼写检查】 8设置自动保存其实Typora 对文件修改之后并不能自动保存，解决方法： 点击【文件】——【偏好设置】——【通用】——自动保存处打钩","link":"/2023/09/01/1markdown%E8%AF%AD%E6%B3%95%E5%AD%A6%E4%B9%A0/"}],"tags":[],"categories":[{"name":"学习","slug":"学习","link":"/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"瑞芯微","slug":"瑞芯微","link":"/categories/%E7%91%9E%E8%8A%AF%E5%BE%AE/"},{"name":"网站的搭建","slug":"网站的搭建","link":"/categories/%E7%BD%91%E7%AB%99%E7%9A%84%E6%90%AD%E5%BB%BA/"},{"name":"生活","slug":"生活","link":"/categories/%E7%94%9F%E6%B4%BB/"}],"pages":[{"title":"categories","text":"","link":"/categories/index.html"},{"title":"friends","text":"","link":"/friends/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"Gallery","text":"","link":"/photos/index.html"}]}